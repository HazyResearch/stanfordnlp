2019-03-17 00:04:03,447 2019-03-17 00:04:03: step 1/50000, loss = 0.214167 (316.299 sec/batch), lr: 0.100000
2019-03-17 00:04:56,415 2019-03-17 00:04:56: step 2/50000, loss = 0.401956 (52.897 sec/batch), lr: 0.100000
2019-03-17 00:05:25,701 2019-03-17 00:05:25: step 3/50000, loss = 0.391160 (29.235 sec/batch), lr: 0.100000
2019-03-17 00:05:40,464 2019-03-17 00:05:40: step 4/50000, loss = 0.371408 (14.709 sec/batch), lr: 0.100000
2019-03-17 00:05:44,997 2019-03-17 00:05:44: step 5/50000, loss = 0.286469 (4.493 sec/batch), lr: 0.100000
2019-03-17 00:11:02,139 2019-03-17 00:11:02: step 6/50000, loss = 0.220449 (315.915 sec/batch), lr: 0.100000
2019-03-17 00:11:54,771 2019-03-17 00:11:54: step 7/50000, loss = 0.399098 (52.557 sec/batch), lr: 0.100000
2019-03-17 00:12:24,066 2019-03-17 00:12:24: step 8/50000, loss = 0.388005 (29.107 sec/batch), lr: 0.100000
2019-03-17 00:12:38,534 2019-03-17 00:12:38: step 9/50000, loss = 0.367839 (14.427 sec/batch), lr: 0.100000
2019-03-17 00:12:43,080 2019-03-17 00:12:43: step 10/50000, loss = 0.282565 (4.501 sec/batch), lr: 0.100000
2019-03-17 00:17:58,918 2019-03-17 00:17:58: step 11/50000, loss = 0.219189 (315.057 sec/batch), lr: 0.100000
2019-03-17 00:18:52,290 2019-03-17 00:18:52: step 12/50000, loss = 0.396146 (53.299 sec/batch), lr: 0.100000
2019-03-17 00:19:21,593 2019-03-17 00:19:21: step 13/50000, loss = 0.384460 (29.116 sec/batch), lr: 0.100000
2019-03-17 00:19:36,135 2019-03-17 00:19:36: step 14/50000, loss = 0.363904 (14.489 sec/batch), lr: 0.100000
2019-03-17 00:19:40,552 2019-03-17 00:19:40: step 15/50000, loss = 0.277853 (4.382 sec/batch), lr: 0.100000
2019-03-17 00:24:57,529 2019-03-17 00:24:57: step 16/50000, loss = 0.217772 (316.158 sec/batch), lr: 0.100000
2019-03-17 00:25:50,601 2019-03-17 00:25:50: step 17/50000, loss = 0.393167 (53.000 sec/batch), lr: 0.100000
2019-03-17 00:26:20,009 2019-03-17 00:26:20: step 18/50000, loss = 0.380980 (29.215 sec/batch), lr: 0.100000
2019-03-17 00:26:34,664 2019-03-17 00:26:34: step 19/50000, loss = 0.359957 (14.512 sec/batch), lr: 0.100000
2019-03-17 00:26:39,266 2019-03-17 00:26:39: step 20/50000, loss = 0.273419 (4.568 sec/batch), lr: 0.100000
2019-03-17 00:31:55,822 2019-03-17 00:31:55: step 21/50000, loss = 0.216497 (315.743 sec/batch), lr: 0.100000
2019-03-17 00:32:48,929 2019-03-17 00:32:48: step 22/50000, loss = 0.390034 (52.783 sec/batch), lr: 0.100000
2019-03-17 00:33:18,244 2019-03-17 00:33:18: step 23/50000, loss = 0.377435 (29.260 sec/batch), lr: 0.100000
2019-03-17 00:33:32,849 2019-03-17 00:33:32: step 24/50000, loss = 0.355924 (14.555 sec/batch), lr: 0.100000
2019-03-17 00:33:37,283 2019-03-17 00:33:37: step 25/50000, loss = 0.268919 (4.400 sec/batch), lr: 0.100000
2019-03-17 00:38:53,622 2019-03-17 00:38:53: step 26/50000, loss = 0.215157 (315.518 sec/batch), lr: 0.100000
2019-03-17 00:39:47,164 2019-03-17 00:39:47: step 27/50000, loss = 0.386967 (53.217 sec/batch), lr: 0.100000
2019-03-17 00:40:16,667 2019-03-17 00:40:16: step 28/50000, loss = 0.374066 (29.314 sec/batch), lr: 0.100000
2019-03-17 00:40:31,031 2019-03-17 00:40:31: step 29/50000, loss = 0.352091 (14.311 sec/batch), lr: 0.100000
2019-03-17 00:40:35,382 2019-03-17 00:40:35: step 30/50000, loss = 0.264165 (4.315 sec/batch), lr: 0.100000
2019-03-17 00:45:52,335 2019-03-17 00:45:52: step 31/50000, loss = 0.213598 (316.131 sec/batch), lr: 0.100000
2019-03-17 00:46:45,674 2019-03-17 00:46:45: step 32/50000, loss = 0.383392 (53.267 sec/batch), lr: 0.100000
2019-03-17 00:47:15,170 2019-03-17 00:47:15: step 33/50000, loss = 0.369708 (29.295 sec/batch), lr: 0.100000
2019-03-17 00:47:29,702 2019-03-17 00:47:29: step 34/50000, loss = 0.346403 (14.476 sec/batch), lr: 0.100000
2019-03-17 00:47:34,296 2019-03-17 00:47:34: step 35/50000, loss = 0.258342 (4.569 sec/batch), lr: 0.100000
2019-03-17 00:52:51,425 2019-03-17 00:52:51: step 36/50000, loss = 0.211449 (315.925 sec/batch), lr: 0.100000
2019-03-17 00:53:44,437 2019-03-17 00:53:44: step 37/50000, loss = 0.378484 (52.941 sec/batch), lr: 0.100000
2019-03-17 00:54:13,984 2019-03-17 00:54:13: step 38/50000, loss = 0.364384 (29.343 sec/batch), lr: 0.100000
2019-03-17 00:54:28,483 2019-03-17 00:54:28: step 39/50000, loss = 0.339839 (14.444 sec/batch), lr: 0.100000
2019-03-17 00:54:32,988 2019-03-17 00:54:32: step 40/50000, loss = 0.249754 (4.481 sec/batch), lr: 0.100000
2019-03-17 00:59:49,886 2019-03-17 00:59:49: step 41/50000, loss = 0.208767 (316.073 sec/batch), lr: 0.100000
2019-03-17 01:00:43,027 2019-03-17 01:00:43: step 42/50000, loss = 0.372153 (52.822 sec/batch), lr: 0.100000
2019-03-17 01:01:12,628 2019-03-17 01:01:12: step 43/50000, loss = 0.356059 (29.408 sec/batch), lr: 0.100000
2019-03-17 01:01:27,035 2019-03-17 01:01:27: step 44/50000, loss = 0.329721 (14.353 sec/batch), lr: 0.100000
2019-03-17 01:01:31,537 2019-03-17 01:01:31: step 45/50000, loss = 0.237572 (4.465 sec/batch), lr: 0.100000
2019-03-17 01:06:48,409 2019-03-17 01:06:48: step 46/50000, loss = 0.204401 (316.055 sec/batch), lr: 0.100000
2019-03-17 01:07:41,557 2019-03-17 01:07:41: step 47/50000, loss = 0.361602 (52.832 sec/batch), lr: 0.100000
2019-03-17 01:08:10,957 2019-03-17 01:08:10: step 48/50000, loss = 0.343199 (29.211 sec/batch), lr: 0.100000
2019-03-17 01:08:25,528 2019-03-17 01:08:25: step 49/50000, loss = 0.312525 (14.519 sec/batch), lr: 0.100000
2019-03-17 01:08:30,142 2019-03-17 01:08:30: step 50/50000, loss = 0.215127 (4.580 sec/batch), lr: 0.100000
2019-03-17 01:13:46,874 2019-03-17 01:13:46: step 51/50000, loss = 0.196543 (315.911 sec/batch), lr: 0.100000
2019-03-17 01:14:39,447 2019-03-17 01:14:39: step 52/50000, loss = 0.342226 (52.247 sec/batch), lr: 0.100000
2019-03-17 01:15:08,658 2019-03-17 01:15:08: step 53/50000, loss = 0.317512 (29.023 sec/batch), lr: 0.100000
2019-03-17 01:15:23,057 2019-03-17 01:15:23: step 54/50000, loss = 0.279209 (14.348 sec/batch), lr: 0.100000
2019-03-17 01:15:27,573 2019-03-17 01:15:27: step 55/50000, loss = 0.172200 (4.479 sec/batch), lr: 0.100000
2019-03-17 01:20:41,745 2019-03-17 01:20:41: step 56/50000, loss = 0.181271 (313.368 sec/batch), lr: 0.100000
2019-03-17 01:21:34,931 2019-03-17 01:21:34: step 57/50000, loss = 0.298409 (52.854 sec/batch), lr: 0.100000
2019-03-17 01:22:04,293 2019-03-17 01:22:04: step 58/50000, loss = 0.261716 (29.308 sec/batch), lr: 0.100000
2019-03-17 01:22:18,912 2019-03-17 01:22:18: step 59/50000, loss = 0.213504 (14.565 sec/batch), lr: 0.100000
2019-03-17 01:22:23,489 2019-03-17 01:22:23: step 60/50000, loss = 0.132334 (4.544 sec/batch), lr: 0.100000
2019-03-17 01:27:38,718 2019-03-17 01:27:38: step 61/50000, loss = 0.155841 (314.412 sec/batch), lr: 0.100000
2019-03-17 01:28:31,594 2019-03-17 01:28:31: step 62/50000, loss = 0.237340 (52.805 sec/batch), lr: 0.100000
2019-03-17 01:29:00,905 2019-03-17 01:29:00: step 63/50000, loss = 0.192292 (29.257 sec/batch), lr: 0.100000
2019-03-17 01:29:15,472 2019-03-17 01:29:15: step 64/50000, loss = 0.184748 (14.515 sec/batch), lr: 0.100000
2019-03-17 01:29:19,933 2019-03-17 01:29:19: step 65/50000, loss = 0.150034 (4.429 sec/batch), lr: 0.100000
2019-03-17 01:34:34,854 2019-03-17 01:34:34: step 66/50000, loss = 0.146133 (314.128 sec/batch), lr: 0.100000
2019-03-17 01:35:28,628 2019-03-17 01:35:28: step 67/50000, loss = 0.213781 (53.369 sec/batch), lr: 0.100000
2019-03-17 01:35:58,044 2019-03-17 01:35:58: step 68/50000, loss = 0.184869 (29.363 sec/batch), lr: 0.100000
2019-03-17 01:36:12,539 2019-03-17 01:36:12: step 69/50000, loss = 0.172279 (14.440 sec/batch), lr: 0.100000
2019-03-17 01:36:17,076 2019-03-17 01:36:17: step 70/50000, loss = 0.201948 (4.492 sec/batch), lr: 0.100000
2019-03-17 01:41:33,048 2019-03-17 01:41:33: step 71/50000, loss = 0.134896 (315.158 sec/batch), lr: 0.100000
2019-03-17 01:42:26,129 2019-03-17 01:42:26: step 72/50000, loss = 0.197007 (52.772 sec/batch), lr: 0.100000
2019-03-17 01:42:55,003 2019-03-17 01:42:55: step 73/50000, loss = 0.221449 (28.821 sec/batch), lr: 0.100000
2019-03-17 01:43:09,287 2019-03-17 01:43:09: step 74/50000, loss = 0.178726 (14.234 sec/batch), lr: 0.100000
2019-03-17 01:43:13,689 2019-03-17 01:43:13: step 75/50000, loss = 0.142370 (4.360 sec/batch), lr: 0.100000
2019-03-17 01:48:25,304 2019-03-17 01:48:25: step 76/50000, loss = 0.149531 (310.805 sec/batch), lr: 0.100000
2019-03-17 01:49:18,123 2019-03-17 01:49:18: step 77/50000, loss = 0.219801 (52.501 sec/batch), lr: 0.100000
2019-03-17 01:49:47,035 2019-03-17 01:49:47: step 78/50000, loss = 0.183649 (28.726 sec/batch), lr: 0.100000
2019-03-17 01:50:01,597 2019-03-17 01:50:01: step 79/50000, loss = 0.183321 (14.476 sec/batch), lr: 0.100000
2019-03-17 01:50:06,060 2019-03-17 01:50:06: step 80/50000, loss = 0.145062 (4.426 sec/batch), lr: 0.100000
2019-03-17 01:55:18,598 2019-03-17 01:55:18: step 81/50000, loss = 0.147482 (311.723 sec/batch), lr: 0.100000
2019-03-17 01:56:11,381 2019-03-17 01:56:11: step 82/50000, loss = 0.215444 (52.645 sec/batch), lr: 0.100000
2019-03-17 01:56:40,398 2019-03-17 01:56:40: step 83/50000, loss = 0.183887 (28.830 sec/batch), lr: 0.100000
2019-03-17 01:56:54,713 2019-03-17 01:56:54: step 84/50000, loss = 0.172400 (14.204 sec/batch), lr: 0.100000
2019-03-17 01:56:59,031 2019-03-17 01:56:59: step 85/50000, loss = 0.199940 (4.283 sec/batch), lr: 0.100000
2019-03-17 02:02:11,523 2019-03-17 02:02:11: step 86/50000, loss = 0.135491 (311.712 sec/batch), lr: 0.100000
2019-03-17 02:03:03,947 2019-03-17 02:03:03: step 87/50000, loss = 0.196516 (52.351 sec/batch), lr: 0.100000
2019-03-17 02:03:33,461 2019-03-17 02:03:33: step 88/50000, loss = 0.220981 (29.461 sec/batch), lr: 0.100000
2019-03-17 02:03:47,831 2019-03-17 02:03:47: step 89/50000, loss = 0.176953 (14.318 sec/batch), lr: 0.100000
2019-03-17 02:03:52,362 2019-03-17 02:03:52: step 90/50000, loss = 0.142472 (4.493 sec/batch), lr: 0.100000
2019-03-17 02:09:04,388 2019-03-17 02:09:04: step 91/50000, loss = 0.150322 (311.223 sec/batch), lr: 0.100000
2019-03-17 02:09:56,410 2019-03-17 02:09:56: step 92/50000, loss = 0.220502 (51.718 sec/batch), lr: 0.100000
2019-03-17 02:10:25,444 2019-03-17 02:10:25: step 93/50000, loss = 0.182452 (28.981 sec/batch), lr: 0.100000
2019-03-17 02:10:39,854 2019-03-17 02:10:39: step 94/50000, loss = 0.221960 (14.357 sec/batch), lr: 0.100000
2019-03-17 02:10:44,404 2019-03-17 02:10:44: step 95/50000, loss = 0.163898 (4.519 sec/batch), lr: 0.100000
2019-03-17 02:15:57,479 2019-03-17 02:15:57: step 96/50000, loss = 0.142210 (311.924 sec/batch), lr: 0.100000
2019-03-17 02:16:49,653 2019-03-17 02:16:49: step 97/50000, loss = 0.204473 (52.101 sec/batch), lr: 0.100000
2019-03-17 02:17:18,563 2019-03-17 02:17:18: step 98/50000, loss = 0.196409 (28.856 sec/batch), lr: 0.100000
2019-03-17 02:17:32,883 2019-03-17 02:17:32: step 99/50000, loss = 0.169279 (14.270 sec/batch), lr: 0.100000
2019-03-17 02:17:37,322 2019-03-17 02:17:37: step 100/50000, loss = 0.134586 (4.396 sec/batch), lr: 0.100000
2019-03-17 02:20:14,618 step 100: Full loss = 0.153512, Edge acc. = 0.2221
2019-03-17 02:20:14,619 step 100: Dev acc. = 0.364533
2019-03-17 02:25:26,843 2019-03-17 02:25:26: step 101/50000, loss = 0.154502 (311.440 sec/batch), lr: 0.100000
2019-03-17 02:26:18,970 2019-03-17 02:26:18: step 102/50000, loss = 0.230121 (52.055 sec/batch), lr: 0.100000
2019-03-17 02:26:47,912 2019-03-17 02:26:47: step 103/50000, loss = 0.185355 (28.887 sec/batch), lr: 0.100000
2019-03-17 02:27:02,119 2019-03-17 02:27:02: step 104/50000, loss = 0.207197 (14.155 sec/batch), lr: 0.100000
2019-03-17 02:27:06,572 2019-03-17 02:27:06: step 105/50000, loss = 0.156877 (4.419 sec/batch), lr: 0.100000
2019-03-17 02:32:19,431 2019-03-17 02:32:19: step 106/50000, loss = 0.144592 (312.052 sec/batch), lr: 0.100000
2019-03-17 02:33:11,904 2019-03-17 02:33:11: step 107/50000, loss = 0.206753 (52.400 sec/batch), lr: 0.100000
2019-03-17 02:33:40,860 2019-03-17 02:33:40: step 108/50000, loss = 0.190415 (28.775 sec/batch), lr: 0.100000
2019-03-17 02:33:55,191 2019-03-17 02:33:55: step 109/50000, loss = 0.169430 (14.232 sec/batch), lr: 0.100000
2019-03-17 02:33:59,523 2019-03-17 02:33:59: step 110/50000, loss = 0.140186 (4.288 sec/batch), lr: 0.100000
2019-03-17 02:39:12,449 2019-03-17 02:39:12: step 111/50000, loss = 0.150159 (312.085 sec/batch), lr: 0.100000
2019-03-17 02:40:04,934 2019-03-17 02:40:04: step 112/50000, loss = 0.219452 (52.413 sec/batch), lr: 0.100000
2019-03-17 02:40:33,953 2019-03-17 02:40:33: step 113/50000, loss = 0.182221 (28.966 sec/batch), lr: 0.100000
2019-03-17 02:40:48,070 2019-03-17 02:40:48: step 114/50000, loss = 0.174839 (14.005 sec/batch), lr: 0.100000
2019-03-17 02:40:52,360 2019-03-17 02:40:52: step 115/50000, loss = 0.137760 (4.257 sec/batch), lr: 0.100000
2019-03-17 02:46:04,603 2019-03-17 02:46:04: step 116/50000, loss = 0.151910 (311.435 sec/batch), lr: 0.100000
2019-03-17 02:46:57,329 2019-03-17 02:46:57: step 117/50000, loss = 0.224291 (52.655 sec/batch), lr: 0.100000
2019-03-17 02:47:26,346 2019-03-17 02:47:26: step 118/50000, loss = 0.181884 (28.821 sec/batch), lr: 0.100000
2019-03-17 02:47:40,444 2019-03-17 02:47:40: step 119/50000, loss = 0.229336 (14.045 sec/batch), lr: 0.100000
2019-03-17 02:47:44,887 2019-03-17 02:47:44: step 120/50000, loss = 0.166998 (4.416 sec/batch), lr: 0.100000
2019-03-17 02:52:57,547 2019-03-17 02:52:57: step 121/50000, loss = 0.142151 (311.848 sec/batch), lr: 0.100000
2019-03-17 02:53:50,327 2019-03-17 02:53:50: step 122/50000, loss = 0.202229 (52.456 sec/batch), lr: 0.100000
2019-03-17 02:54:19,382 2019-03-17 02:54:19: step 123/50000, loss = 0.197957 (29.002 sec/batch), lr: 0.100000
2019-03-17 02:54:33,630 2019-03-17 02:54:33: step 124/50000, loss = 0.170719 (14.194 sec/batch), lr: 0.100000
2019-03-17 02:54:38,050 2019-03-17 02:54:38: step 125/50000, loss = 0.133406 (4.384 sec/batch), lr: 0.100000
2019-03-17 02:59:50,844 2019-03-17 02:59:50: step 126/50000, loss = 0.154498 (311.707 sec/batch), lr: 0.100000
2019-03-17 03:00:43,470 2019-03-17 03:00:43: step 127/50000, loss = 0.229455 (52.307 sec/batch), lr: 0.100000
2019-03-17 03:01:12,664 2019-03-17 03:01:12: step 128/50000, loss = 0.183493 (28.995 sec/batch), lr: 0.100000
2019-03-17 03:01:27,020 2019-03-17 03:01:27: step 129/50000, loss = 0.215697 (14.302 sec/batch), lr: 0.100000
2019-03-17 03:01:31,429 2019-03-17 03:01:31: step 130/50000, loss = 0.158983 (4.372 sec/batch), lr: 0.100000
2019-03-17 03:06:43,773 2019-03-17 03:06:43: step 131/50000, loss = 0.143947 (311.556 sec/batch), lr: 0.100000
2019-03-17 03:07:36,100 2019-03-17 03:07:36: step 132/50000, loss = 0.205832 (52.009 sec/batch), lr: 0.100000
2019-03-17 03:08:04,884 2019-03-17 03:08:04: step 133/50000, loss = 0.192735 (28.730 sec/batch), lr: 0.100000
2019-03-17 03:08:19,246 2019-03-17 03:08:19: step 134/50000, loss = 0.168584 (14.310 sec/batch), lr: 0.100000
2019-03-17 03:08:23,602 2019-03-17 03:08:23: step 135/50000, loss = 0.136846 (4.319 sec/batch), lr: 0.100000
2019-03-17 03:13:35,596 2019-03-17 03:13:35: step 136/50000, loss = 0.150704 (311.202 sec/batch), lr: 0.100000
2019-03-17 03:14:28,362 2019-03-17 03:14:28: step 137/50000, loss = 0.220043 (52.441 sec/batch), lr: 0.100000
2019-03-17 03:14:57,093 2019-03-17 03:14:57: step 138/50000, loss = 0.181919 (28.655 sec/batch), lr: 0.100000
2019-03-17 03:15:11,488 2019-03-17 03:15:11: step 139/50000, loss = 0.168308 (14.343 sec/batch), lr: 0.100000
2019-03-17 03:15:15,851 2019-03-17 03:15:15: step 140/50000, loss = 0.133054 (4.318 sec/batch), lr: 0.100000
2019-03-17 03:20:28,576 2019-03-17 03:20:28: step 141/50000, loss = 0.154847 (311.877 sec/batch), lr: 0.100000
2019-03-17 03:21:21,107 2019-03-17 03:21:21: step 142/50000, loss = 0.230599 (52.208 sec/batch), lr: 0.100000
2019-03-17 03:21:50,103 2019-03-17 03:21:50: step 143/50000, loss = 0.183179 (28.800 sec/batch), lr: 0.100000
2019-03-17 03:22:04,418 2019-03-17 03:22:04: step 144/50000, loss = 0.211584 (14.202 sec/batch), lr: 0.100000
2019-03-17 03:22:08,824 2019-03-17 03:22:08: step 145/50000, loss = 0.155541 (4.361 sec/batch), lr: 0.100000
2019-03-17 03:27:20,758 2019-03-17 03:27:20: step 146/50000, loss = 0.144752 (311.815 sec/batch), lr: 0.100000
2019-03-17 03:28:12,931 2019-03-17 03:28:12: step 147/50000, loss = 0.205383 (51.853 sec/batch), lr: 0.100000
2019-03-17 03:28:41,831 2019-03-17 03:28:41: step 148/50000, loss = 0.191094 (28.707 sec/batch), lr: 0.100000
2019-03-17 03:28:55,986 2019-03-17 03:28:55: step 149/50000, loss = 0.167927 (14.116 sec/batch), lr: 0.100000
2019-03-17 03:29:00,435 2019-03-17 03:29:00: step 150/50000, loss = 0.154545 (4.405 sec/batch), lr: 0.100000
2019-03-17 03:34:11,439 2019-03-17 03:34:11: step 151/50000, loss = 0.145872 (310.191 sec/batch), lr: 0.100000
2019-03-17 03:35:03,913 2019-03-17 03:35:03: step 152/50000, loss = 0.207922 (52.401 sec/batch), lr: 0.100000
2019-03-17 03:35:32,780 2019-03-17 03:35:32: step 153/50000, loss = 0.187821 (28.675 sec/batch), lr: 0.100000
2019-03-17 03:35:46,899 2019-03-17 03:35:46: step 154/50000, loss = 0.167877 (14.066 sec/batch), lr: 0.100000
2019-03-17 03:35:51,282 2019-03-17 03:35:51: step 155/50000, loss = 0.177224 (4.348 sec/batch), lr: 0.100000
2019-03-17 03:41:01,787 2019-03-17 03:41:01: step 156/50000, loss = 0.140541 (309.373 sec/batch), lr: 0.100000
2019-03-17 03:41:53,784 2019-03-17 03:41:53: step 157/50000, loss = 0.197387 (51.688 sec/batch), lr: 0.100000
2019-03-17 03:42:22,448 2019-03-17 03:42:22: step 158/50000, loss = 0.213969 (28.612 sec/batch), lr: 0.100000
2019-03-17 03:42:36,718 2019-03-17 03:42:36: step 159/50000, loss = 0.171013 (14.185 sec/batch), lr: 0.100000
2019-03-17 03:42:41,221 2019-03-17 03:42:41: step 160/50000, loss = 0.133041 (4.470 sec/batch), lr: 0.100000
2019-03-17 03:47:49,217 2019-03-17 03:47:49: step 161/50000, loss = 0.154809 (307.867 sec/batch), lr: 0.100000
2019-03-17 03:48:41,082 2019-03-17 03:48:41: step 162/50000, loss = 0.227705 (51.796 sec/batch), lr: 0.100000
2019-03-17 03:49:09,735 2019-03-17 03:49:09: step 163/50000, loss = 0.181883 (28.472 sec/batch), lr: 0.100000
2019-03-17 03:49:23,920 2019-03-17 03:49:23: step 164/50000, loss = 0.243335 (14.133 sec/batch), lr: 0.100000
2019-03-17 03:49:28,432 2019-03-17 03:49:28: step 165/50000, loss = 0.161495 (4.481 sec/batch), lr: 0.100000
2019-03-17 03:54:35,249 2019-03-17 03:54:35: step 166/50000, loss = 0.144745 (306.075 sec/batch), lr: 0.100000
2019-03-17 03:55:26,574 2019-03-17 03:55:26: step 167/50000, loss = 0.204265 (51.256 sec/batch), lr: 0.100000
2019-03-17 03:55:55,077 2019-03-17 03:55:55: step 168/50000, loss = 0.199794 (28.319 sec/batch), lr: 0.100000
2019-03-17 03:56:09,212 2019-03-17 03:56:09: step 169/50000, loss = 0.168534 (14.030 sec/batch), lr: 0.100000
2019-03-17 03:56:13,663 2019-03-17 03:56:13: step 170/50000, loss = 0.133337 (4.411 sec/batch), lr: 0.100000
2019-03-17 04:01:20,134 2019-03-17 04:01:20: step 171/50000, loss = 0.153652 (305.733 sec/batch), lr: 0.100000
2019-03-17 04:02:12,576 2019-03-17 04:02:12: step 172/50000, loss = 0.221954 (52.372 sec/batch), lr: 0.100000
2019-03-17 04:02:41,043 2019-03-17 04:02:41: step 173/50000, loss = 0.181399 (28.289 sec/batch), lr: 0.100000
2019-03-17 04:02:55,182 2019-03-17 04:02:55: step 174/50000, loss = 0.169110 (14.088 sec/batch), lr: 0.100000
2019-03-17 04:02:59,502 2019-03-17 04:02:59: step 175/50000, loss = 0.206724 (4.277 sec/batch), lr: 0.100000
2019-03-17 04:08:05,898 2019-03-17 04:08:05: step 176/50000, loss = 0.136244 (306.264 sec/batch), lr: 0.100000
2019-03-17 04:08:56,823 2019-03-17 04:08:56: step 177/50000, loss = 0.191210 (50.858 sec/batch), lr: 0.100000
2019-03-17 04:09:25,195 2019-03-17 04:09:25: step 178/50000, loss = 0.275931 (28.320 sec/batch), lr: 0.100000
2019-03-17 04:09:39,116 2019-03-17 04:09:39: step 179/50000, loss = 0.175949 (13.882 sec/batch), lr: 0.100000
2019-03-17 04:09:43,422 2019-03-17 04:09:43: step 180/50000, loss = 0.132554 (4.273 sec/batch), lr: 0.100000
2019-03-17 04:14:49,579 2019-03-17 04:14:49: step 181/50000, loss = 0.155892 (306.037 sec/batch), lr: 0.100000
2019-03-17 04:15:40,572 2019-03-17 04:15:40: step 182/50000, loss = 0.226411 (50.927 sec/batch), lr: 0.100000
2019-03-17 04:16:09,010 2019-03-17 04:16:09: step 183/50000, loss = 0.180924 (28.268 sec/batch), lr: 0.100000
2019-03-17 04:16:23,196 2019-03-17 04:16:23: step 184/50000, loss = 0.167439 (14.079 sec/batch), lr: 0.100000
2019-03-17 04:16:27,633 2019-03-17 04:16:27: step 185/50000, loss = 0.131375 (4.405 sec/batch), lr: 0.100000
2019-03-17 04:21:34,295 2019-03-17 04:21:34: step 186/50000, loss = 0.157637 (305.920 sec/batch), lr: 0.100000
2019-03-17 04:22:25,438 2019-03-17 04:22:25: step 187/50000, loss = 0.231850 (50.882 sec/batch), lr: 0.100000
2019-03-17 04:22:53,897 2019-03-17 04:22:53: step 188/50000, loss = 0.182177 (28.291 sec/batch), lr: 0.100000
2019-03-17 04:23:08,206 2019-03-17 04:23:08: step 189/50000, loss = 0.240737 (14.003 sec/batch), lr: 0.100000
2019-03-17 04:23:12,406 2019-03-17 04:23:12: step 190/50000, loss = 0.152109 (4.168 sec/batch), lr: 0.100000
2019-03-17 04:28:18,849 2019-03-17 04:28:18: step 191/50000, loss = 0.147293 (305.704 sec/batch), lr: 0.100000
2019-03-17 04:29:10,009 2019-03-17 04:29:10: step 192/50000, loss = 0.205277 (51.087 sec/batch), lr: 0.100000
2019-03-17 04:29:38,350 2019-03-17 04:29:38: step 193/50000, loss = 0.203951 (28.177 sec/batch), lr: 0.100000
2019-03-17 04:29:52,159 2019-03-17 04:29:52: step 194/50000, loss = 0.167203 (13.771 sec/batch), lr: 0.100000
2019-03-17 04:29:56,452 2019-03-17 04:29:56: step 195/50000, loss = 0.253935 (4.259 sec/batch), lr: 0.100000
2019-03-17 04:35:02,933 2019-03-17 04:35:02: step 196/50000, loss = 0.134399 (305.764 sec/batch), lr: 0.100000
2019-03-17 04:35:54,765 2019-03-17 04:35:54: step 197/50000, loss = 0.192596 (51.764 sec/batch), lr: 0.100000
2019-03-17 04:36:23,216 2019-03-17 04:36:23: step 198/50000, loss = 0.193805 (28.303 sec/batch), lr: 0.100000
2019-03-17 04:36:37,143 2019-03-17 04:36:37: step 199/50000, loss = 0.199807 (13.823 sec/batch), lr: 0.100000
2019-03-17 04:36:41,559 2019-03-17 04:36:41: step 200/50000, loss = 0.136864 (4.375 sec/batch), lr: 0.100000
2019-03-17 04:39:16,411 step 200: Full loss = 0.152949, Edge acc. = 0.2244
2019-03-17 04:39:16,412 step 200: Dev acc. = 0.370821
2019-03-17 04:44:22,812 2019-03-17 04:44:22: step 201/50000, loss = 0.154017 (305.683 sec/batch), lr: 0.100000
2019-03-17 04:45:13,875 2019-03-17 04:45:13: step 202/50000, loss = 0.217768 (50.996 sec/batch), lr: 0.100000
2019-03-17 04:45:42,262 2019-03-17 04:45:42: step 203/50000, loss = 0.189719 (28.337 sec/batch), lr: 0.100000
2019-03-17 04:45:56,233 2019-03-17 04:45:56: step 204/50000, loss = 0.171412 (13.934 sec/batch), lr: 0.100000
2019-03-17 04:46:00,725 2019-03-17 04:46:00: step 205/50000, loss = 0.219975 (4.452 sec/batch), lr: 0.100000
2019-03-17 04:51:06,996 2019-03-17 04:51:06: step 206/50000, loss = 0.139047 (306.152 sec/batch), lr: 0.100000
2019-03-17 04:51:57,993 2019-03-17 04:51:57: step 207/50000, loss = 0.193371 (50.930 sec/batch), lr: 0.100000
2019-03-17 04:52:26,502 2019-03-17 04:52:26: step 208/50000, loss = 0.222005 (28.332 sec/batch), lr: 0.100000
2019-03-17 04:52:40,480 2019-03-17 04:52:40: step 209/50000, loss = 0.169191 (13.928 sec/batch), lr: 0.100000
2019-03-17 04:52:44,747 2019-03-17 04:52:44: step 210/50000, loss = 0.276217 (4.242 sec/batch), lr: 0.100000
2019-03-17 04:57:50,872 2019-03-17 04:57:50: step 211/50000, loss = 0.138441 (305.407 sec/batch), lr: 0.100000
2019-03-17 04:58:42,154 2019-03-17 04:58:42: step 212/50000, loss = 0.200366 (50.983 sec/batch), lr: 0.100000
2019-03-17 04:59:10,585 2019-03-17 04:59:10: step 213/50000, loss = 0.348571 (28.257 sec/batch), lr: 0.100000
2019-03-17 04:59:24,728 2019-03-17 04:59:24: step 214/50000, loss = 0.172149 (14.094 sec/batch), lr: 0.100000
2019-03-17 04:59:29,042 2019-03-17 04:59:29: step 215/50000, loss = 0.129226 (4.273 sec/batch), lr: 0.100000
2019-03-17 05:04:35,289 2019-03-17 05:04:35: step 216/50000, loss = 0.145840 (305.505 sec/batch), lr: 0.100000
2019-03-17 05:05:26,739 2019-03-17 05:05:26: step 217/50000, loss = 0.200271 (51.144 sec/batch), lr: 0.100000
2019-03-17 05:05:55,487 2019-03-17 05:05:55: step 218/50000, loss = 0.208959 (28.697 sec/batch), lr: 0.100000
2019-03-17 05:06:09,541 2019-03-17 05:06:09: step 219/50000, loss = 0.199335 (13.948 sec/batch), lr: 0.100000
2019-03-17 05:06:13,851 2019-03-17 05:06:13: step 220/50000, loss = 0.130947 (4.277 sec/batch), lr: 0.100000
2019-03-17 05:11:21,117 2019-03-17 05:11:21: step 221/50000, loss = 0.162962 (306.525 sec/batch), lr: 0.100000
2019-03-17 05:12:12,288 2019-03-17 05:12:12: step 222/50000, loss = 0.232465 (50.869 sec/batch), lr: 0.100000
2019-03-17 05:12:40,781 2019-03-17 05:12:40: step 223/50000, loss = 0.193994 (28.343 sec/batch), lr: 0.100000
2019-03-17 05:12:54,904 2019-03-17 05:12:54: step 224/50000, loss = 0.179070 (14.018 sec/batch), lr: 0.100000
2019-03-17 05:12:59,187 2019-03-17 05:12:59: step 225/50000, loss = 0.211883 (4.253 sec/batch), lr: 0.100000
2019-03-17 05:18:05,770 2019-03-17 05:18:05: step 226/50000, loss = 0.146809 (306.460 sec/batch), lr: 0.100000
2019-03-17 05:18:56,784 2019-03-17 05:18:56: step 227/50000, loss = 0.200643 (50.947 sec/batch), lr: 0.100000
2019-03-17 05:19:25,162 2019-03-17 05:19:25: step 228/50000, loss = 0.210912 (28.204 sec/batch), lr: 0.100000
2019-03-17 05:19:39,327 2019-03-17 05:19:39: step 229/50000, loss = 0.193818 (14.116 sec/batch), lr: 0.100000
2019-03-17 05:19:43,568 2019-03-17 05:19:43: step 230/50000, loss = 0.127950 (4.213 sec/batch), lr: 0.100000
2019-03-17 05:24:49,893 2019-03-17 05:24:49: step 231/50000, loss = 0.160773 (306.234 sec/batch), lr: 0.100000
2019-03-17 05:25:40,885 2019-03-17 05:25:40: step 232/50000, loss = 0.224446 (50.927 sec/batch), lr: 0.100000
2019-03-17 05:26:09,342 2019-03-17 05:26:09: step 233/50000, loss = 0.213754 (28.282 sec/batch), lr: 0.100000
2019-03-17 05:26:23,503 2019-03-17 05:26:23: step 234/50000, loss = 0.177789 (14.112 sec/batch), lr: 0.100000
2019-03-17 05:26:27,943 2019-03-17 05:26:27: step 235/50000, loss = 0.229884 (4.401 sec/batch), lr: 0.100000
2019-03-17 05:31:34,013 2019-03-17 05:31:34: step 236/50000, loss = 0.146343 (305.326 sec/batch), lr: 0.100000
2019-03-17 05:32:25,078 2019-03-17 05:32:25: step 237/50000, loss = 0.207388 (50.998 sec/batch), lr: 0.100000
2019-03-17 05:32:53,412 2019-03-17 05:32:53: step 238/50000, loss = 0.210897 (28.164 sec/batch), lr: 0.100000
2019-03-17 05:33:07,416 2019-03-17 05:33:07: step 239/50000, loss = 0.208074 (13.955 sec/batch), lr: 0.100000
2019-03-17 05:33:11,702 2019-03-17 05:33:11: step 240/50000, loss = 0.130182 (4.257 sec/batch), lr: 0.100000
2019-03-17 05:38:17,701 2019-03-17 05:38:17: step 241/50000, loss = 0.163427 (305.872 sec/batch), lr: 0.100000
2019-03-17 05:39:13,611 2019-03-17 05:39:13: step 242/50000, loss = 0.229243 (55.617 sec/batch), lr: 0.100000
2019-03-17 05:39:42,106 2019-03-17 05:39:42: step 243/50000, loss = 0.218867 (28.439 sec/batch), lr: 0.100000
2019-03-17 05:39:56,218 2019-03-17 05:39:56: step 244/50000, loss = 0.179575 (14.064 sec/batch), lr: 0.100000
2019-03-17 05:40:00,545 2019-03-17 05:40:00: step 245/50000, loss = 0.230753 (4.289 sec/batch), lr: 0.100000
2019-03-17 05:45:07,010 2019-03-17 05:45:07: step 246/50000, loss = 0.148774 (305.726 sec/batch), lr: 0.100000
2019-03-17 05:45:58,213 2019-03-17 05:45:58: step 247/50000, loss = 0.218583 (51.135 sec/batch), lr: 0.100000
2019-03-17 05:46:26,660 2019-03-17 05:46:26: step 248/50000, loss = 0.214701 (28.376 sec/batch), lr: 0.100000
2019-03-17 05:46:40,816 2019-03-17 05:46:40: step 249/50000, loss = 0.216511 (14.106 sec/batch), lr: 0.100000
2019-03-17 05:46:45,238 2019-03-17 05:46:45: step 250/50000, loss = 0.128925 (4.383 sec/batch), lr: 0.100000
2019-03-17 05:51:52,023 2019-03-17 05:51:52: step 251/50000, loss = 0.160622 (305.722 sec/batch), lr: 0.100000
2019-03-17 05:52:43,722 2019-03-17 05:52:43: step 252/50000, loss = 0.216896 (51.631 sec/batch), lr: 0.100000
2019-03-17 05:53:12,118 2019-03-17 05:53:12: step 253/50000, loss = 0.298103 (28.217 sec/batch), lr: 0.100000
2019-03-17 05:53:26,073 2019-03-17 05:53:26: step 254/50000, loss = 0.176656 (13.905 sec/batch), lr: 0.100000
2019-03-17 05:53:30,575 2019-03-17 05:53:30: step 255/50000, loss = 0.296472 (4.464 sec/batch), lr: 0.100000
2019-03-17 05:58:36,858 2019-03-17 05:58:36: step 256/50000, loss = 0.147698 (306.156 sec/batch), lr: 0.100000
2019-03-17 05:59:28,750 2019-03-17 05:59:28: step 257/50000, loss = 0.278449 (51.826 sec/batch), lr: 0.100000
2019-03-17 05:59:57,024 2019-03-17 05:59:57: step 258/50000, loss = 0.217233 (28.119 sec/batch), lr: 0.100000
2019-03-17 06:00:11,066 2019-03-17 06:00:11: step 259/50000, loss = 0.275428 (13.936 sec/batch), lr: 0.100000
2019-03-17 06:00:15,547 2019-03-17 06:00:15: step 260/50000, loss = 0.129194 (4.445 sec/batch), lr: 0.100000
2019-03-17 06:05:22,311 2019-03-17 06:05:22: step 261/50000, loss = 0.169977 (306.642 sec/batch), lr: 0.100000
2019-03-17 06:06:14,136 2019-03-17 06:06:14: step 262/50000, loss = 0.233594 (51.758 sec/batch), lr: 0.100000
2019-03-17 06:06:42,640 2019-03-17 06:06:42: step 263/50000, loss = 0.297805 (28.330 sec/batch), lr: 0.100000
2019-03-17 06:06:56,735 2019-03-17 06:06:56: step 264/50000, loss = 0.185641 (14.044 sec/batch), lr: 0.100000
2019-03-17 06:07:01,139 2019-03-17 06:07:01: step 265/50000, loss = 0.273516 (4.375 sec/batch), lr: 0.100000
2019-03-17 06:12:07,422 2019-03-17 06:12:07: step 266/50000, loss = 0.154432 (305.544 sec/batch), lr: 0.100000
2019-03-17 06:12:58,171 2019-03-17 06:12:58: step 267/50000, loss = 0.292014 (50.616 sec/batch), lr: 0.100000
2019-03-17 06:13:26,225 2019-03-17 06:13:26: step 268/50000, loss = 0.223054 (28.005 sec/batch), lr: 0.100000
2019-03-17 06:13:39,998 2019-03-17 06:13:39: step 269/50000, loss = 0.288429 (13.724 sec/batch), lr: 0.100000
2019-03-17 06:13:44,412 2019-03-17 06:13:44: step 270/50000, loss = 0.128966 (4.375 sec/batch), lr: 0.100000
2019-03-17 06:18:46,428 2019-03-17 06:18:46: step 271/50000, loss = 0.172196 (301.892 sec/batch), lr: 0.100000
2019-03-17 06:19:36,924 2019-03-17 06:19:36: step 272/50000, loss = 0.236437 (50.200 sec/batch), lr: 0.100000
2019-03-17 06:20:05,043 2019-03-17 06:20:05: step 273/50000, loss = 0.310347 (27.935 sec/batch), lr: 0.100000
2019-03-17 06:20:18,962 2019-03-17 06:20:18: step 274/50000, loss = 0.194092 (13.870 sec/batch), lr: 0.100000
2019-03-17 06:20:23,365 2019-03-17 06:20:23: step 275/50000, loss = 0.131133 (4.370 sec/batch), lr: 0.100000
2019-03-17 06:25:25,094 2019-03-17 06:25:25: step 276/50000, loss = 0.135545 (300.992 sec/batch), lr: 0.100000
2019-03-17 06:26:15,727 2019-03-17 06:26:15: step 277/50000, loss = 0.249087 (50.336 sec/batch), lr: 0.100000
2019-03-17 06:26:43,844 2019-03-17 06:26:43: step 278/50000, loss = 0.222749 (27.936 sec/batch), lr: 0.100000
2019-03-17 06:26:57,657 2019-03-17 06:26:57: step 279/50000, loss = 0.192074 (13.760 sec/batch), lr: 0.100000
2019-03-17 06:27:01,950 2019-03-17 06:27:01: step 280/50000, loss = 0.215774 (4.263 sec/batch), lr: 0.100000
2019-03-17 06:32:03,967 2019-03-17 06:32:03: step 281/50000, loss = 0.155612 (301.586 sec/batch), lr: 0.100000
2019-03-17 06:32:54,465 2019-03-17 06:32:54: step 282/50000, loss = 0.235789 (50.201 sec/batch), lr: 0.100000
2019-03-17 06:33:22,473 2019-03-17 06:33:22: step 283/50000, loss = 0.225892 (27.838 sec/batch), lr: 0.100000
2019-03-17 06:33:36,367 2019-03-17 06:33:36: step 284/50000, loss = 0.227007 (13.845 sec/batch), lr: 0.100000
2019-03-17 06:33:40,603 2019-03-17 06:33:40: step 285/50000, loss = 0.128685 (4.205 sec/batch), lr: 0.100000
2019-03-17 06:38:42,290 2019-03-17 06:38:42: step 286/50000, loss = 0.144490 (300.947 sec/batch), lr: 0.100000
2019-03-17 06:39:33,245 2019-03-17 06:39:33: step 287/50000, loss = 0.277583 (50.888 sec/batch), lr: 0.100000
2019-03-17 06:40:01,432 2019-03-17 06:40:01: step 288/50000, loss = 0.212118 (28.137 sec/batch), lr: 0.100000
2019-03-17 06:40:15,345 2019-03-17 06:40:15: step 289/50000, loss = 0.276561 (13.864 sec/batch), lr: 0.100000
2019-03-17 06:40:19,764 2019-03-17 06:40:19: step 290/50000, loss = 0.126758 (4.387 sec/batch), lr: 0.100000
2019-03-17 06:45:21,737 2019-03-17 06:45:21: step 291/50000, loss = 0.149376 (301.235 sec/batch), lr: 0.100000
2019-03-17 06:46:12,229 2019-03-17 06:46:12: step 292/50000, loss = 0.256291 (50.425 sec/batch), lr: 0.100000
2019-03-17 06:46:40,164 2019-03-17 06:46:40: step 293/50000, loss = 0.210233 (27.753 sec/batch), lr: 0.100000
2019-03-17 06:46:53,915 2019-03-17 06:46:53: step 294/50000, loss = 0.300389 (13.701 sec/batch), lr: 0.100000
2019-03-17 06:46:58,187 2019-03-17 06:46:58: step 295/50000, loss = 0.126303 (4.243 sec/batch), lr: 0.100000
2019-03-17 06:51:59,923 2019-03-17 06:51:59: step 296/50000, loss = 0.168865 (300.999 sec/batch), lr: 0.100000
2019-03-17 06:52:50,855 2019-03-17 06:52:50: step 297/50000, loss = 0.231776 (50.864 sec/batch), lr: 0.100000
2019-03-17 06:53:18,974 2019-03-17 06:53:18: step 298/50000, loss = 0.301205 (27.945 sec/batch), lr: 0.100000
2019-03-17 06:53:32,944 2019-03-17 06:53:32: step 299/50000, loss = 0.184408 (13.868 sec/batch), lr: 0.100000
2019-03-17 06:53:37,336 2019-03-17 06:53:37: step 300/50000, loss = 0.265909 (4.351 sec/batch), lr: 0.100000
2019-03-17 06:56:09,566 step 300: Full loss = 0.154888, Edge acc. = 0.1679
2019-03-17 06:56:09,568 step 300: Dev acc. = 0.385808
2019-03-17 07:01:13,441 2019-03-17 07:01:13: step 301/50000, loss = 0.154313 (303.699 sec/batch), lr: 0.050000
2019-03-17 07:02:04,236 2019-03-17 07:02:04: step 302/50000, loss = 0.234577 (50.729 sec/batch), lr: 0.050000
2019-03-17 07:02:32,480 2019-03-17 07:02:32: step 303/50000, loss = 0.276773 (28.076 sec/batch), lr: 0.050000
2019-03-17 07:02:46,515 2019-03-17 07:02:46: step 304/50000, loss = 0.191539 (13.932 sec/batch), lr: 0.050000
2019-03-17 07:02:50,955 2019-03-17 07:02:50: step 305/50000, loss = 0.126431 (4.409 sec/batch), lr: 0.050000
2019-03-17 07:07:54,855 2019-03-17 07:07:54: step 306/50000, loss = 0.151746 (303.775 sec/batch), lr: 0.050000
2019-03-17 07:08:45,443 2019-03-17 07:08:45: step 307/50000, loss = 0.227863 (50.523 sec/batch), lr: 0.050000
2019-03-17 07:09:13,640 2019-03-17 07:09:13: step 308/50000, loss = 0.219181 (28.148 sec/batch), lr: 0.050000
2019-03-17 07:09:27,658 2019-03-17 07:09:27: step 309/50000, loss = 0.186455 (13.971 sec/batch), lr: 0.050000
2019-03-17 07:09:32,118 2019-03-17 07:09:32: step 310/50000, loss = 0.126988 (4.419 sec/batch), lr: 0.050000
2019-03-17 07:14:35,502 2019-03-17 07:14:35: step 311/50000, loss = 0.154319 (302.965 sec/batch), lr: 0.050000
2019-03-17 07:15:26,241 2019-03-17 07:15:26: step 312/50000, loss = 0.226420 (50.445 sec/batch), lr: 0.050000
2019-03-17 07:15:54,402 2019-03-17 07:15:54: step 313/50000, loss = 0.214806 (28.110 sec/batch), lr: 0.050000
2019-03-17 07:16:08,391 2019-03-17 07:16:08: step 314/50000, loss = 0.177531 (13.942 sec/batch), lr: 0.050000
2019-03-17 07:16:12,804 2019-03-17 07:16:12: step 315/50000, loss = 0.174024 (4.374 sec/batch), lr: 0.050000
2019-03-17 07:21:16,219 2019-03-17 07:21:16: step 316/50000, loss = 0.138371 (302.680 sec/batch), lr: 0.050000
2019-03-17 07:22:07,095 2019-03-17 07:22:07: step 317/50000, loss = 0.225452 (50.578 sec/batch), lr: 0.050000
2019-03-17 07:22:35,134 2019-03-17 07:22:35: step 318/50000, loss = 0.202120 (27.989 sec/batch), lr: 0.050000
2019-03-17 07:22:49,097 2019-03-17 07:22:49: step 319/50000, loss = 0.199080 (13.915 sec/batch), lr: 0.050000
2019-03-17 07:22:53,372 2019-03-17 07:22:53: step 320/50000, loss = 0.129103 (4.234 sec/batch), lr: 0.050000
2019-03-17 07:27:56,858 2019-03-17 07:27:56: step 321/50000, loss = 0.151574 (302.747 sec/batch), lr: 0.050000
2019-03-17 07:28:47,508 2019-03-17 07:28:47: step 322/50000, loss = 0.220181 (50.583 sec/batch), lr: 0.050000
2019-03-17 07:29:15,731 2019-03-17 07:29:15: step 323/50000, loss = 0.216396 (28.172 sec/batch), lr: 0.050000
2019-03-17 07:29:29,653 2019-03-17 07:29:29: step 324/50000, loss = 0.176243 (13.821 sec/batch), lr: 0.050000
2019-03-17 07:29:34,107 2019-03-17 07:29:34: step 325/50000, loss = 0.177843 (4.423 sec/batch), lr: 0.050000
2019-03-17 07:34:37,377 2019-03-17 07:34:37: step 326/50000, loss = 0.137779 (302.531 sec/batch), lr: 0.050000
2019-03-17 07:35:28,077 2019-03-17 07:35:28: step 327/50000, loss = 0.225476 (50.633 sec/batch), lr: 0.050000
2019-03-17 07:35:33,127 2019-03-17 07:35:33: step 328/50000, loss = 0.000000 (4.998 sec/batch), lr: 0.050000
2019-03-17 07:35:35,881 2019-03-17 07:35:35: step 329/50000, loss = 0.000000 (2.700 sec/batch), lr: 0.050000
2019-03-17 07:35:36,966 2019-03-17 07:35:36: step 330/50000, loss = 0.000000 (1.052 sec/batch), lr: 0.050000
2019-03-17 07:36:46,553 2019-03-17 07:36:46: step 331/50000, loss = 0.000000 (69.461 sec/batch), lr: 0.050000
2019-03-17 07:36:55,277 2019-03-17 07:36:55: step 332/50000, loss = 0.000000 (8.640 sec/batch), lr: 0.050000
2019-03-17 07:37:00,348 2019-03-17 07:37:00: step 333/50000, loss = 0.000000 (5.003 sec/batch), lr: 0.050000
2019-03-17 07:37:03,108 2019-03-17 07:37:03: step 334/50000, loss = 0.000000 (2.703 sec/batch), lr: 0.050000
2019-03-17 07:37:04,206 2019-03-17 07:37:04: step 335/50000, loss = 0.000000 (1.065 sec/batch), lr: 0.050000
2019-03-17 07:38:13,666 2019-03-17 07:38:13: step 336/50000, loss = 0.000000 (69.339 sec/batch), lr: 0.050000
2019-03-17 07:38:22,498 2019-03-17 07:38:22: step 337/50000, loss = 0.000000 (8.747 sec/batch), lr: 0.050000
2019-03-17 07:38:27,740 2019-03-17 07:38:27: step 338/50000, loss = 0.000000 (5.167 sec/batch), lr: 0.050000
2019-03-17 07:38:30,511 2019-03-17 07:38:30: step 339/50000, loss = 0.000000 (2.710 sec/batch), lr: 0.050000
2019-03-17 07:38:31,623 2019-03-17 07:38:31: step 340/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.050000
2019-03-17 07:39:41,415 2019-03-17 07:39:41: step 341/50000, loss = 0.000000 (69.649 sec/batch), lr: 0.050000
2019-03-17 07:39:50,255 2019-03-17 07:39:50: step 342/50000, loss = 0.000000 (8.718 sec/batch), lr: 0.050000
2019-03-17 07:39:55,335 2019-03-17 07:39:55: step 343/50000, loss = 0.000000 (5.030 sec/batch), lr: 0.050000
2019-03-17 07:39:58,192 2019-03-17 07:39:58: step 344/50000, loss = 0.000000 (2.796 sec/batch), lr: 0.050000
2019-03-17 07:39:59,283 2019-03-17 07:39:59: step 345/50000, loss = 0.000000 (1.059 sec/batch), lr: 0.050000
2019-03-17 07:41:08,702 2019-03-17 07:41:08: step 346/50000, loss = 0.000000 (69.284 sec/batch), lr: 0.050000
2019-03-17 07:41:17,430 2019-03-17 07:41:17: step 347/50000, loss = 0.000000 (8.647 sec/batch), lr: 0.050000
2019-03-17 07:41:22,496 2019-03-17 07:41:22: step 348/50000, loss = 0.000000 (4.995 sec/batch), lr: 0.050000
2019-03-17 07:41:25,241 2019-03-17 07:41:25: step 349/50000, loss = 0.000000 (2.691 sec/batch), lr: 0.050000
2019-03-17 07:41:26,327 2019-03-17 07:41:26: step 350/50000, loss = 0.000000 (1.052 sec/batch), lr: 0.050000
2019-03-17 07:42:35,447 2019-03-17 07:42:35: step 351/50000, loss = 0.000000 (69.001 sec/batch), lr: 0.050000
2019-03-17 07:42:44,199 2019-03-17 07:42:44: step 352/50000, loss = 0.000000 (8.671 sec/batch), lr: 0.050000
2019-03-17 07:42:49,400 2019-03-17 07:42:49: step 353/50000, loss = 0.000000 (5.125 sec/batch), lr: 0.050000
2019-03-17 07:42:52,130 2019-03-17 07:42:52: step 354/50000, loss = 0.000000 (2.676 sec/batch), lr: 0.050000
2019-03-17 07:42:53,228 2019-03-17 07:42:53: step 355/50000, loss = 0.000000 (1.064 sec/batch), lr: 0.050000
2019-03-17 07:44:02,504 2019-03-17 07:44:02: step 356/50000, loss = 0.000000 (69.159 sec/batch), lr: 0.050000
2019-03-17 07:44:11,195 2019-03-17 07:44:11: step 357/50000, loss = 0.000000 (8.610 sec/batch), lr: 0.050000
2019-03-17 07:44:16,240 2019-03-17 07:44:16: step 358/50000, loss = 0.000000 (4.978 sec/batch), lr: 0.050000
2019-03-17 07:44:18,974 2019-03-17 07:44:18: step 359/50000, loss = 0.000000 (2.678 sec/batch), lr: 0.050000
2019-03-17 07:44:20,111 2019-03-17 07:44:20: step 360/50000, loss = 0.000000 (1.102 sec/batch), lr: 0.050000
2019-03-17 07:45:29,284 2019-03-17 07:45:29: step 361/50000, loss = 0.000000 (69.037 sec/batch), lr: 0.050000
2019-03-17 07:45:38,034 2019-03-17 07:45:38: step 362/50000, loss = 0.000000 (8.663 sec/batch), lr: 0.050000
2019-03-17 07:45:43,105 2019-03-17 07:45:43: step 363/50000, loss = 0.000000 (5.004 sec/batch), lr: 0.050000
2019-03-17 07:45:45,855 2019-03-17 07:45:45: step 364/50000, loss = 0.000000 (2.692 sec/batch), lr: 0.050000
2019-03-17 07:45:46,965 2019-03-17 07:45:46: step 365/50000, loss = 0.000000 (1.075 sec/batch), lr: 0.050000
2019-03-17 07:46:56,215 2019-03-17 07:46:56: step 366/50000, loss = 0.000000 (69.133 sec/batch), lr: 0.050000
2019-03-17 07:47:04,914 2019-03-17 07:47:04: step 367/50000, loss = 0.000000 (8.618 sec/batch), lr: 0.050000
2019-03-17 07:47:09,975 2019-03-17 07:47:09: step 368/50000, loss = 0.000000 (4.993 sec/batch), lr: 0.050000
2019-03-17 07:47:12,736 2019-03-17 07:47:12: step 369/50000, loss = 0.000000 (2.706 sec/batch), lr: 0.050000
2019-03-17 07:47:13,831 2019-03-17 07:47:13: step 370/50000, loss = 0.000000 (1.061 sec/batch), lr: 0.050000
2019-03-17 07:48:23,357 2019-03-17 07:48:23: step 371/50000, loss = 0.000000 (69.130 sec/batch), lr: 0.050000
2019-03-17 07:48:32,222 2019-03-17 07:48:32: step 372/50000, loss = 0.000000 (8.784 sec/batch), lr: 0.050000
2019-03-17 07:48:37,363 2019-03-17 07:48:37: step 373/50000, loss = 0.000000 (5.078 sec/batch), lr: 0.050000
2019-03-17 07:48:40,144 2019-03-17 07:48:40: step 374/50000, loss = 0.000000 (2.726 sec/batch), lr: 0.050000
2019-03-17 07:48:41,258 2019-03-17 07:48:41: step 375/50000, loss = 0.000000 (1.080 sec/batch), lr: 0.050000
2019-03-17 07:49:51,692 2019-03-17 07:49:51: step 376/50000, loss = 0.000000 (70.303 sec/batch), lr: 0.050000
2019-03-17 07:50:00,529 2019-03-17 07:50:00: step 377/50000, loss = 0.000000 (8.753 sec/batch), lr: 0.050000
2019-03-17 07:50:05,660 2019-03-17 07:50:05: step 378/50000, loss = 0.000000 (5.080 sec/batch), lr: 0.050000
2019-03-17 07:50:08,438 2019-03-17 07:50:08: step 379/50000, loss = 0.000000 (2.723 sec/batch), lr: 0.050000
2019-03-17 07:50:09,548 2019-03-17 07:50:09: step 380/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.050000
2019-03-17 07:51:20,081 2019-03-17 07:51:20: step 381/50000, loss = 0.000000 (70.400 sec/batch), lr: 0.050000
2019-03-17 07:51:28,946 2019-03-17 07:51:28: step 382/50000, loss = 0.000000 (8.785 sec/batch), lr: 0.050000
2019-03-17 07:51:34,085 2019-03-17 07:51:34: step 383/50000, loss = 0.000000 (5.073 sec/batch), lr: 0.050000
2019-03-17 07:51:36,836 2019-03-17 07:51:36: step 384/50000, loss = 0.000000 (2.712 sec/batch), lr: 0.050000
2019-03-17 07:51:37,912 2019-03-17 07:51:37: step 385/50000, loss = 0.000000 (1.053 sec/batch), lr: 0.050000
2019-03-17 07:52:48,587 2019-03-17 07:52:48: step 386/50000, loss = 0.000000 (70.583 sec/batch), lr: 0.050000
2019-03-17 07:52:57,433 2019-03-17 07:52:57: step 387/50000, loss = 0.000000 (8.761 sec/batch), lr: 0.050000
2019-03-17 07:53:02,594 2019-03-17 07:53:02: step 388/50000, loss = 0.000000 (5.092 sec/batch), lr: 0.050000
2019-03-17 07:53:05,376 2019-03-17 07:53:05: step 389/50000, loss = 0.000000 (2.728 sec/batch), lr: 0.050000
2019-03-17 07:53:06,483 2019-03-17 07:53:06: step 390/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.050000
2019-03-17 07:54:16,995 2019-03-17 07:54:16: step 391/50000, loss = 0.000000 (70.396 sec/batch), lr: 0.050000
2019-03-17 07:54:25,892 2019-03-17 07:54:25: step 392/50000, loss = 0.000000 (8.816 sec/batch), lr: 0.050000
2019-03-17 07:54:31,061 2019-03-17 07:54:31: step 393/50000, loss = 0.000000 (5.102 sec/batch), lr: 0.050000
2019-03-17 07:54:33,884 2019-03-17 07:54:33: step 394/50000, loss = 0.000000 (2.764 sec/batch), lr: 0.050000
2019-03-17 07:54:35,028 2019-03-17 07:54:35: step 395/50000, loss = 0.000000 (1.104 sec/batch), lr: 0.050000
2019-03-17 07:55:45,554 2019-03-17 07:55:45: step 396/50000, loss = 0.000000 (70.374 sec/batch), lr: 0.050000
2019-03-17 07:55:54,437 2019-03-17 07:55:54: step 397/50000, loss = 0.000000 (8.803 sec/batch), lr: 0.050000
2019-03-17 07:55:59,585 2019-03-17 07:55:59: step 398/50000, loss = 0.000000 (5.081 sec/batch), lr: 0.050000
2019-03-17 07:56:02,376 2019-03-17 07:56:02: step 399/50000, loss = 0.000000 (2.734 sec/batch), lr: 0.050000
2019-03-17 07:56:03,488 2019-03-17 07:56:03: step 400/50000, loss = 0.000000 (1.078 sec/batch), lr: 0.050000
2019-03-17 07:56:48,682 step 400: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 07:56:48,685 step 400: Dev acc. = 0.000000
2019-03-17 07:57:59,376 2019-03-17 07:57:59: step 401/50000, loss = 0.000000 (70.309 sec/batch), lr: 0.050000
2019-03-17 07:58:08,275 2019-03-17 07:58:08: step 402/50000, loss = 0.000000 (8.818 sec/batch), lr: 0.050000
2019-03-17 07:58:13,412 2019-03-17 07:58:13: step 403/50000, loss = 0.000000 (5.074 sec/batch), lr: 0.050000
2019-03-17 07:58:16,184 2019-03-17 07:58:16: step 404/50000, loss = 0.000000 (2.734 sec/batch), lr: 0.050000
2019-03-17 07:58:17,289 2019-03-17 07:58:17: step 405/50000, loss = 0.000000 (1.070 sec/batch), lr: 0.050000
2019-03-17 07:59:28,171 2019-03-17 07:59:28: step 406/50000, loss = 0.000000 (70.756 sec/batch), lr: 0.050000
2019-03-17 07:59:36,915 2019-03-17 07:59:36: step 407/50000, loss = 0.000000 (8.681 sec/batch), lr: 0.050000
2019-03-17 07:59:42,084 2019-03-17 07:59:42: step 408/50000, loss = 0.000000 (5.107 sec/batch), lr: 0.050000
2019-03-17 07:59:44,880 2019-03-17 07:59:44: step 409/50000, loss = 0.000000 (2.741 sec/batch), lr: 0.050000
2019-03-17 07:59:45,997 2019-03-17 07:59:45: step 410/50000, loss = 0.000000 (1.083 sec/batch), lr: 0.050000
2019-03-17 08:00:56,780 2019-03-17 08:00:56: step 411/50000, loss = 0.000000 (70.668 sec/batch), lr: 0.050000
2019-03-17 08:01:05,589 2019-03-17 08:01:05: step 412/50000, loss = 0.000000 (8.727 sec/batch), lr: 0.050000
2019-03-17 08:01:10,752 2019-03-17 08:01:10: step 413/50000, loss = 0.000000 (5.094 sec/batch), lr: 0.050000
2019-03-17 08:01:13,555 2019-03-17 08:01:13: step 414/50000, loss = 0.000000 (2.746 sec/batch), lr: 0.050000
2019-03-17 08:01:14,663 2019-03-17 08:01:14: step 415/50000, loss = 0.000000 (1.073 sec/batch), lr: 0.050000
2019-03-17 08:02:25,376 2019-03-17 08:02:25: step 416/50000, loss = 0.000000 (70.585 sec/batch), lr: 0.050000
2019-03-17 08:02:34,216 2019-03-17 08:02:34: step 417/50000, loss = 0.000000 (8.773 sec/batch), lr: 0.050000
2019-03-17 08:02:39,345 2019-03-17 08:02:39: step 418/50000, loss = 0.000000 (5.062 sec/batch), lr: 0.050000
2019-03-17 08:02:42,112 2019-03-17 08:02:42: step 419/50000, loss = 0.000000 (2.729 sec/batch), lr: 0.050000
2019-03-17 08:02:43,221 2019-03-17 08:02:43: step 420/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.050000
2019-03-17 08:03:54,281 2019-03-17 08:03:54: step 421/50000, loss = 0.000000 (70.930 sec/batch), lr: 0.050000
2019-03-17 08:04:03,019 2019-03-17 08:04:03: step 422/50000, loss = 0.000000 (8.673 sec/batch), lr: 0.050000
2019-03-17 08:04:08,235 2019-03-17 08:04:08: step 423/50000, loss = 0.000000 (5.149 sec/batch), lr: 0.050000
2019-03-17 08:04:11,025 2019-03-17 08:04:11: step 424/50000, loss = 0.000000 (2.751 sec/batch), lr: 0.050000
2019-03-17 08:04:12,128 2019-03-17 08:04:12: step 425/50000, loss = 0.000000 (1.069 sec/batch), lr: 0.050000
2019-03-17 08:05:22,756 2019-03-17 08:05:22: step 426/50000, loss = 0.000000 (70.518 sec/batch), lr: 0.050000
2019-03-17 08:05:31,579 2019-03-17 08:05:31: step 427/50000, loss = 0.000000 (8.742 sec/batch), lr: 0.050000
2019-03-17 08:05:36,684 2019-03-17 08:05:36: step 428/50000, loss = 0.000000 (5.039 sec/batch), lr: 0.050000
2019-03-17 08:05:39,445 2019-03-17 08:05:39: step 429/50000, loss = 0.000000 (2.724 sec/batch), lr: 0.050000
2019-03-17 08:05:40,544 2019-03-17 08:05:40: step 430/50000, loss = 0.000000 (1.075 sec/batch), lr: 0.050000
2019-03-17 08:06:50,994 2019-03-17 08:06:50: step 431/50000, loss = 0.000000 (70.318 sec/batch), lr: 0.050000
2019-03-17 08:07:00,073 2019-03-17 08:07:00: step 432/50000, loss = 0.000000 (8.731 sec/batch), lr: 0.050000
2019-03-17 08:07:05,212 2019-03-17 08:07:05: step 433/50000, loss = 0.000000 (5.072 sec/batch), lr: 0.050000
2019-03-17 08:07:07,996 2019-03-17 08:07:07: step 434/50000, loss = 0.000000 (2.728 sec/batch), lr: 0.050000
2019-03-17 08:07:09,111 2019-03-17 08:07:09: step 435/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.050000
2019-03-17 08:08:19,673 2019-03-17 08:08:19: step 436/50000, loss = 0.000000 (70.430 sec/batch), lr: 0.050000
2019-03-17 08:08:28,412 2019-03-17 08:08:28: step 437/50000, loss = 0.000000 (8.660 sec/batch), lr: 0.050000
2019-03-17 08:08:33,488 2019-03-17 08:08:33: step 438/50000, loss = 0.000000 (5.026 sec/batch), lr: 0.050000
2019-03-17 08:08:36,260 2019-03-17 08:08:36: step 439/50000, loss = 0.000000 (2.720 sec/batch), lr: 0.050000
2019-03-17 08:08:37,341 2019-03-17 08:08:37: step 440/50000, loss = 0.000000 (1.058 sec/batch), lr: 0.050000
2019-03-17 08:09:47,971 2019-03-17 08:09:47: step 441/50000, loss = 0.000000 (70.518 sec/batch), lr: 0.050000
2019-03-17 08:09:56,720 2019-03-17 08:09:56: step 442/50000, loss = 0.000000 (8.688 sec/batch), lr: 0.050000
2019-03-17 08:10:01,882 2019-03-17 08:10:01: step 443/50000, loss = 0.000000 (5.091 sec/batch), lr: 0.050000
2019-03-17 08:10:04,685 2019-03-17 08:10:04: step 444/50000, loss = 0.000000 (2.742 sec/batch), lr: 0.050000
2019-03-17 08:10:05,789 2019-03-17 08:10:05: step 445/50000, loss = 0.000000 (1.069 sec/batch), lr: 0.050000
2019-03-17 08:11:16,617 2019-03-17 08:11:16: step 446/50000, loss = 0.000000 (70.697 sec/batch), lr: 0.050000
2019-03-17 08:11:25,519 2019-03-17 08:11:25: step 447/50000, loss = 0.000000 (8.820 sec/batch), lr: 0.050000
2019-03-17 08:11:30,602 2019-03-17 08:11:30: step 448/50000, loss = 0.000000 (5.016 sec/batch), lr: 0.050000
2019-03-17 08:11:33,391 2019-03-17 08:11:33: step 449/50000, loss = 0.000000 (2.734 sec/batch), lr: 0.050000
2019-03-17 08:11:34,476 2019-03-17 08:11:34: step 450/50000, loss = 0.000000 (1.053 sec/batch), lr: 0.050000
2019-03-17 08:12:45,186 2019-03-17 08:12:45: step 451/50000, loss = 0.000000 (70.604 sec/batch), lr: 0.050000
2019-03-17 08:12:53,932 2019-03-17 08:12:53: step 452/50000, loss = 0.000000 (8.685 sec/batch), lr: 0.050000
2019-03-17 08:12:59,104 2019-03-17 08:12:59: step 453/50000, loss = 0.000000 (5.102 sec/batch), lr: 0.050000
2019-03-17 08:13:01,914 2019-03-17 08:13:01: step 454/50000, loss = 0.000000 (2.755 sec/batch), lr: 0.050000
2019-03-17 08:13:03,031 2019-03-17 08:13:03: step 455/50000, loss = 0.000000 (1.078 sec/batch), lr: 0.050000
2019-03-17 08:14:13,689 2019-03-17 08:14:13: step 456/50000, loss = 0.000000 (70.522 sec/batch), lr: 0.050000
2019-03-17 08:14:22,530 2019-03-17 08:14:22: step 457/50000, loss = 0.000000 (8.763 sec/batch), lr: 0.050000
2019-03-17 08:14:27,654 2019-03-17 08:14:27: step 458/50000, loss = 0.000000 (5.074 sec/batch), lr: 0.050000
2019-03-17 08:14:30,444 2019-03-17 08:14:30: step 459/50000, loss = 0.000000 (2.734 sec/batch), lr: 0.050000
2019-03-17 08:14:31,525 2019-03-17 08:14:31: step 460/50000, loss = 0.000000 (1.048 sec/batch), lr: 0.050000
2019-03-17 08:15:42,199 2019-03-17 08:15:42: step 461/50000, loss = 0.000000 (70.568 sec/batch), lr: 0.050000
2019-03-17 08:15:51,017 2019-03-17 08:15:51: step 462/50000, loss = 0.000000 (8.738 sec/batch), lr: 0.050000
2019-03-17 08:15:56,119 2019-03-17 08:15:56: step 463/50000, loss = 0.000000 (5.034 sec/batch), lr: 0.050000
2019-03-17 08:15:58,900 2019-03-17 08:15:58: step 464/50000, loss = 0.000000 (2.729 sec/batch), lr: 0.050000
2019-03-17 08:15:59,997 2019-03-17 08:15:59: step 465/50000, loss = 0.000000 (1.063 sec/batch), lr: 0.050000
2019-03-17 08:17:10,940 2019-03-17 08:17:10: step 466/50000, loss = 0.000000 (70.552 sec/batch), lr: 0.050000
2019-03-17 08:17:19,761 2019-03-17 08:17:19: step 467/50000, loss = 0.000000 (8.741 sec/batch), lr: 0.050000
2019-03-17 08:17:24,869 2019-03-17 08:17:24: step 468/50000, loss = 0.000000 (5.058 sec/batch), lr: 0.050000
2019-03-17 08:17:27,622 2019-03-17 08:17:27: step 469/50000, loss = 0.000000 (2.715 sec/batch), lr: 0.050000
2019-03-17 08:17:28,714 2019-03-17 08:17:28: step 470/50000, loss = 0.000000 (1.069 sec/batch), lr: 0.050000
2019-03-17 08:18:39,255 2019-03-17 08:18:39: step 471/50000, loss = 0.000000 (70.406 sec/batch), lr: 0.050000
2019-03-17 08:18:48,058 2019-03-17 08:18:48: step 472/50000, loss = 0.000000 (8.724 sec/batch), lr: 0.050000
2019-03-17 08:18:53,187 2019-03-17 08:18:53: step 473/50000, loss = 0.000000 (5.079 sec/batch), lr: 0.050000
2019-03-17 08:18:55,959 2019-03-17 08:18:55: step 474/50000, loss = 0.000000 (2.715 sec/batch), lr: 0.050000
2019-03-17 08:18:57,029 2019-03-17 08:18:57: step 475/50000, loss = 0.000000 (1.047 sec/batch), lr: 0.050000
2019-03-17 08:20:07,733 2019-03-17 08:20:07: step 476/50000, loss = 0.000000 (70.591 sec/batch), lr: 0.050000
2019-03-17 08:20:16,600 2019-03-17 08:20:16: step 477/50000, loss = 0.000000 (8.785 sec/batch), lr: 0.050000
2019-03-17 08:20:21,666 2019-03-17 08:20:21: step 478/50000, loss = 0.000000 (5.016 sec/batch), lr: 0.050000
2019-03-17 08:20:24,412 2019-03-17 08:20:24: step 479/50000, loss = 0.000000 (2.693 sec/batch), lr: 0.050000
2019-03-17 08:20:25,480 2019-03-17 08:20:25: step 480/50000, loss = 0.000000 (1.045 sec/batch), lr: 0.050000
2019-03-17 08:21:36,135 2019-03-17 08:21:36: step 481/50000, loss = 0.000000 (70.550 sec/batch), lr: 0.050000
2019-03-17 08:21:44,956 2019-03-17 08:21:44: step 482/50000, loss = 0.000000 (8.737 sec/batch), lr: 0.050000
2019-03-17 08:21:50,077 2019-03-17 08:21:50: step 483/50000, loss = 0.000000 (5.053 sec/batch), lr: 0.050000
2019-03-17 08:21:52,845 2019-03-17 08:21:52: step 484/50000, loss = 0.000000 (2.728 sec/batch), lr: 0.050000
2019-03-17 08:21:53,945 2019-03-17 08:21:53: step 485/50000, loss = 0.000000 (1.066 sec/batch), lr: 0.050000
2019-03-17 08:23:04,649 2019-03-17 08:23:04: step 486/50000, loss = 0.000000 (70.576 sec/batch), lr: 0.050000
2019-03-17 08:23:13,365 2019-03-17 08:23:13: step 487/50000, loss = 0.000000 (8.653 sec/batch), lr: 0.050000
2019-03-17 08:23:18,495 2019-03-17 08:23:18: step 488/50000, loss = 0.000000 (5.059 sec/batch), lr: 0.050000
2019-03-17 08:23:21,258 2019-03-17 08:23:21: step 489/50000, loss = 0.000000 (2.726 sec/batch), lr: 0.050000
2019-03-17 08:23:22,363 2019-03-17 08:23:22: step 490/50000, loss = 0.000000 (1.071 sec/batch), lr: 0.050000
2019-03-17 08:24:33,043 2019-03-17 08:24:33: step 491/50000, loss = 0.000000 (70.552 sec/batch), lr: 0.050000
2019-03-17 08:24:41,734 2019-03-17 08:24:41: step 492/50000, loss = 0.000000 (8.630 sec/batch), lr: 0.050000
2019-03-17 08:24:46,825 2019-03-17 08:24:46: step 493/50000, loss = 0.000000 (5.043 sec/batch), lr: 0.050000
2019-03-17 08:24:49,585 2019-03-17 08:24:49: step 494/50000, loss = 0.000000 (2.721 sec/batch), lr: 0.050000
2019-03-17 08:24:50,686 2019-03-17 08:24:50: step 495/50000, loss = 0.000000 (1.068 sec/batch), lr: 0.050000
2019-03-17 08:26:01,673 2019-03-17 08:26:01: step 496/50000, loss = 0.000000 (70.609 sec/batch), lr: 0.050000
2019-03-17 08:26:10,507 2019-03-17 08:26:10: step 497/50000, loss = 0.000000 (8.751 sec/batch), lr: 0.050000
2019-03-17 08:26:15,658 2019-03-17 08:26:15: step 498/50000, loss = 0.000000 (5.084 sec/batch), lr: 0.050000
2019-03-17 08:26:18,451 2019-03-17 08:26:18: step 499/50000, loss = 0.000000 (2.738 sec/batch), lr: 0.050000
2019-03-17 08:26:19,556 2019-03-17 08:26:19: step 500/50000, loss = 0.000000 (1.071 sec/batch), lr: 0.050000
2019-03-17 08:27:04,804 step 500: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 08:27:04,860 step 500: Dev acc. = 0.000000
2019-03-17 08:28:15,548 2019-03-17 08:28:15: step 501/50000, loss = 0.000000 (70.589 sec/batch), lr: 0.050000
2019-03-17 08:28:24,519 2019-03-17 08:28:24: step 502/50000, loss = 0.000000 (8.891 sec/batch), lr: 0.050000
2019-03-17 08:28:29,710 2019-03-17 08:28:29: step 503/50000, loss = 0.000000 (5.124 sec/batch), lr: 0.050000
2019-03-17 08:28:32,514 2019-03-17 08:28:32: step 504/50000, loss = 0.000000 (2.742 sec/batch), lr: 0.050000
2019-03-17 08:28:33,648 2019-03-17 08:28:33: step 505/50000, loss = 0.000000 (1.094 sec/batch), lr: 0.050000
2019-03-17 08:29:44,321 2019-03-17 08:29:44: step 506/50000, loss = 0.000000 (70.538 sec/batch), lr: 0.050000
2019-03-17 08:29:53,243 2019-03-17 08:29:53: step 507/50000, loss = 0.000000 (8.836 sec/batch), lr: 0.050000
2019-03-17 08:29:58,420 2019-03-17 08:29:58: step 508/50000, loss = 0.000000 (5.106 sec/batch), lr: 0.050000
2019-03-17 08:30:01,218 2019-03-17 08:30:01: step 509/50000, loss = 0.000000 (2.741 sec/batch), lr: 0.050000
2019-03-17 08:30:02,334 2019-03-17 08:30:02: step 510/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.050000
2019-03-17 08:31:13,153 2019-03-17 08:31:13: step 511/50000, loss = 0.000000 (70.698 sec/batch), lr: 0.050000
2019-03-17 08:31:22,030 2019-03-17 08:31:22: step 512/50000, loss = 0.000000 (8.797 sec/batch), lr: 0.050000
2019-03-17 08:31:27,201 2019-03-17 08:31:27: step 513/50000, loss = 0.000000 (5.104 sec/batch), lr: 0.050000
2019-03-17 08:31:29,996 2019-03-17 08:31:29: step 514/50000, loss = 0.000000 (2.741 sec/batch), lr: 0.050000
2019-03-17 08:31:31,112 2019-03-17 08:31:31: step 515/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.050000
2019-03-17 08:32:42,021 2019-03-17 08:32:42: step 516/50000, loss = 0.000000 (70.779 sec/batch), lr: 0.050000
2019-03-17 08:32:50,900 2019-03-17 08:32:50: step 517/50000, loss = 0.000000 (8.798 sec/batch), lr: 0.050000
2019-03-17 08:32:56,056 2019-03-17 08:32:56: step 518/50000, loss = 0.000000 (5.089 sec/batch), lr: 0.050000
2019-03-17 08:32:58,841 2019-03-17 08:32:58: step 519/50000, loss = 0.000000 (2.731 sec/batch), lr: 0.050000
2019-03-17 08:32:59,949 2019-03-17 08:32:59: step 520/50000, loss = 0.000000 (1.073 sec/batch), lr: 0.050000
2019-03-17 08:34:10,737 2019-03-17 08:34:10: step 521/50000, loss = 0.000000 (70.660 sec/batch), lr: 0.050000
2019-03-17 08:34:19,608 2019-03-17 08:34:19: step 522/50000, loss = 0.000000 (8.787 sec/batch), lr: 0.050000
2019-03-17 08:34:24,893 2019-03-17 08:34:24: step 523/50000, loss = 0.000000 (5.209 sec/batch), lr: 0.050000
2019-03-17 08:34:27,684 2019-03-17 08:34:27: step 524/50000, loss = 0.000000 (2.737 sec/batch), lr: 0.050000
2019-03-17 08:34:28,809 2019-03-17 08:34:28: step 525/50000, loss = 0.000000 (1.090 sec/batch), lr: 0.050000
2019-03-17 08:35:39,494 2019-03-17 08:35:39: step 526/50000, loss = 0.000000 (70.534 sec/batch), lr: 0.050000
2019-03-17 08:35:48,369 2019-03-17 08:35:48: step 527/50000, loss = 0.000000 (8.794 sec/batch), lr: 0.050000
2019-03-17 08:35:53,529 2019-03-17 08:35:53: step 528/50000, loss = 0.000000 (5.091 sec/batch), lr: 0.050000
2019-03-17 08:35:56,322 2019-03-17 08:35:56: step 529/50000, loss = 0.000000 (2.731 sec/batch), lr: 0.050000
2019-03-17 08:35:57,437 2019-03-17 08:35:57: step 530/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.050000
2019-03-17 08:37:08,184 2019-03-17 08:37:08: step 531/50000, loss = 0.000000 (70.629 sec/batch), lr: 0.050000
2019-03-17 08:37:17,036 2019-03-17 08:37:17: step 532/50000, loss = 0.000000 (8.767 sec/batch), lr: 0.050000
2019-03-17 08:37:22,124 2019-03-17 08:37:22: step 533/50000, loss = 0.000000 (5.020 sec/batch), lr: 0.050000
2019-03-17 08:37:24,909 2019-03-17 08:37:24: step 534/50000, loss = 0.000000 (2.730 sec/batch), lr: 0.050000
2019-03-17 08:37:26,018 2019-03-17 08:37:26: step 535/50000, loss = 0.000000 (1.070 sec/batch), lr: 0.050000
2019-03-17 08:38:36,825 2019-03-17 08:38:36: step 536/50000, loss = 0.000000 (70.675 sec/batch), lr: 0.050000
2019-03-17 08:38:45,745 2019-03-17 08:38:45: step 537/50000, loss = 0.000000 (8.839 sec/batch), lr: 0.050000
2019-03-17 08:38:50,907 2019-03-17 08:38:50: step 538/50000, loss = 0.000000 (5.094 sec/batch), lr: 0.050000
2019-03-17 08:38:53,692 2019-03-17 08:38:53: step 539/50000, loss = 0.000000 (2.730 sec/batch), lr: 0.050000
2019-03-17 08:38:54,795 2019-03-17 08:38:54: step 540/50000, loss = 0.000000 (1.070 sec/batch), lr: 0.050000
2019-03-17 08:40:05,677 2019-03-17 08:40:05: step 541/50000, loss = 0.000000 (70.750 sec/batch), lr: 0.050000
2019-03-17 08:40:14,573 2019-03-17 08:40:14: step 542/50000, loss = 0.000000 (8.812 sec/batch), lr: 0.050000
2019-03-17 08:40:19,743 2019-03-17 08:40:19: step 543/50000, loss = 0.000000 (5.101 sec/batch), lr: 0.050000
2019-03-17 08:40:22,557 2019-03-17 08:40:22: step 544/50000, loss = 0.000000 (2.754 sec/batch), lr: 0.050000
2019-03-17 08:40:23,668 2019-03-17 08:40:23: step 545/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.050000
2019-03-17 08:41:34,461 2019-03-17 08:41:34: step 546/50000, loss = 0.000000 (70.661 sec/batch), lr: 0.050000
2019-03-17 08:41:43,379 2019-03-17 08:41:43: step 547/50000, loss = 0.000000 (8.835 sec/batch), lr: 0.050000
2019-03-17 08:41:48,677 2019-03-17 08:41:48: step 548/50000, loss = 0.000000 (5.220 sec/batch), lr: 0.050000
2019-03-17 08:41:51,468 2019-03-17 08:41:51: step 549/50000, loss = 0.000000 (2.735 sec/batch), lr: 0.050000
2019-03-17 08:41:52,578 2019-03-17 08:41:52: step 550/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.050000
2019-03-17 08:43:03,238 2019-03-17 08:43:03: step 551/50000, loss = 0.000000 (70.530 sec/batch), lr: 0.050000
2019-03-17 08:43:12,136 2019-03-17 08:43:12: step 552/50000, loss = 0.000000 (8.813 sec/batch), lr: 0.050000
2019-03-17 08:43:17,292 2019-03-17 08:43:17: step 553/50000, loss = 0.000000 (5.091 sec/batch), lr: 0.050000
2019-03-17 08:43:20,091 2019-03-17 08:43:20: step 554/50000, loss = 0.000000 (2.743 sec/batch), lr: 0.050000
2019-03-17 08:43:21,206 2019-03-17 08:43:21: step 555/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.050000
2019-03-17 08:44:32,300 2019-03-17 08:44:32: step 556/50000, loss = 0.000000 (70.681 sec/batch), lr: 0.050000
2019-03-17 08:44:41,188 2019-03-17 08:44:41: step 557/50000, loss = 0.000000 (8.805 sec/batch), lr: 0.050000
2019-03-17 08:44:46,360 2019-03-17 08:44:46: step 558/50000, loss = 0.000000 (5.104 sec/batch), lr: 0.050000
2019-03-17 08:44:49,168 2019-03-17 08:44:49: step 559/50000, loss = 0.000000 (2.748 sec/batch), lr: 0.050000
2019-03-17 08:44:50,278 2019-03-17 08:44:50: step 560/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.050000
2019-03-17 08:46:01,080 2019-03-17 08:46:01: step 561/50000, loss = 0.000000 (70.685 sec/batch), lr: 0.050000
2019-03-17 08:46:09,960 2019-03-17 08:46:09: step 562/50000, loss = 0.000000 (8.797 sec/batch), lr: 0.050000
2019-03-17 08:46:15,115 2019-03-17 08:46:15: step 563/50000, loss = 0.000000 (5.088 sec/batch), lr: 0.050000
2019-03-17 08:46:17,915 2019-03-17 08:46:17: step 564/50000, loss = 0.000000 (2.744 sec/batch), lr: 0.050000
2019-03-17 08:46:19,030 2019-03-17 08:46:19: step 565/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.050000
2019-03-17 08:47:29,736 2019-03-17 08:47:29: step 566/50000, loss = 0.000000 (70.574 sec/batch), lr: 0.050000
2019-03-17 08:47:38,633 2019-03-17 08:47:38: step 567/50000, loss = 0.000000 (8.815 sec/batch), lr: 0.050000
2019-03-17 08:47:43,959 2019-03-17 08:47:43: step 568/50000, loss = 0.000000 (5.248 sec/batch), lr: 0.050000
2019-03-17 08:47:46,755 2019-03-17 08:47:46: step 569/50000, loss = 0.000000 (2.734 sec/batch), lr: 0.050000
2019-03-17 08:47:47,866 2019-03-17 08:47:47: step 570/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.050000
2019-03-17 08:48:58,510 2019-03-17 08:48:58: step 571/50000, loss = 0.000000 (70.512 sec/batch), lr: 0.050000
2019-03-17 08:49:07,392 2019-03-17 08:49:07: step 572/50000, loss = 0.000000 (8.801 sec/batch), lr: 0.050000
2019-03-17 08:49:12,543 2019-03-17 08:49:12: step 573/50000, loss = 0.000000 (5.084 sec/batch), lr: 0.050000
2019-03-17 08:49:15,325 2019-03-17 08:49:15: step 574/50000, loss = 0.000000 (2.728 sec/batch), lr: 0.050000
2019-03-17 08:49:16,440 2019-03-17 08:49:16: step 575/50000, loss = 0.000000 (1.080 sec/batch), lr: 0.050000
2019-03-17 08:50:27,185 2019-03-17 08:50:27: step 576/50000, loss = 0.000000 (70.612 sec/batch), lr: 0.050000
2019-03-17 08:50:36,126 2019-03-17 08:50:36: step 577/50000, loss = 0.000000 (8.858 sec/batch), lr: 0.050000
2019-03-17 08:50:41,320 2019-03-17 08:50:41: step 578/50000, loss = 0.000000 (5.125 sec/batch), lr: 0.050000
2019-03-17 08:50:44,122 2019-03-17 08:50:44: step 579/50000, loss = 0.000000 (2.748 sec/batch), lr: 0.050000
2019-03-17 08:50:45,267 2019-03-17 08:50:45: step 580/50000, loss = 0.000000 (1.111 sec/batch), lr: 0.050000
2019-03-17 08:51:56,391 2019-03-17 08:51:56: step 581/50000, loss = 0.000000 (71.003 sec/batch), lr: 0.050000
2019-03-17 08:52:05,165 2019-03-17 08:52:05: step 582/50000, loss = 0.000000 (8.706 sec/batch), lr: 0.050000
2019-03-17 08:52:10,327 2019-03-17 08:52:10: step 583/50000, loss = 0.000000 (5.095 sec/batch), lr: 0.050000
2019-03-17 08:52:13,104 2019-03-17 08:52:13: step 584/50000, loss = 0.000000 (2.721 sec/batch), lr: 0.050000
2019-03-17 08:52:14,215 2019-03-17 08:52:14: step 585/50000, loss = 0.000000 (1.078 sec/batch), lr: 0.050000
2019-03-17 08:53:24,920 2019-03-17 08:53:24: step 586/50000, loss = 0.000000 (70.586 sec/batch), lr: 0.050000
2019-03-17 08:53:34,096 2019-03-17 08:53:34: step 587/50000, loss = 0.000000 (8.753 sec/batch), lr: 0.050000
2019-03-17 08:53:39,271 2019-03-17 08:53:39: step 588/50000, loss = 0.000000 (5.108 sec/batch), lr: 0.050000
2019-03-17 08:53:42,037 2019-03-17 08:53:42: step 589/50000, loss = 0.000000 (2.711 sec/batch), lr: 0.050000
2019-03-17 08:53:43,136 2019-03-17 08:53:43: step 590/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.050000
2019-03-17 08:54:53,866 2019-03-17 08:54:53: step 591/50000, loss = 0.000000 (70.611 sec/batch), lr: 0.050000
2019-03-17 08:55:02,763 2019-03-17 08:55:02: step 592/50000, loss = 0.000000 (8.816 sec/batch), lr: 0.050000
2019-03-17 08:55:07,929 2019-03-17 08:55:07: step 593/50000, loss = 0.000000 (5.099 sec/batch), lr: 0.050000
2019-03-17 08:55:10,731 2019-03-17 08:55:10: step 594/50000, loss = 0.000000 (2.744 sec/batch), lr: 0.050000
2019-03-17 08:55:11,839 2019-03-17 08:55:11: step 595/50000, loss = 0.000000 (1.074 sec/batch), lr: 0.050000
2019-03-17 08:56:22,418 2019-03-17 08:56:22: step 596/50000, loss = 0.000000 (70.446 sec/batch), lr: 0.050000
2019-03-17 08:56:31,349 2019-03-17 08:56:31: step 597/50000, loss = 0.000000 (8.847 sec/batch), lr: 0.050000
2019-03-17 08:56:36,659 2019-03-17 08:56:36: step 598/50000, loss = 0.000000 (5.233 sec/batch), lr: 0.050000
2019-03-17 08:56:39,462 2019-03-17 08:56:39: step 599/50000, loss = 0.000000 (2.744 sec/batch), lr: 0.050000
2019-03-17 08:56:40,577 2019-03-17 08:56:40: step 600/50000, loss = 0.000000 (1.080 sec/batch), lr: 0.050000
2019-03-17 08:57:25,656 step 600: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 08:57:25,712 step 600: Dev acc. = 0.000000
2019-03-17 08:58:36,569 2019-03-17 08:58:36: step 601/50000, loss = 0.000000 (70.744 sec/batch), lr: 0.025000
2019-03-17 08:58:45,464 2019-03-17 08:58:45: step 602/50000, loss = 0.000000 (8.811 sec/batch), lr: 0.025000
2019-03-17 08:58:50,625 2019-03-17 08:58:50: step 603/50000, loss = 0.000000 (5.093 sec/batch), lr: 0.025000
2019-03-17 08:58:53,412 2019-03-17 08:58:53: step 604/50000, loss = 0.000000 (2.732 sec/batch), lr: 0.025000
2019-03-17 08:58:54,526 2019-03-17 08:58:54: step 605/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.025000
2019-03-17 09:00:05,332 2019-03-17 09:00:05: step 606/50000, loss = 0.000000 (70.675 sec/batch), lr: 0.025000
2019-03-17 09:00:14,255 2019-03-17 09:00:14: step 607/50000, loss = 0.000000 (8.841 sec/batch), lr: 0.025000
2019-03-17 09:00:19,431 2019-03-17 09:00:19: step 608/50000, loss = 0.000000 (5.108 sec/batch), lr: 0.025000
2019-03-17 09:00:22,232 2019-03-17 09:00:22: step 609/50000, loss = 0.000000 (2.746 sec/batch), lr: 0.025000
2019-03-17 09:00:23,340 2019-03-17 09:00:23: step 610/50000, loss = 0.000000 (1.075 sec/batch), lr: 0.025000
2019-03-17 09:01:34,197 2019-03-17 09:01:34: step 611/50000, loss = 0.000000 (70.724 sec/batch), lr: 0.025000
2019-03-17 09:01:43,073 2019-03-17 09:01:43: step 612/50000, loss = 0.000000 (8.794 sec/batch), lr: 0.025000
2019-03-17 09:01:48,219 2019-03-17 09:01:48: step 613/50000, loss = 0.000000 (5.078 sec/batch), lr: 0.025000
2019-03-17 09:01:51,009 2019-03-17 09:01:51: step 614/50000, loss = 0.000000 (2.734 sec/batch), lr: 0.025000
2019-03-17 09:01:52,122 2019-03-17 09:01:52: step 615/50000, loss = 0.000000 (1.080 sec/batch), lr: 0.025000
2019-03-17 09:03:02,714 2019-03-17 09:03:02: step 616/50000, loss = 0.000000 (70.459 sec/batch), lr: 0.025000
2019-03-17 09:03:11,578 2019-03-17 09:03:11: step 617/50000, loss = 0.000000 (8.783 sec/batch), lr: 0.025000
2019-03-17 09:03:16,996 2019-03-17 09:03:16: step 618/50000, loss = 0.000000 (5.349 sec/batch), lr: 0.025000
2019-03-17 09:03:19,760 2019-03-17 09:03:19: step 619/50000, loss = 0.000000 (2.711 sec/batch), lr: 0.025000
2019-03-17 09:03:20,854 2019-03-17 09:03:20: step 620/50000, loss = 0.000000 (1.060 sec/batch), lr: 0.025000
2019-03-17 09:04:31,553 2019-03-17 09:04:31: step 621/50000, loss = 0.000000 (70.571 sec/batch), lr: 0.025000
2019-03-17 09:04:40,350 2019-03-17 09:04:40: step 622/50000, loss = 0.000000 (8.714 sec/batch), lr: 0.025000
2019-03-17 09:04:45,460 2019-03-17 09:04:45: step 623/50000, loss = 0.000000 (5.043 sec/batch), lr: 0.025000
2019-03-17 09:04:48,217 2019-03-17 09:04:48: step 624/50000, loss = 0.000000 (2.700 sec/batch), lr: 0.025000
2019-03-17 09:04:49,308 2019-03-17 09:04:49: step 625/50000, loss = 0.000000 (1.057 sec/batch), lr: 0.025000
2019-03-17 09:06:00,011 2019-03-17 09:06:00: step 626/50000, loss = 0.000000 (70.569 sec/batch), lr: 0.025000
2019-03-17 09:06:08,859 2019-03-17 09:06:08: step 627/50000, loss = 0.000000 (8.768 sec/batch), lr: 0.025000
2019-03-17 09:06:14,024 2019-03-17 09:06:14: step 628/50000, loss = 0.000000 (5.097 sec/batch), lr: 0.025000
2019-03-17 09:06:16,820 2019-03-17 09:06:16: step 629/50000, loss = 0.000000 (2.741 sec/batch), lr: 0.025000
2019-03-17 09:06:17,928 2019-03-17 09:06:17: step 630/50000, loss = 0.000000 (1.074 sec/batch), lr: 0.025000
2019-03-17 09:07:28,567 2019-03-17 09:07:28: step 631/50000, loss = 0.000000 (70.508 sec/batch), lr: 0.025000
2019-03-17 09:07:37,472 2019-03-17 09:07:37: step 632/50000, loss = 0.000000 (8.823 sec/batch), lr: 0.025000
2019-03-17 09:07:42,644 2019-03-17 09:07:42: step 633/50000, loss = 0.000000 (5.104 sec/batch), lr: 0.025000
2019-03-17 09:07:45,440 2019-03-17 09:07:45: step 634/50000, loss = 0.000000 (2.738 sec/batch), lr: 0.025000
2019-03-17 09:07:46,548 2019-03-17 09:07:46: step 635/50000, loss = 0.000000 (1.074 sec/batch), lr: 0.025000
2019-03-17 09:08:57,312 2019-03-17 09:08:57: step 636/50000, loss = 0.000000 (70.645 sec/batch), lr: 0.025000
2019-03-17 09:09:06,130 2019-03-17 09:09:06: step 637/50000, loss = 0.000000 (8.735 sec/batch), lr: 0.025000
2019-03-17 09:09:11,271 2019-03-17 09:09:11: step 638/50000, loss = 0.000000 (5.071 sec/batch), lr: 0.025000
2019-03-17 09:09:14,061 2019-03-17 09:09:14: step 639/50000, loss = 0.000000 (2.734 sec/batch), lr: 0.025000
2019-03-17 09:09:15,171 2019-03-17 09:09:15: step 640/50000, loss = 0.000000 (1.075 sec/batch), lr: 0.025000
2019-03-17 09:10:25,834 2019-03-17 09:10:25: step 641/50000, loss = 0.000000 (70.532 sec/batch), lr: 0.025000
2019-03-17 09:10:34,743 2019-03-17 09:10:34: step 642/50000, loss = 0.000000 (8.827 sec/batch), lr: 0.025000
2019-03-17 09:10:39,938 2019-03-17 09:10:39: step 643/50000, loss = 0.000000 (5.127 sec/batch), lr: 0.025000
2019-03-17 09:10:42,754 2019-03-17 09:10:42: step 644/50000, loss = 0.000000 (2.756 sec/batch), lr: 0.025000
2019-03-17 09:10:43,878 2019-03-17 09:10:43: step 645/50000, loss = 0.000000 (1.090 sec/batch), lr: 0.025000
2019-03-17 09:11:54,996 2019-03-17 09:11:54: step 646/50000, loss = 0.000000 (70.980 sec/batch), lr: 0.025000
2019-03-17 09:12:03,927 2019-03-17 09:12:03: step 647/50000, loss = 0.000000 (8.851 sec/batch), lr: 0.025000
2019-03-17 09:12:09,096 2019-03-17 09:12:09: step 648/50000, loss = 0.000000 (5.105 sec/batch), lr: 0.025000
2019-03-17 09:12:11,888 2019-03-17 09:12:11: step 649/50000, loss = 0.000000 (2.736 sec/batch), lr: 0.025000
2019-03-17 09:12:13,000 2019-03-17 09:12:13: step 650/50000, loss = 0.000000 (1.078 sec/batch), lr: 0.025000
2019-03-17 09:13:24,180 2019-03-17 09:13:24: step 651/50000, loss = 0.000000 (70.756 sec/batch), lr: 0.025000
2019-03-17 09:13:33,043 2019-03-17 09:13:33: step 652/50000, loss = 0.000000 (8.782 sec/batch), lr: 0.025000
2019-03-17 09:13:38,149 2019-03-17 09:13:38: step 653/50000, loss = 0.000000 (5.034 sec/batch), lr: 0.025000
2019-03-17 09:13:40,917 2019-03-17 09:13:40: step 654/50000, loss = 0.000000 (2.706 sec/batch), lr: 0.025000
2019-03-17 09:13:42,014 2019-03-17 09:13:42: step 655/50000, loss = 0.000000 (1.064 sec/batch), lr: 0.025000
2019-03-17 09:14:52,807 2019-03-17 09:14:52: step 656/50000, loss = 0.000000 (70.660 sec/batch), lr: 0.025000
2019-03-17 09:15:01,698 2019-03-17 09:15:01: step 657/50000, loss = 0.000000 (8.810 sec/batch), lr: 0.025000
2019-03-17 09:15:06,824 2019-03-17 09:15:06: step 658/50000, loss = 0.000000 (5.057 sec/batch), lr: 0.025000
2019-03-17 09:15:09,595 2019-03-17 09:15:09: step 659/50000, loss = 0.000000 (2.717 sec/batch), lr: 0.025000
2019-03-17 09:15:10,711 2019-03-17 09:15:10: step 660/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.025000
2019-03-17 09:16:21,623 2019-03-17 09:16:21: step 661/50000, loss = 0.000000 (70.781 sec/batch), lr: 0.025000
2019-03-17 09:16:30,573 2019-03-17 09:16:30: step 662/50000, loss = 0.000000 (8.867 sec/batch), lr: 0.025000
2019-03-17 09:16:35,851 2019-03-17 09:16:35: step 663/50000, loss = 0.000000 (5.201 sec/batch), lr: 0.025000
2019-03-17 09:16:38,635 2019-03-17 09:16:38: step 664/50000, loss = 0.000000 (2.729 sec/batch), lr: 0.025000
2019-03-17 09:16:39,748 2019-03-17 09:16:39: step 665/50000, loss = 0.000000 (1.079 sec/batch), lr: 0.025000
2019-03-17 09:17:50,658 2019-03-17 09:17:50: step 666/50000, loss = 0.000000 (70.773 sec/batch), lr: 0.025000
2019-03-17 09:17:59,563 2019-03-17 09:17:59: step 667/50000, loss = 0.000000 (8.821 sec/batch), lr: 0.025000
2019-03-17 09:18:04,703 2019-03-17 09:18:04: step 668/50000, loss = 0.000000 (5.072 sec/batch), lr: 0.025000
2019-03-17 09:18:07,490 2019-03-17 09:18:07: step 669/50000, loss = 0.000000 (2.731 sec/batch), lr: 0.025000
2019-03-17 09:18:08,597 2019-03-17 09:18:08: step 670/50000, loss = 0.000000 (1.073 sec/batch), lr: 0.025000
2019-03-17 09:19:19,315 2019-03-17 09:19:19: step 671/50000, loss = 0.000000 (70.585 sec/batch), lr: 0.025000
2019-03-17 09:19:28,242 2019-03-17 09:19:28: step 672/50000, loss = 0.000000 (8.843 sec/batch), lr: 0.025000
2019-03-17 09:19:33,535 2019-03-17 09:19:33: step 673/50000, loss = 0.000000 (5.217 sec/batch), lr: 0.025000
2019-03-17 09:19:36,359 2019-03-17 09:19:36: step 674/50000, loss = 0.000000 (2.762 sec/batch), lr: 0.025000
2019-03-17 09:19:37,491 2019-03-17 09:19:37: step 675/50000, loss = 0.000000 (1.092 sec/batch), lr: 0.025000
2019-03-17 09:20:48,265 2019-03-17 09:20:48: step 676/50000, loss = 0.000000 (70.640 sec/batch), lr: 0.025000
2019-03-17 09:20:57,193 2019-03-17 09:20:57: step 677/50000, loss = 0.000000 (8.842 sec/batch), lr: 0.025000
2019-03-17 09:21:02,472 2019-03-17 09:21:02: step 678/50000, loss = 0.000000 (5.202 sec/batch), lr: 0.025000
2019-03-17 09:21:05,248 2019-03-17 09:21:05: step 679/50000, loss = 0.000000 (2.720 sec/batch), lr: 0.025000
2019-03-17 09:21:06,356 2019-03-17 09:21:06: step 680/50000, loss = 0.000000 (1.074 sec/batch), lr: 0.025000
2019-03-17 09:22:16,835 2019-03-17 09:22:16: step 681/50000, loss = 0.000000 (70.063 sec/batch), lr: 0.025000
2019-03-17 09:22:25,661 2019-03-17 09:22:25: step 682/50000, loss = 0.000000 (8.744 sec/batch), lr: 0.025000
2019-03-17 09:22:30,801 2019-03-17 09:22:30: step 683/50000, loss = 0.000000 (5.072 sec/batch), lr: 0.025000
2019-03-17 09:22:33,567 2019-03-17 09:22:33: step 684/50000, loss = 0.000000 (2.711 sec/batch), lr: 0.025000
2019-03-17 09:22:34,758 2019-03-17 09:22:34: step 685/50000, loss = 0.000000 (1.162 sec/batch), lr: 0.025000
2019-03-17 09:23:45,647 2019-03-17 09:23:45: step 686/50000, loss = 0.000000 (70.750 sec/batch), lr: 0.025000
2019-03-17 09:23:54,510 2019-03-17 09:23:54: step 687/50000, loss = 0.000000 (8.779 sec/batch), lr: 0.025000
2019-03-17 09:23:59,663 2019-03-17 09:23:59: step 688/50000, loss = 0.000000 (5.087 sec/batch), lr: 0.025000
2019-03-17 09:24:02,448 2019-03-17 09:24:02: step 689/50000, loss = 0.000000 (2.730 sec/batch), lr: 0.025000
2019-03-17 09:24:03,525 2019-03-17 09:24:03: step 690/50000, loss = 0.000000 (1.043 sec/batch), lr: 0.025000
2019-03-17 09:25:14,323 2019-03-17 09:25:14: step 691/50000, loss = 0.000000 (70.682 sec/batch), lr: 0.025000
2019-03-17 09:25:23,084 2019-03-17 09:25:23: step 692/50000, loss = 0.000000 (8.697 sec/batch), lr: 0.025000
2019-03-17 09:25:28,185 2019-03-17 09:25:28: step 693/50000, loss = 0.000000 (5.051 sec/batch), lr: 0.025000
2019-03-17 09:25:30,951 2019-03-17 09:25:30: step 694/50000, loss = 0.000000 (2.729 sec/batch), lr: 0.025000
2019-03-17 09:25:32,143 2019-03-17 09:25:32: step 695/50000, loss = 0.000000 (1.163 sec/batch), lr: 0.025000
2019-03-17 09:26:42,368 2019-03-17 09:26:42: step 696/50000, loss = 0.000000 (70.093 sec/batch), lr: 0.025000
2019-03-17 09:26:51,084 2019-03-17 09:26:51: step 697/50000, loss = 0.000000 (8.644 sec/batch), lr: 0.025000
2019-03-17 09:26:56,219 2019-03-17 09:26:56: step 698/50000, loss = 0.000000 (5.063 sec/batch), lr: 0.025000
2019-03-17 09:26:58,994 2019-03-17 09:26:58: step 699/50000, loss = 0.000000 (2.721 sec/batch), lr: 0.025000
2019-03-17 09:27:00,099 2019-03-17 09:27:00: step 700/50000, loss = 0.000000 (1.071 sec/batch), lr: 0.025000
2019-03-17 09:27:45,167 step 700: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 09:27:45,225 step 700: Dev acc. = 0.000000
2019-03-17 09:28:55,726 2019-03-17 09:28:55: step 701/50000, loss = 0.000000 (70.390 sec/batch), lr: 0.025000
2019-03-17 09:29:04,547 2019-03-17 09:29:04: step 702/50000, loss = 0.000000 (8.742 sec/batch), lr: 0.025000
2019-03-17 09:29:09,689 2019-03-17 09:29:09: step 703/50000, loss = 0.000000 (5.076 sec/batch), lr: 0.025000
2019-03-17 09:29:12,471 2019-03-17 09:29:12: step 704/50000, loss = 0.000000 (2.727 sec/batch), lr: 0.025000
2019-03-17 09:29:13,578 2019-03-17 09:29:13: step 705/50000, loss = 0.000000 (1.073 sec/batch), lr: 0.025000
2019-03-17 09:30:24,115 2019-03-17 09:30:24: step 706/50000, loss = 0.000000 (70.405 sec/batch), lr: 0.025000
2019-03-17 09:30:32,971 2019-03-17 09:30:32: step 707/50000, loss = 0.000000 (8.778 sec/batch), lr: 0.025000
2019-03-17 09:30:38,255 2019-03-17 09:30:38: step 708/50000, loss = 0.000000 (5.206 sec/batch), lr: 0.025000
2019-03-17 09:30:41,055 2019-03-17 09:30:41: step 709/50000, loss = 0.000000 (2.739 sec/batch), lr: 0.025000
2019-03-17 09:30:42,157 2019-03-17 09:30:42: step 710/50000, loss = 0.000000 (1.069 sec/batch), lr: 0.025000
2019-03-17 09:31:52,405 2019-03-17 09:31:52: step 711/50000, loss = 0.000000 (70.119 sec/batch), lr: 0.025000
2019-03-17 09:32:01,501 2019-03-17 09:32:01: step 712/50000, loss = 0.000000 (8.693 sec/batch), lr: 0.025000
2019-03-17 09:32:06,768 2019-03-17 09:32:06: step 713/50000, loss = 0.000000 (5.192 sec/batch), lr: 0.025000
2019-03-17 09:32:09,543 2019-03-17 09:32:09: step 714/50000, loss = 0.000000 (2.720 sec/batch), lr: 0.025000
2019-03-17 09:32:10,655 2019-03-17 09:32:10: step 715/50000, loss = 0.000000 (1.078 sec/batch), lr: 0.025000
2019-03-17 09:33:21,176 2019-03-17 09:33:21: step 716/50000, loss = 0.000000 (70.394 sec/batch), lr: 0.025000
2019-03-17 09:33:29,899 2019-03-17 09:33:29: step 717/50000, loss = 0.000000 (8.656 sec/batch), lr: 0.025000
2019-03-17 09:33:35,010 2019-03-17 09:33:35: step 718/50000, loss = 0.000000 (5.038 sec/batch), lr: 0.025000
2019-03-17 09:33:37,800 2019-03-17 09:33:37: step 719/50000, loss = 0.000000 (2.738 sec/batch), lr: 0.025000
2019-03-17 09:33:38,927 2019-03-17 09:33:38: step 720/50000, loss = 0.000000 (1.088 sec/batch), lr: 0.025000
2019-03-17 09:34:49,304 2019-03-17 09:34:49: step 721/50000, loss = 0.000000 (70.246 sec/batch), lr: 0.025000
2019-03-17 09:34:58,149 2019-03-17 09:34:58: step 722/50000, loss = 0.000000 (8.763 sec/batch), lr: 0.025000
2019-03-17 09:35:03,385 2019-03-17 09:35:03: step 723/50000, loss = 0.000000 (5.160 sec/batch), lr: 0.025000
2019-03-17 09:35:06,180 2019-03-17 09:35:06: step 724/50000, loss = 0.000000 (2.741 sec/batch), lr: 0.025000
2019-03-17 09:35:07,306 2019-03-17 09:35:07: step 725/50000, loss = 0.000000 (1.086 sec/batch), lr: 0.025000
2019-03-17 09:36:17,630 2019-03-17 09:36:17: step 726/50000, loss = 0.000000 (70.192 sec/batch), lr: 0.025000
2019-03-17 09:36:26,502 2019-03-17 09:36:26: step 727/50000, loss = 0.000000 (8.790 sec/batch), lr: 0.025000
2019-03-17 09:36:31,622 2019-03-17 09:36:31: step 728/50000, loss = 0.000000 (5.066 sec/batch), lr: 0.025000
2019-03-17 09:36:34,399 2019-03-17 09:36:34: step 729/50000, loss = 0.000000 (2.721 sec/batch), lr: 0.025000
2019-03-17 09:36:35,503 2019-03-17 09:36:35: step 730/50000, loss = 0.000000 (1.070 sec/batch), lr: 0.025000
2019-03-17 09:37:46,027 2019-03-17 09:37:46: step 731/50000, loss = 0.000000 (70.386 sec/batch), lr: 0.025000
2019-03-17 09:37:54,860 2019-03-17 09:37:54: step 732/50000, loss = 0.000000 (8.753 sec/batch), lr: 0.025000
2019-03-17 09:38:00,148 2019-03-17 09:38:00: step 733/50000, loss = 0.000000 (5.210 sec/batch), lr: 0.025000
2019-03-17 09:38:02,926 2019-03-17 09:38:02: step 734/50000, loss = 0.000000 (2.723 sec/batch), lr: 0.025000
2019-03-17 09:38:04,035 2019-03-17 09:38:04: step 735/50000, loss = 0.000000 (1.075 sec/batch), lr: 0.025000
2019-03-17 09:39:14,250 2019-03-17 09:39:14: step 736/50000, loss = 0.000000 (70.098 sec/batch), lr: 0.025000
2019-03-17 09:39:22,939 2019-03-17 09:39:22: step 737/50000, loss = 0.000000 (8.624 sec/batch), lr: 0.025000
2019-03-17 09:39:28,051 2019-03-17 09:39:28: step 738/50000, loss = 0.000000 (5.064 sec/batch), lr: 0.025000
2019-03-17 09:39:30,840 2019-03-17 09:39:30: step 739/50000, loss = 0.000000 (2.734 sec/batch), lr: 0.025000
2019-03-17 09:39:31,948 2019-03-17 09:39:31: step 740/50000, loss = 0.000000 (1.074 sec/batch), lr: 0.025000
2019-03-17 09:40:42,296 2019-03-17 09:40:42: step 741/50000, loss = 0.000000 (70.219 sec/batch), lr: 0.025000
2019-03-17 09:40:51,012 2019-03-17 09:40:51: step 742/50000, loss = 0.000000 (8.655 sec/batch), lr: 0.025000
2019-03-17 09:40:56,413 2019-03-17 09:40:56: step 743/50000, loss = 0.000000 (5.066 sec/batch), lr: 0.025000
2019-03-17 09:40:59,219 2019-03-17 09:40:59: step 744/50000, loss = 0.000000 (2.751 sec/batch), lr: 0.025000
2019-03-17 09:41:00,325 2019-03-17 09:41:00: step 745/50000, loss = 0.000000 (1.072 sec/batch), lr: 0.025000
2019-03-17 09:42:10,913 2019-03-17 09:42:10: step 746/50000, loss = 0.000000 (70.455 sec/batch), lr: 0.025000
2019-03-17 09:42:19,769 2019-03-17 09:42:19: step 747/50000, loss = 0.000000 (8.770 sec/batch), lr: 0.025000
2019-03-17 09:42:24,954 2019-03-17 09:42:24: step 748/50000, loss = 0.000000 (5.115 sec/batch), lr: 0.025000
2019-03-17 09:42:27,737 2019-03-17 09:42:27: step 749/50000, loss = 0.000000 (2.731 sec/batch), lr: 0.025000
2019-03-17 09:42:28,842 2019-03-17 09:42:28: step 750/50000, loss = 0.000000 (1.071 sec/batch), lr: 0.025000
2019-03-17 09:43:39,225 2019-03-17 09:43:39: step 751/50000, loss = 0.000000 (70.270 sec/batch), lr: 0.025000
2019-03-17 09:43:48,077 2019-03-17 09:43:48: step 752/50000, loss = 0.000000 (8.770 sec/batch), lr: 0.025000
2019-03-17 09:43:53,271 2019-03-17 09:43:53: step 753/50000, loss = 0.000000 (5.129 sec/batch), lr: 0.025000
2019-03-17 09:43:56,066 2019-03-17 09:43:56: step 754/50000, loss = 0.000000 (2.747 sec/batch), lr: 0.025000
2019-03-17 09:43:57,158 2019-03-17 09:43:57: step 755/50000, loss = 0.000000 (1.058 sec/batch), lr: 0.025000
2019-03-17 09:45:06,250 2019-03-17 09:45:06: step 756/50000, loss = 0.000000 (68.960 sec/batch), lr: 0.025000
2019-03-17 09:45:14,963 2019-03-17 09:45:14: step 757/50000, loss = 0.000000 (8.630 sec/batch), lr: 0.025000
2019-03-17 09:45:20,024 2019-03-17 09:45:20: step 758/50000, loss = 0.000000 (4.995 sec/batch), lr: 0.025000
2019-03-17 09:45:22,784 2019-03-17 09:45:22: step 759/50000, loss = 0.000000 (2.703 sec/batch), lr: 0.025000
2019-03-17 09:45:23,894 2019-03-17 09:45:23: step 760/50000, loss = 0.000000 (1.071 sec/batch), lr: 0.025000
2019-03-17 09:46:33,083 2019-03-17 09:46:33: step 761/50000, loss = 0.000000 (69.061 sec/batch), lr: 0.025000
2019-03-17 09:46:41,685 2019-03-17 09:46:41: step 762/50000, loss = 0.000000 (8.538 sec/batch), lr: 0.025000
2019-03-17 09:46:46,765 2019-03-17 09:46:46: step 763/50000, loss = 0.000000 (5.025 sec/batch), lr: 0.025000
2019-03-17 09:46:49,530 2019-03-17 09:46:49: step 764/50000, loss = 0.000000 (2.707 sec/batch), lr: 0.025000
2019-03-17 09:46:50,646 2019-03-17 09:46:50: step 765/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.025000
2019-03-17 09:48:00,489 2019-03-17 09:48:00: step 766/50000, loss = 0.000000 (69.691 sec/batch), lr: 0.025000
2019-03-17 09:48:09,234 2019-03-17 09:48:09: step 767/50000, loss = 0.000000 (8.664 sec/batch), lr: 0.025000
2019-03-17 09:48:14,465 2019-03-17 09:48:14: step 768/50000, loss = 0.000000 (5.153 sec/batch), lr: 0.025000
2019-03-17 09:48:17,237 2019-03-17 09:48:17: step 769/50000, loss = 0.000000 (2.717 sec/batch), lr: 0.025000
2019-03-17 09:48:18,303 2019-03-17 09:48:18: step 770/50000, loss = 0.000000 (1.033 sec/batch), lr: 0.025000
2019-03-17 09:49:27,952 2019-03-17 09:49:27: step 771/50000, loss = 0.000000 (69.521 sec/batch), lr: 0.025000
2019-03-17 09:49:36,739 2019-03-17 09:49:36: step 772/50000, loss = 0.000000 (8.704 sec/batch), lr: 0.025000
2019-03-17 09:49:41,820 2019-03-17 09:49:41: step 773/50000, loss = 0.000000 (5.019 sec/batch), lr: 0.025000
2019-03-17 09:49:44,527 2019-03-17 09:49:44: step 774/50000, loss = 0.000000 (2.667 sec/batch), lr: 0.025000
2019-03-17 09:49:45,630 2019-03-17 09:49:45: step 775/50000, loss = 0.000000 (1.068 sec/batch), lr: 0.025000
2019-03-17 09:50:55,403 2019-03-17 09:50:55: step 776/50000, loss = 0.000000 (69.355 sec/batch), lr: 0.025000
2019-03-17 09:51:04,177 2019-03-17 09:51:04: step 777/50000, loss = 0.000000 (8.690 sec/batch), lr: 0.025000
2019-03-17 09:51:09,260 2019-03-17 09:51:09: step 778/50000, loss = 0.000000 (5.018 sec/batch), lr: 0.025000
2019-03-17 09:51:12,018 2019-03-17 09:51:12: step 779/50000, loss = 0.000000 (2.703 sec/batch), lr: 0.025000
2019-03-17 09:51:13,114 2019-03-17 09:51:13: step 780/50000, loss = 0.000000 (1.062 sec/batch), lr: 0.025000
2019-03-17 09:52:22,750 2019-03-17 09:52:22: step 781/50000, loss = 0.000000 (69.504 sec/batch), lr: 0.025000
2019-03-17 09:52:31,494 2019-03-17 09:52:31: step 782/50000, loss = 0.000000 (8.663 sec/batch), lr: 0.025000
2019-03-17 09:52:36,568 2019-03-17 09:52:36: step 783/50000, loss = 0.000000 (5.002 sec/batch), lr: 0.025000
2019-03-17 09:52:39,317 2019-03-17 09:52:39: step 784/50000, loss = 0.000000 (2.692 sec/batch), lr: 0.025000
2019-03-17 09:52:40,438 2019-03-17 09:52:40: step 785/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.025000
2019-03-17 09:53:50,162 2019-03-17 09:53:50: step 786/50000, loss = 0.000000 (69.608 sec/batch), lr: 0.025000
2019-03-17 09:53:58,892 2019-03-17 09:53:58: step 787/50000, loss = 0.000000 (8.649 sec/batch), lr: 0.025000
2019-03-17 09:54:03,966 2019-03-17 09:54:03: step 788/50000, loss = 0.000000 (5.007 sec/batch), lr: 0.025000
2019-03-17 09:54:06,719 2019-03-17 09:54:06: step 789/50000, loss = 0.000000 (2.698 sec/batch), lr: 0.025000
2019-03-17 09:54:07,815 2019-03-17 09:54:07: step 790/50000, loss = 0.000000 (1.062 sec/batch), lr: 0.025000
2019-03-17 09:55:17,476 2019-03-17 09:55:17: step 791/50000, loss = 0.000000 (69.531 sec/batch), lr: 0.025000
2019-03-17 09:55:26,244 2019-03-17 09:55:26: step 792/50000, loss = 0.000000 (8.683 sec/batch), lr: 0.025000
2019-03-17 09:55:31,290 2019-03-17 09:55:31: step 793/50000, loss = 0.000000 (4.981 sec/batch), lr: 0.025000
2019-03-17 09:55:34,012 2019-03-17 09:55:34: step 794/50000, loss = 0.000000 (2.667 sec/batch), lr: 0.025000
2019-03-17 09:55:35,077 2019-03-17 09:55:35: step 795/50000, loss = 0.000000 (1.032 sec/batch), lr: 0.025000
2019-03-17 09:56:44,768 2019-03-17 09:56:44: step 796/50000, loss = 0.000000 (69.549 sec/batch), lr: 0.025000
2019-03-17 09:56:53,530 2019-03-17 09:56:53: step 797/50000, loss = 0.000000 (8.680 sec/batch), lr: 0.025000
2019-03-17 09:56:58,594 2019-03-17 09:56:58: step 798/50000, loss = 0.000000 (5.007 sec/batch), lr: 0.025000
2019-03-17 09:57:01,328 2019-03-17 09:57:01: step 799/50000, loss = 0.000000 (2.680 sec/batch), lr: 0.025000
2019-03-17 09:57:02,405 2019-03-17 09:57:02: step 800/50000, loss = 0.000000 (1.043 sec/batch), lr: 0.025000
2019-03-17 09:57:46,941 step 800: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 09:57:46,997 step 800: Dev acc. = 0.000000
2019-03-17 09:58:56,609 2019-03-17 09:58:56: step 801/50000, loss = 0.000000 (69.498 sec/batch), lr: 0.025000
2019-03-17 09:59:05,357 2019-03-17 09:59:05: step 802/50000, loss = 0.000000 (8.663 sec/batch), lr: 0.025000
2019-03-17 09:59:10,439 2019-03-17 09:59:10: step 803/50000, loss = 0.000000 (5.016 sec/batch), lr: 0.025000
2019-03-17 09:59:13,201 2019-03-17 09:59:13: step 804/50000, loss = 0.000000 (2.707 sec/batch), lr: 0.025000
2019-03-17 09:59:14,294 2019-03-17 09:59:14: step 805/50000, loss = 0.000000 (1.059 sec/batch), lr: 0.025000
2019-03-17 10:00:23,933 2019-03-17 10:00:23: step 806/50000, loss = 0.000000 (69.507 sec/batch), lr: 0.025000
2019-03-17 10:00:32,960 2019-03-17 10:00:32: step 807/50000, loss = 0.000000 (8.617 sec/batch), lr: 0.025000
2019-03-17 10:00:38,044 2019-03-17 10:00:38: step 808/50000, loss = 0.000000 (5.014 sec/batch), lr: 0.025000
2019-03-17 10:00:40,806 2019-03-17 10:00:40: step 809/50000, loss = 0.000000 (2.707 sec/batch), lr: 0.025000
2019-03-17 10:00:41,904 2019-03-17 10:00:41: step 810/50000, loss = 0.000000 (1.064 sec/batch), lr: 0.025000
2019-03-17 10:01:51,697 2019-03-17 10:01:51: step 811/50000, loss = 0.000000 (69.678 sec/batch), lr: 0.025000
2019-03-17 10:02:00,434 2019-03-17 10:02:00: step 812/50000, loss = 0.000000 (8.659 sec/batch), lr: 0.025000
2019-03-17 10:02:05,442 2019-03-17 10:02:05: step 813/50000, loss = 0.000000 (4.941 sec/batch), lr: 0.025000
2019-03-17 10:02:08,179 2019-03-17 10:02:08: step 814/50000, loss = 0.000000 (2.683 sec/batch), lr: 0.025000
2019-03-17 10:02:09,279 2019-03-17 10:02:09: step 815/50000, loss = 0.000000 (1.061 sec/batch), lr: 0.025000
2019-03-17 10:03:19,295 2019-03-17 10:03:19: step 816/50000, loss = 0.000000 (69.884 sec/batch), lr: 0.025000
2019-03-17 10:03:28,078 2019-03-17 10:03:28: step 817/50000, loss = 0.000000 (8.683 sec/batch), lr: 0.025000
2019-03-17 10:03:33,190 2019-03-17 10:03:33: step 818/50000, loss = 0.000000 (5.059 sec/batch), lr: 0.025000
2019-03-17 10:03:35,955 2019-03-17 10:03:35: step 819/50000, loss = 0.000000 (2.724 sec/batch), lr: 0.025000
2019-03-17 10:03:37,042 2019-03-17 10:03:37: step 820/50000, loss = 0.000000 (1.064 sec/batch), lr: 0.025000
2019-03-17 10:04:47,276 2019-03-17 10:04:47: step 821/50000, loss = 0.000000 (70.126 sec/batch), lr: 0.025000
2019-03-17 10:04:56,060 2019-03-17 10:04:56: step 822/50000, loss = 0.000000 (8.699 sec/batch), lr: 0.025000
2019-03-17 10:05:01,140 2019-03-17 10:05:01: step 823/50000, loss = 0.000000 (5.014 sec/batch), lr: 0.025000
2019-03-17 10:05:03,894 2019-03-17 10:05:03: step 824/50000, loss = 0.000000 (2.697 sec/batch), lr: 0.025000
2019-03-17 10:05:04,990 2019-03-17 10:05:04: step 825/50000, loss = 0.000000 (1.063 sec/batch), lr: 0.025000
2019-03-17 10:06:14,601 2019-03-17 10:06:14: step 826/50000, loss = 0.000000 (69.509 sec/batch), lr: 0.025000
2019-03-17 10:06:23,343 2019-03-17 10:06:23: step 827/50000, loss = 0.000000 (8.660 sec/batch), lr: 0.025000
2019-03-17 10:06:28,409 2019-03-17 10:06:28: step 828/50000, loss = 0.000000 (5.016 sec/batch), lr: 0.025000
2019-03-17 10:06:31,179 2019-03-17 10:06:31: step 829/50000, loss = 0.000000 (2.708 sec/batch), lr: 0.025000
2019-03-17 10:06:32,273 2019-03-17 10:06:32: step 830/50000, loss = 0.000000 (1.063 sec/batch), lr: 0.025000
2019-03-17 10:07:41,994 2019-03-17 10:07:41: step 831/50000, loss = 0.000000 (69.590 sec/batch), lr: 0.025000
2019-03-17 10:07:50,758 2019-03-17 10:07:50: step 832/50000, loss = 0.000000 (8.684 sec/batch), lr: 0.025000
2019-03-17 10:07:55,848 2019-03-17 10:07:55: step 833/50000, loss = 0.000000 (5.026 sec/batch), lr: 0.025000
2019-03-17 10:07:58,598 2019-03-17 10:07:58: step 834/50000, loss = 0.000000 (2.694 sec/batch), lr: 0.025000
2019-03-17 10:07:59,694 2019-03-17 10:07:59: step 835/50000, loss = 0.000000 (1.063 sec/batch), lr: 0.025000
2019-03-17 10:09:09,529 2019-03-17 10:09:09: step 836/50000, loss = 0.000000 (69.437 sec/batch), lr: 0.025000
2019-03-17 10:09:18,185 2019-03-17 10:09:18: step 837/50000, loss = 0.000000 (8.572 sec/batch), lr: 0.025000
2019-03-17 10:09:23,259 2019-03-17 10:09:23: step 838/50000, loss = 0.000000 (5.007 sec/batch), lr: 0.025000
2019-03-17 10:09:26,015 2019-03-17 10:09:26: step 839/50000, loss = 0.000000 (2.706 sec/batch), lr: 0.025000
2019-03-17 10:09:27,127 2019-03-17 10:09:27: step 840/50000, loss = 0.000000 (1.073 sec/batch), lr: 0.025000
2019-03-17 10:10:36,624 2019-03-17 10:10:36: step 841/50000, loss = 0.000000 (69.367 sec/batch), lr: 0.025000
2019-03-17 10:10:45,237 2019-03-17 10:10:45: step 842/50000, loss = 0.000000 (8.514 sec/batch), lr: 0.025000
2019-03-17 10:10:50,283 2019-03-17 10:10:50: step 843/50000, loss = 0.000000 (4.975 sec/batch), lr: 0.025000
2019-03-17 10:10:53,028 2019-03-17 10:10:53: step 844/50000, loss = 0.000000 (2.689 sec/batch), lr: 0.025000
2019-03-17 10:10:54,118 2019-03-17 10:10:54: step 845/50000, loss = 0.000000 (1.056 sec/batch), lr: 0.025000
2019-03-17 10:12:03,397 2019-03-17 10:12:03: step 846/50000, loss = 0.000000 (69.148 sec/batch), lr: 0.025000
2019-03-17 10:12:12,146 2019-03-17 10:12:12: step 847/50000, loss = 0.000000 (8.667 sec/batch), lr: 0.025000
2019-03-17 10:12:17,357 2019-03-17 10:12:17: step 848/50000, loss = 0.000000 (5.133 sec/batch), lr: 0.025000
2019-03-17 10:12:20,105 2019-03-17 10:12:20: step 849/50000, loss = 0.000000 (2.691 sec/batch), lr: 0.025000
2019-03-17 10:12:21,196 2019-03-17 10:12:21: step 850/50000, loss = 0.000000 (1.058 sec/batch), lr: 0.025000
2019-03-17 10:13:30,598 2019-03-17 10:13:30: step 851/50000, loss = 0.000000 (69.284 sec/batch), lr: 0.025000
2019-03-17 10:13:39,362 2019-03-17 10:13:39: step 852/50000, loss = 0.000000 (8.683 sec/batch), lr: 0.025000
2019-03-17 10:13:44,537 2019-03-17 10:13:44: step 853/50000, loss = 0.000000 (5.099 sec/batch), lr: 0.025000
2019-03-17 10:13:47,289 2019-03-17 10:13:47: step 854/50000, loss = 0.000000 (2.696 sec/batch), lr: 0.025000
2019-03-17 10:13:48,381 2019-03-17 10:13:48: step 855/50000, loss = 0.000000 (1.059 sec/batch), lr: 0.025000
2019-03-17 10:14:57,577 2019-03-17 10:14:57: step 856/50000, loss = 0.000000 (69.059 sec/batch), lr: 0.025000
2019-03-17 10:15:06,316 2019-03-17 10:15:06: step 857/50000, loss = 0.000000 (8.658 sec/batch), lr: 0.025000
2019-03-17 10:15:11,383 2019-03-17 10:15:11: step 858/50000, loss = 0.000000 (5.000 sec/batch), lr: 0.025000
2019-03-17 10:15:14,125 2019-03-17 10:15:14: step 859/50000, loss = 0.000000 (2.688 sec/batch), lr: 0.025000
2019-03-17 10:15:15,219 2019-03-17 10:15:15: step 860/50000, loss = 0.000000 (1.060 sec/batch), lr: 0.025000
2019-03-17 10:16:24,677 2019-03-17 10:16:24: step 861/50000, loss = 0.000000 (69.326 sec/batch), lr: 0.025000
2019-03-17 10:16:33,442 2019-03-17 10:16:33: step 862/50000, loss = 0.000000 (8.683 sec/batch), lr: 0.025000
2019-03-17 10:16:38,523 2019-03-17 10:16:38: step 863/50000, loss = 0.000000 (5.013 sec/batch), lr: 0.025000
2019-03-17 10:16:41,266 2019-03-17 10:16:41: step 864/50000, loss = 0.000000 (2.690 sec/batch), lr: 0.025000
2019-03-17 10:16:42,359 2019-03-17 10:16:42: step 865/50000, loss = 0.000000 (1.059 sec/batch), lr: 0.025000
2019-03-17 10:17:51,560 2019-03-17 10:17:51: step 866/50000, loss = 0.000000 (68.795 sec/batch), lr: 0.025000
2019-03-17 10:18:00,283 2019-03-17 10:18:00: step 867/50000, loss = 0.000000 (8.642 sec/batch), lr: 0.025000
2019-03-17 10:18:05,348 2019-03-17 10:18:05: step 868/50000, loss = 0.000000 (4.994 sec/batch), lr: 0.025000
2019-03-17 10:18:08,337 2019-03-17 10:18:08: step 869/50000, loss = 0.000000 (2.911 sec/batch), lr: 0.025000
2019-03-17 10:18:09,442 2019-03-17 10:18:09: step 870/50000, loss = 0.000000 (1.071 sec/batch), lr: 0.025000
2019-03-17 10:19:19,943 2019-03-17 10:19:19: step 871/50000, loss = 0.000000 (70.371 sec/batch), lr: 0.025000
2019-03-17 10:19:28,789 2019-03-17 10:19:28: step 872/50000, loss = 0.000000 (8.759 sec/batch), lr: 0.025000
2019-03-17 10:19:33,940 2019-03-17 10:19:33: step 873/50000, loss = 0.000000 (5.082 sec/batch), lr: 0.025000
2019-03-17 10:19:36,729 2019-03-17 10:19:36: step 874/50000, loss = 0.000000 (2.733 sec/batch), lr: 0.025000
2019-03-17 10:19:37,832 2019-03-17 10:19:37: step 875/50000, loss = 0.000000 (1.070 sec/batch), lr: 0.025000
2019-03-17 10:20:48,599 2019-03-17 10:20:48: step 876/50000, loss = 0.000000 (70.656 sec/batch), lr: 0.025000
2019-03-17 10:20:57,319 2019-03-17 10:20:57: step 877/50000, loss = 0.000000 (8.656 sec/batch), lr: 0.025000
2019-03-17 10:21:02,532 2019-03-17 10:21:02: step 878/50000, loss = 0.000000 (5.150 sec/batch), lr: 0.025000
2019-03-17 10:21:05,324 2019-03-17 10:21:05: step 879/50000, loss = 0.000000 (2.740 sec/batch), lr: 0.025000
2019-03-17 10:21:06,433 2019-03-17 10:21:06: step 880/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.025000
2019-03-17 10:22:17,217 2019-03-17 10:22:17: step 881/50000, loss = 0.000000 (70.654 sec/batch), lr: 0.025000
2019-03-17 10:22:26,145 2019-03-17 10:22:26: step 882/50000, loss = 0.000000 (8.849 sec/batch), lr: 0.025000
2019-03-17 10:22:31,322 2019-03-17 10:22:31: step 883/50000, loss = 0.000000 (5.108 sec/batch), lr: 0.025000
2019-03-17 10:22:34,133 2019-03-17 10:22:34: step 884/50000, loss = 0.000000 (2.750 sec/batch), lr: 0.025000
2019-03-17 10:22:35,262 2019-03-17 10:22:35: step 885/50000, loss = 0.000000 (1.094 sec/batch), lr: 0.025000
2019-03-17 10:23:46,157 2019-03-17 10:23:46: step 886/50000, loss = 0.000000 (70.746 sec/batch), lr: 0.025000
2019-03-17 10:23:55,039 2019-03-17 10:23:55: step 887/50000, loss = 0.000000 (8.800 sec/batch), lr: 0.025000
2019-03-17 10:24:00,216 2019-03-17 10:24:00: step 888/50000, loss = 0.000000 (5.110 sec/batch), lr: 0.025000
2019-03-17 10:24:03,011 2019-03-17 10:24:03: step 889/50000, loss = 0.000000 (2.740 sec/batch), lr: 0.025000
2019-03-17 10:24:04,123 2019-03-17 10:24:04: step 890/50000, loss = 0.000000 (1.079 sec/batch), lr: 0.025000
2019-03-17 10:25:14,780 2019-03-17 10:25:14: step 891/50000, loss = 0.000000 (70.526 sec/batch), lr: 0.025000
2019-03-17 10:25:23,646 2019-03-17 10:25:23: step 892/50000, loss = 0.000000 (8.785 sec/batch), lr: 0.025000
2019-03-17 10:25:28,969 2019-03-17 10:25:28: step 893/50000, loss = 0.000000 (5.246 sec/batch), lr: 0.025000
2019-03-17 10:25:31,779 2019-03-17 10:25:31: step 894/50000, loss = 0.000000 (2.749 sec/batch), lr: 0.025000
2019-03-17 10:25:32,913 2019-03-17 10:25:32: step 895/50000, loss = 0.000000 (1.099 sec/batch), lr: 0.025000
2019-03-17 10:26:43,865 2019-03-17 10:26:43: step 896/50000, loss = 0.000000 (70.801 sec/batch), lr: 0.025000
2019-03-17 10:26:52,762 2019-03-17 10:26:52: step 897/50000, loss = 0.000000 (8.815 sec/batch), lr: 0.025000
2019-03-17 10:26:57,920 2019-03-17 10:26:57: step 898/50000, loss = 0.000000 (5.089 sec/batch), lr: 0.025000
2019-03-17 10:27:01,001 2019-03-17 10:27:01: step 899/50000, loss = 0.000000 (3.025 sec/batch), lr: 0.025000
2019-03-17 10:27:02,111 2019-03-17 10:27:02: step 900/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.025000
2019-03-17 10:27:47,245 step 900: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 10:27:47,253 step 900: Dev acc. = 0.000000
2019-03-17 10:28:57,980 2019-03-17 10:28:57: step 901/50000, loss = 0.000000 (70.614 sec/batch), lr: 0.012500
2019-03-17 10:29:06,852 2019-03-17 10:29:06: step 902/50000, loss = 0.000000 (8.791 sec/batch), lr: 0.012500
2019-03-17 10:29:12,149 2019-03-17 10:29:12: step 903/50000, loss = 0.000000 (5.221 sec/batch), lr: 0.012500
2019-03-17 10:29:14,943 2019-03-17 10:29:14: step 904/50000, loss = 0.000000 (2.738 sec/batch), lr: 0.012500
2019-03-17 10:29:16,059 2019-03-17 10:29:16: step 905/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.012500
2019-03-17 10:30:27,108 2019-03-17 10:30:27: step 906/50000, loss = 0.000000 (70.919 sec/batch), lr: 0.012500
2019-03-17 10:30:35,865 2019-03-17 10:30:35: step 907/50000, loss = 0.000000 (8.694 sec/batch), lr: 0.012500
2019-03-17 10:30:41,058 2019-03-17 10:30:41: step 908/50000, loss = 0.000000 (5.125 sec/batch), lr: 0.012500
2019-03-17 10:30:43,885 2019-03-17 10:30:43: step 909/50000, loss = 0.000000 (2.766 sec/batch), lr: 0.012500
2019-03-17 10:30:45,018 2019-03-17 10:30:45: step 910/50000, loss = 0.000000 (1.092 sec/batch), lr: 0.012500
2019-03-17 10:31:56,007 2019-03-17 10:31:56: step 911/50000, loss = 0.000000 (70.859 sec/batch), lr: 0.012500
2019-03-17 10:32:04,876 2019-03-17 10:32:04: step 912/50000, loss = 0.000000 (8.789 sec/batch), lr: 0.012500
2019-03-17 10:32:10,034 2019-03-17 10:32:10: step 913/50000, loss = 0.000000 (5.091 sec/batch), lr: 0.012500
2019-03-17 10:32:12,834 2019-03-17 10:32:12: step 914/50000, loss = 0.000000 (2.745 sec/batch), lr: 0.012500
2019-03-17 10:32:13,947 2019-03-17 10:32:13: step 915/50000, loss = 0.000000 (1.080 sec/batch), lr: 0.012500
2019-03-17 10:33:24,674 2019-03-17 10:33:24: step 916/50000, loss = 0.000000 (70.599 sec/batch), lr: 0.012500
2019-03-17 10:33:33,626 2019-03-17 10:33:33: step 917/50000, loss = 0.000000 (8.868 sec/batch), lr: 0.012500
2019-03-17 10:33:38,811 2019-03-17 10:33:38: step 918/50000, loss = 0.000000 (5.121 sec/batch), lr: 0.012500
2019-03-17 10:33:41,620 2019-03-17 10:33:41: step 919/50000, loss = 0.000000 (2.747 sec/batch), lr: 0.012500
2019-03-17 10:33:42,737 2019-03-17 10:33:42: step 920/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.012500
2019-03-17 10:34:53,514 2019-03-17 10:34:53: step 921/50000, loss = 0.000000 (70.640 sec/batch), lr: 0.012500
2019-03-17 10:35:02,403 2019-03-17 10:35:02: step 922/50000, loss = 0.000000 (8.807 sec/batch), lr: 0.012500
2019-03-17 10:35:07,565 2019-03-17 10:35:07: step 923/50000, loss = 0.000000 (5.094 sec/batch), lr: 0.012500
2019-03-17 10:35:10,351 2019-03-17 10:35:10: step 924/50000, loss = 0.000000 (2.731 sec/batch), lr: 0.012500
2019-03-17 10:35:11,468 2019-03-17 10:35:11: step 925/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.012500
2019-03-17 10:36:22,295 2019-03-17 10:36:22: step 926/50000, loss = 0.000000 (70.697 sec/batch), lr: 0.012500
2019-03-17 10:36:31,422 2019-03-17 10:36:31: step 927/50000, loss = 0.000000 (8.729 sec/batch), lr: 0.012500
2019-03-17 10:36:36,580 2019-03-17 10:36:36: step 928/50000, loss = 0.000000 (5.090 sec/batch), lr: 0.012500
2019-03-17 10:36:39,376 2019-03-17 10:36:39: step 929/50000, loss = 0.000000 (2.741 sec/batch), lr: 0.012500
2019-03-17 10:36:40,509 2019-03-17 10:36:40: step 930/50000, loss = 0.000000 (1.098 sec/batch), lr: 0.012500
2019-03-17 10:37:51,078 2019-03-17 10:37:51: step 931/50000, loss = 0.000000 (70.417 sec/batch), lr: 0.012500
2019-03-17 10:37:59,976 2019-03-17 10:37:59: step 932/50000, loss = 0.000000 (8.817 sec/batch), lr: 0.012500
2019-03-17 10:38:05,153 2019-03-17 10:38:05: step 933/50000, loss = 0.000000 (5.110 sec/batch), lr: 0.012500
2019-03-17 10:38:07,962 2019-03-17 10:38:07: step 934/50000, loss = 0.000000 (2.748 sec/batch), lr: 0.012500
2019-03-17 10:38:09,077 2019-03-17 10:38:09: step 935/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.012500
2019-03-17 10:39:19,785 2019-03-17 10:39:19: step 936/50000, loss = 0.000000 (70.577 sec/batch), lr: 0.012500
2019-03-17 10:39:28,667 2019-03-17 10:39:28: step 937/50000, loss = 0.000000 (8.797 sec/batch), lr: 0.012500
2019-03-17 10:39:33,850 2019-03-17 10:39:33: step 938/50000, loss = 0.000000 (5.112 sec/batch), lr: 0.012500
2019-03-17 10:39:36,781 2019-03-17 10:39:36: step 939/50000, loss = 0.000000 (2.867 sec/batch), lr: 0.012500
2019-03-17 10:39:37,899 2019-03-17 10:39:37: step 940/50000, loss = 0.000000 (1.083 sec/batch), lr: 0.012500
2019-03-17 10:40:48,659 2019-03-17 10:40:48: step 941/50000, loss = 0.000000 (70.643 sec/batch), lr: 0.012500
2019-03-17 10:40:57,579 2019-03-17 10:40:57: step 942/50000, loss = 0.000000 (8.836 sec/batch), lr: 0.012500
2019-03-17 10:41:02,869 2019-03-17 10:41:02: step 943/50000, loss = 0.000000 (5.214 sec/batch), lr: 0.012500
2019-03-17 10:41:05,675 2019-03-17 10:41:05: step 944/50000, loss = 0.000000 (2.749 sec/batch), lr: 0.012500
2019-03-17 10:41:06,788 2019-03-17 10:41:06: step 945/50000, loss = 0.000000 (1.079 sec/batch), lr: 0.012500
2019-03-17 10:42:17,478 2019-03-17 10:42:17: step 946/50000, loss = 0.000000 (70.560 sec/batch), lr: 0.012500
2019-03-17 10:42:26,359 2019-03-17 10:42:26: step 947/50000, loss = 0.000000 (8.801 sec/batch), lr: 0.012500
2019-03-17 10:42:31,512 2019-03-17 10:42:31: step 948/50000, loss = 0.000000 (5.086 sec/batch), lr: 0.012500
2019-03-17 10:42:34,296 2019-03-17 10:42:34: step 949/50000, loss = 0.000000 (2.729 sec/batch), lr: 0.012500
2019-03-17 10:42:35,405 2019-03-17 10:42:35: step 950/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.012500
2019-03-17 10:43:46,134 2019-03-17 10:43:46: step 951/50000, loss = 0.000000 (70.597 sec/batch), lr: 0.012500
2019-03-17 10:43:55,021 2019-03-17 10:43:55: step 952/50000, loss = 0.000000 (8.806 sec/batch), lr: 0.012500
2019-03-17 10:44:00,169 2019-03-17 10:44:00: step 953/50000, loss = 0.000000 (5.080 sec/batch), lr: 0.012500
2019-03-17 10:44:02,964 2019-03-17 10:44:02: step 954/50000, loss = 0.000000 (2.740 sec/batch), lr: 0.012500
2019-03-17 10:44:04,076 2019-03-17 10:44:04: step 955/50000, loss = 0.000000 (1.078 sec/batch), lr: 0.012500
2019-03-17 10:45:14,817 2019-03-17 10:45:14: step 956/50000, loss = 0.000000 (70.612 sec/batch), lr: 0.012500
2019-03-17 10:45:23,694 2019-03-17 10:45:23: step 957/50000, loss = 0.000000 (8.794 sec/batch), lr: 0.012500
2019-03-17 10:45:28,874 2019-03-17 10:45:28: step 958/50000, loss = 0.000000 (5.112 sec/batch), lr: 0.012500
2019-03-17 10:45:31,663 2019-03-17 10:45:31: step 959/50000, loss = 0.000000 (2.735 sec/batch), lr: 0.012500
2019-03-17 10:45:32,770 2019-03-17 10:45:32: step 960/50000, loss = 0.000000 (1.073 sec/batch), lr: 0.012500
2019-03-17 10:46:43,877 2019-03-17 10:46:43: step 961/50000, loss = 0.000000 (70.712 sec/batch), lr: 0.012500
2019-03-17 10:46:52,768 2019-03-17 10:46:52: step 962/50000, loss = 0.000000 (8.809 sec/batch), lr: 0.012500
2019-03-17 10:46:57,952 2019-03-17 10:46:57: step 963/50000, loss = 0.000000 (5.116 sec/batch), lr: 0.012500
2019-03-17 10:47:00,744 2019-03-17 10:47:00: step 964/50000, loss = 0.000000 (2.734 sec/batch), lr: 0.012500
2019-03-17 10:47:01,858 2019-03-17 10:47:01: step 965/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.012500
2019-03-17 10:48:12,574 2019-03-17 10:48:12: step 966/50000, loss = 0.000000 (70.586 sec/batch), lr: 0.012500
2019-03-17 10:48:21,437 2019-03-17 10:48:21: step 967/50000, loss = 0.000000 (8.783 sec/batch), lr: 0.012500
2019-03-17 10:48:26,739 2019-03-17 10:48:26: step 968/50000, loss = 0.000000 (5.226 sec/batch), lr: 0.012500
2019-03-17 10:48:29,527 2019-03-17 10:48:29: step 969/50000, loss = 0.000000 (2.733 sec/batch), lr: 0.012500
2019-03-17 10:48:30,641 2019-03-17 10:48:30: step 970/50000, loss = 0.000000 (1.079 sec/batch), lr: 0.012500
2019-03-17 10:49:41,533 2019-03-17 10:49:41: step 971/50000, loss = 0.000000 (70.759 sec/batch), lr: 0.012500
2019-03-17 10:49:50,437 2019-03-17 10:49:50: step 972/50000, loss = 0.000000 (8.819 sec/batch), lr: 0.012500
2019-03-17 10:49:55,608 2019-03-17 10:49:55: step 973/50000, loss = 0.000000 (5.104 sec/batch), lr: 0.012500
2019-03-17 10:49:58,407 2019-03-17 10:49:58: step 974/50000, loss = 0.000000 (2.744 sec/batch), lr: 0.012500
2019-03-17 10:49:59,516 2019-03-17 10:49:59: step 975/50000, loss = 0.000000 (1.075 sec/batch), lr: 0.012500
2019-03-17 10:51:10,352 2019-03-17 10:51:10: step 976/50000, loss = 0.000000 (70.718 sec/batch), lr: 0.012500
2019-03-17 10:51:19,249 2019-03-17 10:51:19: step 977/50000, loss = 0.000000 (8.814 sec/batch), lr: 0.012500
2019-03-17 10:51:24,420 2019-03-17 10:51:24: step 978/50000, loss = 0.000000 (5.103 sec/batch), lr: 0.012500
2019-03-17 10:51:27,227 2019-03-17 10:51:27: step 979/50000, loss = 0.000000 (2.752 sec/batch), lr: 0.012500
2019-03-17 10:51:28,369 2019-03-17 10:51:28: step 980/50000, loss = 0.000000 (1.102 sec/batch), lr: 0.012500
2019-03-17 10:52:38,913 2019-03-17 10:52:38: step 981/50000, loss = 0.000000 (70.392 sec/batch), lr: 0.012500
2019-03-17 10:52:47,849 2019-03-17 10:52:47: step 982/50000, loss = 0.000000 (8.853 sec/batch), lr: 0.012500
2019-03-17 10:52:53,018 2019-03-17 10:52:53: step 983/50000, loss = 0.000000 (5.101 sec/batch), lr: 0.012500
2019-03-17 10:52:55,819 2019-03-17 10:52:55: step 984/50000, loss = 0.000000 (2.743 sec/batch), lr: 0.012500
2019-03-17 10:52:56,929 2019-03-17 10:52:56: step 985/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.012500
2019-03-17 10:54:07,791 2019-03-17 10:54:07: step 986/50000, loss = 0.000000 (70.729 sec/batch), lr: 0.012500
2019-03-17 10:54:16,662 2019-03-17 10:54:16: step 987/50000, loss = 0.000000 (8.790 sec/batch), lr: 0.012500
2019-03-17 10:54:21,851 2019-03-17 10:54:21: step 988/50000, loss = 0.000000 (5.123 sec/batch), lr: 0.012500
2019-03-17 10:54:24,698 2019-03-17 10:54:24: step 989/50000, loss = 0.000000 (2.790 sec/batch), lr: 0.012500
2019-03-17 10:54:25,831 2019-03-17 10:54:25: step 990/50000, loss = 0.000000 (1.099 sec/batch), lr: 0.012500
2019-03-17 10:55:37,250 2019-03-17 10:55:37: step 991/50000, loss = 0.000000 (71.024 sec/batch), lr: 0.012500
2019-03-17 10:55:46,217 2019-03-17 10:55:46: step 992/50000, loss = 0.000000 (8.883 sec/batch), lr: 0.012500
2019-03-17 10:55:51,401 2019-03-17 10:55:51: step 993/50000, loss = 0.000000 (5.114 sec/batch), lr: 0.012500
2019-03-17 10:55:54,227 2019-03-17 10:55:54: step 994/50000, loss = 0.000000 (2.770 sec/batch), lr: 0.012500
2019-03-17 10:55:55,367 2019-03-17 10:55:55: step 995/50000, loss = 0.000000 (1.105 sec/batch), lr: 0.012500
2019-03-17 10:57:06,270 2019-03-17 10:57:06: step 996/50000, loss = 0.000000 (70.769 sec/batch), lr: 0.012500
2019-03-17 10:57:15,177 2019-03-17 10:57:15: step 997/50000, loss = 0.000000 (8.826 sec/batch), lr: 0.012500
2019-03-17 10:57:20,340 2019-03-17 10:57:20: step 998/50000, loss = 0.000000 (5.098 sec/batch), lr: 0.012500
2019-03-17 10:57:23,122 2019-03-17 10:57:23: step 999/50000, loss = 0.000000 (2.728 sec/batch), lr: 0.012500
2019-03-17 10:57:24,242 2019-03-17 10:57:24: step 1000/50000, loss = 0.000000 (1.085 sec/batch), lr: 0.012500
2019-03-17 10:58:09,431 step 1000: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 10:58:09,438 step 1000: Dev acc. = 0.000000
2019-03-17 10:59:20,189 2019-03-17 10:59:20: step 1001/50000, loss = 0.000000 (70.636 sec/batch), lr: 0.012500
2019-03-17 10:59:29,121 2019-03-17 10:59:29: step 1002/50000, loss = 0.000000 (8.849 sec/batch), lr: 0.012500
2019-03-17 10:59:34,303 2019-03-17 10:59:34: step 1003/50000, loss = 0.000000 (5.111 sec/batch), lr: 0.012500
2019-03-17 10:59:37,100 2019-03-17 10:59:37: step 1004/50000, loss = 0.000000 (2.742 sec/batch), lr: 0.012500
2019-03-17 10:59:38,222 2019-03-17 10:59:38: step 1005/50000, loss = 0.000000 (1.087 sec/batch), lr: 0.012500
2019-03-17 11:00:48,908 2019-03-17 11:00:48: step 1006/50000, loss = 0.000000 (70.546 sec/batch), lr: 0.012500
2019-03-17 11:00:57,802 2019-03-17 11:00:57: step 1007/50000, loss = 0.000000 (8.813 sec/batch), lr: 0.012500
2019-03-17 11:01:02,963 2019-03-17 11:01:02: step 1008/50000, loss = 0.000000 (5.090 sec/batch), lr: 0.012500
2019-03-17 11:01:05,770 2019-03-17 11:01:05: step 1009/50000, loss = 0.000000 (2.750 sec/batch), lr: 0.012500
2019-03-17 11:01:06,887 2019-03-17 11:01:06: step 1010/50000, loss = 0.000000 (1.084 sec/batch), lr: 0.012500
2019-03-17 11:02:17,660 2019-03-17 11:02:17: step 1011/50000, loss = 0.000000 (70.642 sec/batch), lr: 0.012500
2019-03-17 11:02:26,543 2019-03-17 11:02:26: step 1012/50000, loss = 0.000000 (8.803 sec/batch), lr: 0.012500
2019-03-17 11:02:31,709 2019-03-17 11:02:31: step 1013/50000, loss = 0.000000 (5.099 sec/batch), lr: 0.012500
2019-03-17 11:02:34,512 2019-03-17 11:02:34: step 1014/50000, loss = 0.000000 (2.748 sec/batch), lr: 0.012500
2019-03-17 11:02:35,627 2019-03-17 11:02:35: step 1015/50000, loss = 0.000000 (1.080 sec/batch), lr: 0.012500
2019-03-17 11:03:46,402 2019-03-17 11:03:46: step 1016/50000, loss = 0.000000 (70.658 sec/batch), lr: 0.012500
2019-03-17 11:03:55,361 2019-03-17 11:03:55: step 1017/50000, loss = 0.000000 (8.873 sec/batch), lr: 0.012500
2019-03-17 11:04:00,558 2019-03-17 11:04:00: step 1018/50000, loss = 0.000000 (5.129 sec/batch), lr: 0.012500
2019-03-17 11:04:03,351 2019-03-17 11:04:03: step 1019/50000, loss = 0.000000 (2.737 sec/batch), lr: 0.012500
2019-03-17 11:04:04,467 2019-03-17 11:04:04: step 1020/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.012500
2019-03-17 11:05:15,135 2019-03-17 11:05:15: step 1021/50000, loss = 0.000000 (70.256 sec/batch), lr: 0.012500
2019-03-17 11:05:23,960 2019-03-17 11:05:23: step 1022/50000, loss = 0.000000 (8.763 sec/batch), lr: 0.012500
2019-03-17 11:05:29,178 2019-03-17 11:05:29: step 1023/50000, loss = 0.000000 (5.147 sec/batch), lr: 0.012500
2019-03-17 11:05:32,121 2019-03-17 11:05:32: step 1024/50000, loss = 0.000000 (2.879 sec/batch), lr: 0.012500
2019-03-17 11:05:33,235 2019-03-17 11:05:33: step 1025/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.012500
2019-03-17 11:06:44,261 2019-03-17 11:06:44: step 1026/50000, loss = 0.000000 (70.906 sec/batch), lr: 0.012500
2019-03-17 11:06:53,222 2019-03-17 11:06:53: step 1027/50000, loss = 0.000000 (8.878 sec/batch), lr: 0.012500
2019-03-17 11:06:58,399 2019-03-17 11:06:58: step 1028/50000, loss = 0.000000 (5.108 sec/batch), lr: 0.012500
2019-03-17 11:07:01,209 2019-03-17 11:07:01: step 1029/50000, loss = 0.000000 (2.752 sec/batch), lr: 0.012500
2019-03-17 11:07:02,327 2019-03-17 11:07:02: step 1030/50000, loss = 0.000000 (1.084 sec/batch), lr: 0.012500
2019-03-17 11:08:13,669 2019-03-17 11:08:13: step 1031/50000, loss = 0.000000 (71.210 sec/batch), lr: 0.012500
2019-03-17 11:08:22,629 2019-03-17 11:08:22: step 1032/50000, loss = 0.000000 (8.879 sec/batch), lr: 0.012500
2019-03-17 11:08:27,812 2019-03-17 11:08:27: step 1033/50000, loss = 0.000000 (5.116 sec/batch), lr: 0.012500
2019-03-17 11:08:30,629 2019-03-17 11:08:30: step 1034/50000, loss = 0.000000 (2.762 sec/batch), lr: 0.012500
2019-03-17 11:08:31,752 2019-03-17 11:08:31: step 1035/50000, loss = 0.000000 (1.090 sec/batch), lr: 0.012500
2019-03-17 11:09:42,833 2019-03-17 11:09:42: step 1036/50000, loss = 0.000000 (70.947 sec/batch), lr: 0.012500
2019-03-17 11:09:51,827 2019-03-17 11:09:51: step 1037/50000, loss = 0.000000 (8.910 sec/batch), lr: 0.012500
2019-03-17 11:09:57,011 2019-03-17 11:09:57: step 1038/50000, loss = 0.000000 (5.118 sec/batch), lr: 0.012500
2019-03-17 11:09:59,818 2019-03-17 11:09:59: step 1039/50000, loss = 0.000000 (2.754 sec/batch), lr: 0.012500
2019-03-17 11:10:00,943 2019-03-17 11:10:00: step 1040/50000, loss = 0.000000 (1.090 sec/batch), lr: 0.012500
2019-03-17 11:11:12,415 2019-03-17 11:11:12: step 1041/50000, loss = 0.000000 (71.341 sec/batch), lr: 0.012500
2019-03-17 11:11:21,343 2019-03-17 11:11:21: step 1042/50000, loss = 0.000000 (8.846 sec/batch), lr: 0.012500
2019-03-17 11:11:26,547 2019-03-17 11:11:26: step 1043/50000, loss = 0.000000 (5.135 sec/batch), lr: 0.012500
2019-03-17 11:11:29,359 2019-03-17 11:11:29: step 1044/50000, loss = 0.000000 (2.758 sec/batch), lr: 0.012500
2019-03-17 11:11:30,492 2019-03-17 11:11:30: step 1045/50000, loss = 0.000000 (1.098 sec/batch), lr: 0.012500
2019-03-17 11:12:41,348 2019-03-17 11:12:41: step 1046/50000, loss = 0.000000 (70.703 sec/batch), lr: 0.012500
2019-03-17 11:12:50,369 2019-03-17 11:12:50: step 1047/50000, loss = 0.000000 (8.939 sec/batch), lr: 0.012500
2019-03-17 11:12:55,561 2019-03-17 11:12:55: step 1048/50000, loss = 0.000000 (5.120 sec/batch), lr: 0.012500
2019-03-17 11:12:58,361 2019-03-17 11:12:58: step 1049/50000, loss = 0.000000 (2.746 sec/batch), lr: 0.012500
2019-03-17 11:12:59,473 2019-03-17 11:12:59: step 1050/50000, loss = 0.000000 (1.078 sec/batch), lr: 0.012500
2019-03-17 11:14:10,536 2019-03-17 11:14:10: step 1051/50000, loss = 0.000000 (70.930 sec/batch), lr: 0.012500
2019-03-17 11:14:19,761 2019-03-17 11:14:19: step 1052/50000, loss = 0.000000 (8.826 sec/batch), lr: 0.012500
2019-03-17 11:14:24,968 2019-03-17 11:14:24: step 1053/50000, loss = 0.000000 (5.140 sec/batch), lr: 0.012500
2019-03-17 11:14:27,782 2019-03-17 11:14:27: step 1054/50000, loss = 0.000000 (2.757 sec/batch), lr: 0.012500
2019-03-17 11:14:28,897 2019-03-17 11:14:28: step 1055/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.012500
2019-03-17 11:15:40,042 2019-03-17 11:15:40: step 1056/50000, loss = 0.000000 (71.018 sec/batch), lr: 0.012500
2019-03-17 11:15:49,008 2019-03-17 11:15:49: step 1057/50000, loss = 0.000000 (8.883 sec/batch), lr: 0.012500
2019-03-17 11:15:54,201 2019-03-17 11:15:54: step 1058/50000, loss = 0.000000 (5.129 sec/batch), lr: 0.012500
2019-03-17 11:15:57,007 2019-03-17 11:15:57: step 1059/50000, loss = 0.000000 (2.750 sec/batch), lr: 0.012500
2019-03-17 11:15:58,123 2019-03-17 11:15:58: step 1060/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.012500
2019-03-17 11:17:09,487 2019-03-17 11:17:09: step 1061/50000, loss = 0.000000 (71.233 sec/batch), lr: 0.012500
2019-03-17 11:17:18,436 2019-03-17 11:17:18: step 1062/50000, loss = 0.000000 (8.866 sec/batch), lr: 0.012500
2019-03-17 11:17:23,633 2019-03-17 11:17:23: step 1063/50000, loss = 0.000000 (5.126 sec/batch), lr: 0.012500
2019-03-17 11:17:26,442 2019-03-17 11:17:26: step 1064/50000, loss = 0.000000 (2.753 sec/batch), lr: 0.012500
2019-03-17 11:17:27,563 2019-03-17 11:17:27: step 1065/50000, loss = 0.000000 (1.086 sec/batch), lr: 0.012500
2019-03-17 11:18:38,830 2019-03-17 11:18:38: step 1066/50000, loss = 0.000000 (71.134 sec/batch), lr: 0.012500
2019-03-17 11:18:47,813 2019-03-17 11:18:47: step 1067/50000, loss = 0.000000 (8.902 sec/batch), lr: 0.012500
2019-03-17 11:18:53,025 2019-03-17 11:18:53: step 1068/50000, loss = 0.000000 (5.144 sec/batch), lr: 0.012500
2019-03-17 11:18:55,833 2019-03-17 11:18:55: step 1069/50000, loss = 0.000000 (2.752 sec/batch), lr: 0.012500
2019-03-17 11:18:56,953 2019-03-17 11:18:56: step 1070/50000, loss = 0.000000 (1.085 sec/batch), lr: 0.012500
2019-03-17 11:20:08,140 2019-03-17 11:20:08: step 1071/50000, loss = 0.000000 (71.054 sec/batch), lr: 0.012500
2019-03-17 11:20:17,107 2019-03-17 11:20:17: step 1072/50000, loss = 0.000000 (8.886 sec/batch), lr: 0.012500
2019-03-17 11:20:22,307 2019-03-17 11:20:22: step 1073/50000, loss = 0.000000 (5.131 sec/batch), lr: 0.012500
2019-03-17 11:20:25,109 2019-03-17 11:20:25: step 1074/50000, loss = 0.000000 (2.746 sec/batch), lr: 0.012500
2019-03-17 11:20:26,241 2019-03-17 11:20:26: step 1075/50000, loss = 0.000000 (1.097 sec/batch), lr: 0.012500
2019-03-17 11:21:37,428 2019-03-17 11:21:37: step 1076/50000, loss = 0.000000 (71.033 sec/batch), lr: 0.012500
2019-03-17 11:21:46,382 2019-03-17 11:21:46: step 1077/50000, loss = 0.000000 (8.869 sec/batch), lr: 0.012500
2019-03-17 11:21:51,548 2019-03-17 11:21:51: step 1078/50000, loss = 0.000000 (5.098 sec/batch), lr: 0.012500
2019-03-17 11:21:54,424 2019-03-17 11:21:54: step 1079/50000, loss = 0.000000 (2.828 sec/batch), lr: 0.012500
2019-03-17 11:21:55,543 2019-03-17 11:21:55: step 1080/50000, loss = 0.000000 (1.083 sec/batch), lr: 0.012500
2019-03-17 11:23:06,200 2019-03-17 11:23:06: step 1081/50000, loss = 0.000000 (70.527 sec/batch), lr: 0.012500
2019-03-17 11:23:15,257 2019-03-17 11:23:15: step 1082/50000, loss = 0.000000 (8.715 sec/batch), lr: 0.012500
2019-03-17 11:23:20,425 2019-03-17 11:23:20: step 1083/50000, loss = 0.000000 (5.100 sec/batch), lr: 0.012500
2019-03-17 11:23:23,224 2019-03-17 11:23:23: step 1084/50000, loss = 0.000000 (2.736 sec/batch), lr: 0.012500
2019-03-17 11:23:24,330 2019-03-17 11:23:24: step 1085/50000, loss = 0.000000 (1.072 sec/batch), lr: 0.012500
2019-03-17 11:24:35,064 2019-03-17 11:24:35: step 1086/50000, loss = 0.000000 (70.603 sec/batch), lr: 0.012500
2019-03-17 11:24:43,760 2019-03-17 11:24:43: step 1087/50000, loss = 0.000000 (8.635 sec/batch), lr: 0.012500
2019-03-17 11:24:48,892 2019-03-17 11:24:48: step 1088/50000, loss = 0.000000 (5.065 sec/batch), lr: 0.012500
2019-03-17 11:24:51,669 2019-03-17 11:24:51: step 1089/50000, loss = 0.000000 (2.720 sec/batch), lr: 0.012500
2019-03-17 11:24:52,776 2019-03-17 11:24:52: step 1090/50000, loss = 0.000000 (1.073 sec/batch), lr: 0.012500
2019-03-17 11:26:03,276 2019-03-17 11:26:03: step 1091/50000, loss = 0.000000 (70.364 sec/batch), lr: 0.012500
2019-03-17 11:26:12,098 2019-03-17 11:26:12: step 1092/50000, loss = 0.000000 (8.740 sec/batch), lr: 0.012500
2019-03-17 11:26:17,331 2019-03-17 11:26:17: step 1093/50000, loss = 0.000000 (5.156 sec/batch), lr: 0.012500
2019-03-17 11:26:20,108 2019-03-17 11:26:20: step 1094/50000, loss = 0.000000 (2.722 sec/batch), lr: 0.012500
2019-03-17 11:26:21,226 2019-03-17 11:26:21: step 1095/50000, loss = 0.000000 (1.083 sec/batch), lr: 0.012500
2019-03-17 11:27:31,537 2019-03-17 11:27:31: step 1096/50000, loss = 0.000000 (70.180 sec/batch), lr: 0.012500
2019-03-17 11:27:40,397 2019-03-17 11:27:40: step 1097/50000, loss = 0.000000 (8.776 sec/batch), lr: 0.012500
2019-03-17 11:27:45,528 2019-03-17 11:27:45: step 1098/50000, loss = 0.000000 (5.064 sec/batch), lr: 0.012500
2019-03-17 11:27:48,302 2019-03-17 11:27:48: step 1099/50000, loss = 0.000000 (2.718 sec/batch), lr: 0.012500
2019-03-17 11:27:49,409 2019-03-17 11:27:49: step 1100/50000, loss = 0.000000 (1.074 sec/batch), lr: 0.012500
2019-03-17 11:28:34,450 step 1100: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 11:28:34,505 step 1100: Dev acc. = 0.000000
2019-03-17 11:29:44,986 2019-03-17 11:29:44: step 1101/50000, loss = 0.000000 (70.368 sec/batch), lr: 0.012500
2019-03-17 11:29:53,825 2019-03-17 11:29:53: step 1102/50000, loss = 0.000000 (8.756 sec/batch), lr: 0.012500
2019-03-17 11:29:59,014 2019-03-17 11:29:59: step 1103/50000, loss = 0.000000 (5.126 sec/batch), lr: 0.012500
2019-03-17 11:30:02,017 2019-03-17 11:30:02: step 1104/50000, loss = 0.000000 (2.921 sec/batch), lr: 0.012500
2019-03-17 11:30:03,130 2019-03-17 11:30:03: step 1105/50000, loss = 0.000000 (1.079 sec/batch), lr: 0.012500
2019-03-17 11:31:13,472 2019-03-17 11:31:13: step 1106/50000, loss = 0.000000 (70.215 sec/batch), lr: 0.012500
2019-03-17 11:31:22,225 2019-03-17 11:31:22: step 1107/50000, loss = 0.000000 (8.691 sec/batch), lr: 0.012500
2019-03-17 11:31:27,373 2019-03-17 11:31:27: step 1108/50000, loss = 0.000000 (5.082 sec/batch), lr: 0.012500
2019-03-17 11:31:30,166 2019-03-17 11:31:30: step 1109/50000, loss = 0.000000 (2.738 sec/batch), lr: 0.012500
2019-03-17 11:31:31,289 2019-03-17 11:31:31: step 1110/50000, loss = 0.000000 (1.088 sec/batch), lr: 0.012500
2019-03-17 11:32:42,362 2019-03-17 11:32:42: step 1111/50000, loss = 0.000000 (70.670 sec/batch), lr: 0.012500
2019-03-17 11:32:51,112 2019-03-17 11:32:51: step 1112/50000, loss = 0.000000 (8.678 sec/batch), lr: 0.012500
2019-03-17 11:32:56,245 2019-03-17 11:32:56: step 1113/50000, loss = 0.000000 (5.084 sec/batch), lr: 0.012500
2019-03-17 11:32:59,018 2019-03-17 11:32:59: step 1114/50000, loss = 0.000000 (2.718 sec/batch), lr: 0.012500
2019-03-17 11:33:00,126 2019-03-17 11:33:00: step 1115/50000, loss = 0.000000 (1.074 sec/batch), lr: 0.012500
2019-03-17 11:34:10,869 2019-03-17 11:34:10: step 1116/50000, loss = 0.000000 (70.624 sec/batch), lr: 0.012500
2019-03-17 11:34:19,601 2019-03-17 11:34:19: step 1117/50000, loss = 0.000000 (8.668 sec/batch), lr: 0.012500
2019-03-17 11:34:24,776 2019-03-17 11:34:24: step 1118/50000, loss = 0.000000 (5.107 sec/batch), lr: 0.012500
2019-03-17 11:34:27,699 2019-03-17 11:34:27: step 1119/50000, loss = 0.000000 (2.858 sec/batch), lr: 0.012500
2019-03-17 11:34:28,813 2019-03-17 11:34:28: step 1120/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.012500
2019-03-17 11:35:39,423 2019-03-17 11:35:39: step 1121/50000, loss = 0.000000 (70.479 sec/batch), lr: 0.012500
2019-03-17 11:35:48,319 2019-03-17 11:35:48: step 1122/50000, loss = 0.000000 (8.815 sec/batch), lr: 0.012500
2019-03-17 11:35:53,460 2019-03-17 11:35:53: step 1123/50000, loss = 0.000000 (5.069 sec/batch), lr: 0.012500
2019-03-17 11:35:56,241 2019-03-17 11:35:56: step 1124/50000, loss = 0.000000 (2.730 sec/batch), lr: 0.012500
2019-03-17 11:35:57,350 2019-03-17 11:35:57: step 1125/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.012500
2019-03-17 11:37:07,778 2019-03-17 11:37:07: step 1126/50000, loss = 0.000000 (70.297 sec/batch), lr: 0.012500
2019-03-17 11:37:16,660 2019-03-17 11:37:16: step 1127/50000, loss = 0.000000 (8.799 sec/batch), lr: 0.012500
2019-03-17 11:37:21,809 2019-03-17 11:37:21: step 1128/50000, loss = 0.000000 (5.084 sec/batch), lr: 0.012500
2019-03-17 11:37:24,610 2019-03-17 11:37:24: step 1129/50000, loss = 0.000000 (2.745 sec/batch), lr: 0.012500
2019-03-17 11:37:25,728 2019-03-17 11:37:25: step 1130/50000, loss = 0.000000 (1.084 sec/batch), lr: 0.012500
2019-03-17 11:38:36,564 2019-03-17 11:38:36: step 1131/50000, loss = 0.000000 (70.703 sec/batch), lr: 0.012500
2019-03-17 11:38:45,448 2019-03-17 11:38:45: step 1132/50000, loss = 0.000000 (8.803 sec/batch), lr: 0.012500
2019-03-17 11:38:50,577 2019-03-17 11:38:50: step 1133/50000, loss = 0.000000 (5.061 sec/batch), lr: 0.012500
2019-03-17 11:38:53,366 2019-03-17 11:38:53: step 1134/50000, loss = 0.000000 (2.734 sec/batch), lr: 0.012500
2019-03-17 11:38:54,467 2019-03-17 11:38:54: step 1135/50000, loss = 0.000000 (1.067 sec/batch), lr: 0.012500
2019-03-17 11:40:05,233 2019-03-17 11:40:05: step 1136/50000, loss = 0.000000 (70.642 sec/batch), lr: 0.012500
2019-03-17 11:40:14,137 2019-03-17 11:40:14: step 1137/50000, loss = 0.000000 (8.820 sec/batch), lr: 0.012500
2019-03-17 11:40:19,297 2019-03-17 11:40:19: step 1138/50000, loss = 0.000000 (5.087 sec/batch), lr: 0.012500
2019-03-17 11:40:22,069 2019-03-17 11:40:22: step 1139/50000, loss = 0.000000 (2.715 sec/batch), lr: 0.012500
2019-03-17 11:40:23,140 2019-03-17 11:40:23: step 1140/50000, loss = 0.000000 (1.049 sec/batch), lr: 0.012500
2019-03-17 11:41:33,582 2019-03-17 11:41:33: step 1141/50000, loss = 0.000000 (70.312 sec/batch), lr: 0.012500
2019-03-17 11:41:42,488 2019-03-17 11:41:42: step 1142/50000, loss = 0.000000 (8.824 sec/batch), lr: 0.012500
2019-03-17 11:41:47,634 2019-03-17 11:41:47: step 1143/50000, loss = 0.000000 (5.082 sec/batch), lr: 0.012500
2019-03-17 11:41:50,715 2019-03-17 11:41:50: step 1144/50000, loss = 0.000000 (2.737 sec/batch), lr: 0.012500
2019-03-17 11:41:51,827 2019-03-17 11:41:51: step 1145/50000, loss = 0.000000 (1.078 sec/batch), lr: 0.012500
2019-03-17 11:43:02,587 2019-03-17 11:43:02: step 1146/50000, loss = 0.000000 (70.630 sec/batch), lr: 0.012500
2019-03-17 11:43:11,476 2019-03-17 11:43:11: step 1147/50000, loss = 0.000000 (8.809 sec/batch), lr: 0.012500
2019-03-17 11:43:16,637 2019-03-17 11:43:16: step 1148/50000, loss = 0.000000 (5.095 sec/batch), lr: 0.012500
2019-03-17 11:43:19,431 2019-03-17 11:43:19: step 1149/50000, loss = 0.000000 (2.738 sec/batch), lr: 0.012500
2019-03-17 11:43:20,550 2019-03-17 11:43:20: step 1150/50000, loss = 0.000000 (1.085 sec/batch), lr: 0.012500
2019-03-17 11:44:31,244 2019-03-17 11:44:31: step 1151/50000, loss = 0.000000 (70.579 sec/batch), lr: 0.012500
2019-03-17 11:44:40,166 2019-03-17 11:44:40: step 1152/50000, loss = 0.000000 (8.799 sec/batch), lr: 0.012500
2019-03-17 11:44:45,305 2019-03-17 11:44:45: step 1153/50000, loss = 0.000000 (5.069 sec/batch), lr: 0.012500
2019-03-17 11:44:48,062 2019-03-17 11:44:48: step 1154/50000, loss = 0.000000 (2.701 sec/batch), lr: 0.012500
2019-03-17 11:44:49,172 2019-03-17 11:44:49: step 1155/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.012500
2019-03-17 11:46:00,037 2019-03-17 11:46:00: step 1156/50000, loss = 0.000000 (70.732 sec/batch), lr: 0.012500
2019-03-17 11:46:08,735 2019-03-17 11:46:08: step 1157/50000, loss = 0.000000 (8.617 sec/batch), lr: 0.012500
2019-03-17 11:46:13,871 2019-03-17 11:46:13: step 1158/50000, loss = 0.000000 (5.083 sec/batch), lr: 0.012500
2019-03-17 11:46:16,606 2019-03-17 11:46:16: step 1159/50000, loss = 0.000000 (2.681 sec/batch), lr: 0.012500
2019-03-17 11:46:17,682 2019-03-17 11:46:17: step 1160/50000, loss = 0.000000 (1.042 sec/batch), lr: 0.012500
2019-03-17 11:47:27,072 2019-03-17 11:47:27: step 1161/50000, loss = 0.000000 (69.273 sec/batch), lr: 0.012500
2019-03-17 11:47:35,760 2019-03-17 11:47:35: step 1162/50000, loss = 0.000000 (8.604 sec/batch), lr: 0.012500
2019-03-17 11:47:40,813 2019-03-17 11:47:40: step 1163/50000, loss = 0.000000 (4.989 sec/batch), lr: 0.012500
2019-03-17 11:47:43,574 2019-03-17 11:47:43: step 1164/50000, loss = 0.000000 (2.704 sec/batch), lr: 0.012500
2019-03-17 11:47:44,683 2019-03-17 11:47:44: step 1165/50000, loss = 0.000000 (1.070 sec/batch), lr: 0.012500
2019-03-17 11:48:53,787 2019-03-17 11:48:53: step 1166/50000, loss = 0.000000 (68.971 sec/batch), lr: 0.012500
2019-03-17 11:49:02,524 2019-03-17 11:49:02: step 1167/50000, loss = 0.000000 (8.655 sec/batch), lr: 0.012500
2019-03-17 11:49:07,703 2019-03-17 11:49:07: step 1168/50000, loss = 0.000000 (5.102 sec/batch), lr: 0.012500
2019-03-17 11:49:10,444 2019-03-17 11:49:10: step 1169/50000, loss = 0.000000 (2.682 sec/batch), lr: 0.012500
2019-03-17 11:49:11,537 2019-03-17 11:49:11: step 1170/50000, loss = 0.000000 (1.060 sec/batch), lr: 0.012500
2019-03-17 11:50:20,753 2019-03-17 11:50:20: step 1171/50000, loss = 0.000000 (69.085 sec/batch), lr: 0.012500
2019-03-17 11:50:29,503 2019-03-17 11:50:29: step 1172/50000, loss = 0.000000 (8.668 sec/batch), lr: 0.012500
2019-03-17 11:50:34,832 2019-03-17 11:50:34: step 1173/50000, loss = 0.000000 (4.998 sec/batch), lr: 0.012500
2019-03-17 11:50:37,595 2019-03-17 11:50:37: step 1174/50000, loss = 0.000000 (2.709 sec/batch), lr: 0.012500
2019-03-17 11:50:38,696 2019-03-17 11:50:38: step 1175/50000, loss = 0.000000 (1.061 sec/batch), lr: 0.012500
2019-03-17 11:51:47,902 2019-03-17 11:51:47: step 1176/50000, loss = 0.000000 (69.064 sec/batch), lr: 0.012500
2019-03-17 11:51:56,632 2019-03-17 11:51:56: step 1177/50000, loss = 0.000000 (8.649 sec/batch), lr: 0.012500
2019-03-17 11:52:01,685 2019-03-17 11:52:01: step 1178/50000, loss = 0.000000 (4.983 sec/batch), lr: 0.012500
2019-03-17 11:52:04,435 2019-03-17 11:52:04: step 1179/50000, loss = 0.000000 (2.693 sec/batch), lr: 0.012500
2019-03-17 11:52:05,670 2019-03-17 11:52:05: step 1180/50000, loss = 0.000000 (1.196 sec/batch), lr: 0.012500
2019-03-17 11:53:15,424 2019-03-17 11:53:15: step 1181/50000, loss = 0.000000 (69.622 sec/batch), lr: 0.012500
2019-03-17 11:53:24,176 2019-03-17 11:53:24: step 1182/50000, loss = 0.000000 (8.670 sec/batch), lr: 0.012500
2019-03-17 11:53:29,255 2019-03-17 11:53:29: step 1183/50000, loss = 0.000000 (5.011 sec/batch), lr: 0.012500
2019-03-17 11:53:31,998 2019-03-17 11:53:31: step 1184/50000, loss = 0.000000 (2.697 sec/batch), lr: 0.012500
2019-03-17 11:53:33,080 2019-03-17 11:53:33: step 1185/50000, loss = 0.000000 (1.048 sec/batch), lr: 0.012500
2019-03-17 11:54:42,838 2019-03-17 11:54:42: step 1186/50000, loss = 0.000000 (69.624 sec/batch), lr: 0.012500
2019-03-17 11:54:51,453 2019-03-17 11:54:51: step 1187/50000, loss = 0.000000 (8.552 sec/batch), lr: 0.012500
2019-03-17 11:54:56,507 2019-03-17 11:54:56: step 1188/50000, loss = 0.000000 (5.004 sec/batch), lr: 0.012500
2019-03-17 11:54:59,236 2019-03-17 11:54:59: step 1189/50000, loss = 0.000000 (2.684 sec/batch), lr: 0.012500
2019-03-17 11:55:00,311 2019-03-17 11:55:00: step 1190/50000, loss = 0.000000 (1.053 sec/batch), lr: 0.012500
2019-03-17 11:56:09,999 2019-03-17 11:56:09: step 1191/50000, loss = 0.000000 (69.556 sec/batch), lr: 0.012500
2019-03-17 11:56:18,758 2019-03-17 11:56:18: step 1192/50000, loss = 0.000000 (8.678 sec/batch), lr: 0.012500
2019-03-17 11:56:23,847 2019-03-17 11:56:23: step 1193/50000, loss = 0.000000 (5.020 sec/batch), lr: 0.012500
2019-03-17 11:56:26,601 2019-03-17 11:56:26: step 1194/50000, loss = 0.000000 (2.693 sec/batch), lr: 0.012500
2019-03-17 11:56:27,699 2019-03-17 11:56:27: step 1195/50000, loss = 0.000000 (1.065 sec/batch), lr: 0.012500
2019-03-17 11:57:37,232 2019-03-17 11:57:37: step 1196/50000, loss = 0.000000 (69.395 sec/batch), lr: 0.012500
2019-03-17 11:57:45,974 2019-03-17 11:57:45: step 1197/50000, loss = 0.000000 (8.658 sec/batch), lr: 0.012500
2019-03-17 11:57:51,043 2019-03-17 11:57:51: step 1198/50000, loss = 0.000000 (5.004 sec/batch), lr: 0.012500
2019-03-17 11:57:53,777 2019-03-17 11:57:53: step 1199/50000, loss = 0.000000 (2.679 sec/batch), lr: 0.012500
2019-03-17 11:57:54,868 2019-03-17 11:57:54: step 1200/50000, loss = 0.000000 (1.058 sec/batch), lr: 0.012500
2019-03-17 11:58:39,125 step 1200: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 11:58:39,181 step 1200: Dev acc. = 0.000000
2019-03-17 11:59:48,411 2019-03-17 11:59:48: step 1201/50000, loss = 0.000000 (69.116 sec/batch), lr: 0.006250
2019-03-17 11:59:57,410 2019-03-17 11:59:57: step 1202/50000, loss = 0.000000 (8.605 sec/batch), lr: 0.006250
2019-03-17 12:00:02,603 2019-03-17 12:00:02: step 1203/50000, loss = 0.000000 (5.117 sec/batch), lr: 0.006250
2019-03-17 12:00:05,355 2019-03-17 12:00:05: step 1204/50000, loss = 0.000000 (2.696 sec/batch), lr: 0.006250
2019-03-17 12:00:06,434 2019-03-17 12:00:06: step 1205/50000, loss = 0.000000 (1.046 sec/batch), lr: 0.006250
2019-03-17 12:01:15,753 2019-03-17 12:01:15: step 1206/50000, loss = 0.000000 (69.190 sec/batch), lr: 0.006250
2019-03-17 12:01:24,493 2019-03-17 12:01:24: step 1207/50000, loss = 0.000000 (8.654 sec/batch), lr: 0.006250
2019-03-17 12:01:29,527 2019-03-17 12:01:29: step 1208/50000, loss = 0.000000 (4.971 sec/batch), lr: 0.006250
2019-03-17 12:01:32,278 2019-03-17 12:01:32: step 1209/50000, loss = 0.000000 (2.696 sec/batch), lr: 0.006250
2019-03-17 12:01:33,380 2019-03-17 12:01:33: step 1210/50000, loss = 0.000000 (1.068 sec/batch), lr: 0.006250
2019-03-17 12:02:43,950 2019-03-17 12:02:43: step 1211/50000, loss = 0.000000 (70.431 sec/batch), lr: 0.006250
2019-03-17 12:02:52,713 2019-03-17 12:02:52: step 1212/50000, loss = 0.000000 (8.698 sec/batch), lr: 0.006250
2019-03-17 12:02:57,980 2019-03-17 12:02:57: step 1213/50000, loss = 0.000000 (5.190 sec/batch), lr: 0.006250
2019-03-17 12:03:00,758 2019-03-17 12:03:00: step 1214/50000, loss = 0.000000 (2.723 sec/batch), lr: 0.006250
2019-03-17 12:03:01,864 2019-03-17 12:03:01: step 1215/50000, loss = 0.000000 (1.072 sec/batch), lr: 0.006250
2019-03-17 12:04:12,655 2019-03-17 12:04:12: step 1216/50000, loss = 0.000000 (70.656 sec/batch), lr: 0.006250
2019-03-17 12:04:21,523 2019-03-17 12:04:21: step 1217/50000, loss = 0.000000 (8.785 sec/batch), lr: 0.006250
2019-03-17 12:04:26,831 2019-03-17 12:04:26: step 1218/50000, loss = 0.000000 (5.229 sec/batch), lr: 0.006250
2019-03-17 12:04:29,634 2019-03-17 12:04:29: step 1219/50000, loss = 0.000000 (2.741 sec/batch), lr: 0.006250
2019-03-17 12:04:30,749 2019-03-17 12:04:30: step 1220/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.006250
2019-03-17 12:05:41,210 2019-03-17 12:05:41: step 1221/50000, loss = 0.000000 (70.340 sec/batch), lr: 0.006250
2019-03-17 12:05:50,136 2019-03-17 12:05:50: step 1222/50000, loss = 0.000000 (8.842 sec/batch), lr: 0.006250
2019-03-17 12:05:55,429 2019-03-17 12:05:55: step 1223/50000, loss = 0.000000 (5.216 sec/batch), lr: 0.006250
2019-03-17 12:05:58,242 2019-03-17 12:05:58: step 1224/50000, loss = 0.000000 (2.758 sec/batch), lr: 0.006250
2019-03-17 12:05:59,351 2019-03-17 12:05:59: step 1225/50000, loss = 0.000000 (1.078 sec/batch), lr: 0.006250
2019-03-17 12:07:10,315 2019-03-17 12:07:10: step 1226/50000, loss = 0.000000 (70.834 sec/batch), lr: 0.006250
2019-03-17 12:07:19,203 2019-03-17 12:07:19: step 1227/50000, loss = 0.000000 (8.808 sec/batch), lr: 0.006250
2019-03-17 12:07:24,475 2019-03-17 12:07:24: step 1228/50000, loss = 0.000000 (5.196 sec/batch), lr: 0.006250
2019-03-17 12:07:27,306 2019-03-17 12:07:27: step 1229/50000, loss = 0.000000 (2.773 sec/batch), lr: 0.006250
2019-03-17 12:07:28,440 2019-03-17 12:07:28: step 1230/50000, loss = 0.000000 (1.093 sec/batch), lr: 0.006250
2019-03-17 12:08:39,932 2019-03-17 12:08:39: step 1231/50000, loss = 0.000000 (71.074 sec/batch), lr: 0.006250
2019-03-17 12:08:48,887 2019-03-17 12:08:48: step 1232/50000, loss = 0.000000 (8.870 sec/batch), lr: 0.006250
2019-03-17 12:08:54,063 2019-03-17 12:08:54: step 1233/50000, loss = 0.000000 (5.108 sec/batch), lr: 0.006250
2019-03-17 12:08:56,871 2019-03-17 12:08:56: step 1234/50000, loss = 0.000000 (2.752 sec/batch), lr: 0.006250
2019-03-17 12:08:57,991 2019-03-17 12:08:57: step 1235/50000, loss = 0.000000 (1.086 sec/batch), lr: 0.006250
2019-03-17 12:10:08,836 2019-03-17 12:10:08: step 1236/50000, loss = 0.000000 (70.712 sec/batch), lr: 0.006250
2019-03-17 12:10:17,799 2019-03-17 12:10:17: step 1237/50000, loss = 0.000000 (8.880 sec/batch), lr: 0.006250
2019-03-17 12:10:23,010 2019-03-17 12:10:23: step 1238/50000, loss = 0.000000 (5.144 sec/batch), lr: 0.006250
2019-03-17 12:10:25,871 2019-03-17 12:10:25: step 1239/50000, loss = 0.000000 (2.803 sec/batch), lr: 0.006250
2019-03-17 12:10:27,027 2019-03-17 12:10:27: step 1240/50000, loss = 0.000000 (1.116 sec/batch), lr: 0.006250
2019-03-17 12:11:38,153 2019-03-17 12:11:38: step 1241/50000, loss = 0.000000 (70.971 sec/batch), lr: 0.006250
2019-03-17 12:11:47,148 2019-03-17 12:11:47: step 1242/50000, loss = 0.000000 (8.914 sec/batch), lr: 0.006250
2019-03-17 12:11:52,357 2019-03-17 12:11:52: step 1243/50000, loss = 0.000000 (5.141 sec/batch), lr: 0.006250
2019-03-17 12:11:55,185 2019-03-17 12:11:55: step 1244/50000, loss = 0.000000 (2.767 sec/batch), lr: 0.006250
2019-03-17 12:11:56,301 2019-03-17 12:11:56: step 1245/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.006250
2019-03-17 12:13:07,481 2019-03-17 12:13:07: step 1246/50000, loss = 0.000000 (71.043 sec/batch), lr: 0.006250
2019-03-17 12:13:16,444 2019-03-17 12:13:16: step 1247/50000, loss = 0.000000 (8.880 sec/batch), lr: 0.006250
2019-03-17 12:13:21,641 2019-03-17 12:13:21: step 1248/50000, loss = 0.000000 (5.129 sec/batch), lr: 0.006250
2019-03-17 12:13:24,445 2019-03-17 12:13:24: step 1249/50000, loss = 0.000000 (2.748 sec/batch), lr: 0.006250
2019-03-17 12:13:25,584 2019-03-17 12:13:25: step 1250/50000, loss = 0.000000 (1.106 sec/batch), lr: 0.006250
2019-03-17 12:14:36,651 2019-03-17 12:14:36: step 1251/50000, loss = 0.000000 (70.934 sec/batch), lr: 0.006250
2019-03-17 12:14:45,616 2019-03-17 12:14:45: step 1252/50000, loss = 0.000000 (8.881 sec/batch), lr: 0.006250
2019-03-17 12:14:50,923 2019-03-17 12:14:50: step 1253/50000, loss = 0.000000 (5.231 sec/batch), lr: 0.006250
2019-03-17 12:14:53,732 2019-03-17 12:14:53: step 1254/50000, loss = 0.000000 (2.755 sec/batch), lr: 0.006250
2019-03-17 12:14:54,854 2019-03-17 12:14:54: step 1255/50000, loss = 0.000000 (1.088 sec/batch), lr: 0.006250
2019-03-17 12:16:06,060 2019-03-17 12:16:06: step 1256/50000, loss = 0.000000 (71.073 sec/batch), lr: 0.006250
2019-03-17 12:16:14,891 2019-03-17 12:16:14: step 1257/50000, loss = 0.000000 (8.750 sec/batch), lr: 0.006250
2019-03-17 12:16:20,065 2019-03-17 12:16:20: step 1258/50000, loss = 0.000000 (5.109 sec/batch), lr: 0.006250
2019-03-17 12:16:22,898 2019-03-17 12:16:22: step 1259/50000, loss = 0.000000 (2.778 sec/batch), lr: 0.006250
2019-03-17 12:16:23,994 2019-03-17 12:16:23: step 1260/50000, loss = 0.000000 (1.060 sec/batch), lr: 0.006250
2019-03-17 12:17:35,111 2019-03-17 12:17:35: step 1261/50000, loss = 0.000000 (70.733 sec/batch), lr: 0.006250
2019-03-17 12:17:44,013 2019-03-17 12:17:44: step 1262/50000, loss = 0.000000 (8.821 sec/batch), lr: 0.006250
2019-03-17 12:17:49,176 2019-03-17 12:17:49: step 1263/50000, loss = 0.000000 (5.099 sec/batch), lr: 0.006250
2019-03-17 12:17:51,972 2019-03-17 12:17:51: step 1264/50000, loss = 0.000000 (2.738 sec/batch), lr: 0.006250
2019-03-17 12:17:53,064 2019-03-17 12:17:53: step 1265/50000, loss = 0.000000 (1.060 sec/batch), lr: 0.006250
2019-03-17 12:19:03,791 2019-03-17 12:19:03: step 1266/50000, loss = 0.000000 (70.595 sec/batch), lr: 0.006250
2019-03-17 12:19:12,688 2019-03-17 12:19:12: step 1267/50000, loss = 0.000000 (8.812 sec/batch), lr: 0.006250
2019-03-17 12:19:17,843 2019-03-17 12:19:17: step 1268/50000, loss = 0.000000 (5.091 sec/batch), lr: 0.006250
2019-03-17 12:19:20,643 2019-03-17 12:19:20: step 1269/50000, loss = 0.000000 (2.744 sec/batch), lr: 0.006250
2019-03-17 12:19:21,762 2019-03-17 12:19:21: step 1270/50000, loss = 0.000000 (1.086 sec/batch), lr: 0.006250
2019-03-17 12:20:32,827 2019-03-17 12:20:32: step 1271/50000, loss = 0.000000 (70.932 sec/batch), lr: 0.006250
2019-03-17 12:20:41,734 2019-03-17 12:20:41: step 1272/50000, loss = 0.000000 (8.826 sec/batch), lr: 0.006250
2019-03-17 12:20:46,896 2019-03-17 12:20:46: step 1273/50000, loss = 0.000000 (5.095 sec/batch), lr: 0.006250
2019-03-17 12:20:49,696 2019-03-17 12:20:49: step 1274/50000, loss = 0.000000 (2.744 sec/batch), lr: 0.006250
2019-03-17 12:20:50,801 2019-03-17 12:20:50: step 1275/50000, loss = 0.000000 (1.071 sec/batch), lr: 0.006250
2019-03-17 12:22:01,621 2019-03-17 12:22:01: step 1276/50000, loss = 0.000000 (70.687 sec/batch), lr: 0.006250
2019-03-17 12:22:10,550 2019-03-17 12:22:10: step 1277/50000, loss = 0.000000 (8.849 sec/batch), lr: 0.006250
2019-03-17 12:22:15,719 2019-03-17 12:22:15: step 1278/50000, loss = 0.000000 (5.102 sec/batch), lr: 0.006250
2019-03-17 12:22:18,520 2019-03-17 12:22:18: step 1279/50000, loss = 0.000000 (2.745 sec/batch), lr: 0.006250
2019-03-17 12:22:19,634 2019-03-17 12:22:19: step 1280/50000, loss = 0.000000 (1.080 sec/batch), lr: 0.006250
2019-03-17 12:23:30,635 2019-03-17 12:23:30: step 1281/50000, loss = 0.000000 (70.869 sec/batch), lr: 0.006250
2019-03-17 12:23:39,562 2019-03-17 12:23:39: step 1282/50000, loss = 0.000000 (8.845 sec/batch), lr: 0.006250
2019-03-17 12:23:44,749 2019-03-17 12:23:44: step 1283/50000, loss = 0.000000 (5.119 sec/batch), lr: 0.006250
2019-03-17 12:23:47,566 2019-03-17 12:23:47: step 1284/50000, loss = 0.000000 (2.754 sec/batch), lr: 0.006250
2019-03-17 12:23:48,676 2019-03-17 12:23:48: step 1285/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.006250
2019-03-17 12:24:59,546 2019-03-17 12:24:59: step 1286/50000, loss = 0.000000 (70.739 sec/batch), lr: 0.006250
2019-03-17 12:25:08,429 2019-03-17 12:25:08: step 1287/50000, loss = 0.000000 (8.802 sec/batch), lr: 0.006250
2019-03-17 12:25:13,741 2019-03-17 12:25:13: step 1288/50000, loss = 0.000000 (5.234 sec/batch), lr: 0.006250
2019-03-17 12:25:16,544 2019-03-17 12:25:16: step 1289/50000, loss = 0.000000 (2.749 sec/batch), lr: 0.006250
2019-03-17 12:25:17,655 2019-03-17 12:25:17: step 1290/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.006250
2019-03-17 12:26:28,635 2019-03-17 12:26:28: step 1291/50000, loss = 0.000000 (70.861 sec/batch), lr: 0.006250
2019-03-17 12:26:37,537 2019-03-17 12:26:37: step 1292/50000, loss = 0.000000 (8.819 sec/batch), lr: 0.006250
2019-03-17 12:26:42,718 2019-03-17 12:26:42: step 1293/50000, loss = 0.000000 (5.113 sec/batch), lr: 0.006250
2019-03-17 12:26:45,816 2019-03-17 12:26:45: step 1294/50000, loss = 0.000000 (3.040 sec/batch), lr: 0.006250
2019-03-17 12:26:46,903 2019-03-17 12:26:46: step 1295/50000, loss = 0.000000 (1.052 sec/batch), lr: 0.006250
2019-03-17 12:27:57,721 2019-03-17 12:27:57: step 1296/50000, loss = 0.000000 (70.688 sec/batch), lr: 0.006250
2019-03-17 12:28:06,586 2019-03-17 12:28:06: step 1297/50000, loss = 0.000000 (8.784 sec/batch), lr: 0.006250
2019-03-17 12:28:11,772 2019-03-17 12:28:11: step 1298/50000, loss = 0.000000 (5.117 sec/batch), lr: 0.006250
2019-03-17 12:28:14,677 2019-03-17 12:28:14: step 1299/50000, loss = 0.000000 (2.843 sec/batch), lr: 0.006250
2019-03-17 12:28:15,761 2019-03-17 12:28:15: step 1300/50000, loss = 0.000000 (1.050 sec/batch), lr: 0.006250
2019-03-17 12:29:00,947 step 1300: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 12:29:01,004 step 1300: Dev acc. = 0.000000
2019-03-17 12:30:11,555 2019-03-17 12:30:11: step 1301/50000, loss = 0.000000 (70.437 sec/batch), lr: 0.006250
2019-03-17 12:30:20,470 2019-03-17 12:30:20: step 1302/50000, loss = 0.000000 (8.831 sec/batch), lr: 0.006250
2019-03-17 12:30:25,644 2019-03-17 12:30:25: step 1303/50000, loss = 0.000000 (5.101 sec/batch), lr: 0.006250
2019-03-17 12:30:28,439 2019-03-17 12:30:28: step 1304/50000, loss = 0.000000 (2.738 sec/batch), lr: 0.006250
2019-03-17 12:30:29,564 2019-03-17 12:30:29: step 1305/50000, loss = 0.000000 (1.090 sec/batch), lr: 0.006250
2019-03-17 12:31:40,313 2019-03-17 12:31:40: step 1306/50000, loss = 0.000000 (70.615 sec/batch), lr: 0.006250
2019-03-17 12:31:49,148 2019-03-17 12:31:49: step 1307/50000, loss = 0.000000 (8.753 sec/batch), lr: 0.006250
2019-03-17 12:31:54,440 2019-03-17 12:31:54: step 1308/50000, loss = 0.000000 (5.217 sec/batch), lr: 0.006250
2019-03-17 12:31:57,218 2019-03-17 12:31:57: step 1309/50000, loss = 0.000000 (2.723 sec/batch), lr: 0.006250
2019-03-17 12:31:58,326 2019-03-17 12:31:58: step 1310/50000, loss = 0.000000 (1.073 sec/batch), lr: 0.006250
2019-03-17 12:33:08,930 2019-03-17 12:33:08: step 1311/50000, loss = 0.000000 (70.472 sec/batch), lr: 0.006250
2019-03-17 12:33:17,837 2019-03-17 12:33:17: step 1312/50000, loss = 0.000000 (8.824 sec/batch), lr: 0.006250
2019-03-17 12:33:22,989 2019-03-17 12:33:22: step 1313/50000, loss = 0.000000 (5.084 sec/batch), lr: 0.006250
2019-03-17 12:33:25,792 2019-03-17 12:33:25: step 1314/50000, loss = 0.000000 (2.749 sec/batch), lr: 0.006250
2019-03-17 12:33:26,910 2019-03-17 12:33:26: step 1315/50000, loss = 0.000000 (1.085 sec/batch), lr: 0.006250
2019-03-17 12:34:37,408 2019-03-17 12:34:37: step 1316/50000, loss = 0.000000 (70.368 sec/batch), lr: 0.006250
2019-03-17 12:34:46,285 2019-03-17 12:34:46: step 1317/50000, loss = 0.000000 (8.793 sec/batch), lr: 0.006250
2019-03-17 12:34:51,444 2019-03-17 12:34:51: step 1318/50000, loss = 0.000000 (5.086 sec/batch), lr: 0.006250
2019-03-17 12:34:54,247 2019-03-17 12:34:54: step 1319/50000, loss = 0.000000 (2.746 sec/batch), lr: 0.006250
2019-03-17 12:34:55,357 2019-03-17 12:34:55: step 1320/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.006250
2019-03-17 12:36:06,018 2019-03-17 12:36:06: step 1321/50000, loss = 0.000000 (70.533 sec/batch), lr: 0.006250
2019-03-17 12:36:14,771 2019-03-17 12:36:14: step 1322/50000, loss = 0.000000 (8.690 sec/batch), lr: 0.006250
2019-03-17 12:36:19,926 2019-03-17 12:36:19: step 1323/50000, loss = 0.000000 (5.091 sec/batch), lr: 0.006250
2019-03-17 12:36:22,714 2019-03-17 12:36:22: step 1324/50000, loss = 0.000000 (2.748 sec/batch), lr: 0.006250
2019-03-17 12:36:23,846 2019-03-17 12:36:23: step 1325/50000, loss = 0.000000 (1.097 sec/batch), lr: 0.006250
2019-03-17 12:37:34,754 2019-03-17 12:37:34: step 1326/50000, loss = 0.000000 (70.520 sec/batch), lr: 0.006250
2019-03-17 12:37:43,646 2019-03-17 12:37:43: step 1327/50000, loss = 0.000000 (8.810 sec/batch), lr: 0.006250
2019-03-17 12:37:48,802 2019-03-17 12:37:48: step 1328/50000, loss = 0.000000 (5.093 sec/batch), lr: 0.006250
2019-03-17 12:37:51,603 2019-03-17 12:37:51: step 1329/50000, loss = 0.000000 (2.746 sec/batch), lr: 0.006250
2019-03-17 12:37:52,721 2019-03-17 12:37:52: step 1330/50000, loss = 0.000000 (1.085 sec/batch), lr: 0.006250
2019-03-17 12:39:03,384 2019-03-17 12:39:03: step 1331/50000, loss = 0.000000 (70.533 sec/batch), lr: 0.006250
2019-03-17 12:39:12,274 2019-03-17 12:39:12: step 1332/50000, loss = 0.000000 (8.805 sec/batch), lr: 0.006250
2019-03-17 12:39:17,568 2019-03-17 12:39:17: step 1333/50000, loss = 0.000000 (5.217 sec/batch), lr: 0.006250
2019-03-17 12:39:20,372 2019-03-17 12:39:20: step 1334/50000, loss = 0.000000 (2.750 sec/batch), lr: 0.006250
2019-03-17 12:39:21,487 2019-03-17 12:39:21: step 1335/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.006250
2019-03-17 12:40:32,055 2019-03-17 12:40:32: step 1336/50000, loss = 0.000000 (70.436 sec/batch), lr: 0.006250
2019-03-17 12:40:40,976 2019-03-17 12:40:40: step 1337/50000, loss = 0.000000 (8.840 sec/batch), lr: 0.006250
2019-03-17 12:40:46,252 2019-03-17 12:40:46: step 1338/50000, loss = 0.000000 (5.199 sec/batch), lr: 0.006250
2019-03-17 12:40:49,055 2019-03-17 12:40:49: step 1339/50000, loss = 0.000000 (2.748 sec/batch), lr: 0.006250
2019-03-17 12:40:50,166 2019-03-17 12:40:50: step 1340/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.006250
2019-03-17 12:42:00,758 2019-03-17 12:42:00: step 1341/50000, loss = 0.000000 (70.456 sec/batch), lr: 0.006250
2019-03-17 12:42:09,671 2019-03-17 12:42:09: step 1342/50000, loss = 0.000000 (8.831 sec/batch), lr: 0.006250
2019-03-17 12:42:14,820 2019-03-17 12:42:14: step 1343/50000, loss = 0.000000 (5.080 sec/batch), lr: 0.006250
2019-03-17 12:42:17,607 2019-03-17 12:42:17: step 1344/50000, loss = 0.000000 (2.732 sec/batch), lr: 0.006250
2019-03-17 12:42:18,724 2019-03-17 12:42:18: step 1345/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.006250
2019-03-17 12:43:29,287 2019-03-17 12:43:29: step 1346/50000, loss = 0.000000 (70.435 sec/batch), lr: 0.006250
2019-03-17 12:43:38,169 2019-03-17 12:43:38: step 1347/50000, loss = 0.000000 (8.796 sec/batch), lr: 0.006250
2019-03-17 12:43:43,441 2019-03-17 12:43:43: step 1348/50000, loss = 0.000000 (5.198 sec/batch), lr: 0.006250
2019-03-17 12:43:46,210 2019-03-17 12:43:46: step 1349/50000, loss = 0.000000 (2.718 sec/batch), lr: 0.006250
2019-03-17 12:43:47,331 2019-03-17 12:43:47: step 1350/50000, loss = 0.000000 (1.086 sec/batch), lr: 0.006250
2019-03-17 12:44:57,946 2019-03-17 12:44:57: step 1351/50000, loss = 0.000000 (70.499 sec/batch), lr: 0.006250
2019-03-17 12:45:06,849 2019-03-17 12:45:06: step 1352/50000, loss = 0.000000 (8.819 sec/batch), lr: 0.006250
2019-03-17 12:45:11,983 2019-03-17 12:45:11: step 1353/50000, loss = 0.000000 (5.064 sec/batch), lr: 0.006250
2019-03-17 12:45:14,786 2019-03-17 12:45:14: step 1354/50000, loss = 0.000000 (2.748 sec/batch), lr: 0.006250
2019-03-17 12:45:15,896 2019-03-17 12:45:15: step 1355/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.006250
2019-03-17 12:46:26,683 2019-03-17 12:46:26: step 1356/50000, loss = 0.000000 (70.367 sec/batch), lr: 0.006250
2019-03-17 12:46:35,573 2019-03-17 12:46:35: step 1357/50000, loss = 0.000000 (8.806 sec/batch), lr: 0.006250
2019-03-17 12:46:40,878 2019-03-17 12:46:40: step 1358/50000, loss = 0.000000 (5.229 sec/batch), lr: 0.006250
2019-03-17 12:46:43,672 2019-03-17 12:46:43: step 1359/50000, loss = 0.000000 (2.732 sec/batch), lr: 0.006250
2019-03-17 12:46:44,785 2019-03-17 12:46:44: step 1360/50000, loss = 0.000000 (1.087 sec/batch), lr: 0.006250
2019-03-17 12:47:55,116 2019-03-17 12:47:55: step 1361/50000, loss = 0.000000 (70.199 sec/batch), lr: 0.006250
2019-03-17 12:48:03,986 2019-03-17 12:48:03: step 1362/50000, loss = 0.000000 (8.787 sec/batch), lr: 0.006250
2019-03-17 12:48:09,149 2019-03-17 12:48:09: step 1363/50000, loss = 0.000000 (5.095 sec/batch), lr: 0.006250
2019-03-17 12:48:11,949 2019-03-17 12:48:11: step 1364/50000, loss = 0.000000 (2.745 sec/batch), lr: 0.006250
2019-03-17 12:48:13,079 2019-03-17 12:48:13: step 1365/50000, loss = 0.000000 (1.091 sec/batch), lr: 0.006250
2019-03-17 12:49:23,671 2019-03-17 12:49:23: step 1366/50000, loss = 0.000000 (70.458 sec/batch), lr: 0.006250
2019-03-17 12:49:32,492 2019-03-17 12:49:32: step 1367/50000, loss = 0.000000 (8.741 sec/batch), lr: 0.006250
2019-03-17 12:49:37,595 2019-03-17 12:49:37: step 1368/50000, loss = 0.000000 (5.054 sec/batch), lr: 0.006250
2019-03-17 12:49:40,365 2019-03-17 12:49:40: step 1369/50000, loss = 0.000000 (2.730 sec/batch), lr: 0.006250
2019-03-17 12:49:41,465 2019-03-17 12:49:41: step 1370/50000, loss = 0.000000 (1.066 sec/batch), lr: 0.006250
2019-03-17 12:50:52,187 2019-03-17 12:50:52: step 1371/50000, loss = 0.000000 (70.584 sec/batch), lr: 0.006250
2019-03-17 12:51:01,074 2019-03-17 12:51:01: step 1372/50000, loss = 0.000000 (8.807 sec/batch), lr: 0.006250
2019-03-17 12:51:06,146 2019-03-17 12:51:06: step 1373/50000, loss = 0.000000 (5.023 sec/batch), lr: 0.006250
2019-03-17 12:51:08,885 2019-03-17 12:51:08: step 1374/50000, loss = 0.000000 (2.703 sec/batch), lr: 0.006250
2019-03-17 12:51:09,956 2019-03-17 12:51:09: step 1375/50000, loss = 0.000000 (1.048 sec/batch), lr: 0.006250
2019-03-17 12:52:20,370 2019-03-17 12:52:20: step 1376/50000, loss = 0.000000 (70.306 sec/batch), lr: 0.006250
2019-03-17 12:52:29,253 2019-03-17 12:52:29: step 1377/50000, loss = 0.000000 (8.803 sec/batch), lr: 0.006250
2019-03-17 12:52:34,418 2019-03-17 12:52:34: step 1378/50000, loss = 0.000000 (5.095 sec/batch), lr: 0.006250
2019-03-17 12:52:37,216 2019-03-17 12:52:37: step 1379/50000, loss = 0.000000 (2.742 sec/batch), lr: 0.006250
2019-03-17 12:52:38,326 2019-03-17 12:52:38: step 1380/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.006250
2019-03-17 12:53:48,992 2019-03-17 12:53:48: step 1381/50000, loss = 0.000000 (70.536 sec/batch), lr: 0.006250
2019-03-17 12:53:57,863 2019-03-17 12:53:57: step 1382/50000, loss = 0.000000 (8.789 sec/batch), lr: 0.006250
2019-03-17 12:54:03,003 2019-03-17 12:54:03: step 1383/50000, loss = 0.000000 (5.074 sec/batch), lr: 0.006250
2019-03-17 12:54:05,805 2019-03-17 12:54:05: step 1384/50000, loss = 0.000000 (2.747 sec/batch), lr: 0.006250
2019-03-17 12:54:06,936 2019-03-17 12:54:06: step 1385/50000, loss = 0.000000 (1.091 sec/batch), lr: 0.006250
2019-03-17 12:55:17,660 2019-03-17 12:55:17: step 1386/50000, loss = 0.000000 (70.594 sec/batch), lr: 0.006250
2019-03-17 12:55:26,808 2019-03-17 12:55:26: step 1387/50000, loss = 0.000000 (9.061 sec/batch), lr: 0.006250
2019-03-17 12:55:31,985 2019-03-17 12:55:31: step 1388/50000, loss = 0.000000 (5.108 sec/batch), lr: 0.006250
2019-03-17 12:55:34,920 2019-03-17 12:55:34: step 1389/50000, loss = 0.000000 (2.873 sec/batch), lr: 0.006250
2019-03-17 12:55:36,036 2019-03-17 12:55:36: step 1390/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.006250
2019-03-17 12:56:47,042 2019-03-17 12:56:47: step 1391/50000, loss = 0.000000 (70.874 sec/batch), lr: 0.006250
2019-03-17 12:56:55,989 2019-03-17 12:56:55: step 1392/50000, loss = 0.000000 (8.863 sec/batch), lr: 0.006250
2019-03-17 12:57:01,170 2019-03-17 12:57:01: step 1393/50000, loss = 0.000000 (5.113 sec/batch), lr: 0.006250
2019-03-17 12:57:03,968 2019-03-17 12:57:03: step 1394/50000, loss = 0.000000 (2.743 sec/batch), lr: 0.006250
2019-03-17 12:57:05,074 2019-03-17 12:57:05: step 1395/50000, loss = 0.000000 (1.071 sec/batch), lr: 0.006250
2019-03-17 12:58:16,143 2019-03-17 12:58:16: step 1396/50000, loss = 0.000000 (70.955 sec/batch), lr: 0.006250
2019-03-17 12:58:25,132 2019-03-17 12:58:25: step 1397/50000, loss = 0.000000 (8.906 sec/batch), lr: 0.006250
2019-03-17 12:58:30,417 2019-03-17 12:58:30: step 1398/50000, loss = 0.000000 (5.208 sec/batch), lr: 0.006250
2019-03-17 12:58:33,202 2019-03-17 12:58:33: step 1399/50000, loss = 0.000000 (2.744 sec/batch), lr: 0.006250
2019-03-17 12:58:34,316 2019-03-17 12:58:34: step 1400/50000, loss = 0.000000 (1.079 sec/batch), lr: 0.006250
2019-03-17 12:59:19,552 step 1400: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 12:59:19,609 step 1400: Dev acc. = 0.000000
2019-03-17 13:00:30,080 2019-03-17 13:00:30: step 1401/50000, loss = 0.000000 (70.363 sec/batch), lr: 0.006250
2019-03-17 13:00:38,760 2019-03-17 13:00:38: step 1402/50000, loss = 0.000000 (8.617 sec/batch), lr: 0.006250
2019-03-17 13:00:43,888 2019-03-17 13:00:43: step 1403/50000, loss = 0.000000 (5.078 sec/batch), lr: 0.006250
2019-03-17 13:00:46,687 2019-03-17 13:00:46: step 1404/50000, loss = 0.000000 (2.741 sec/batch), lr: 0.006250
2019-03-17 13:00:47,797 2019-03-17 13:00:47: step 1405/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.006250
2019-03-17 13:01:58,346 2019-03-17 13:01:58: step 1406/50000, loss = 0.000000 (70.413 sec/batch), lr: 0.006250
2019-03-17 13:02:07,229 2019-03-17 13:02:07: step 1407/50000, loss = 0.000000 (8.803 sec/batch), lr: 0.006250
2019-03-17 13:02:12,409 2019-03-17 13:02:12: step 1408/50000, loss = 0.000000 (5.110 sec/batch), lr: 0.006250
2019-03-17 13:02:15,200 2019-03-17 13:02:15: step 1409/50000, loss = 0.000000 (2.737 sec/batch), lr: 0.006250
2019-03-17 13:02:16,302 2019-03-17 13:02:16: step 1410/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.006250
2019-03-17 13:03:26,823 2019-03-17 13:03:26: step 1411/50000, loss = 0.000000 (70.389 sec/batch), lr: 0.006250
2019-03-17 13:03:35,631 2019-03-17 13:03:35: step 1412/50000, loss = 0.000000 (8.724 sec/batch), lr: 0.006250
2019-03-17 13:03:40,778 2019-03-17 13:03:40: step 1413/50000, loss = 0.000000 (5.072 sec/batch), lr: 0.006250
2019-03-17 13:03:43,527 2019-03-17 13:03:43: step 1414/50000, loss = 0.000000 (2.694 sec/batch), lr: 0.006250
2019-03-17 13:03:44,623 2019-03-17 13:03:44: step 1415/50000, loss = 0.000000 (1.062 sec/batch), lr: 0.006250
2019-03-17 13:04:55,803 2019-03-17 13:04:55: step 1416/50000, loss = 0.000000 (71.048 sec/batch), lr: 0.006250
2019-03-17 13:05:04,700 2019-03-17 13:05:04: step 1417/50000, loss = 0.000000 (8.817 sec/batch), lr: 0.006250
2019-03-17 13:05:09,888 2019-03-17 13:05:09: step 1418/50000, loss = 0.000000 (5.120 sec/batch), lr: 0.006250
2019-03-17 13:05:12,835 2019-03-17 13:05:12: step 1419/50000, loss = 0.000000 (2.884 sec/batch), lr: 0.006250
2019-03-17 13:05:13,950 2019-03-17 13:05:13: step 1420/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.006250
2019-03-17 13:06:25,055 2019-03-17 13:06:25: step 1421/50000, loss = 0.000000 (70.972 sec/batch), lr: 0.006250
2019-03-17 13:06:33,938 2019-03-17 13:06:33: step 1422/50000, loss = 0.000000 (8.802 sec/batch), lr: 0.006250
2019-03-17 13:06:39,224 2019-03-17 13:06:39: step 1423/50000, loss = 0.000000 (5.209 sec/batch), lr: 0.006250
2019-03-17 13:06:42,018 2019-03-17 13:06:42: step 1424/50000, loss = 0.000000 (2.737 sec/batch), lr: 0.006250
2019-03-17 13:06:43,132 2019-03-17 13:06:43: step 1425/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.006250
2019-03-17 13:07:53,708 2019-03-17 13:07:53: step 1426/50000, loss = 0.000000 (70.447 sec/batch), lr: 0.006250
2019-03-17 13:08:02,604 2019-03-17 13:08:02: step 1427/50000, loss = 0.000000 (8.813 sec/batch), lr: 0.006250
2019-03-17 13:08:07,763 2019-03-17 13:08:07: step 1428/50000, loss = 0.000000 (5.091 sec/batch), lr: 0.006250
2019-03-17 13:08:10,557 2019-03-17 13:08:10: step 1429/50000, loss = 0.000000 (2.739 sec/batch), lr: 0.006250
2019-03-17 13:08:11,670 2019-03-17 13:08:11: step 1430/50000, loss = 0.000000 (1.080 sec/batch), lr: 0.006250
2019-03-17 13:09:22,283 2019-03-17 13:09:22: step 1431/50000, loss = 0.000000 (70.481 sec/batch), lr: 0.006250
2019-03-17 13:09:31,179 2019-03-17 13:09:31: step 1432/50000, loss = 0.000000 (8.815 sec/batch), lr: 0.006250
2019-03-17 13:09:36,325 2019-03-17 13:09:36: step 1433/50000, loss = 0.000000 (5.078 sec/batch), lr: 0.006250
2019-03-17 13:09:39,134 2019-03-17 13:09:39: step 1434/50000, loss = 0.000000 (2.753 sec/batch), lr: 0.006250
2019-03-17 13:09:40,239 2019-03-17 13:09:40: step 1435/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.006250
2019-03-17 13:10:50,918 2019-03-17 13:10:50: step 1436/50000, loss = 0.000000 (70.549 sec/batch), lr: 0.006250
2019-03-17 13:10:59,806 2019-03-17 13:10:59: step 1437/50000, loss = 0.000000 (8.808 sec/batch), lr: 0.006250
2019-03-17 13:11:05,133 2019-03-17 13:11:05: step 1438/50000, loss = 0.000000 (5.253 sec/batch), lr: 0.006250
2019-03-17 13:11:07,979 2019-03-17 13:11:07: step 1439/50000, loss = 0.000000 (2.789 sec/batch), lr: 0.006250
2019-03-17 13:11:09,106 2019-03-17 13:11:09: step 1440/50000, loss = 0.000000 (1.094 sec/batch), lr: 0.006250
2019-03-17 13:12:19,899 2019-03-17 13:12:19: step 1441/50000, loss = 0.000000 (70.664 sec/batch), lr: 0.006250
2019-03-17 13:12:28,797 2019-03-17 13:12:28: step 1442/50000, loss = 0.000000 (8.818 sec/batch), lr: 0.006250
2019-03-17 13:12:33,973 2019-03-17 13:12:33: step 1443/50000, loss = 0.000000 (5.109 sec/batch), lr: 0.006250
2019-03-17 13:12:36,775 2019-03-17 13:12:36: step 1444/50000, loss = 0.000000 (2.747 sec/batch), lr: 0.006250
2019-03-17 13:12:37,892 2019-03-17 13:12:37: step 1445/50000, loss = 0.000000 (1.083 sec/batch), lr: 0.006250
2019-03-17 13:13:48,766 2019-03-17 13:13:48: step 1446/50000, loss = 0.000000 (70.477 sec/batch), lr: 0.006250
2019-03-17 13:13:57,707 2019-03-17 13:13:57: step 1447/50000, loss = 0.000000 (8.860 sec/batch), lr: 0.006250
2019-03-17 13:14:02,945 2019-03-17 13:14:02: step 1448/50000, loss = 0.000000 (5.172 sec/batch), lr: 0.006250
2019-03-17 13:14:05,795 2019-03-17 13:14:05: step 1449/50000, loss = 0.000000 (2.788 sec/batch), lr: 0.006250
2019-03-17 13:14:06,952 2019-03-17 13:14:06: step 1450/50000, loss = 0.000000 (1.117 sec/batch), lr: 0.006250
2019-03-17 13:15:17,885 2019-03-17 13:15:17: step 1451/50000, loss = 0.000000 (70.801 sec/batch), lr: 0.006250
2019-03-17 13:15:26,677 2019-03-17 13:15:26: step 1452/50000, loss = 0.000000 (8.710 sec/batch), lr: 0.006250
2019-03-17 13:15:31,856 2019-03-17 13:15:31: step 1453/50000, loss = 0.000000 (5.111 sec/batch), lr: 0.006250
2019-03-17 13:15:34,682 2019-03-17 13:15:34: step 1454/50000, loss = 0.000000 (2.770 sec/batch), lr: 0.006250
2019-03-17 13:15:35,822 2019-03-17 13:15:35: step 1455/50000, loss = 0.000000 (1.100 sec/batch), lr: 0.006250
2019-03-17 13:16:46,474 2019-03-17 13:16:46: step 1456/50000, loss = 0.000000 (70.522 sec/batch), lr: 0.006250
2019-03-17 13:16:55,312 2019-03-17 13:16:55: step 1457/50000, loss = 0.000000 (8.747 sec/batch), lr: 0.006250
2019-03-17 13:17:00,642 2019-03-17 13:17:00: step 1458/50000, loss = 0.000000 (5.255 sec/batch), lr: 0.006250
2019-03-17 13:17:03,422 2019-03-17 13:17:03: step 1459/50000, loss = 0.000000 (2.719 sec/batch), lr: 0.006250
2019-03-17 13:17:04,531 2019-03-17 13:17:04: step 1460/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.006250
2019-03-17 13:18:15,386 2019-03-17 13:18:15: step 1461/50000, loss = 0.000000 (70.721 sec/batch), lr: 0.006250
2019-03-17 13:18:24,324 2019-03-17 13:18:24: step 1462/50000, loss = 0.000000 (8.858 sec/batch), lr: 0.006250
2019-03-17 13:18:29,633 2019-03-17 13:18:29: step 1463/50000, loss = 0.000000 (5.236 sec/batch), lr: 0.006250
2019-03-17 13:18:32,445 2019-03-17 13:18:32: step 1464/50000, loss = 0.000000 (2.757 sec/batch), lr: 0.006250
2019-03-17 13:18:33,576 2019-03-17 13:18:33: step 1465/50000, loss = 0.000000 (1.097 sec/batch), lr: 0.006250
2019-03-17 13:19:43,788 2019-03-17 13:19:43: step 1466/50000, loss = 0.000000 (70.058 sec/batch), lr: 0.006250
2019-03-17 13:19:52,725 2019-03-17 13:19:52: step 1467/50000, loss = 0.000000 (8.855 sec/batch), lr: 0.006250
2019-03-17 13:19:58,054 2019-03-17 13:19:58: step 1468/50000, loss = 0.000000 (5.252 sec/batch), lr: 0.006250
2019-03-17 13:20:00,870 2019-03-17 13:20:00: step 1469/50000, loss = 0.000000 (2.754 sec/batch), lr: 0.006250
2019-03-17 13:20:02,002 2019-03-17 13:20:02: step 1470/50000, loss = 0.000000 (1.098 sec/batch), lr: 0.006250
2019-03-17 13:21:13,041 2019-03-17 13:21:13: step 1471/50000, loss = 0.000000 (70.901 sec/batch), lr: 0.006250
2019-03-17 13:21:22,049 2019-03-17 13:21:22: step 1472/50000, loss = 0.000000 (8.926 sec/batch), lr: 0.006250
2019-03-17 13:21:27,379 2019-03-17 13:21:27: step 1473/50000, loss = 0.000000 (5.252 sec/batch), lr: 0.006250
2019-03-17 13:21:30,275 2019-03-17 13:21:30: step 1474/50000, loss = 0.000000 (2.832 sec/batch), lr: 0.006250
2019-03-17 13:21:31,394 2019-03-17 13:21:31: step 1475/50000, loss = 0.000000 (1.085 sec/batch), lr: 0.006250
2019-03-17 13:22:41,861 2019-03-17 13:22:41: step 1476/50000, loss = 0.000000 (70.339 sec/batch), lr: 0.006250
2019-03-17 13:22:50,992 2019-03-17 13:22:50: step 1477/50000, loss = 0.000000 (8.731 sec/batch), lr: 0.006250
2019-03-17 13:22:56,282 2019-03-17 13:22:56: step 1478/50000, loss = 0.000000 (5.214 sec/batch), lr: 0.006250
2019-03-17 13:22:59,072 2019-03-17 13:22:59: step 1479/50000, loss = 0.000000 (2.730 sec/batch), lr: 0.006250
2019-03-17 13:23:00,171 2019-03-17 13:23:00: step 1480/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.006250
2019-03-17 13:24:10,714 2019-03-17 13:24:10: step 1481/50000, loss = 0.000000 (70.422 sec/batch), lr: 0.006250
2019-03-17 13:24:19,333 2019-03-17 13:24:19: step 1482/50000, loss = 0.000000 (8.554 sec/batch), lr: 0.006250
2019-03-17 13:24:24,404 2019-03-17 13:24:24: step 1483/50000, loss = 0.000000 (5.019 sec/batch), lr: 0.006250
2019-03-17 13:24:27,161 2019-03-17 13:24:27: step 1484/50000, loss = 0.000000 (2.718 sec/batch), lr: 0.006250
2019-03-17 13:24:28,281 2019-03-17 13:24:28: step 1485/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.006250
2019-03-17 13:25:38,103 2019-03-17 13:25:38: step 1486/50000, loss = 0.000000 (69.689 sec/batch), lr: 0.006250
2019-03-17 13:25:46,881 2019-03-17 13:25:46: step 1487/50000, loss = 0.000000 (8.695 sec/batch), lr: 0.006250
2019-03-17 13:25:51,962 2019-03-17 13:25:51: step 1488/50000, loss = 0.000000 (5.028 sec/batch), lr: 0.006250
2019-03-17 13:25:54,758 2019-03-17 13:25:54: step 1489/50000, loss = 0.000000 (2.739 sec/batch), lr: 0.006250
2019-03-17 13:25:55,868 2019-03-17 13:25:55: step 1490/50000, loss = 0.000000 (1.070 sec/batch), lr: 0.006250
2019-03-17 13:27:05,723 2019-03-17 13:27:05: step 1491/50000, loss = 0.000000 (69.741 sec/batch), lr: 0.006250
2019-03-17 13:27:14,493 2019-03-17 13:27:14: step 1492/50000, loss = 0.000000 (8.687 sec/batch), lr: 0.006250
2019-03-17 13:27:19,576 2019-03-17 13:27:19: step 1493/50000, loss = 0.000000 (5.015 sec/batch), lr: 0.006250
2019-03-17 13:27:22,329 2019-03-17 13:27:22: step 1494/50000, loss = 0.000000 (2.698 sec/batch), lr: 0.006250
2019-03-17 13:27:23,434 2019-03-17 13:27:23: step 1495/50000, loss = 0.000000 (1.071 sec/batch), lr: 0.006250
2019-03-17 13:28:33,535 2019-03-17 13:28:33: step 1496/50000, loss = 0.000000 (69.972 sec/batch), lr: 0.006250
2019-03-17 13:28:42,240 2019-03-17 13:28:42: step 1497/50000, loss = 0.000000 (8.643 sec/batch), lr: 0.006250
2019-03-17 13:28:47,365 2019-03-17 13:28:47: step 1498/50000, loss = 0.000000 (5.058 sec/batch), lr: 0.006250
2019-03-17 13:28:50,129 2019-03-17 13:28:50: step 1499/50000, loss = 0.000000 (2.714 sec/batch), lr: 0.006250
2019-03-17 13:28:51,231 2019-03-17 13:28:51: step 1500/50000, loss = 0.000000 (1.068 sec/batch), lr: 0.006250
2019-03-17 13:29:35,930 step 1500: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 13:29:35,987 step 1500: Dev acc. = 0.000000
2019-03-17 13:30:46,080 2019-03-17 13:30:46: step 1501/50000, loss = 0.000000 (69.993 sec/batch), lr: 0.003125
2019-03-17 13:30:54,826 2019-03-17 13:30:54: step 1502/50000, loss = 0.000000 (8.667 sec/batch), lr: 0.003125
2019-03-17 13:30:59,930 2019-03-17 13:30:59: step 1503/50000, loss = 0.000000 (5.049 sec/batch), lr: 0.003125
2019-03-17 13:31:02,691 2019-03-17 13:31:02: step 1504/50000, loss = 0.000000 (2.715 sec/batch), lr: 0.003125
2019-03-17 13:31:03,794 2019-03-17 13:31:03: step 1505/50000, loss = 0.000000 (1.071 sec/batch), lr: 0.003125
2019-03-17 13:32:14,209 2019-03-17 13:32:14: step 1506/50000, loss = 0.000000 (70.004 sec/batch), lr: 0.003125
2019-03-17 13:32:22,873 2019-03-17 13:32:22: step 1507/50000, loss = 0.000000 (8.600 sec/batch), lr: 0.003125
2019-03-17 13:32:28,102 2019-03-17 13:32:28: step 1508/50000, loss = 0.000000 (5.153 sec/batch), lr: 0.003125
2019-03-17 13:32:30,874 2019-03-17 13:32:30: step 1509/50000, loss = 0.000000 (2.711 sec/batch), lr: 0.003125
2019-03-17 13:32:31,968 2019-03-17 13:32:31: step 1510/50000, loss = 0.000000 (1.061 sec/batch), lr: 0.003125
2019-03-17 13:33:43,052 2019-03-17 13:33:43: step 1511/50000, loss = 0.000000 (70.961 sec/batch), lr: 0.003125
2019-03-17 13:33:51,866 2019-03-17 13:33:51: step 1512/50000, loss = 0.000000 (8.751 sec/batch), lr: 0.003125
2019-03-17 13:33:57,173 2019-03-17 13:33:57: step 1513/50000, loss = 0.000000 (5.243 sec/batch), lr: 0.003125
2019-03-17 13:34:00,008 2019-03-17 13:34:00: step 1514/50000, loss = 0.000000 (2.773 sec/batch), lr: 0.003125
2019-03-17 13:34:01,152 2019-03-17 13:34:01: step 1515/50000, loss = 0.000000 (1.109 sec/batch), lr: 0.003125
2019-03-17 13:35:12,938 2019-03-17 13:35:12: step 1516/50000, loss = 0.000000 (71.633 sec/batch), lr: 0.003125
2019-03-17 13:35:21,962 2019-03-17 13:35:21: step 1517/50000, loss = 0.000000 (8.943 sec/batch), lr: 0.003125
2019-03-17 13:35:27,189 2019-03-17 13:35:27: step 1518/50000, loss = 0.000000 (5.159 sec/batch), lr: 0.003125
2019-03-17 13:35:30,046 2019-03-17 13:35:30: step 1519/50000, loss = 0.000000 (2.801 sec/batch), lr: 0.003125
2019-03-17 13:35:31,200 2019-03-17 13:35:31: step 1520/50000, loss = 0.000000 (1.115 sec/batch), lr: 0.003125
2019-03-17 13:36:42,977 2019-03-17 13:36:42: step 1521/50000, loss = 0.000000 (71.625 sec/batch), lr: 0.003125
2019-03-17 13:36:52,101 2019-03-17 13:36:52: step 1522/50000, loss = 0.000000 (9.042 sec/batch), lr: 0.003125
2019-03-17 13:36:57,877 2019-03-17 13:36:57: step 1523/50000, loss = 0.000000 (5.698 sec/batch), lr: 0.003125
2019-03-17 13:37:01,205 2019-03-17 13:37:01: step 1524/50000, loss = 0.000000 (3.261 sec/batch), lr: 0.003125
2019-03-17 13:37:02,371 2019-03-17 13:37:02: step 1525/50000, loss = 0.000000 (1.139 sec/batch), lr: 0.003125
2019-03-17 13:39:41,144 2019-03-17 13:39:41: step 1526/50000, loss = 0.000000 (158.619 sec/batch), lr: 0.003125
2019-03-17 13:40:08,537 2019-03-17 13:40:08: step 1527/50000, loss = 0.000000 (27.313 sec/batch), lr: 0.003125
2019-03-17 13:40:24,177 2019-03-17 13:40:24: step 1528/50000, loss = 0.000000 (15.580 sec/batch), lr: 0.003125
2019-03-17 13:40:32,517 2019-03-17 13:40:32: step 1529/50000, loss = 0.000000 (8.281 sec/batch), lr: 0.003125
2019-03-17 13:40:35,548 2019-03-17 13:40:35: step 1530/50000, loss = 0.000000 (2.993 sec/batch), lr: 0.003125
2019-03-17 13:44:24,437 2019-03-17 13:44:24: step 1531/50000, loss = 0.000000 (228.759 sec/batch), lr: 0.003125
2019-03-17 13:44:51,828 2019-03-17 13:44:51: step 1532/50000, loss = 0.000000 (27.306 sec/batch), lr: 0.003125
2019-03-17 13:45:06,975 2019-03-17 13:45:06: step 1533/50000, loss = 0.000000 (15.073 sec/batch), lr: 0.003125
2019-03-17 13:45:15,287 2019-03-17 13:45:15: step 1534/50000, loss = 0.000000 (8.252 sec/batch), lr: 0.003125
2019-03-17 13:45:18,345 2019-03-17 13:45:18: step 1535/50000, loss = 0.000000 (3.022 sec/batch), lr: 0.003125
2019-03-17 13:49:06,438 2019-03-17 13:49:06: step 1536/50000, loss = 0.000000 (227.966 sec/batch), lr: 0.003125
2019-03-17 13:49:33,705 2019-03-17 13:49:33: step 1537/50000, loss = 0.000000 (27.186 sec/batch), lr: 0.003125
2019-03-17 13:49:49,511 2019-03-17 13:49:49: step 1538/50000, loss = 0.000000 (15.740 sec/batch), lr: 0.003125
2019-03-17 13:49:58,076 2019-03-17 13:49:58: step 1539/50000, loss = 0.000000 (8.203 sec/batch), lr: 0.003125
2019-03-17 13:50:01,056 2019-03-17 13:50:01: step 1540/50000, loss = 0.000000 (2.947 sec/batch), lr: 0.003125
2019-03-17 13:53:48,140 2019-03-17 13:53:48: step 1541/50000, loss = 0.000000 (226.956 sec/batch), lr: 0.003125
2019-03-17 13:54:15,377 2019-03-17 13:54:15: step 1542/50000, loss = 0.000000 (27.155 sec/batch), lr: 0.003125
2019-03-17 13:54:31,209 2019-03-17 13:54:31: step 1543/50000, loss = 0.000000 (15.759 sec/batch), lr: 0.003125
2019-03-17 13:54:39,515 2019-03-17 13:54:39: step 1544/50000, loss = 0.000000 (8.246 sec/batch), lr: 0.003125
2019-03-17 13:54:42,516 2019-03-17 13:54:42: step 1545/50000, loss = 0.000000 (2.968 sec/batch), lr: 0.003125
2019-03-17 13:55:57,978 2019-03-17 13:55:57: step 1546/50000, loss = 0.000000 (75.344 sec/batch), lr: 0.003125
2019-03-17 13:56:06,789 2019-03-17 13:56:06: step 1547/50000, loss = 0.000000 (8.730 sec/batch), lr: 0.003125
2019-03-17 13:56:11,902 2019-03-17 13:56:11: step 1548/50000, loss = 0.000000 (5.064 sec/batch), lr: 0.003125
2019-03-17 13:56:14,682 2019-03-17 13:56:14: step 1549/50000, loss = 0.000000 (2.724 sec/batch), lr: 0.003125
2019-03-17 13:56:15,746 2019-03-17 13:56:15: step 1550/50000, loss = 0.000000 (1.041 sec/batch), lr: 0.003125
2019-03-17 13:57:26,994 2019-03-17 13:57:26: step 1551/50000, loss = 0.000000 (71.146 sec/batch), lr: 0.003125
2019-03-17 13:57:35,903 2019-03-17 13:57:35: step 1552/50000, loss = 0.000000 (8.825 sec/batch), lr: 0.003125
2019-03-17 13:57:41,091 2019-03-17 13:57:41: step 1553/50000, loss = 0.000000 (5.122 sec/batch), lr: 0.003125
2019-03-17 13:57:43,902 2019-03-17 13:57:43: step 1554/50000, loss = 0.000000 (2.757 sec/batch), lr: 0.003125
2019-03-17 13:57:45,023 2019-03-17 13:57:45: step 1555/50000, loss = 0.000000 (1.086 sec/batch), lr: 0.003125
2019-03-17 13:58:56,132 2019-03-17 13:58:56: step 1556/50000, loss = 0.000000 (70.979 sec/batch), lr: 0.003125
2019-03-17 13:59:05,140 2019-03-17 13:59:05: step 1557/50000, loss = 0.000000 (8.924 sec/batch), lr: 0.003125
2019-03-17 13:59:10,491 2019-03-17 13:59:10: step 1558/50000, loss = 0.000000 (5.274 sec/batch), lr: 0.003125
2019-03-17 13:59:13,314 2019-03-17 13:59:13: step 1559/50000, loss = 0.000000 (2.761 sec/batch), lr: 0.003125
2019-03-17 13:59:14,448 2019-03-17 13:59:14: step 1560/50000, loss = 0.000000 (1.099 sec/batch), lr: 0.003125
2019-03-17 14:00:25,641 2019-03-17 14:00:25: step 1561/50000, loss = 0.000000 (71.038 sec/batch), lr: 0.003125
2019-03-17 14:00:34,627 2019-03-17 14:00:34: step 1562/50000, loss = 0.000000 (8.899 sec/batch), lr: 0.003125
2019-03-17 14:00:39,822 2019-03-17 14:00:39: step 1563/50000, loss = 0.000000 (5.127 sec/batch), lr: 0.003125
2019-03-17 14:00:42,632 2019-03-17 14:00:42: step 1564/50000, loss = 0.000000 (2.755 sec/batch), lr: 0.003125
2019-03-17 14:00:43,774 2019-03-17 14:00:43: step 1565/50000, loss = 0.000000 (1.107 sec/batch), lr: 0.003125
2019-03-17 14:01:55,050 2019-03-17 14:01:55: step 1566/50000, loss = 0.000000 (71.122 sec/batch), lr: 0.003125
2019-03-17 14:02:03,972 2019-03-17 14:02:03: step 1567/50000, loss = 0.000000 (8.842 sec/batch), lr: 0.003125
2019-03-17 14:02:09,427 2019-03-17 14:02:09: step 1568/50000, loss = 0.000000 (5.117 sec/batch), lr: 0.003125
2019-03-17 14:02:12,269 2019-03-17 14:02:12: step 1569/50000, loss = 0.000000 (2.786 sec/batch), lr: 0.003125
2019-03-17 14:02:13,426 2019-03-17 14:02:13: step 1570/50000, loss = 0.000000 (1.118 sec/batch), lr: 0.003125
2019-03-17 14:03:24,543 2019-03-17 14:03:24: step 1571/50000, loss = 0.000000 (70.970 sec/batch), lr: 0.003125
2019-03-17 14:03:33,339 2019-03-17 14:03:33: step 1572/50000, loss = 0.000000 (8.733 sec/batch), lr: 0.003125
2019-03-17 14:03:38,509 2019-03-17 14:03:38: step 1573/50000, loss = 0.000000 (5.119 sec/batch), lr: 0.003125
2019-03-17 14:03:41,298 2019-03-17 14:03:41: step 1574/50000, loss = 0.000000 (2.752 sec/batch), lr: 0.003125
2019-03-17 14:03:42,398 2019-03-17 14:03:42: step 1575/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.003125
2019-03-17 14:04:53,921 2019-03-17 14:04:53: step 1576/50000, loss = 0.000000 (71.389 sec/batch), lr: 0.003125
2019-03-17 14:05:02,894 2019-03-17 14:05:02: step 1577/50000, loss = 0.000000 (8.892 sec/batch), lr: 0.003125
2019-03-17 14:05:08,137 2019-03-17 14:05:08: step 1578/50000, loss = 0.000000 (5.177 sec/batch), lr: 0.003125
2019-03-17 14:05:10,975 2019-03-17 14:05:10: step 1579/50000, loss = 0.000000 (2.777 sec/batch), lr: 0.003125
2019-03-17 14:05:12,114 2019-03-17 14:05:12: step 1580/50000, loss = 0.000000 (1.105 sec/batch), lr: 0.003125
2019-03-17 14:06:23,664 2019-03-17 14:06:23: step 1581/50000, loss = 0.000000 (71.402 sec/batch), lr: 0.003125
2019-03-17 14:06:32,652 2019-03-17 14:06:32: step 1582/50000, loss = 0.000000 (8.903 sec/batch), lr: 0.003125
2019-03-17 14:06:38,021 2019-03-17 14:06:38: step 1583/50000, loss = 0.000000 (5.292 sec/batch), lr: 0.003125
2019-03-17 14:06:40,875 2019-03-17 14:06:40: step 1584/50000, loss = 0.000000 (2.793 sec/batch), lr: 0.003125
2019-03-17 14:06:42,025 2019-03-17 14:06:42: step 1585/50000, loss = 0.000000 (1.111 sec/batch), lr: 0.003125
2019-03-17 14:07:53,156 2019-03-17 14:07:53: step 1586/50000, loss = 0.000000 (71.013 sec/batch), lr: 0.003125
2019-03-17 14:08:02,106 2019-03-17 14:08:02: step 1587/50000, loss = 0.000000 (8.867 sec/batch), lr: 0.003125
2019-03-17 14:08:07,328 2019-03-17 14:08:07: step 1588/50000, loss = 0.000000 (5.153 sec/batch), lr: 0.003125
2019-03-17 14:08:10,141 2019-03-17 14:08:10: step 1589/50000, loss = 0.000000 (2.759 sec/batch), lr: 0.003125
2019-03-17 14:08:11,272 2019-03-17 14:08:11: step 1590/50000, loss = 0.000000 (1.097 sec/batch), lr: 0.003125
2019-03-17 14:09:22,142 2019-03-17 14:09:22: step 1591/50000, loss = 0.000000 (70.738 sec/batch), lr: 0.003125
2019-03-17 14:09:31,129 2019-03-17 14:09:31: step 1592/50000, loss = 0.000000 (8.906 sec/batch), lr: 0.003125
2019-03-17 14:09:36,473 2019-03-17 14:09:36: step 1593/50000, loss = 0.000000 (5.267 sec/batch), lr: 0.003125
2019-03-17 14:09:39,269 2019-03-17 14:09:39: step 1594/50000, loss = 0.000000 (2.736 sec/batch), lr: 0.003125
2019-03-17 14:09:40,399 2019-03-17 14:09:40: step 1595/50000, loss = 0.000000 (1.094 sec/batch), lr: 0.003125
2019-03-17 14:10:51,722 2019-03-17 14:10:51: step 1596/50000, loss = 0.000000 (71.192 sec/batch), lr: 0.003125
2019-03-17 14:11:00,717 2019-03-17 14:11:00: step 1597/50000, loss = 0.000000 (8.913 sec/batch), lr: 0.003125
2019-03-17 14:11:06,172 2019-03-17 14:11:06: step 1598/50000, loss = 0.000000 (5.123 sec/batch), lr: 0.003125
2019-03-17 14:11:09,003 2019-03-17 14:11:09: step 1599/50000, loss = 0.000000 (2.774 sec/batch), lr: 0.003125
2019-03-17 14:11:10,132 2019-03-17 14:11:10: step 1600/50000, loss = 0.000000 (1.095 sec/batch), lr: 0.003125
2019-03-17 14:11:55,531 step 1600: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 14:11:55,589 step 1600: Dev acc. = 0.000000
2019-03-17 14:13:06,927 2019-03-17 14:13:06: step 1601/50000, loss = 0.000000 (71.223 sec/batch), lr: 0.003125
2019-03-17 14:13:15,872 2019-03-17 14:13:15: step 1602/50000, loss = 0.000000 (8.859 sec/batch), lr: 0.003125
2019-03-17 14:13:21,220 2019-03-17 14:13:21: step 1603/50000, loss = 0.000000 (5.272 sec/batch), lr: 0.003125
2019-03-17 14:13:24,086 2019-03-17 14:13:24: step 1604/50000, loss = 0.000000 (2.804 sec/batch), lr: 0.003125
2019-03-17 14:13:25,236 2019-03-17 14:13:25: step 1605/50000, loss = 0.000000 (1.110 sec/batch), lr: 0.003125
2019-03-17 14:14:36,646 2019-03-17 14:14:36: step 1606/50000, loss = 0.000000 (71.281 sec/batch), lr: 0.003125
2019-03-17 14:14:45,601 2019-03-17 14:14:45: step 1607/50000, loss = 0.000000 (8.870 sec/batch), lr: 0.003125
2019-03-17 14:14:50,816 2019-03-17 14:14:50: step 1608/50000, loss = 0.000000 (5.149 sec/batch), lr: 0.003125
2019-03-17 14:14:53,677 2019-03-17 14:14:53: step 1609/50000, loss = 0.000000 (2.801 sec/batch), lr: 0.003125
2019-03-17 14:14:54,838 2019-03-17 14:14:54: step 1610/50000, loss = 0.000000 (1.121 sec/batch), lr: 0.003125
2019-03-17 14:16:06,288 2019-03-17 14:16:06: step 1611/50000, loss = 0.000000 (71.299 sec/batch), lr: 0.003125
2019-03-17 14:16:15,090 2019-03-17 14:16:15: step 1612/50000, loss = 0.000000 (8.722 sec/batch), lr: 0.003125
2019-03-17 14:16:20,284 2019-03-17 14:16:20: step 1613/50000, loss = 0.000000 (5.144 sec/batch), lr: 0.003125
2019-03-17 14:16:23,133 2019-03-17 14:16:23: step 1614/50000, loss = 0.000000 (2.790 sec/batch), lr: 0.003125
2019-03-17 14:16:24,291 2019-03-17 14:16:24: step 1615/50000, loss = 0.000000 (1.120 sec/batch), lr: 0.003125
2019-03-17 14:17:35,855 2019-03-17 14:17:35: step 1616/50000, loss = 0.000000 (71.410 sec/batch), lr: 0.003125
2019-03-17 14:17:44,852 2019-03-17 14:17:44: step 1617/50000, loss = 0.000000 (8.914 sec/batch), lr: 0.003125
2019-03-17 14:17:50,118 2019-03-17 14:17:50: step 1618/50000, loss = 0.000000 (5.199 sec/batch), lr: 0.003125
2019-03-17 14:17:52,963 2019-03-17 14:17:52: step 1619/50000, loss = 0.000000 (2.784 sec/batch), lr: 0.003125
2019-03-17 14:17:54,119 2019-03-17 14:17:54: step 1620/50000, loss = 0.000000 (1.116 sec/batch), lr: 0.003125
2019-03-17 14:19:05,519 2019-03-17 14:19:05: step 1621/50000, loss = 0.000000 (71.270 sec/batch), lr: 0.003125
2019-03-17 14:19:14,509 2019-03-17 14:19:14: step 1622/50000, loss = 0.000000 (8.904 sec/batch), lr: 0.003125
2019-03-17 14:19:19,763 2019-03-17 14:19:19: step 1623/50000, loss = 0.000000 (5.182 sec/batch), lr: 0.003125
2019-03-17 14:19:22,607 2019-03-17 14:19:22: step 1624/50000, loss = 0.000000 (2.782 sec/batch), lr: 0.003125
2019-03-17 14:19:23,736 2019-03-17 14:19:23: step 1625/50000, loss = 0.000000 (1.095 sec/batch), lr: 0.003125
2019-03-17 14:20:35,272 2019-03-17 14:20:35: step 1626/50000, loss = 0.000000 (71.407 sec/batch), lr: 0.003125
2019-03-17 14:20:44,167 2019-03-17 14:20:44: step 1627/50000, loss = 0.000000 (8.812 sec/batch), lr: 0.003125
2019-03-17 14:20:49,512 2019-03-17 14:20:49: step 1628/50000, loss = 0.000000 (5.270 sec/batch), lr: 0.003125
2019-03-17 14:20:52,305 2019-03-17 14:20:52: step 1629/50000, loss = 0.000000 (2.736 sec/batch), lr: 0.003125
2019-03-17 14:20:53,441 2019-03-17 14:20:53: step 1630/50000, loss = 0.000000 (1.100 sec/batch), lr: 0.003125
2019-03-17 14:22:05,140 2019-03-17 14:22:05: step 1631/50000, loss = 0.000000 (71.304 sec/batch), lr: 0.003125
2019-03-17 14:22:14,139 2019-03-17 14:22:14: step 1632/50000, loss = 0.000000 (8.914 sec/batch), lr: 0.003125
2019-03-17 14:22:19,371 2019-03-17 14:22:19: step 1633/50000, loss = 0.000000 (5.166 sec/batch), lr: 0.003125
2019-03-17 14:22:22,212 2019-03-17 14:22:22: step 1634/50000, loss = 0.000000 (2.785 sec/batch), lr: 0.003125
2019-03-17 14:22:23,357 2019-03-17 14:22:23: step 1635/50000, loss = 0.000000 (1.112 sec/batch), lr: 0.003125
2019-03-17 14:23:34,674 2019-03-17 14:23:34: step 1636/50000, loss = 0.000000 (71.163 sec/batch), lr: 0.003125
2019-03-17 14:23:43,694 2019-03-17 14:23:43: step 1637/50000, loss = 0.000000 (8.938 sec/batch), lr: 0.003125
2019-03-17 14:23:48,886 2019-03-17 14:23:48: step 1638/50000, loss = 0.000000 (5.123 sec/batch), lr: 0.003125
2019-03-17 14:23:51,736 2019-03-17 14:23:51: step 1639/50000, loss = 0.000000 (2.789 sec/batch), lr: 0.003125
2019-03-17 14:23:52,873 2019-03-17 14:23:52: step 1640/50000, loss = 0.000000 (1.097 sec/batch), lr: 0.003125
2019-03-17 14:25:04,231 2019-03-17 14:25:04: step 1641/50000, loss = 0.000000 (71.244 sec/batch), lr: 0.003125
2019-03-17 14:25:13,065 2019-03-17 14:25:13: step 1642/50000, loss = 0.000000 (8.754 sec/batch), lr: 0.003125
2019-03-17 14:25:18,278 2019-03-17 14:25:18: step 1643/50000, loss = 0.000000 (5.161 sec/batch), lr: 0.003125
2019-03-17 14:25:21,126 2019-03-17 14:25:21: step 1644/50000, loss = 0.000000 (2.785 sec/batch), lr: 0.003125
2019-03-17 14:25:22,267 2019-03-17 14:25:22: step 1645/50000, loss = 0.000000 (1.101 sec/batch), lr: 0.003125
2019-03-17 14:26:33,667 2019-03-17 14:26:33: step 1646/50000, loss = 0.000000 (71.286 sec/batch), lr: 0.003125
2019-03-17 14:26:42,638 2019-03-17 14:26:42: step 1647/50000, loss = 0.000000 (8.888 sec/batch), lr: 0.003125
2019-03-17 14:26:47,984 2019-03-17 14:26:47: step 1648/50000, loss = 0.000000 (5.270 sec/batch), lr: 0.003125
2019-03-17 14:26:50,841 2019-03-17 14:26:50: step 1649/50000, loss = 0.000000 (2.803 sec/batch), lr: 0.003125
2019-03-17 14:26:51,997 2019-03-17 14:26:51: step 1650/50000, loss = 0.000000 (1.116 sec/batch), lr: 0.003125
2019-03-17 14:28:03,070 2019-03-17 14:28:03: step 1651/50000, loss = 0.000000 (70.918 sec/batch), lr: 0.003125
2019-03-17 14:28:12,029 2019-03-17 14:28:12: step 1652/50000, loss = 0.000000 (8.873 sec/batch), lr: 0.003125
2019-03-17 14:28:17,410 2019-03-17 14:28:17: step 1653/50000, loss = 0.000000 (5.300 sec/batch), lr: 0.003125
2019-03-17 14:28:20,329 2019-03-17 14:28:20: step 1654/50000, loss = 0.000000 (2.858 sec/batch), lr: 0.003125
2019-03-17 14:28:21,489 2019-03-17 14:28:21: step 1655/50000, loss = 0.000000 (1.119 sec/batch), lr: 0.003125
2019-03-17 14:29:33,178 2019-03-17 14:29:33: step 1656/50000, loss = 0.000000 (71.532 sec/batch), lr: 0.003125
2019-03-17 14:29:42,018 2019-03-17 14:29:42: step 1657/50000, loss = 0.000000 (8.758 sec/batch), lr: 0.003125
2019-03-17 14:29:47,087 2019-03-17 14:29:47: step 1658/50000, loss = 0.000000 (5.002 sec/batch), lr: 0.003125
2019-03-17 14:29:49,833 2019-03-17 14:29:49: step 1659/50000, loss = 0.000000 (2.692 sec/batch), lr: 0.003125
2019-03-17 14:29:50,942 2019-03-17 14:29:50: step 1660/50000, loss = 0.000000 (1.075 sec/batch), lr: 0.003125
2019-03-17 14:31:01,919 2019-03-17 14:31:01: step 1661/50000, loss = 0.000000 (70.550 sec/batch), lr: 0.003125
2019-03-17 14:31:10,788 2019-03-17 14:31:10: step 1662/50000, loss = 0.000000 (8.788 sec/batch), lr: 0.003125
2019-03-17 14:31:16,076 2019-03-17 14:31:16: step 1663/50000, loss = 0.000000 (5.210 sec/batch), lr: 0.003125
2019-03-17 14:31:18,883 2019-03-17 14:31:18: step 1664/50000, loss = 0.000000 (2.750 sec/batch), lr: 0.003125
2019-03-17 14:31:19,978 2019-03-17 14:31:19: step 1665/50000, loss = 0.000000 (1.061 sec/batch), lr: 0.003125
2019-03-17 14:32:30,602 2019-03-17 14:32:30: step 1666/50000, loss = 0.000000 (70.506 sec/batch), lr: 0.003125
2019-03-17 14:32:39,484 2019-03-17 14:32:39: step 1667/50000, loss = 0.000000 (8.801 sec/batch), lr: 0.003125
2019-03-17 14:32:44,666 2019-03-17 14:32:44: step 1668/50000, loss = 0.000000 (5.115 sec/batch), lr: 0.003125
2019-03-17 14:32:47,605 2019-03-17 14:32:47: step 1669/50000, loss = 0.000000 (2.877 sec/batch), lr: 0.003125
2019-03-17 14:32:48,728 2019-03-17 14:32:48: step 1670/50000, loss = 0.000000 (1.089 sec/batch), lr: 0.003125
2019-03-17 14:34:00,406 2019-03-17 14:34:00: step 1671/50000, loss = 0.000000 (71.546 sec/batch), lr: 0.003125
2019-03-17 14:34:09,435 2019-03-17 14:34:09: step 1672/50000, loss = 0.000000 (8.944 sec/batch), lr: 0.003125
2019-03-17 14:34:14,796 2019-03-17 14:34:14: step 1673/50000, loss = 0.000000 (5.284 sec/batch), lr: 0.003125
2019-03-17 14:34:17,600 2019-03-17 14:34:17: step 1674/50000, loss = 0.000000 (2.749 sec/batch), lr: 0.003125
2019-03-17 14:34:18,748 2019-03-17 14:34:18: step 1675/50000, loss = 0.000000 (1.113 sec/batch), lr: 0.003125
2019-03-17 14:35:29,730 2019-03-17 14:35:29: step 1676/50000, loss = 0.000000 (70.831 sec/batch), lr: 0.003125
2019-03-17 14:35:38,656 2019-03-17 14:35:38: step 1677/50000, loss = 0.000000 (8.846 sec/batch), lr: 0.003125
2019-03-17 14:35:43,989 2019-03-17 14:35:43: step 1678/50000, loss = 0.000000 (5.257 sec/batch), lr: 0.003125
2019-03-17 14:35:46,799 2019-03-17 14:35:46: step 1679/50000, loss = 0.000000 (2.748 sec/batch), lr: 0.003125
2019-03-17 14:35:47,939 2019-03-17 14:35:47: step 1680/50000, loss = 0.000000 (1.106 sec/batch), lr: 0.003125
2019-03-17 14:36:59,319 2019-03-17 14:36:59: step 1681/50000, loss = 0.000000 (71.224 sec/batch), lr: 0.003125
2019-03-17 14:37:08,282 2019-03-17 14:37:08: step 1682/50000, loss = 0.000000 (8.878 sec/batch), lr: 0.003125
2019-03-17 14:37:13,615 2019-03-17 14:37:13: step 1683/50000, loss = 0.000000 (5.255 sec/batch), lr: 0.003125
2019-03-17 14:37:16,443 2019-03-17 14:37:16: step 1684/50000, loss = 0.000000 (2.774 sec/batch), lr: 0.003125
2019-03-17 14:37:17,566 2019-03-17 14:37:17: step 1685/50000, loss = 0.000000 (1.088 sec/batch), lr: 0.003125
2019-03-17 14:38:29,065 2019-03-17 14:38:29: step 1686/50000, loss = 0.000000 (71.364 sec/batch), lr: 0.003125
2019-03-17 14:38:37,962 2019-03-17 14:38:37: step 1687/50000, loss = 0.000000 (8.814 sec/batch), lr: 0.003125
2019-03-17 14:38:43,200 2019-03-17 14:38:43: step 1688/50000, loss = 0.000000 (5.170 sec/batch), lr: 0.003125
2019-03-17 14:38:46,053 2019-03-17 14:38:46: step 1689/50000, loss = 0.000000 (2.791 sec/batch), lr: 0.003125
2019-03-17 14:38:47,213 2019-03-17 14:38:47: step 1690/50000, loss = 0.000000 (1.120 sec/batch), lr: 0.003125
2019-03-17 14:39:59,023 2019-03-17 14:39:59: step 1691/50000, loss = 0.000000 (71.404 sec/batch), lr: 0.003125
2019-03-17 14:40:07,912 2019-03-17 14:40:07: step 1692/50000, loss = 0.000000 (8.805 sec/batch), lr: 0.003125
2019-03-17 14:40:13,146 2019-03-17 14:40:13: step 1693/50000, loss = 0.000000 (5.165 sec/batch), lr: 0.003125
2019-03-17 14:40:15,992 2019-03-17 14:40:15: step 1694/50000, loss = 0.000000 (2.784 sec/batch), lr: 0.003125
2019-03-17 14:40:17,140 2019-03-17 14:40:17: step 1695/50000, loss = 0.000000 (1.109 sec/batch), lr: 0.003125
2019-03-17 14:41:28,224 2019-03-17 14:41:28: step 1696/50000, loss = 0.000000 (70.947 sec/batch), lr: 0.003125
2019-03-17 14:41:37,248 2019-03-17 14:41:37: step 1697/50000, loss = 0.000000 (8.942 sec/batch), lr: 0.003125
2019-03-17 14:41:42,527 2019-03-17 14:41:42: step 1698/50000, loss = 0.000000 (5.201 sec/batch), lr: 0.003125
2019-03-17 14:41:45,332 2019-03-17 14:41:45: step 1699/50000, loss = 0.000000 (2.752 sec/batch), lr: 0.003125
2019-03-17 14:41:46,444 2019-03-17 14:41:46: step 1700/50000, loss = 0.000000 (1.079 sec/batch), lr: 0.003125
2019-03-17 14:42:32,043 step 1700: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 14:42:32,101 step 1700: Dev acc. = 0.000000
2019-03-17 14:43:43,452 2019-03-17 14:43:43: step 1701/50000, loss = 0.000000 (71.251 sec/batch), lr: 0.003125
2019-03-17 14:43:52,461 2019-03-17 14:43:52: step 1702/50000, loss = 0.000000 (8.929 sec/batch), lr: 0.003125
2019-03-17 14:43:57,818 2019-03-17 14:43:57: step 1703/50000, loss = 0.000000 (5.280 sec/batch), lr: 0.003125
2019-03-17 14:44:00,623 2019-03-17 14:44:00: step 1704/50000, loss = 0.000000 (2.743 sec/batch), lr: 0.003125
2019-03-17 14:44:01,770 2019-03-17 14:44:01: step 1705/50000, loss = 0.000000 (1.112 sec/batch), lr: 0.003125
2019-03-17 14:45:13,226 2019-03-17 14:45:13: step 1706/50000, loss = 0.000000 (71.301 sec/batch), lr: 0.003125
2019-03-17 14:45:22,224 2019-03-17 14:45:22: step 1707/50000, loss = 0.000000 (8.915 sec/batch), lr: 0.003125
2019-03-17 14:45:27,576 2019-03-17 14:45:27: step 1708/50000, loss = 0.000000 (5.274 sec/batch), lr: 0.003125
2019-03-17 14:45:30,565 2019-03-17 14:45:30: step 1709/50000, loss = 0.000000 (2.923 sec/batch), lr: 0.003125
2019-03-17 14:45:31,717 2019-03-17 14:45:31: step 1710/50000, loss = 0.000000 (1.113 sec/batch), lr: 0.003125
2019-03-17 14:46:42,948 2019-03-17 14:46:42: step 1711/50000, loss = 0.000000 (71.096 sec/batch), lr: 0.003125
2019-03-17 14:46:51,913 2019-03-17 14:46:51: step 1712/50000, loss = 0.000000 (8.883 sec/batch), lr: 0.003125
2019-03-17 14:46:57,237 2019-03-17 14:46:57: step 1713/50000, loss = 0.000000 (5.247 sec/batch), lr: 0.003125
2019-03-17 14:47:00,081 2019-03-17 14:47:00: step 1714/50000, loss = 0.000000 (2.782 sec/batch), lr: 0.003125
2019-03-17 14:47:01,239 2019-03-17 14:47:01: step 1715/50000, loss = 0.000000 (1.118 sec/batch), lr: 0.003125
2019-03-17 14:48:12,735 2019-03-17 14:48:12: step 1716/50000, loss = 0.000000 (71.342 sec/batch), lr: 0.003125
2019-03-17 14:48:21,652 2019-03-17 14:48:21: step 1717/50000, loss = 0.000000 (8.835 sec/batch), lr: 0.003125
2019-03-17 14:48:27,033 2019-03-17 14:48:27: step 1718/50000, loss = 0.000000 (5.276 sec/batch), lr: 0.003125
2019-03-17 14:48:29,836 2019-03-17 14:48:29: step 1719/50000, loss = 0.000000 (2.750 sec/batch), lr: 0.003125
2019-03-17 14:48:30,970 2019-03-17 14:48:30: step 1720/50000, loss = 0.000000 (1.099 sec/batch), lr: 0.003125
2019-03-17 14:49:42,666 2019-03-17 14:49:42: step 1721/50000, loss = 0.000000 (71.270 sec/batch), lr: 0.003125
2019-03-17 14:49:51,634 2019-03-17 14:49:51: step 1722/50000, loss = 0.000000 (8.883 sec/batch), lr: 0.003125
2019-03-17 14:49:56,959 2019-03-17 14:49:56: step 1723/50000, loss = 0.000000 (5.249 sec/batch), lr: 0.003125
2019-03-17 14:49:59,783 2019-03-17 14:49:59: step 1724/50000, loss = 0.000000 (2.766 sec/batch), lr: 0.003125
2019-03-17 14:50:00,916 2019-03-17 14:50:00: step 1725/50000, loss = 0.000000 (1.099 sec/batch), lr: 0.003125
2019-03-17 14:51:12,158 2019-03-17 14:51:12: step 1726/50000, loss = 0.000000 (71.089 sec/batch), lr: 0.003125
2019-03-17 14:51:21,024 2019-03-17 14:51:21: step 1727/50000, loss = 0.000000 (8.784 sec/batch), lr: 0.003125
2019-03-17 14:51:26,245 2019-03-17 14:51:26: step 1728/50000, loss = 0.000000 (5.152 sec/batch), lr: 0.003125
2019-03-17 14:51:29,144 2019-03-17 14:51:29: step 1729/50000, loss = 0.000000 (2.837 sec/batch), lr: 0.003125
2019-03-17 14:51:30,291 2019-03-17 14:51:30: step 1730/50000, loss = 0.000000 (1.107 sec/batch), lr: 0.003125
2019-03-17 14:52:41,489 2019-03-17 14:52:41: step 1731/50000, loss = 0.000000 (71.046 sec/batch), lr: 0.003125
2019-03-17 14:52:50,408 2019-03-17 14:52:50: step 1732/50000, loss = 0.000000 (8.838 sec/batch), lr: 0.003125
2019-03-17 14:52:55,572 2019-03-17 14:52:55: step 1733/50000, loss = 0.000000 (5.100 sec/batch), lr: 0.003125
2019-03-17 14:52:58,366 2019-03-17 14:52:58: step 1734/50000, loss = 0.000000 (2.738 sec/batch), lr: 0.003125
2019-03-17 14:52:59,482 2019-03-17 14:52:59: step 1735/50000, loss = 0.000000 (1.083 sec/batch), lr: 0.003125
2019-03-17 14:54:10,291 2019-03-17 14:54:10: step 1736/50000, loss = 0.000000 (70.680 sec/batch), lr: 0.003125
2019-03-17 14:54:19,165 2019-03-17 14:54:19: step 1737/50000, loss = 0.000000 (8.795 sec/batch), lr: 0.003125
2019-03-17 14:54:24,327 2019-03-17 14:54:24: step 1738/50000, loss = 0.000000 (5.094 sec/batch), lr: 0.003125
2019-03-17 14:54:27,131 2019-03-17 14:54:27: step 1739/50000, loss = 0.000000 (2.750 sec/batch), lr: 0.003125
2019-03-17 14:54:28,242 2019-03-17 14:54:28: step 1740/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.003125
2019-03-17 14:55:40,264 2019-03-17 14:55:40: step 1741/50000, loss = 0.000000 (71.900 sec/batch), lr: 0.003125
2019-03-17 14:55:49,155 2019-03-17 14:55:49: step 1742/50000, loss = 0.000000 (8.810 sec/batch), lr: 0.003125
2019-03-17 14:55:54,261 2019-03-17 14:55:54: step 1743/50000, loss = 0.000000 (5.039 sec/batch), lr: 0.003125
2019-03-17 14:55:57,058 2019-03-17 14:55:57: step 1744/50000, loss = 0.000000 (2.735 sec/batch), lr: 0.003125
2019-03-17 14:55:58,162 2019-03-17 14:55:58: step 1745/50000, loss = 0.000000 (1.070 sec/batch), lr: 0.003125
2019-03-17 14:57:09,432 2019-03-17 14:57:09: step 1746/50000, loss = 0.000000 (71.113 sec/batch), lr: 0.003125
2019-03-17 14:57:18,411 2019-03-17 14:57:18: step 1747/50000, loss = 0.000000 (8.894 sec/batch), lr: 0.003125
2019-03-17 14:57:23,737 2019-03-17 14:57:23: step 1748/50000, loss = 0.000000 (5.249 sec/batch), lr: 0.003125
2019-03-17 14:57:26,597 2019-03-17 14:57:26: step 1749/50000, loss = 0.000000 (2.799 sec/batch), lr: 0.003125
2019-03-17 14:57:27,850 2019-03-17 14:57:27: step 1750/50000, loss = 0.000000 (1.214 sec/batch), lr: 0.003125
2019-03-17 14:58:38,814 2019-03-17 14:58:38: step 1751/50000, loss = 0.000000 (70.813 sec/batch), lr: 0.003125
2019-03-17 14:58:47,743 2019-03-17 14:58:47: step 1752/50000, loss = 0.000000 (8.846 sec/batch), lr: 0.003125
2019-03-17 14:58:52,931 2019-03-17 14:58:52: step 1753/50000, loss = 0.000000 (5.120 sec/batch), lr: 0.003125
2019-03-17 14:58:55,939 2019-03-17 14:58:55: step 1754/50000, loss = 0.000000 (2.953 sec/batch), lr: 0.003125
2019-03-17 14:58:57,017 2019-03-17 14:58:57: step 1755/50000, loss = 0.000000 (1.045 sec/batch), lr: 0.003125
2019-03-17 15:00:08,022 2019-03-17 15:00:08: step 1756/50000, loss = 0.000000 (70.862 sec/batch), lr: 0.003125
2019-03-17 15:00:16,961 2019-03-17 15:00:16: step 1757/50000, loss = 0.000000 (8.859 sec/batch), lr: 0.003125
2019-03-17 15:00:22,116 2019-03-17 15:00:22: step 1758/50000, loss = 0.000000 (5.083 sec/batch), lr: 0.003125
2019-03-17 15:00:24,952 2019-03-17 15:00:24: step 1759/50000, loss = 0.000000 (2.779 sec/batch), lr: 0.003125
2019-03-17 15:00:26,062 2019-03-17 15:00:26: step 1760/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.003125
2019-03-17 15:01:37,098 2019-03-17 15:01:37: step 1761/50000, loss = 0.000000 (70.912 sec/batch), lr: 0.003125
2019-03-17 15:01:46,048 2019-03-17 15:01:46: step 1762/50000, loss = 0.000000 (8.869 sec/batch), lr: 0.003125
2019-03-17 15:01:51,338 2019-03-17 15:01:51: step 1763/50000, loss = 0.000000 (5.216 sec/batch), lr: 0.003125
2019-03-17 15:01:54,173 2019-03-17 15:01:54: step 1764/50000, loss = 0.000000 (2.773 sec/batch), lr: 0.003125
2019-03-17 15:01:55,319 2019-03-17 15:01:55: step 1765/50000, loss = 0.000000 (1.107 sec/batch), lr: 0.003125
2019-03-17 15:03:06,004 2019-03-17 15:03:06: step 1766/50000, loss = 0.000000 (70.529 sec/batch), lr: 0.003125
2019-03-17 15:03:14,965 2019-03-17 15:03:14: step 1767/50000, loss = 0.000000 (8.769 sec/batch), lr: 0.003125
2019-03-17 15:03:20,124 2019-03-17 15:03:20: step 1768/50000, loss = 0.000000 (5.087 sec/batch), lr: 0.003125
2019-03-17 15:03:22,911 2019-03-17 15:03:22: step 1769/50000, loss = 0.000000 (2.732 sec/batch), lr: 0.003125
2019-03-17 15:03:24,056 2019-03-17 15:03:24: step 1770/50000, loss = 0.000000 (1.105 sec/batch), lr: 0.003125
2019-03-17 15:04:34,375 2019-03-17 15:04:34: step 1771/50000, loss = 0.000000 (70.182 sec/batch), lr: 0.003125
2019-03-17 15:04:43,177 2019-03-17 15:04:43: step 1772/50000, loss = 0.000000 (8.719 sec/batch), lr: 0.003125
2019-03-17 15:04:48,297 2019-03-17 15:04:48: step 1773/50000, loss = 0.000000 (5.052 sec/batch), lr: 0.003125
2019-03-17 15:04:51,094 2019-03-17 15:04:51: step 1774/50000, loss = 0.000000 (2.744 sec/batch), lr: 0.003125
2019-03-17 15:04:52,238 2019-03-17 15:04:52: step 1775/50000, loss = 0.000000 (1.104 sec/batch), lr: 0.003125
2019-03-17 15:06:02,781 2019-03-17 15:06:02: step 1776/50000, loss = 0.000000 (70.403 sec/batch), lr: 0.003125
2019-03-17 15:06:11,597 2019-03-17 15:06:11: step 1777/50000, loss = 0.000000 (8.734 sec/batch), lr: 0.003125
2019-03-17 15:06:16,702 2019-03-17 15:06:16: step 1778/50000, loss = 0.000000 (5.040 sec/batch), lr: 0.003125
2019-03-17 15:06:19,480 2019-03-17 15:06:19: step 1779/50000, loss = 0.000000 (2.737 sec/batch), lr: 0.003125
2019-03-17 15:06:20,585 2019-03-17 15:06:20: step 1780/50000, loss = 0.000000 (1.072 sec/batch), lr: 0.003125
2019-03-17 15:07:30,962 2019-03-17 15:07:30: step 1781/50000, loss = 0.000000 (70.240 sec/batch), lr: 0.003125
2019-03-17 15:07:39,776 2019-03-17 15:07:39: step 1782/50000, loss = 0.000000 (8.728 sec/batch), lr: 0.003125
2019-03-17 15:07:45,224 2019-03-17 15:07:45: step 1783/50000, loss = 0.000000 (5.124 sec/batch), lr: 0.003125
2019-03-17 15:07:48,123 2019-03-17 15:07:48: step 1784/50000, loss = 0.000000 (2.837 sec/batch), lr: 0.003125
2019-03-17 15:07:49,239 2019-03-17 15:07:49: step 1785/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.003125
2019-03-17 15:08:59,388 2019-03-17 15:08:59: step 1786/50000, loss = 0.000000 (70.019 sec/batch), lr: 0.003125
2019-03-17 15:09:08,182 2019-03-17 15:09:08: step 1787/50000, loss = 0.000000 (8.715 sec/batch), lr: 0.003125
2019-03-17 15:09:13,285 2019-03-17 15:09:13: step 1788/50000, loss = 0.000000 (5.049 sec/batch), lr: 0.003125
2019-03-17 15:09:16,052 2019-03-17 15:09:16: step 1789/50000, loss = 0.000000 (2.728 sec/batch), lr: 0.003125
2019-03-17 15:09:17,160 2019-03-17 15:09:17: step 1790/50000, loss = 0.000000 (1.075 sec/batch), lr: 0.003125
2019-03-17 15:10:27,123 2019-03-17 15:10:27: step 1791/50000, loss = 0.000000 (69.840 sec/batch), lr: 0.003125
2019-03-17 15:10:35,963 2019-03-17 15:10:35: step 1792/50000, loss = 0.000000 (8.760 sec/batch), lr: 0.003125
2019-03-17 15:10:41,111 2019-03-17 15:10:41: step 1793/50000, loss = 0.000000 (5.086 sec/batch), lr: 0.003125
2019-03-17 15:10:43,860 2019-03-17 15:10:43: step 1794/50000, loss = 0.000000 (2.695 sec/batch), lr: 0.003125
2019-03-17 15:10:44,989 2019-03-17 15:10:44: step 1795/50000, loss = 0.000000 (1.096 sec/batch), lr: 0.003125
2019-03-17 15:11:55,037 2019-03-17 15:11:55: step 1796/50000, loss = 0.000000 (69.909 sec/batch), lr: 0.003125
2019-03-17 15:12:03,910 2019-03-17 15:12:03: step 1797/50000, loss = 0.000000 (8.748 sec/batch), lr: 0.003125
2019-03-17 15:12:09,138 2019-03-17 15:12:09: step 1798/50000, loss = 0.000000 (5.152 sec/batch), lr: 0.003125
2019-03-17 15:12:11,907 2019-03-17 15:12:11: step 1799/50000, loss = 0.000000 (2.713 sec/batch), lr: 0.003125
2019-03-17 15:12:13,050 2019-03-17 15:12:13: step 1800/50000, loss = 0.000000 (1.103 sec/batch), lr: 0.003125
2019-03-17 15:12:57,588 step 1800: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 15:12:57,645 step 1800: Dev acc. = 0.000000
2019-03-17 15:14:07,340 2019-03-17 15:14:07: step 1801/50000, loss = 0.000000 (69.587 sec/batch), lr: 0.001563
2019-03-17 15:14:16,079 2019-03-17 15:14:16: step 1802/50000, loss = 0.000000 (8.654 sec/batch), lr: 0.001563
2019-03-17 15:14:21,153 2019-03-17 15:14:21: step 1803/50000, loss = 0.000000 (5.007 sec/batch), lr: 0.001563
2019-03-17 15:14:23,877 2019-03-17 15:14:23: step 1804/50000, loss = 0.000000 (2.669 sec/batch), lr: 0.001563
2019-03-17 15:14:24,997 2019-03-17 15:14:24: step 1805/50000, loss = 0.000000 (1.086 sec/batch), lr: 0.001563
2019-03-17 15:15:34,436 2019-03-17 15:15:34: step 1806/50000, loss = 0.000000 (69.303 sec/batch), lr: 0.001563
2019-03-17 15:15:43,181 2019-03-17 15:15:43: step 1807/50000, loss = 0.000000 (8.662 sec/batch), lr: 0.001563
2019-03-17 15:15:48,247 2019-03-17 15:15:48: step 1808/50000, loss = 0.000000 (4.999 sec/batch), lr: 0.001563
2019-03-17 15:15:50,988 2019-03-17 15:15:50: step 1809/50000, loss = 0.000000 (2.687 sec/batch), lr: 0.001563
2019-03-17 15:15:52,082 2019-03-17 15:15:52: step 1810/50000, loss = 0.000000 (1.060 sec/batch), lr: 0.001563
2019-03-17 15:17:01,887 2019-03-17 15:17:01: step 1811/50000, loss = 0.000000 (69.675 sec/batch), lr: 0.001563
2019-03-17 15:17:11,087 2019-03-17 15:17:11: step 1812/50000, loss = 0.000000 (8.806 sec/batch), lr: 0.001563
2019-03-17 15:17:16,476 2019-03-17 15:17:16: step 1813/50000, loss = 0.000000 (5.313 sec/batch), lr: 0.001563
2019-03-17 15:17:19,466 2019-03-17 15:17:19: step 1814/50000, loss = 0.000000 (2.928 sec/batch), lr: 0.001563
2019-03-17 15:17:20,619 2019-03-17 15:17:20: step 1815/50000, loss = 0.000000 (1.118 sec/batch), lr: 0.001563
2019-03-17 15:18:30,866 2019-03-17 15:18:30: step 1816/50000, loss = 0.000000 (70.093 sec/batch), lr: 0.001563
2019-03-17 15:18:39,699 2019-03-17 15:18:39: step 1817/50000, loss = 0.000000 (8.752 sec/batch), lr: 0.001563
2019-03-17 15:18:44,954 2019-03-17 15:18:44: step 1818/50000, loss = 0.000000 (5.178 sec/batch), lr: 0.001563
2019-03-17 15:18:47,856 2019-03-17 15:18:47: step 1819/50000, loss = 0.000000 (2.840 sec/batch), lr: 0.001563
2019-03-17 15:18:49,008 2019-03-17 15:18:49: step 1820/50000, loss = 0.000000 (1.112 sec/batch), lr: 0.001563
2019-03-17 15:19:59,087 2019-03-17 15:19:59: step 1821/50000, loss = 0.000000 (69.927 sec/batch), lr: 0.001563
2019-03-17 15:20:08,100 2019-03-17 15:20:08: step 1822/50000, loss = 0.000000 (8.931 sec/batch), lr: 0.001563
2019-03-17 15:20:13,447 2019-03-17 15:20:13: step 1823/50000, loss = 0.000000 (5.268 sec/batch), lr: 0.001563
2019-03-17 15:20:16,275 2019-03-17 15:20:16: step 1824/50000, loss = 0.000000 (2.773 sec/batch), lr: 0.001563
2019-03-17 15:20:17,410 2019-03-17 15:20:17: step 1825/50000, loss = 0.000000 (1.100 sec/batch), lr: 0.001563
2019-03-17 15:21:28,697 2019-03-17 15:21:28: step 1826/50000, loss = 0.000000 (71.154 sec/batch), lr: 0.001563
2019-03-17 15:21:37,671 2019-03-17 15:21:37: step 1827/50000, loss = 0.000000 (8.892 sec/batch), lr: 0.001563
2019-03-17 15:21:42,882 2019-03-17 15:21:42: step 1828/50000, loss = 0.000000 (5.139 sec/batch), lr: 0.001563
2019-03-17 15:21:45,708 2019-03-17 15:21:45: step 1829/50000, loss = 0.000000 (2.771 sec/batch), lr: 0.001563
2019-03-17 15:21:46,840 2019-03-17 15:21:46: step 1830/50000, loss = 0.000000 (1.098 sec/batch), lr: 0.001563
2019-03-17 15:22:58,098 2019-03-17 15:22:58: step 1831/50000, loss = 0.000000 (71.104 sec/batch), lr: 0.001563
2019-03-17 15:23:07,083 2019-03-17 15:23:07: step 1832/50000, loss = 0.000000 (8.901 sec/batch), lr: 0.001563
2019-03-17 15:23:12,427 2019-03-17 15:23:12: step 1833/50000, loss = 0.000000 (5.266 sec/batch), lr: 0.001563
2019-03-17 15:23:15,244 2019-03-17 15:23:15: step 1834/50000, loss = 0.000000 (2.761 sec/batch), lr: 0.001563
2019-03-17 15:23:16,374 2019-03-17 15:23:16: step 1835/50000, loss = 0.000000 (1.090 sec/batch), lr: 0.001563
2019-03-17 15:24:27,769 2019-03-17 15:24:27: step 1836/50000, loss = 0.000000 (71.282 sec/batch), lr: 0.001563
2019-03-17 15:24:36,513 2019-03-17 15:24:36: step 1837/50000, loss = 0.000000 (8.644 sec/batch), lr: 0.001563
2019-03-17 15:24:41,594 2019-03-17 15:24:41: step 1838/50000, loss = 0.000000 (5.031 sec/batch), lr: 0.001563
2019-03-17 15:24:44,309 2019-03-17 15:24:44: step 1839/50000, loss = 0.000000 (2.677 sec/batch), lr: 0.001563
2019-03-17 15:24:45,351 2019-03-17 15:24:45: step 1840/50000, loss = 0.000000 (1.019 sec/batch), lr: 0.001563
2019-03-17 15:25:56,543 2019-03-17 15:25:56: step 1841/50000, loss = 0.000000 (71.096 sec/batch), lr: 0.001563
2019-03-17 15:26:05,525 2019-03-17 15:26:05: step 1842/50000, loss = 0.000000 (8.637 sec/batch), lr: 0.001563
2019-03-17 15:26:10,616 2019-03-17 15:26:10: step 1843/50000, loss = 0.000000 (5.041 sec/batch), lr: 0.001563
2019-03-17 15:26:13,338 2019-03-17 15:26:13: step 1844/50000, loss = 0.000000 (2.684 sec/batch), lr: 0.001563
2019-03-17 15:26:14,391 2019-03-17 15:26:14: step 1845/50000, loss = 0.000000 (1.029 sec/batch), lr: 0.001563
2019-03-17 15:27:25,748 2019-03-17 15:27:25: step 1846/50000, loss = 0.000000 (71.260 sec/batch), lr: 0.001563
2019-03-17 15:27:34,514 2019-03-17 15:27:34: step 1847/50000, loss = 0.000000 (8.702 sec/batch), lr: 0.001563
2019-03-17 15:27:39,613 2019-03-17 15:27:39: step 1848/50000, loss = 0.000000 (5.049 sec/batch), lr: 0.001563
2019-03-17 15:27:42,358 2019-03-17 15:27:42: step 1849/50000, loss = 0.000000 (2.708 sec/batch), lr: 0.001563
2019-03-17 15:27:43,411 2019-03-17 15:27:43: step 1850/50000, loss = 0.000000 (1.030 sec/batch), lr: 0.001563
2019-03-17 15:28:54,663 2019-03-17 15:28:54: step 1851/50000, loss = 0.000000 (71.143 sec/batch), lr: 0.001563
2019-03-17 15:29:03,329 2019-03-17 15:29:03: step 1852/50000, loss = 0.000000 (8.602 sec/batch), lr: 0.001563
2019-03-17 15:29:08,384 2019-03-17 15:29:08: step 1853/50000, loss = 0.000000 (5.005 sec/batch), lr: 0.001563
2019-03-17 15:29:11,089 2019-03-17 15:29:11: step 1854/50000, loss = 0.000000 (2.667 sec/batch), lr: 0.001563
2019-03-17 15:29:12,126 2019-03-17 15:29:12: step 1855/50000, loss = 0.000000 (1.014 sec/batch), lr: 0.001563
2019-03-17 15:30:22,881 2019-03-17 15:30:22: step 1856/50000, loss = 0.000000 (70.648 sec/batch), lr: 0.001563
2019-03-17 15:30:31,572 2019-03-17 15:30:31: step 1857/50000, loss = 0.000000 (8.627 sec/batch), lr: 0.001563
2019-03-17 15:30:36,619 2019-03-17 15:30:36: step 1858/50000, loss = 0.000000 (4.998 sec/batch), lr: 0.001563
2019-03-17 15:30:39,323 2019-03-17 15:30:39: step 1859/50000, loss = 0.000000 (2.666 sec/batch), lr: 0.001563
2019-03-17 15:30:40,355 2019-03-17 15:30:40: step 1860/50000, loss = 0.000000 (1.009 sec/batch), lr: 0.001563
2019-03-17 15:31:51,036 2019-03-17 15:31:51: step 1861/50000, loss = 0.000000 (70.575 sec/batch), lr: 0.001563
2019-03-17 15:31:59,696 2019-03-17 15:31:59: step 1862/50000, loss = 0.000000 (8.596 sec/batch), lr: 0.001563
2019-03-17 15:32:04,752 2019-03-17 15:32:04: step 1863/50000, loss = 0.000000 (5.006 sec/batch), lr: 0.001563
2019-03-17 15:32:07,442 2019-03-17 15:32:07: step 1864/50000, loss = 0.000000 (2.653 sec/batch), lr: 0.001563
2019-03-17 15:32:08,474 2019-03-17 15:32:08: step 1865/50000, loss = 0.000000 (1.010 sec/batch), lr: 0.001563
2019-03-17 15:33:19,392 2019-03-17 15:33:19: step 1866/50000, loss = 0.000000 (70.812 sec/batch), lr: 0.001563
2019-03-17 15:33:28,082 2019-03-17 15:33:28: step 1867/50000, loss = 0.000000 (8.625 sec/batch), lr: 0.001563
2019-03-17 15:33:33,168 2019-03-17 15:33:33: step 1868/50000, loss = 0.000000 (5.037 sec/batch), lr: 0.001563
2019-03-17 15:33:35,869 2019-03-17 15:33:35: step 1869/50000, loss = 0.000000 (2.664 sec/batch), lr: 0.001563
2019-03-17 15:33:36,894 2019-03-17 15:33:36: step 1870/50000, loss = 0.000000 (1.002 sec/batch), lr: 0.001563
2019-03-17 15:34:47,626 2019-03-17 15:34:47: step 1871/50000, loss = 0.000000 (70.625 sec/batch), lr: 0.001563
2019-03-17 15:34:56,266 2019-03-17 15:34:56: step 1872/50000, loss = 0.000000 (8.580 sec/batch), lr: 0.001563
2019-03-17 15:35:01,566 2019-03-17 15:35:01: step 1873/50000, loss = 0.000000 (4.979 sec/batch), lr: 0.001563
2019-03-17 15:35:04,244 2019-03-17 15:35:04: step 1874/50000, loss = 0.000000 (2.641 sec/batch), lr: 0.001563
2019-03-17 15:35:05,266 2019-03-17 15:35:05: step 1875/50000, loss = 0.000000 (1.000 sec/batch), lr: 0.001563
2019-03-17 15:36:15,885 2019-03-17 15:36:15: step 1876/50000, loss = 0.000000 (70.512 sec/batch), lr: 0.001563
2019-03-17 15:36:24,556 2019-03-17 15:36:24: step 1877/50000, loss = 0.000000 (8.606 sec/batch), lr: 0.001563
2019-03-17 15:36:29,592 2019-03-17 15:36:29: step 1878/50000, loss = 0.000000 (4.987 sec/batch), lr: 0.001563
2019-03-17 15:36:32,275 2019-03-17 15:36:32: step 1879/50000, loss = 0.000000 (2.646 sec/batch), lr: 0.001563
2019-03-17 15:36:33,315 2019-03-17 15:36:33: step 1880/50000, loss = 0.000000 (1.016 sec/batch), lr: 0.001563
2019-03-17 15:37:44,146 2019-03-17 15:37:44: step 1881/50000, loss = 0.000000 (70.732 sec/batch), lr: 0.001563
2019-03-17 15:37:52,850 2019-03-17 15:37:52: step 1882/50000, loss = 0.000000 (8.638 sec/batch), lr: 0.001563
2019-03-17 15:37:57,924 2019-03-17 15:37:57: step 1883/50000, loss = 0.000000 (5.021 sec/batch), lr: 0.001563
2019-03-17 15:38:00,614 2019-03-17 15:38:00: step 1884/50000, loss = 0.000000 (2.652 sec/batch), lr: 0.001563
2019-03-17 15:38:01,644 2019-03-17 15:38:01: step 1885/50000, loss = 0.000000 (1.008 sec/batch), lr: 0.001563
2019-03-17 15:39:12,302 2019-03-17 15:39:12: step 1886/50000, loss = 0.000000 (70.555 sec/batch), lr: 0.001563
2019-03-17 15:39:20,947 2019-03-17 15:39:20: step 1887/50000, loss = 0.000000 (8.581 sec/batch), lr: 0.001563
2019-03-17 15:39:25,987 2019-03-17 15:39:25: step 1888/50000, loss = 0.000000 (4.991 sec/batch), lr: 0.001563
2019-03-17 15:39:28,676 2019-03-17 15:39:28: step 1889/50000, loss = 0.000000 (2.651 sec/batch), lr: 0.001563
2019-03-17 15:39:29,705 2019-03-17 15:39:29: step 1890/50000, loss = 0.000000 (1.007 sec/batch), lr: 0.001563
2019-03-17 15:40:40,325 2019-03-17 15:40:40: step 1891/50000, loss = 0.000000 (70.513 sec/batch), lr: 0.001563
2019-03-17 15:40:48,959 2019-03-17 15:40:48: step 1892/50000, loss = 0.000000 (8.574 sec/batch), lr: 0.001563
2019-03-17 15:40:54,005 2019-03-17 15:40:54: step 1893/50000, loss = 0.000000 (4.996 sec/batch), lr: 0.001563
2019-03-17 15:40:56,690 2019-03-17 15:40:56: step 1894/50000, loss = 0.000000 (2.647 sec/batch), lr: 0.001563
2019-03-17 15:40:57,718 2019-03-17 15:40:57: step 1895/50000, loss = 0.000000 (1.005 sec/batch), lr: 0.001563
2019-03-17 15:42:08,309 2019-03-17 15:42:08: step 1896/50000, loss = 0.000000 (70.485 sec/batch), lr: 0.001563
2019-03-17 15:42:16,949 2019-03-17 15:42:16: step 1897/50000, loss = 0.000000 (8.576 sec/batch), lr: 0.001563
2019-03-17 15:42:21,984 2019-03-17 15:42:21: step 1898/50000, loss = 0.000000 (4.986 sec/batch), lr: 0.001563
2019-03-17 15:42:24,690 2019-03-17 15:42:24: step 1899/50000, loss = 0.000000 (2.668 sec/batch), lr: 0.001563
2019-03-17 15:42:25,720 2019-03-17 15:42:25: step 1900/50000, loss = 0.000000 (1.007 sec/batch), lr: 0.001563
2019-03-17 15:43:10,997 step 1900: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 15:43:11,007 step 1900: Dev acc. = 0.000000
2019-03-17 15:44:21,527 2019-03-17 15:44:21: step 1901/50000, loss = 0.000000 (70.421 sec/batch), lr: 0.001563
2019-03-17 15:44:30,205 2019-03-17 15:44:30: step 1902/50000, loss = 0.000000 (8.618 sec/batch), lr: 0.001563
2019-03-17 15:44:35,249 2019-03-17 15:44:35: step 1903/50000, loss = 0.000000 (4.995 sec/batch), lr: 0.001563
2019-03-17 15:44:37,938 2019-03-17 15:44:37: step 1904/50000, loss = 0.000000 (2.652 sec/batch), lr: 0.001563
2019-03-17 15:44:38,967 2019-03-17 15:44:38: step 1905/50000, loss = 0.000000 (1.007 sec/batch), lr: 0.001563
2019-03-17 15:45:49,997 2019-03-17 15:45:49: step 1906/50000, loss = 0.000000 (70.650 sec/batch), lr: 0.001563
2019-03-17 15:45:58,622 2019-03-17 15:45:58: step 1907/50000, loss = 0.000000 (8.564 sec/batch), lr: 0.001563
2019-03-17 15:46:03,664 2019-03-17 15:46:03: step 1908/50000, loss = 0.000000 (4.991 sec/batch), lr: 0.001563
2019-03-17 15:46:06,355 2019-03-17 15:46:06: step 1909/50000, loss = 0.000000 (2.654 sec/batch), lr: 0.001563
2019-03-17 15:46:07,384 2019-03-17 15:46:07: step 1910/50000, loss = 0.000000 (1.007 sec/batch), lr: 0.001563
2019-03-17 15:47:18,060 2019-03-17 15:47:18: step 1911/50000, loss = 0.000000 (70.569 sec/batch), lr: 0.001563
2019-03-17 15:47:26,715 2019-03-17 15:47:26: step 1912/50000, loss = 0.000000 (8.594 sec/batch), lr: 0.001563
2019-03-17 15:47:31,757 2019-03-17 15:47:31: step 1913/50000, loss = 0.000000 (4.990 sec/batch), lr: 0.001563
2019-03-17 15:47:34,463 2019-03-17 15:47:34: step 1914/50000, loss = 0.000000 (2.669 sec/batch), lr: 0.001563
2019-03-17 15:47:35,498 2019-03-17 15:47:35: step 1915/50000, loss = 0.000000 (1.012 sec/batch), lr: 0.001563
2019-03-17 15:48:47,156 2019-03-17 15:48:47: step 1916/50000, loss = 0.000000 (71.551 sec/batch), lr: 0.001563
2019-03-17 15:48:55,900 2019-03-17 15:48:55: step 1917/50000, loss = 0.000000 (8.682 sec/batch), lr: 0.001563
2019-03-17 15:49:00,971 2019-03-17 15:49:00: step 1918/50000, loss = 0.000000 (5.021 sec/batch), lr: 0.001563
2019-03-17 15:49:03,681 2019-03-17 15:49:03: step 1919/50000, loss = 0.000000 (2.673 sec/batch), lr: 0.001563
2019-03-17 15:49:04,744 2019-03-17 15:49:04: step 1920/50000, loss = 0.000000 (1.039 sec/batch), lr: 0.001563
2019-03-17 15:50:15,913 2019-03-17 15:50:15: step 1921/50000, loss = 0.000000 (71.059 sec/batch), lr: 0.001563
2019-03-17 15:50:24,659 2019-03-17 15:50:24: step 1922/50000, loss = 0.000000 (8.683 sec/batch), lr: 0.001563
2019-03-17 15:50:29,755 2019-03-17 15:50:29: step 1923/50000, loss = 0.000000 (5.047 sec/batch), lr: 0.001563
2019-03-17 15:50:32,462 2019-03-17 15:50:32: step 1924/50000, loss = 0.000000 (2.669 sec/batch), lr: 0.001563
2019-03-17 15:50:33,498 2019-03-17 15:50:33: step 1925/50000, loss = 0.000000 (1.013 sec/batch), lr: 0.001563
2019-03-17 15:51:44,632 2019-03-17 15:51:44: step 1926/50000, loss = 0.000000 (71.028 sec/batch), lr: 0.001563
2019-03-17 15:51:53,388 2019-03-17 15:51:53: step 1927/50000, loss = 0.000000 (8.690 sec/batch), lr: 0.001563
2019-03-17 15:51:58,482 2019-03-17 15:51:58: step 1928/50000, loss = 0.000000 (5.044 sec/batch), lr: 0.001563
2019-03-17 15:52:01,201 2019-03-17 15:52:01: step 1929/50000, loss = 0.000000 (2.682 sec/batch), lr: 0.001563
2019-03-17 15:52:02,240 2019-03-17 15:52:02: step 1930/50000, loss = 0.000000 (1.016 sec/batch), lr: 0.001563
2019-03-17 15:53:13,392 2019-03-17 15:53:13: step 1931/50000, loss = 0.000000 (71.044 sec/batch), lr: 0.001563
2019-03-17 15:53:22,479 2019-03-17 15:53:22: step 1932/50000, loss = 0.000000 (8.964 sec/batch), lr: 0.001563
2019-03-17 15:53:27,835 2019-03-17 15:53:27: step 1933/50000, loss = 0.000000 (5.279 sec/batch), lr: 0.001563
2019-03-17 15:53:30,787 2019-03-17 15:53:30: step 1934/50000, loss = 0.000000 (2.889 sec/batch), lr: 0.001563
2019-03-17 15:53:31,884 2019-03-17 15:53:31: step 1935/50000, loss = 0.000000 (1.057 sec/batch), lr: 0.001563
2019-03-17 15:54:43,246 2019-03-17 15:54:43: step 1936/50000, loss = 0.000000 (71.223 sec/batch), lr: 0.001563
2019-03-17 15:54:52,498 2019-03-17 15:54:52: step 1937/50000, loss = 0.000000 (9.170 sec/batch), lr: 0.001563
2019-03-17 15:54:57,816 2019-03-17 15:54:57: step 1938/50000, loss = 0.000000 (5.239 sec/batch), lr: 0.001563
2019-03-17 15:55:00,655 2019-03-17 15:55:00: step 1939/50000, loss = 0.000000 (2.777 sec/batch), lr: 0.001563
2019-03-17 15:55:01,893 2019-03-17 15:55:01: step 1940/50000, loss = 0.000000 (1.199 sec/batch), lr: 0.001563
2019-03-17 15:56:12,780 2019-03-17 15:56:12: step 1941/50000, loss = 0.000000 (70.750 sec/batch), lr: 0.001563
2019-03-17 15:56:21,666 2019-03-17 15:56:21: step 1942/50000, loss = 0.000000 (8.801 sec/batch), lr: 0.001563
2019-03-17 15:56:26,839 2019-03-17 15:56:26: step 1943/50000, loss = 0.000000 (5.111 sec/batch), lr: 0.001563
2019-03-17 15:56:29,637 2019-03-17 15:56:29: step 1944/50000, loss = 0.000000 (2.741 sec/batch), lr: 0.001563
2019-03-17 15:56:30,753 2019-03-17 15:56:30: step 1945/50000, loss = 0.000000 (1.082 sec/batch), lr: 0.001563
2019-03-17 15:57:41,245 2019-03-17 15:57:41: step 1946/50000, loss = 0.000000 (70.355 sec/batch), lr: 0.001563
2019-03-17 15:57:49,989 2019-03-17 15:57:49: step 1947/50000, loss = 0.000000 (8.673 sec/batch), lr: 0.001563
2019-03-17 15:57:55,131 2019-03-17 15:57:55: step 1948/50000, loss = 0.000000 (5.090 sec/batch), lr: 0.001563
2019-03-17 15:57:57,906 2019-03-17 15:57:57: step 1949/50000, loss = 0.000000 (2.722 sec/batch), lr: 0.001563
2019-03-17 15:57:59,006 2019-03-17 15:57:59: step 1950/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.001563
2019-03-17 15:59:09,830 2019-03-17 15:59:09: step 1951/50000, loss = 0.000000 (70.694 sec/batch), lr: 0.001563
2019-03-17 15:59:18,594 2019-03-17 15:59:18: step 1952/50000, loss = 0.000000 (8.693 sec/batch), lr: 0.001563
2019-03-17 15:59:23,753 2019-03-17 15:59:23: step 1953/50000, loss = 0.000000 (5.091 sec/batch), lr: 0.001563
2019-03-17 15:59:26,541 2019-03-17 15:59:26: step 1954/50000, loss = 0.000000 (2.727 sec/batch), lr: 0.001563
2019-03-17 15:59:27,641 2019-03-17 15:59:27: step 1955/50000, loss = 0.000000 (1.076 sec/batch), lr: 0.001563
2019-03-17 16:00:38,447 2019-03-17 16:00:38: step 1956/50000, loss = 0.000000 (70.673 sec/batch), lr: 0.001563
2019-03-17 16:00:47,249 2019-03-17 16:00:47: step 1957/50000, loss = 0.000000 (8.739 sec/batch), lr: 0.001563
2019-03-17 16:00:52,470 2019-03-17 16:00:52: step 1958/50000, loss = 0.000000 (5.157 sec/batch), lr: 0.001563
2019-03-17 16:00:55,307 2019-03-17 16:00:55: step 1959/50000, loss = 0.000000 (2.781 sec/batch), lr: 0.001563
2019-03-17 16:00:56,427 2019-03-17 16:00:56: step 1960/50000, loss = 0.000000 (1.096 sec/batch), lr: 0.001563
2019-03-17 16:02:07,429 2019-03-17 16:02:07: step 1961/50000, loss = 0.000000 (70.869 sec/batch), lr: 0.001563
2019-03-17 16:02:16,246 2019-03-17 16:02:16: step 1962/50000, loss = 0.000000 (8.752 sec/batch), lr: 0.001563
2019-03-17 16:02:21,407 2019-03-17 16:02:21: step 1963/50000, loss = 0.000000 (5.095 sec/batch), lr: 0.001563
2019-03-17 16:02:24,202 2019-03-17 16:02:24: step 1964/50000, loss = 0.000000 (2.754 sec/batch), lr: 0.001563
2019-03-17 16:02:25,306 2019-03-17 16:02:25: step 1965/50000, loss = 0.000000 (1.079 sec/batch), lr: 0.001563
2019-03-17 16:03:36,050 2019-03-17 16:03:36: step 1966/50000, loss = 0.000000 (70.631 sec/batch), lr: 0.001563
2019-03-17 16:03:44,962 2019-03-17 16:03:44: step 1967/50000, loss = 0.000000 (8.828 sec/batch), lr: 0.001563
2019-03-17 16:03:50,153 2019-03-17 16:03:50: step 1968/50000, loss = 0.000000 (5.137 sec/batch), lr: 0.001563
2019-03-17 16:03:52,959 2019-03-17 16:03:52: step 1969/50000, loss = 0.000000 (2.752 sec/batch), lr: 0.001563
2019-03-17 16:03:54,048 2019-03-17 16:03:54: step 1970/50000, loss = 0.000000 (1.065 sec/batch), lr: 0.001563
2019-03-17 16:05:05,303 2019-03-17 16:05:05: step 1971/50000, loss = 0.000000 (70.833 sec/batch), lr: 0.001563
2019-03-17 16:05:13,986 2019-03-17 16:05:13: step 1972/50000, loss = 0.000000 (8.614 sec/batch), lr: 0.001563
2019-03-17 16:05:19,127 2019-03-17 16:05:19: step 1973/50000, loss = 0.000000 (5.090 sec/batch), lr: 0.001563
2019-03-17 16:05:21,869 2019-03-17 16:05:21: step 1974/50000, loss = 0.000000 (2.701 sec/batch), lr: 0.001563
2019-03-17 16:05:22,974 2019-03-17 16:05:22: step 1975/50000, loss = 0.000000 (1.071 sec/batch), lr: 0.001563
2019-03-17 16:06:33,370 2019-03-17 16:06:33: step 1976/50000, loss = 0.000000 (70.284 sec/batch), lr: 0.001563
2019-03-17 16:06:42,073 2019-03-17 16:06:42: step 1977/50000, loss = 0.000000 (8.623 sec/batch), lr: 0.001563
2019-03-17 16:06:47,159 2019-03-17 16:06:47: step 1978/50000, loss = 0.000000 (5.019 sec/batch), lr: 0.001563
2019-03-17 16:06:49,901 2019-03-17 16:06:49: step 1979/50000, loss = 0.000000 (2.686 sec/batch), lr: 0.001563
2019-03-17 16:06:50,981 2019-03-17 16:06:50: step 1980/50000, loss = 0.000000 (1.057 sec/batch), lr: 0.001563
2019-03-17 16:08:01,359 2019-03-17 16:08:01: step 1981/50000, loss = 0.000000 (70.252 sec/batch), lr: 0.001563
2019-03-17 16:08:10,302 2019-03-17 16:08:10: step 1982/50000, loss = 0.000000 (8.868 sec/batch), lr: 0.001563
2019-03-17 16:08:15,725 2019-03-17 16:08:15: step 1983/50000, loss = 0.000000 (5.347 sec/batch), lr: 0.001563
2019-03-17 16:08:18,750 2019-03-17 16:08:18: step 1984/50000, loss = 0.000000 (2.962 sec/batch), lr: 0.001563
2019-03-17 16:08:20,017 2019-03-17 16:08:20: step 1985/50000, loss = 0.000000 (1.227 sec/batch), lr: 0.001563
2019-03-17 16:09:31,567 2019-03-17 16:09:31: step 1986/50000, loss = 0.000000 (71.396 sec/batch), lr: 0.001563
2019-03-17 16:09:40,409 2019-03-17 16:09:40: step 1987/50000, loss = 0.000000 (8.778 sec/batch), lr: 0.001563
2019-03-17 16:09:45,703 2019-03-17 16:09:45: step 1988/50000, loss = 0.000000 (5.218 sec/batch), lr: 0.001563
2019-03-17 16:09:48,521 2019-03-17 16:09:48: step 1989/50000, loss = 0.000000 (2.780 sec/batch), lr: 0.001563
2019-03-17 16:09:49,664 2019-03-17 16:09:49: step 1990/50000, loss = 0.000000 (1.109 sec/batch), lr: 0.001563
2019-03-17 16:11:00,987 2019-03-17 16:11:00: step 1991/50000, loss = 0.000000 (71.204 sec/batch), lr: 0.001563
2019-03-17 16:11:09,875 2019-03-17 16:11:09: step 1992/50000, loss = 0.000000 (8.805 sec/batch), lr: 0.001563
2019-03-17 16:11:15,061 2019-03-17 16:11:15: step 1993/50000, loss = 0.000000 (5.121 sec/batch), lr: 0.001563
2019-03-17 16:11:17,894 2019-03-17 16:11:17: step 1994/50000, loss = 0.000000 (2.773 sec/batch), lr: 0.001563
2019-03-17 16:11:19,011 2019-03-17 16:11:19: step 1995/50000, loss = 0.000000 (1.083 sec/batch), lr: 0.001563
2019-03-17 16:12:30,118 2019-03-17 16:12:30: step 1996/50000, loss = 0.000000 (70.973 sec/batch), lr: 0.001563
2019-03-17 16:12:39,073 2019-03-17 16:12:39: step 1997/50000, loss = 0.000000 (8.872 sec/batch), lr: 0.001563
2019-03-17 16:12:44,274 2019-03-17 16:12:44: step 1998/50000, loss = 0.000000 (5.134 sec/batch), lr: 0.001563
2019-03-17 16:12:47,485 2019-03-17 16:12:47: step 1999/50000, loss = 0.000000 (2.825 sec/batch), lr: 0.001563
2019-03-17 16:12:48,628 2019-03-17 16:12:48: step 2000/50000, loss = 0.000000 (1.103 sec/batch), lr: 0.001563
2019-03-17 16:13:33,936 step 2000: Full loss = 0.000000, Edge acc. = 0.0000
2019-03-17 16:13:33,994 step 2000: Dev acc. = 0.000000
2019-03-17 16:14:45,059 2019-03-17 16:14:45: step 2001/50000, loss = 0.000000 (70.954 sec/batch), lr: 0.001563
2019-03-17 16:14:54,031 2019-03-17 16:14:54: step 2002/50000, loss = 0.000000 (8.845 sec/batch), lr: 0.001563
2019-03-17 16:14:59,219 2019-03-17 16:14:59: step 2003/50000, loss = 0.000000 (5.116 sec/batch), lr: 0.001563
2019-03-17 16:15:01,984 2019-03-17 16:15:01: step 2004/50000, loss = 0.000000 (2.711 sec/batch), lr: 0.001563
2019-03-17 16:15:03,104 2019-03-17 16:15:03: step 2005/50000, loss = 0.000000 (1.087 sec/batch), lr: 0.001563
2019-03-17 16:16:14,197 2019-03-17 16:16:14: step 2006/50000, loss = 0.000000 (70.961 sec/batch), lr: 0.001563
2019-03-17 16:16:23,117 2019-03-17 16:16:23: step 2007/50000, loss = 0.000000 (8.839 sec/batch), lr: 0.001563
2019-03-17 16:16:28,310 2019-03-17 16:16:28: step 2008/50000, loss = 0.000000 (5.124 sec/batch), lr: 0.001563
2019-03-17 16:16:31,201 2019-03-17 16:16:31: step 2009/50000, loss = 0.000000 (2.825 sec/batch), lr: 0.001563
2019-03-17 16:16:32,328 2019-03-17 16:16:32: step 2010/50000, loss = 0.000000 (1.087 sec/batch), lr: 0.001563
2019-03-17 16:17:43,244 2019-03-17 16:17:43: step 2011/50000, loss = 0.000000 (70.760 sec/batch), lr: 0.001563
2019-03-17 16:17:51,971 2019-03-17 16:17:51: step 2012/50000, loss = 0.000000 (8.646 sec/batch), lr: 0.001563
2019-03-17 16:17:57,182 2019-03-17 16:17:57: step 2013/50000, loss = 0.000000 (5.133 sec/batch), lr: 0.001563
2019-03-17 16:17:59,980 2019-03-17 16:17:59: step 2014/50000, loss = 0.000000 (2.757 sec/batch), lr: 0.001563
2019-03-17 16:18:01,124 2019-03-17 16:18:01: step 2015/50000, loss = 0.000000 (1.106 sec/batch), lr: 0.001563
2019-03-17 16:19:11,084 2019-03-17 16:19:11: step 2016/50000, loss = 0.000000 (69.805 sec/batch), lr: 0.001563
2019-03-17 16:19:19,911 2019-03-17 16:19:19: step 2017/50000, loss = 0.000000 (8.746 sec/batch), lr: 0.001563
2019-03-17 16:19:25,000 2019-03-17 16:19:25: step 2018/50000, loss = 0.000000 (5.025 sec/batch), lr: 0.001563
2019-03-17 16:19:27,768 2019-03-17 16:19:27: step 2019/50000, loss = 0.000000 (2.728 sec/batch), lr: 0.001563
2019-03-17 16:19:28,902 2019-03-17 16:19:28: step 2020/50000, loss = 0.000000 (1.094 sec/batch), lr: 0.001563
2019-03-17 16:20:41,413 2019-03-17 16:20:41: step 2021/50000, loss = 0.000000 (72.357 sec/batch), lr: 0.001563
2019-03-17 16:20:50,407 2019-03-17 16:20:50: step 2022/50000, loss = 0.000000 (8.908 sec/batch), lr: 0.001563
2019-03-17 16:20:55,721 2019-03-17 16:20:55: step 2023/50000, loss = 0.000000 (5.238 sec/batch), lr: 0.001563
2019-03-17 16:20:58,556 2019-03-17 16:20:58: step 2024/50000, loss = 0.000000 (2.780 sec/batch), lr: 0.001563
2019-03-17 16:20:59,697 2019-03-17 16:20:59: step 2025/50000, loss = 0.000000 (1.101 sec/batch), lr: 0.001563
2019-03-17 16:22:10,952 2019-03-17 16:22:10: step 2026/50000, loss = 0.000000 (71.128 sec/batch), lr: 0.001563
2019-03-17 16:22:20,151 2019-03-17 16:22:20: step 2027/50000, loss = 0.000000 (8.791 sec/batch), lr: 0.001563
2019-03-17 16:22:25,362 2019-03-17 16:22:25: step 2028/50000, loss = 0.000000 (5.140 sec/batch), lr: 0.001563
2019-03-17 16:22:28,144 2019-03-17 16:22:28: step 2029/50000, loss = 0.000000 (2.741 sec/batch), lr: 0.001563
2019-03-17 16:22:29,225 2019-03-17 16:22:29: step 2030/50000, loss = 0.000000 (1.058 sec/batch), lr: 0.001563
2019-03-17 16:23:40,417 2019-03-17 16:23:40: step 2031/50000, loss = 0.000000 (71.038 sec/batch), lr: 0.001563
2019-03-17 16:23:49,343 2019-03-17 16:23:49: step 2032/50000, loss = 0.000000 (8.846 sec/batch), lr: 0.001563
2019-03-17 16:23:54,553 2019-03-17 16:23:54: step 2033/50000, loss = 0.000000 (5.147 sec/batch), lr: 0.001563
2019-03-17 16:23:57,381 2019-03-17 16:23:57: step 2034/50000, loss = 0.000000 (2.773 sec/batch), lr: 0.001563
2019-03-17 16:23:58,522 2019-03-17 16:23:58: step 2035/50000, loss = 0.000000 (1.102 sec/batch), lr: 0.001563
2019-03-17 16:25:09,736 2019-03-17 16:25:09: step 2036/50000, loss = 0.000000 (71.088 sec/batch), lr: 0.001563
2019-03-17 16:25:18,684 2019-03-17 16:25:18: step 2037/50000, loss = 0.000000 (8.863 sec/batch), lr: 0.001563
2019-03-17 16:25:24,007 2019-03-17 16:25:24: step 2038/50000, loss = 0.000000 (5.244 sec/batch), lr: 0.001563
2019-03-17 16:25:26,814 2019-03-17 16:25:26: step 2039/50000, loss = 0.000000 (2.753 sec/batch), lr: 0.001563
2019-03-17 16:25:27,939 2019-03-17 16:25:27: step 2040/50000, loss = 0.000000 (1.089 sec/batch), lr: 0.001563
2019-03-17 16:26:39,032 2019-03-17 16:26:39: step 2041/50000, loss = 0.000000 (70.962 sec/batch), lr: 0.001563
2019-03-17 16:26:47,983 2019-03-17 16:26:47: step 2042/50000, loss = 0.000000 (8.871 sec/batch), lr: 0.001563
2019-03-17 16:26:53,188 2019-03-17 16:26:53: step 2043/50000, loss = 0.000000 (5.134 sec/batch), lr: 0.001563
2019-03-17 16:26:56,013 2019-03-17 16:26:56: step 2044/50000, loss = 0.000000 (2.768 sec/batch), lr: 0.001563
2019-03-17 16:26:57,118 2019-03-17 16:26:57: step 2045/50000, loss = 0.000000 (1.081 sec/batch), lr: 0.001563
2019-03-17 16:28:09,140 2019-03-17 16:28:09: step 2046/50000, loss = 0.000000 (71.902 sec/batch), lr: 0.001563
2019-03-17 16:28:19,278 2019-03-17 16:28:19: step 2047/50000, loss = 0.000000 (10.053 sec/batch), lr: 0.001563
2019-03-17 16:28:24,438 2019-03-17 16:28:24: step 2048/50000, loss = 0.000000 (5.093 sec/batch), lr: 0.001563
2019-03-17 16:28:27,271 2019-03-17 16:28:27: step 2049/50000, loss = 0.000000 (2.793 sec/batch), lr: 0.001563
2019-03-17 16:28:28,354 2019-03-17 16:28:28: step 2050/50000, loss = 0.000000 (1.049 sec/batch), lr: 0.001563
2019-03-17 16:29:39,562 2019-03-17 16:29:39: step 2051/50000, loss = 0.000000 (71.092 sec/batch), lr: 0.001563
2019-03-17 16:29:48,517 2019-03-17 16:29:48: step 2052/50000, loss = 0.000000 (8.872 sec/batch), lr: 0.001563
2019-03-17 16:29:53,717 2019-03-17 16:29:53: step 2053/50000, loss = 0.000000 (5.132 sec/batch), lr: 0.001563
2019-03-17 16:29:56,502 2019-03-17 16:29:56: step 2054/50000, loss = 0.000000 (2.729 sec/batch), lr: 0.001563
2019-03-17 16:29:57,614 2019-03-17 16:29:57: step 2055/50000, loss = 0.000000 (1.077 sec/batch), lr: 0.001563
2019-03-17 16:31:09,606 2019-03-17 16:31:09: step 2056/50000, loss = 0.000000 (71.872 sec/batch), lr: 0.001563
2019-03-17 16:31:18,693 2019-03-17 16:31:18: step 2057/50000, loss = 0.000000 (8.960 sec/batch), lr: 0.001563
2019-03-17 16:31:24,042 2019-03-17 16:31:24: step 2058/50000, loss = 0.000000 (5.270 sec/batch), lr: 0.001563
2019-03-17 16:31:26,823 2019-03-17 16:31:26: step 2059/50000, loss = 0.000000 (2.728 sec/batch), lr: 0.001563
2019-03-17 16:31:27,947 2019-03-17 16:31:27: step 2060/50000, loss = 0.000000 (1.089 sec/batch), lr: 0.001563
2019-03-17 16:32:40,410 2019-03-17 16:32:40: step 2061/50000, loss = 0.000000 (72.019 sec/batch), lr: 0.001563
2019-03-17 16:32:49,444 2019-03-17 16:32:49: step 2062/50000, loss = 0.000000 (8.950 sec/batch), lr: 0.001563
2019-03-17 16:32:54,828 2019-03-17 16:32:54: step 2063/50000, loss = 0.000000 (5.307 sec/batch), lr: 0.001563
2019-03-17 16:32:57,801 2019-03-17 16:32:57: step 2064/50000, loss = 0.000000 (2.910 sec/batch), lr: 0.001563
2019-03-17 16:32:58,932 2019-03-17 16:32:58: step 2065/50000, loss = 0.000000 (1.097 sec/batch), lr: 0.001563
2019-03-22 12:05:08,187 2019-03-22 12:05:08: step 1/50000, loss = 0.447643 (2.013 sec/batch), lr: 0.100000
2019-03-22 12:05:10,315 2019-03-22 12:05:10: step 2/50000, loss = 0.467903 (2.122 sec/batch), lr: 0.100000
2019-03-22 12:05:12,362 2019-03-22 12:05:12: step 3/50000, loss = 0.467592 (2.042 sec/batch), lr: 0.100000
2019-03-22 12:05:14,503 2019-03-22 12:05:14: step 4/50000, loss = 0.467362 (2.136 sec/batch), lr: 0.100000
2019-03-22 12:05:16,630 2019-03-22 12:05:16: step 5/50000, loss = 0.466268 (2.121 sec/batch), lr: 0.100000
2019-03-22 12:05:18,657 2019-03-22 12:05:18: step 6/50000, loss = 0.464419 (2.023 sec/batch), lr: 0.100000
2019-03-22 12:05:20,757 2019-03-22 12:05:20: step 7/50000, loss = 0.462355 (2.095 sec/batch), lr: 0.100000
2019-03-22 12:05:22,707 2019-03-22 12:05:22: step 8/50000, loss = 0.463565 (1.945 sec/batch), lr: 0.100000
2019-03-22 12:05:24,709 2019-03-22 12:05:24: step 9/50000, loss = 0.460709 (1.999 sec/batch), lr: 0.100000
2019-03-22 12:05:26,947 2019-03-22 12:05:26: step 10/50000, loss = 0.461074 (2.232 sec/batch), lr: 0.100000
2019-03-22 12:05:28,928 2019-03-22 12:05:28: step 11/50000, loss = 0.459467 (1.976 sec/batch), lr: 0.100000
2019-03-22 12:05:30,880 2019-03-22 12:05:30: step 12/50000, loss = 0.460933 (1.947 sec/batch), lr: 0.100000
2019-03-22 12:05:33,036 2019-03-22 12:05:33: step 13/50000, loss = 0.456760 (2.151 sec/batch), lr: 0.100000
2019-03-22 12:05:34,969 2019-03-22 12:05:34: step 14/50000, loss = 0.457544 (1.928 sec/batch), lr: 0.100000
2019-03-22 12:05:36,934 2019-03-22 12:05:36: step 15/50000, loss = 0.457066 (1.961 sec/batch), lr: 0.100000
2019-03-22 12:05:39,294 2019-03-22 12:05:39: step 16/50000, loss = 0.455986 (2.342 sec/batch), lr: 0.100000
2019-03-22 12:05:41,537 2019-03-22 12:05:41: step 17/50000, loss = 0.453560 (2.238 sec/batch), lr: 0.100000
2019-03-22 12:05:43,708 2019-03-22 12:05:43: step 18/50000, loss = 0.455922 (2.166 sec/batch), lr: 0.100000
2019-03-22 12:05:45,681 2019-03-22 12:05:45: step 19/50000, loss = 0.457678 (1.968 sec/batch), lr: 0.100000
2019-03-22 12:05:47,991 2019-03-22 12:05:47: step 20/50000, loss = 0.453481 (2.305 sec/batch), lr: 0.100000
2019-03-22 12:05:49,993 2019-03-22 12:05:49: step 21/50000, loss = 0.455006 (1.997 sec/batch), lr: 0.100000
2019-03-22 12:05:51,950 2019-03-22 12:05:51: step 22/50000, loss = 0.449471 (1.952 sec/batch), lr: 0.100000
2019-03-22 12:05:53,907 2019-03-22 12:05:53: step 23/50000, loss = 0.449905 (1.952 sec/batch), lr: 0.100000
2019-03-22 12:05:55,956 2019-03-22 12:05:55: step 24/50000, loss = 0.450883 (2.044 sec/batch), lr: 0.100000
2019-03-22 12:05:57,957 2019-03-22 12:05:57: step 25/50000, loss = 0.447837 (1.997 sec/batch), lr: 0.100000
2019-03-22 12:05:59,959 2019-03-22 12:05:59: step 26/50000, loss = 0.447428 (1.997 sec/batch), lr: 0.100000
2019-03-22 12:06:01,941 2019-03-22 12:06:01: step 27/50000, loss = 0.448498 (1.977 sec/batch), lr: 0.100000
2019-03-22 12:06:03,882 2019-03-22 12:06:03: step 28/50000, loss = 0.446559 (1.937 sec/batch), lr: 0.100000
2019-03-22 12:06:05,928 2019-03-22 12:06:05: step 29/50000, loss = 0.445072 (2.041 sec/batch), lr: 0.100000
2019-03-22 12:06:07,919 2019-03-22 12:06:07: step 30/50000, loss = 0.444268 (1.987 sec/batch), lr: 0.100000
2019-03-22 12:06:09,896 2019-03-22 12:06:09: step 31/50000, loss = 0.443447 (1.972 sec/batch), lr: 0.100000
2019-03-22 12:06:12,007 2019-03-22 12:06:12: step 32/50000, loss = 0.446086 (2.106 sec/batch), lr: 0.100000
2019-03-22 12:06:14,294 2019-03-22 12:06:14: step 33/50000, loss = 0.443184 (2.282 sec/batch), lr: 0.100000
2019-03-22 12:06:16,564 2019-03-22 12:06:16: step 34/50000, loss = 0.436906 (2.265 sec/batch), lr: 0.100000
2019-03-22 12:06:18,783 2019-03-22 12:06:18: step 35/50000, loss = 0.437965 (2.214 sec/batch), lr: 0.100000
2019-03-22 12:06:20,966 2019-03-22 12:06:20: step 36/50000, loss = 0.433288 (2.178 sec/batch), lr: 0.100000
2019-03-22 12:06:22,986 2019-03-22 12:06:22: step 37/50000, loss = 0.433054 (2.015 sec/batch), lr: 0.100000
2019-03-22 12:06:24,971 2019-03-22 12:06:24: step 38/50000, loss = 0.429258 (1.981 sec/batch), lr: 0.100000
2019-03-22 12:06:26,936 2019-03-22 12:06:26: step 39/50000, loss = 0.429677 (1.960 sec/batch), lr: 0.100000
2019-03-22 12:06:28,910 2019-03-22 12:06:28: step 40/50000, loss = 0.426034 (1.970 sec/batch), lr: 0.100000
2019-03-22 12:16:25,723 2019-03-22 12:16:25: step 1/50000, loss = 0.447643 (2.234 sec/batch), lr: 0.100000
2019-03-22 12:16:27,693 2019-03-22 12:16:27: step 2/50000, loss = 0.467903 (1.966 sec/batch), lr: 0.100000
2019-03-22 12:16:29,750 2019-03-22 12:16:29: step 3/50000, loss = 0.467592 (2.053 sec/batch), lr: 0.100000
2019-03-22 12:16:31,882 2019-03-22 12:16:31: step 4/50000, loss = 0.467362 (2.128 sec/batch), lr: 0.100000
2019-03-22 12:16:33,910 2019-03-22 12:16:33: step 5/50000, loss = 0.466268 (2.024 sec/batch), lr: 0.100000
2019-03-22 12:16:35,956 2019-03-22 12:16:35: step 6/50000, loss = 0.464419 (2.042 sec/batch), lr: 0.100000
2019-03-22 12:16:38,004 2019-03-22 12:16:38: step 7/50000, loss = 0.462355 (2.044 sec/batch), lr: 0.100000
2019-03-22 12:16:40,055 2019-03-22 12:16:40: step 8/50000, loss = 0.463565 (2.047 sec/batch), lr: 0.100000
2019-03-22 12:16:42,017 2019-03-22 12:16:42: step 9/50000, loss = 0.460709 (1.958 sec/batch), lr: 0.100000
2019-03-22 12:16:44,087 2019-03-22 12:16:44: step 10/50000, loss = 0.461074 (2.067 sec/batch), lr: 0.100000
2019-03-22 12:16:46,038 2019-03-22 12:16:46: step 11/50000, loss = 0.459467 (1.947 sec/batch), lr: 0.100000
2019-03-22 12:16:48,019 2019-03-22 12:16:48: step 12/50000, loss = 0.460933 (1.978 sec/batch), lr: 0.100000
2019-03-22 12:16:49,964 2019-03-22 12:16:49: step 13/50000, loss = 0.456760 (1.942 sec/batch), lr: 0.100000
2019-03-22 12:16:53,682 2019-03-22 12:16:53: step 14/50000, loss = 0.457544 (2.006 sec/batch), lr: 0.100000
2019-03-22 12:16:55,677 2019-03-22 12:16:55: step 15/50000, loss = 0.457066 (1.992 sec/batch), lr: 0.100000
2019-03-22 12:16:57,644 2019-03-22 12:16:57: step 16/50000, loss = 0.455986 (1.963 sec/batch), lr: 0.100000
2019-03-22 12:16:59,668 2019-03-22 12:16:59: step 17/50000, loss = 0.453560 (2.020 sec/batch), lr: 0.100000
2019-03-22 12:17:01,677 2019-03-22 12:17:01: step 18/50000, loss = 0.455922 (2.006 sec/batch), lr: 0.100000
2019-03-22 12:17:03,964 2019-03-22 12:17:03: step 19/50000, loss = 0.457678 (2.283 sec/batch), lr: 0.100000
2019-03-22 12:17:06,194 2019-03-22 12:17:06: step 20/50000, loss = 0.453481 (2.226 sec/batch), lr: 0.100000
2019-03-22 12:17:08,414 2019-03-22 12:17:08: step 21/50000, loss = 0.455006 (2.217 sec/batch), lr: 0.100000
2019-03-22 12:17:10,643 2019-03-22 12:17:10: step 22/50000, loss = 0.449471 (2.225 sec/batch), lr: 0.100000
2019-03-22 12:17:12,841 2019-03-22 12:17:12: step 23/50000, loss = 0.449905 (2.194 sec/batch), lr: 0.100000
2019-03-22 12:17:15,043 2019-03-22 12:17:15: step 24/50000, loss = 0.450883 (2.198 sec/batch), lr: 0.100000
2019-03-22 12:17:17,308 2019-03-22 12:17:17: step 25/50000, loss = 0.447837 (2.261 sec/batch), lr: 0.100000
2019-03-22 12:17:19,530 2019-03-22 12:17:19: step 26/50000, loss = 0.447428 (2.222 sec/batch), lr: 0.100000
2019-03-22 12:17:21,800 2019-03-22 12:17:21: step 27/50000, loss = 0.448498 (2.267 sec/batch), lr: 0.100000
2019-03-22 12:17:24,117 2019-03-22 12:17:24: step 28/50000, loss = 0.446559 (2.313 sec/batch), lr: 0.100000
2019-03-22 12:17:26,336 2019-03-22 12:17:26: step 29/50000, loss = 0.445072 (2.215 sec/batch), lr: 0.100000
2019-03-22 12:17:28,705 2019-03-22 12:17:28: step 30/50000, loss = 0.444268 (2.366 sec/batch), lr: 0.100000
2019-03-22 12:17:31,015 2019-03-22 12:17:31: step 31/50000, loss = 0.443447 (2.306 sec/batch), lr: 0.100000
2019-03-22 12:17:33,326 2019-03-22 12:17:33: step 32/50000, loss = 0.446086 (2.307 sec/batch), lr: 0.100000
2019-03-22 12:17:35,599 2019-03-22 12:17:35: step 33/50000, loss = 0.443184 (2.269 sec/batch), lr: 0.100000
2019-03-22 12:17:37,775 2019-03-22 12:17:37: step 34/50000, loss = 0.436906 (2.173 sec/batch), lr: 0.100000
2019-03-22 12:17:39,989 2019-03-22 12:17:39: step 35/50000, loss = 0.437965 (2.210 sec/batch), lr: 0.100000
2019-03-22 12:17:42,223 2019-03-22 12:17:42: step 36/50000, loss = 0.433288 (2.230 sec/batch), lr: 0.100000
2019-03-22 12:17:44,194 2019-03-22 12:17:44: step 37/50000, loss = 0.433054 (1.968 sec/batch), lr: 0.100000
2019-03-22 12:17:46,262 2019-03-22 12:17:46: step 38/50000, loss = 0.429258 (2.064 sec/batch), lr: 0.100000
2019-03-22 12:17:48,272 2019-03-22 12:17:48: step 39/50000, loss = 0.429677 (2.005 sec/batch), lr: 0.100000
2019-03-22 12:17:50,245 2019-03-22 12:17:50: step 40/50000, loss = 0.426034 (1.969 sec/batch), lr: 0.100000
2019-03-22 12:17:52,269 2019-03-22 12:17:52: step 41/50000, loss = 0.421609 (2.020 sec/batch), lr: 0.100000
2019-03-22 12:17:54,397 2019-03-22 12:17:54: step 42/50000, loss = 0.421030 (2.124 sec/batch), lr: 0.100000
2019-03-22 12:17:56,323 2019-03-22 12:17:56: step 43/50000, loss = 0.417761 (1.922 sec/batch), lr: 0.100000
2019-03-22 12:17:58,395 2019-03-22 12:17:58: step 44/50000, loss = 0.412700 (2.068 sec/batch), lr: 0.100000
2019-03-22 12:18:00,398 2019-03-22 12:18:00: step 45/50000, loss = 0.404762 (2.000 sec/batch), lr: 0.100000
2019-03-22 12:18:02,353 2019-03-22 12:18:02: step 46/50000, loss = 0.400455 (1.951 sec/batch), lr: 0.100000
2019-03-22 12:18:04,360 2019-03-22 12:18:04: step 47/50000, loss = 0.387621 (2.003 sec/batch), lr: 0.100000
2019-03-22 12:18:06,405 2019-03-22 12:18:06: step 48/50000, loss = 0.392830 (2.041 sec/batch), lr: 0.100000
2019-03-22 12:18:08,380 2019-03-22 12:18:08: step 49/50000, loss = 0.377870 (1.971 sec/batch), lr: 0.100000
2019-03-22 12:18:10,582 2019-03-22 12:18:10: step 50/50000, loss = 0.353023 (2.198 sec/batch), lr: 0.100000
2019-03-22 12:18:12,598 2019-03-22 12:18:12: step 51/50000, loss = 0.357219 (2.012 sec/batch), lr: 0.100000
2019-03-22 12:18:14,617 2019-03-22 12:18:14: step 52/50000, loss = 0.341374 (2.016 sec/batch), lr: 0.100000
2019-03-22 12:18:16,600 2019-03-22 12:18:16: step 53/50000, loss = 0.329448 (1.978 sec/batch), lr: 0.100000
2019-03-22 12:18:18,629 2019-03-22 12:18:18: step 54/50000, loss = 0.319068 (2.025 sec/batch), lr: 0.100000
2019-03-22 12:18:20,573 2019-03-22 12:18:20: step 55/50000, loss = 0.277234 (1.940 sec/batch), lr: 0.100000
2019-03-22 12:18:22,578 2019-03-22 12:18:22: step 56/50000, loss = 0.264416 (2.002 sec/batch), lr: 0.100000
2019-03-22 12:18:24,662 2019-03-22 12:18:24: step 57/50000, loss = 0.226285 (2.080 sec/batch), lr: 0.100000
2019-03-22 12:18:26,651 2019-03-22 12:18:26: step 58/50000, loss = 0.207997 (1.986 sec/batch), lr: 0.100000
2019-03-22 12:18:28,715 2019-03-22 12:18:28: step 59/50000, loss = 0.221327 (2.060 sec/batch), lr: 0.100000
2019-03-22 12:18:30,742 2019-03-22 12:18:30: step 60/50000, loss = 0.207527 (2.023 sec/batch), lr: 0.100000
2019-03-22 12:18:32,713 2019-03-22 12:18:32: step 61/50000, loss = 0.245904 (1.967 sec/batch), lr: 0.100000
2019-03-22 12:18:34,691 2019-03-22 12:18:34: step 62/50000, loss = 0.232038 (1.974 sec/batch), lr: 0.100000
2019-03-22 12:18:36,716 2019-03-22 12:18:36: step 63/50000, loss = 0.227075 (2.021 sec/batch), lr: 0.100000
2019-03-22 12:18:38,787 2019-03-22 12:18:38: step 64/50000, loss = 0.227227 (2.067 sec/batch), lr: 0.100000
2019-03-22 12:18:40,835 2019-03-22 12:18:40: step 65/50000, loss = 0.213877 (2.044 sec/batch), lr: 0.100000
2019-03-22 12:18:42,824 2019-03-22 12:18:42: step 66/50000, loss = 0.217947 (1.985 sec/batch), lr: 0.100000
2019-03-22 12:18:44,803 2019-03-22 12:18:44: step 67/50000, loss = 0.217166 (1.975 sec/batch), lr: 0.100000
2019-03-22 12:18:46,760 2019-03-22 12:18:46: step 68/50000, loss = 0.225699 (1.954 sec/batch), lr: 0.100000
2019-03-22 12:18:48,739 2019-03-22 12:18:48: step 69/50000, loss = 0.223924 (1.975 sec/batch), lr: 0.100000
2019-03-22 12:18:50,704 2019-03-22 12:18:50: step 70/50000, loss = 0.229405 (1.961 sec/batch), lr: 0.100000
2019-03-22 12:18:52,669 2019-03-22 12:18:52: step 71/50000, loss = 0.223922 (1.960 sec/batch), lr: 0.100000
2019-03-22 12:18:54,599 2019-03-22 12:18:54: step 72/50000, loss = 0.232716 (1.927 sec/batch), lr: 0.100000
2019-03-22 12:18:56,627 2019-03-22 12:18:56: step 73/50000, loss = 0.226870 (2.024 sec/batch), lr: 0.100000
2019-03-22 12:18:58,701 2019-03-22 12:18:58: step 74/50000, loss = 0.226983 (2.071 sec/batch), lr: 0.100000
2019-03-22 12:19:00,702 2019-03-22 12:19:00: step 75/50000, loss = 0.209886 (1.997 sec/batch), lr: 0.100000
2019-03-22 12:19:02,736 2019-03-22 12:19:02: step 76/50000, loss = 0.208933 (2.031 sec/batch), lr: 0.100000
2019-03-22 12:19:04,725 2019-03-22 12:19:04: step 77/50000, loss = 0.233611 (1.984 sec/batch), lr: 0.100000
2019-03-22 12:19:06,686 2019-03-22 12:19:06: step 78/50000, loss = 0.211186 (1.958 sec/batch), lr: 0.100000
2019-03-22 12:19:08,683 2019-03-22 12:19:08: step 79/50000, loss = 0.211726 (1.993 sec/batch), lr: 0.100000
2019-03-22 12:19:10,642 2019-03-22 12:19:10: step 80/50000, loss = 0.209854 (1.955 sec/batch), lr: 0.100000
2019-03-22 12:19:12,672 2019-03-22 12:19:12: step 81/50000, loss = 0.227518 (2.026 sec/batch), lr: 0.100000
2019-03-22 12:19:14,684 2019-03-22 12:19:14: step 82/50000, loss = 0.224057 (2.009 sec/batch), lr: 0.100000
2019-03-22 12:19:16,839 2019-03-22 12:19:16: step 83/50000, loss = 0.232310 (2.152 sec/batch), lr: 0.100000
2019-03-22 12:19:18,795 2019-03-22 12:19:18: step 84/50000, loss = 0.212001 (1.952 sec/batch), lr: 0.100000
2019-03-22 12:19:20,889 2019-03-22 12:19:20: step 85/50000, loss = 0.222731 (2.090 sec/batch), lr: 0.100000
2019-03-22 12:19:22,846 2019-03-22 12:19:22: step 86/50000, loss = 0.218814 (1.953 sec/batch), lr: 0.100000
2019-03-22 12:19:24,737 2019-03-22 12:19:24: step 87/50000, loss = 0.231812 (1.888 sec/batch), lr: 0.100000
2019-03-22 12:19:26,858 2019-03-22 12:19:26: step 88/50000, loss = 0.226220 (2.117 sec/batch), lr: 0.100000
2019-03-22 12:19:28,831 2019-03-22 12:19:28: step 89/50000, loss = 0.208787 (1.970 sec/batch), lr: 0.100000
2019-03-22 12:19:30,796 2019-03-22 12:19:30: step 90/50000, loss = 0.212423 (1.961 sec/batch), lr: 0.100000
2019-03-22 12:19:32,773 2019-03-22 12:19:32: step 91/50000, loss = 0.222966 (1.973 sec/batch), lr: 0.100000
2019-03-22 12:19:34,846 2019-03-22 12:19:34: step 92/50000, loss = 0.218870 (2.069 sec/batch), lr: 0.100000
2019-03-22 12:19:36,867 2019-03-22 12:19:36: step 93/50000, loss = 0.210803 (2.018 sec/batch), lr: 0.100000
2019-03-22 12:19:38,835 2019-03-22 12:19:38: step 94/50000, loss = 0.206230 (1.964 sec/batch), lr: 0.100000
2019-03-22 12:19:40,868 2019-03-22 12:19:40: step 95/50000, loss = 0.233113 (2.030 sec/batch), lr: 0.100000
2019-03-22 12:19:42,850 2019-03-22 12:19:42: step 96/50000, loss = 0.221667 (1.978 sec/batch), lr: 0.100000
2019-03-22 12:19:44,876 2019-03-22 12:19:44: step 97/50000, loss = 0.216915 (2.022 sec/batch), lr: 0.100000
2019-03-22 12:19:46,935 2019-03-22 12:19:46: step 98/50000, loss = 0.223833 (2.055 sec/batch), lr: 0.100000
2019-03-22 12:19:48,883 2019-03-22 12:19:48: step 99/50000, loss = 0.277519 (1.945 sec/batch), lr: 0.100000
2019-03-22 12:19:50,872 2019-03-22 12:19:50: step 100/50000, loss = 0.215516 (1.985 sec/batch), lr: 0.100000
2019-03-22 12:20:28,147 step 100: Full loss = 0.353102, Edge acc. = 0.2240
2019-03-22 12:20:28,149 step 100: Dev acc. = 0.367423
2019-03-22 12:20:30,192 2019-03-22 12:20:30: step 101/50000, loss = 0.174558 (2.043 sec/batch), lr: 0.100000
2019-03-22 12:20:32,295 2019-03-22 12:20:32: step 102/50000, loss = 0.125824 (2.102 sec/batch), lr: 0.100000
2019-03-22 12:20:34,604 2019-03-22 12:20:34: step 103/50000, loss = 0.121693 (2.308 sec/batch), lr: 0.100000
2019-03-22 12:20:36,825 2019-03-22 12:20:36: step 104/50000, loss = 0.122414 (2.221 sec/batch), lr: 0.100000
2019-03-22 12:20:39,082 2019-03-22 12:20:39: step 105/50000, loss = 0.123329 (2.257 sec/batch), lr: 0.100000
2019-03-22 12:20:41,376 2019-03-22 12:20:41: step 106/50000, loss = 0.119010 (2.291 sec/batch), lr: 0.100000
2019-03-22 12:20:43,677 2019-03-22 12:20:43: step 107/50000, loss = 0.115775 (2.298 sec/batch), lr: 0.100000
2019-03-22 12:20:45,938 2019-03-22 12:20:45: step 108/50000, loss = 0.120399 (2.259 sec/batch), lr: 0.100000
2019-03-22 12:20:48,180 2019-03-22 12:20:48: step 109/50000, loss = 0.116724 (2.239 sec/batch), lr: 0.100000
2019-03-22 12:20:50,402 2019-03-22 12:20:50: step 110/50000, loss = 0.124656 (2.218 sec/batch), lr: 0.100000
2019-03-22 12:20:52,776 2019-03-22 12:20:52: step 111/50000, loss = 0.118018 (2.371 sec/batch), lr: 0.100000
2019-03-22 12:20:54,918 2019-03-22 12:20:54: step 112/50000, loss = 0.122847 (2.138 sec/batch), lr: 0.100000
2019-03-22 12:20:57,196 2019-03-22 12:20:57: step 113/50000, loss = 0.124237 (2.275 sec/batch), lr: 0.100000
2019-03-22 12:20:59,690 2019-03-22 12:20:59: step 114/50000, loss = 0.121553 (2.491 sec/batch), lr: 0.100000
2019-03-22 12:21:01,999 2019-03-22 12:21:01: step 115/50000, loss = 0.122171 (2.308 sec/batch), lr: 0.100000
2019-03-22 12:21:04,111 2019-03-22 12:21:04: step 116/50000, loss = 0.119617 (2.108 sec/batch), lr: 0.100000
2019-03-22 12:21:06,365 2019-03-22 12:21:06: step 117/50000, loss = 0.115553 (2.251 sec/batch), lr: 0.100000
2019-03-22 12:21:08,643 2019-03-22 12:21:08: step 118/50000, loss = 0.124097 (2.275 sec/batch), lr: 0.100000
2019-03-22 12:21:10,877 2019-03-22 12:21:10: step 119/50000, loss = 0.120087 (2.231 sec/batch), lr: 0.100000
2019-03-22 12:21:12,940 2019-03-22 12:21:12: step 120/50000, loss = 0.116069 (2.060 sec/batch), lr: 0.100000
2019-03-22 12:21:14,992 2019-03-22 12:21:14: step 121/50000, loss = 0.122209 (2.049 sec/batch), lr: 0.100000
2019-03-22 12:21:17,047 2019-03-22 12:21:17: step 122/50000, loss = 0.114288 (2.052 sec/batch), lr: 0.100000
2019-03-22 12:23:19,915 2019-03-22 12:23:19: step 1/50000, loss = 0.477961 (2.185 sec/batch), lr: 1.000000
2019-03-22 12:23:22,245 2019-03-22 12:23:22: step 2/50000, loss = 0.485306 (2.326 sec/batch), lr: 1.000000
2019-03-22 12:23:24,458 2019-03-22 12:23:24: step 3/50000, loss = 0.482536 (2.209 sec/batch), lr: 1.000000
2019-03-22 12:23:26,696 2019-03-22 12:23:26: step 4/50000, loss = 0.479265 (2.234 sec/batch), lr: 1.000000
2019-03-22 12:23:28,810 2019-03-22 12:23:28: step 5/50000, loss = 0.474763 (2.111 sec/batch), lr: 1.000000
2019-03-22 12:23:30,894 2019-03-22 12:23:30: step 6/50000, loss = 0.469349 (2.081 sec/batch), lr: 1.000000
2019-03-22 12:23:33,005 2019-03-22 12:23:33: step 7/50000, loss = 0.462302 (2.106 sec/batch), lr: 1.000000
2019-03-22 12:23:35,286 2019-03-22 12:23:35: step 8/50000, loss = 0.449353 (2.277 sec/batch), lr: 1.000000
2019-03-22 12:23:37,496 2019-03-22 12:23:37: step 9/50000, loss = 0.419134 (2.210 sec/batch), lr: 1.000000
2019-03-22 12:23:39,721 2019-03-22 12:23:39: step 10/50000, loss = 0.317714 (2.221 sec/batch), lr: 1.000000
2019-03-22 12:23:41,715 2019-03-22 12:23:41: step 11/50000, loss = 0.261432 (1.990 sec/batch), lr: 1.000000
2019-03-22 12:23:43,740 2019-03-22 12:23:43: step 12/50000, loss = 0.410087 (2.021 sec/batch), lr: 1.000000
2019-03-22 12:23:45,642 2019-03-22 12:23:45: step 13/50000, loss = 0.221696 (1.899 sec/batch), lr: 1.000000
2019-03-22 12:23:47,667 2019-03-22 12:23:47: step 14/50000, loss = 0.383713 (2.021 sec/batch), lr: 1.000000
2019-03-22 12:23:49,709 2019-03-22 12:23:49: step 15/50000, loss = 0.357103 (2.038 sec/batch), lr: 1.000000
2019-03-22 12:23:51,787 2019-03-22 12:23:51: step 16/50000, loss = 0.416568 (2.074 sec/batch), lr: 1.000000
2019-03-22 12:23:53,810 2019-03-22 12:23:53: step 17/50000, loss = 0.197211 (2.019 sec/batch), lr: 1.000000
2019-03-22 12:23:55,821 2019-03-22 12:23:55: step 18/50000, loss = 0.280224 (2.007 sec/batch), lr: 1.000000
2019-03-22 12:23:57,828 2019-03-22 12:23:57: step 19/50000, loss = 0.187007 (2.004 sec/batch), lr: 1.000000
2019-03-22 12:23:59,870 2019-03-22 12:23:59: step 20/50000, loss = 0.186047 (2.039 sec/batch), lr: 1.000000
2019-03-22 12:24:01,790 2019-03-22 12:24:01: step 21/50000, loss = 0.208892 (1.917 sec/batch), lr: 1.000000
2019-03-22 12:24:03,676 2019-03-22 12:24:03: step 22/50000, loss = 0.168241 (1.883 sec/batch), lr: 1.000000
2019-03-22 12:24:05,566 2019-03-22 12:24:05: step 23/50000, loss = 0.370324 (1.887 sec/batch), lr: 1.000000
2019-03-22 12:24:07,589 2019-03-22 12:24:07: step 24/50000, loss = 0.163279 (2.019 sec/batch), lr: 1.000000
2019-03-22 12:24:09,615 2019-03-22 12:24:09: step 25/50000, loss = 0.183479 (2.022 sec/batch), lr: 1.000000
2019-03-22 12:24:11,588 2019-03-22 12:24:11: step 26/50000, loss = 0.252912 (1.970 sec/batch), lr: 1.000000
2019-03-22 12:24:13,584 2019-03-22 12:24:13: step 27/50000, loss = 0.318762 (1.992 sec/batch), lr: 1.000000
2019-03-22 12:24:15,620 2019-03-22 12:24:15: step 28/50000, loss = 0.195183 (2.032 sec/batch), lr: 1.000000
2019-03-22 12:24:17,609 2019-03-22 12:24:17: step 29/50000, loss = 0.308675 (1.986 sec/batch), lr: 1.000000
2019-03-22 12:24:19,607 2019-03-22 12:24:19: step 30/50000, loss = 0.178916 (1.994 sec/batch), lr: 1.000000
2019-03-22 12:24:21,610 2019-03-22 12:24:21: step 31/50000, loss = 0.291008 (2.000 sec/batch), lr: 1.000000
2019-03-22 12:24:23,538 2019-03-22 12:24:23: step 32/50000, loss = 0.174030 (1.924 sec/batch), lr: 1.000000
2019-03-22 12:24:25,603 2019-03-22 12:24:25: step 33/50000, loss = 0.274207 (2.061 sec/batch), lr: 1.000000
2019-03-22 12:24:27,599 2019-03-22 12:24:27: step 34/50000, loss = 0.168446 (1.992 sec/batch), lr: 1.000000
2019-03-22 12:24:29,591 2019-03-22 12:24:29: step 35/50000, loss = 0.262891 (1.988 sec/batch), lr: 1.000000
2019-03-22 12:24:31,549 2019-03-22 12:24:31: step 36/50000, loss = 0.160429 (1.954 sec/batch), lr: 1.000000
2019-03-22 12:24:33,459 2019-03-22 12:24:33: step 37/50000, loss = 0.249313 (1.906 sec/batch), lr: 1.000000
2019-03-22 12:24:35,419 2019-03-22 12:24:35: step 38/50000, loss = 0.156501 (1.956 sec/batch), lr: 1.000000
2019-03-22 12:24:37,627 2019-03-22 12:24:37: step 39/50000, loss = 0.242578 (2.204 sec/batch), lr: 1.000000
2019-03-22 12:24:39,870 2019-03-22 12:24:39: step 40/50000, loss = 0.149531 (2.239 sec/batch), lr: 1.000000
2019-03-22 12:24:42,101 2019-03-22 12:24:42: step 41/50000, loss = 0.228427 (2.227 sec/batch), lr: 1.000000
2019-03-22 12:24:44,326 2019-03-22 12:24:44: step 42/50000, loss = 0.143096 (2.221 sec/batch), lr: 1.000000
2019-03-22 12:24:46,551 2019-03-22 12:24:46: step 43/50000, loss = 0.222421 (2.223 sec/batch), lr: 1.000000
2019-03-22 12:24:48,484 2019-03-22 12:24:48: step 44/50000, loss = 0.136436 (1.929 sec/batch), lr: 1.000000
2019-03-22 12:24:50,600 2019-03-22 12:24:50: step 45/50000, loss = 0.213942 (2.112 sec/batch), lr: 1.000000
2019-03-22 12:24:52,524 2019-03-22 12:24:52: step 46/50000, loss = 0.131383 (1.920 sec/batch), lr: 1.000000
2019-03-22 12:24:54,470 2019-03-22 12:24:54: step 47/50000, loss = 0.207441 (1.943 sec/batch), lr: 1.000000
2019-03-22 12:24:56,496 2019-03-22 12:24:56: step 48/50000, loss = 0.125156 (2.022 sec/batch), lr: 1.000000
2019-03-22 12:24:58,439 2019-03-22 12:24:58: step 49/50000, loss = 0.196758 (1.940 sec/batch), lr: 1.000000
2019-03-22 12:25:00,458 2019-03-22 12:25:00: step 50/50000, loss = 0.121898 (2.014 sec/batch), lr: 1.000000
2019-03-22 12:25:02,403 2019-03-22 12:25:02: step 51/50000, loss = 0.194185 (1.942 sec/batch), lr: 1.000000
2019-03-22 12:25:04,368 2019-03-22 12:25:04: step 52/50000, loss = 0.115180 (1.961 sec/batch), lr: 1.000000
2019-03-22 12:25:06,283 2019-03-22 12:25:06: step 53/50000, loss = 0.185400 (1.911 sec/batch), lr: 1.000000
2019-03-22 12:25:08,486 2019-03-22 12:25:08: step 54/50000, loss = 0.109623 (2.198 sec/batch), lr: 1.000000
2019-03-22 12:25:10,600 2019-03-22 12:25:10: step 55/50000, loss = 0.185008 (2.110 sec/batch), lr: 1.000000
2019-03-22 12:25:12,515 2019-03-22 12:25:12: step 56/50000, loss = 0.103654 (1.911 sec/batch), lr: 1.000000
2019-03-22 12:25:14,553 2019-03-22 12:25:14: step 57/50000, loss = 0.174180 (2.034 sec/batch), lr: 1.000000
2019-03-22 12:25:16,543 2019-03-22 12:25:16: step 58/50000, loss = 0.102490 (1.986 sec/batch), lr: 1.000000
2019-03-22 12:25:18,450 2019-03-22 12:25:18: step 59/50000, loss = 0.177782 (1.904 sec/batch), lr: 1.000000
2019-03-22 12:25:20,446 2019-03-22 12:25:20: step 60/50000, loss = 0.099051 (1.992 sec/batch), lr: 1.000000
2019-03-22 12:25:22,418 2019-03-22 12:25:22: step 61/50000, loss = 0.168024 (1.968 sec/batch), lr: 1.000000
2019-03-22 12:25:24,397 2019-03-22 12:25:24: step 62/50000, loss = 0.094458 (1.975 sec/batch), lr: 1.000000
2019-03-22 12:25:26,368 2019-03-22 12:25:26: step 63/50000, loss = 0.174054 (1.967 sec/batch), lr: 1.000000
2019-03-22 12:25:28,307 2019-03-22 12:25:28: step 64/50000, loss = 0.091803 (1.936 sec/batch), lr: 1.000000
2019-03-22 12:26:07,589 2019-03-22 12:26:07: step 1/50000, loss = 0.477961 (1.942 sec/batch), lr: 1.000000
2019-03-22 12:26:09,624 2019-03-22 12:26:09: step 2/50000, loss = 0.485306 (2.030 sec/batch), lr: 1.000000
2019-03-22 12:26:11,618 2019-03-22 12:26:11: step 3/50000, loss = 0.482536 (1.991 sec/batch), lr: 1.000000
2019-03-22 12:26:13,557 2019-03-22 12:26:13: step 4/50000, loss = 0.479265 (1.935 sec/batch), lr: 1.000000
2019-03-22 12:26:15,456 2019-03-22 12:26:15: step 5/50000, loss = 0.474763 (1.896 sec/batch), lr: 1.000000
2019-03-22 12:26:17,464 2019-03-22 12:26:17: step 6/50000, loss = 0.469349 (2.007 sec/batch), lr: 1.000000
2019-03-22 12:26:19,421 2019-03-22 12:26:19: step 7/50000, loss = 0.462302 (1.953 sec/batch), lr: 1.000000
2019-03-22 12:26:21,736 2019-03-22 12:26:21: step 8/50000, loss = 0.449353 (2.311 sec/batch), lr: 1.000000
2019-03-22 12:26:23,894 2019-03-22 12:26:23: step 9/50000, loss = 0.419134 (2.154 sec/batch), lr: 1.000000
2019-03-22 12:26:26,130 2019-03-22 12:26:26: step 10/50000, loss = 0.317714 (2.233 sec/batch), lr: 1.000000
2019-03-22 12:26:28,329 2019-03-22 12:26:28: step 11/50000, loss = 0.261432 (2.195 sec/batch), lr: 1.000000
2019-03-22 12:26:30,532 2019-03-22 12:26:30: step 12/50000, loss = 0.410087 (2.200 sec/batch), lr: 1.000000
2019-03-22 12:26:32,740 2019-03-22 12:26:32: step 13/50000, loss = 0.221696 (2.204 sec/batch), lr: 1.000000
2019-03-22 12:26:34,961 2019-03-22 12:26:34: step 14/50000, loss = 0.383713 (2.217 sec/batch), lr: 1.000000
2019-03-22 12:26:36,904 2019-03-22 12:26:36: step 15/50000, loss = 0.357103 (1.939 sec/batch), lr: 1.000000
2019-03-22 12:26:38,844 2019-03-22 12:26:38: step 16/50000, loss = 0.416568 (1.936 sec/batch), lr: 1.000000
2019-03-22 12:26:40,868 2019-03-22 12:26:40: step 17/50000, loss = 0.197211 (2.021 sec/batch), lr: 1.000000
2019-03-22 12:26:42,801 2019-03-22 12:26:42: step 18/50000, loss = 0.280224 (1.928 sec/batch), lr: 1.000000
2019-03-22 12:26:45,099 2019-03-22 12:26:45: step 19/50000, loss = 0.187007 (2.294 sec/batch), lr: 1.000000
2019-03-22 12:26:47,274 2019-03-22 12:26:47: step 20/50000, loss = 0.186047 (2.171 sec/batch), lr: 1.000000
2019-03-22 12:26:49,221 2019-03-22 12:26:49: step 21/50000, loss = 0.208892 (1.943 sec/batch), lr: 1.000000
2019-03-22 12:26:51,195 2019-03-22 12:26:51: step 22/50000, loss = 0.168241 (1.970 sec/batch), lr: 1.000000
2019-03-22 12:26:53,084 2019-03-22 12:26:53: step 23/50000, loss = 0.370324 (1.885 sec/batch), lr: 1.000000
2019-03-22 12:27:36,018 2019-03-22 12:27:36: step 1/50000, loss = 0.477961 (2.117 sec/batch), lr: 0.100000
2019-03-22 12:27:38,159 2019-03-22 12:27:38: step 2/50000, loss = 0.488857 (2.137 sec/batch), lr: 0.100000
2019-03-22 12:27:40,122 2019-03-22 12:27:40: step 3/50000, loss = 0.488614 (1.959 sec/batch), lr: 0.100000
2019-03-22 12:27:42,102 2019-03-22 12:27:42: step 4/50000, loss = 0.488391 (1.976 sec/batch), lr: 0.100000
2019-03-22 12:27:44,074 2019-03-22 12:27:44: step 5/50000, loss = 0.488228 (1.967 sec/batch), lr: 0.100000
2019-03-22 12:27:46,218 2019-03-22 12:27:46: step 6/50000, loss = 0.488071 (2.140 sec/batch), lr: 0.100000
2019-03-22 12:27:48,261 2019-03-22 12:27:48: step 7/50000, loss = 0.487911 (2.039 sec/batch), lr: 0.100000
2019-03-22 12:27:50,226 2019-03-22 12:27:50: step 8/50000, loss = 0.487748 (1.961 sec/batch), lr: 0.100000
2019-03-22 12:27:52,257 2019-03-22 12:27:52: step 9/50000, loss = 0.487583 (2.027 sec/batch), lr: 0.100000
2019-03-22 12:27:54,230 2019-03-22 12:27:54: step 10/50000, loss = 0.487413 (1.969 sec/batch), lr: 0.100000
2019-03-22 12:27:56,232 2019-03-22 12:27:56: step 11/50000, loss = 0.487238 (1.998 sec/batch), lr: 0.100000
2019-03-22 12:27:58,164 2019-03-22 12:27:58: step 12/50000, loss = 0.487058 (1.928 sec/batch), lr: 0.100000
2019-03-22 12:28:00,171 2019-03-22 12:28:00: step 13/50000, loss = 0.486872 (2.004 sec/batch), lr: 0.100000
2019-03-22 12:28:02,165 2019-03-22 12:28:02: step 14/50000, loss = 0.486682 (1.990 sec/batch), lr: 0.100000
2019-03-22 12:28:04,209 2019-03-22 12:28:04: step 15/50000, loss = 0.486489 (2.039 sec/batch), lr: 0.100000
2019-03-22 12:28:06,142 2019-03-22 12:28:06: step 16/50000, loss = 0.486289 (1.930 sec/batch), lr: 0.100000
2019-03-22 12:28:08,080 2019-03-22 12:28:08: step 17/50000, loss = 0.486081 (1.933 sec/batch), lr: 0.100000
2019-03-22 12:28:10,098 2019-03-22 12:28:10: step 18/50000, loss = 0.485870 (2.014 sec/batch), lr: 0.100000
2019-03-22 12:28:12,089 2019-03-22 12:28:12: step 19/50000, loss = 0.485665 (1.987 sec/batch), lr: 0.100000
2019-03-22 12:28:14,108 2019-03-22 12:28:14: step 20/50000, loss = 0.485457 (2.015 sec/batch), lr: 0.100000
2019-03-22 12:28:16,200 2019-03-22 12:28:16: step 21/50000, loss = 0.485246 (2.088 sec/batch), lr: 0.100000
2019-03-22 12:28:18,175 2019-03-22 12:28:18: step 22/50000, loss = 0.485036 (1.971 sec/batch), lr: 0.100000
2019-03-22 12:28:20,179 2019-03-22 12:28:20: step 23/50000, loss = 0.484814 (2.000 sec/batch), lr: 0.100000
2019-03-22 12:28:22,384 2019-03-22 12:28:22: step 24/50000, loss = 0.484590 (2.201 sec/batch), lr: 0.100000
2019-03-22 12:28:24,574 2019-03-22 12:28:24: step 25/50000, loss = 0.484367 (2.186 sec/batch), lr: 0.100000
2019-03-22 12:28:26,792 2019-03-22 12:28:26: step 26/50000, loss = 0.484142 (2.214 sec/batch), lr: 0.100000
2019-03-22 12:28:29,075 2019-03-22 12:28:29: step 27/50000, loss = 0.483909 (2.280 sec/batch), lr: 0.100000
2019-03-22 12:28:31,294 2019-03-22 12:28:31: step 28/50000, loss = 0.483678 (2.214 sec/batch), lr: 0.100000
2019-03-22 12:28:33,219 2019-03-22 12:28:33: step 29/50000, loss = 0.483438 (1.922 sec/batch), lr: 0.100000
2019-03-22 12:28:35,537 2019-03-22 12:28:35: step 30/50000, loss = 0.483184 (2.313 sec/batch), lr: 0.100000
2019-03-22 12:28:37,749 2019-03-22 12:28:37: step 31/50000, loss = 0.482924 (2.209 sec/batch), lr: 0.100000
2019-03-22 12:28:39,998 2019-03-22 12:28:39: step 32/50000, loss = 0.482662 (2.246 sec/batch), lr: 0.100000
2019-03-22 12:28:42,188 2019-03-22 12:28:42: step 33/50000, loss = 0.482396 (2.186 sec/batch), lr: 0.100000
2019-03-22 12:28:44,394 2019-03-22 12:28:44: step 34/50000, loss = 0.482137 (2.203 sec/batch), lr: 0.100000
2019-03-22 12:28:46,584 2019-03-22 12:28:46: step 35/50000, loss = 0.481856 (2.186 sec/batch), lr: 0.100000
2019-03-22 12:28:48,767 2019-03-22 12:28:48: step 36/50000, loss = 0.481566 (2.179 sec/batch), lr: 0.100000
2019-03-22 12:28:50,789 2019-03-22 12:28:50: step 37/50000, loss = 0.481266 (2.018 sec/batch), lr: 0.100000
2019-03-22 12:28:52,759 2019-03-22 12:28:52: step 38/50000, loss = 0.480972 (1.966 sec/batch), lr: 0.100000
2019-03-22 12:28:54,690 2019-03-22 12:28:54: step 39/50000, loss = 0.480665 (1.928 sec/batch), lr: 0.100000
2019-03-22 12:28:56,655 2019-03-22 12:28:56: step 40/50000, loss = 0.480360 (1.961 sec/batch), lr: 0.100000
2019-03-22 12:28:58,672 2019-03-22 12:28:58: step 41/50000, loss = 0.480030 (2.014 sec/batch), lr: 0.100000
2019-03-22 12:29:00,711 2019-03-22 12:29:00: step 42/50000, loss = 0.479702 (2.034 sec/batch), lr: 0.100000
2019-03-22 12:29:02,681 2019-03-22 12:29:02: step 43/50000, loss = 0.479376 (1.966 sec/batch), lr: 0.100000
2019-03-22 12:29:04,617 2019-03-22 12:29:04: step 44/50000, loss = 0.479027 (1.932 sec/batch), lr: 0.100000
2019-03-22 12:29:06,647 2019-03-22 12:29:06: step 45/50000, loss = 0.478677 (2.026 sec/batch), lr: 0.100000
2019-03-22 12:29:08,671 2019-03-22 12:29:08: step 46/50000, loss = 0.478325 (2.020 sec/batch), lr: 0.100000
2019-03-22 12:29:10,651 2019-03-22 12:29:10: step 47/50000, loss = 0.477935 (1.976 sec/batch), lr: 0.100000
2019-03-22 12:29:12,659 2019-03-22 12:29:12: step 48/50000, loss = 0.477539 (2.004 sec/batch), lr: 0.100000
2019-03-22 12:29:14,725 2019-03-22 12:29:14: step 49/50000, loss = 0.477156 (2.062 sec/batch), lr: 0.100000
2019-03-22 12:29:16,870 2019-03-22 12:29:16: step 50/50000, loss = 0.476749 (2.141 sec/batch), lr: 0.100000
2019-03-22 12:29:19,061 2019-03-22 12:29:19: step 51/50000, loss = 0.476318 (2.187 sec/batch), lr: 0.100000
2019-03-22 12:29:21,349 2019-03-22 12:29:21: step 52/50000, loss = 0.475893 (2.284 sec/batch), lr: 0.100000
2019-03-22 12:29:23,564 2019-03-22 12:29:23: step 53/50000, loss = 0.475445 (2.211 sec/batch), lr: 0.100000
2019-03-22 12:29:25,648 2019-03-22 12:29:25: step 54/50000, loss = 0.474971 (2.080 sec/batch), lr: 0.100000
2019-03-22 12:29:27,607 2019-03-22 12:29:27: step 55/50000, loss = 0.474495 (1.955 sec/batch), lr: 0.100000
2019-03-22 12:29:29,801 2019-03-22 12:29:29: step 56/50000, loss = 0.474001 (2.191 sec/batch), lr: 0.100000
2019-03-22 12:29:31,656 2019-03-22 12:29:31: step 57/50000, loss = 0.473493 (1.851 sec/batch), lr: 0.100000
2019-03-22 12:29:33,562 2019-03-22 12:29:33: step 58/50000, loss = 0.472950 (1.903 sec/batch), lr: 0.100000
2019-03-22 12:29:35,587 2019-03-22 12:29:35: step 59/50000, loss = 0.472398 (2.021 sec/batch), lr: 0.100000
2019-03-22 12:29:37,438 2019-03-22 12:29:37: step 60/50000, loss = 0.471820 (1.848 sec/batch), lr: 0.100000
2019-03-22 12:29:39,369 2019-03-22 12:29:39: step 61/50000, loss = 0.471209 (1.927 sec/batch), lr: 0.100000
2019-03-22 12:29:41,270 2019-03-22 12:29:41: step 62/50000, loss = 0.470573 (1.898 sec/batch), lr: 0.100000
2019-03-22 12:29:43,385 2019-03-22 12:29:43: step 63/50000, loss = 0.469920 (2.111 sec/batch), lr: 0.100000
2019-03-22 12:29:45,657 2019-03-22 12:29:45: step 64/50000, loss = 0.469217 (2.268 sec/batch), lr: 0.100000
2019-03-22 12:29:47,896 2019-03-22 12:29:47: step 65/50000, loss = 0.468495 (2.235 sec/batch), lr: 0.100000
2019-03-22 12:29:49,926 2019-03-22 12:29:49: step 66/50000, loss = 0.467746 (2.026 sec/batch), lr: 0.100000
2019-03-22 12:29:51,900 2019-03-22 12:29:51: step 67/50000, loss = 0.466906 (1.971 sec/batch), lr: 0.100000
2019-03-22 12:29:53,910 2019-03-22 12:29:53: step 68/50000, loss = 0.466062 (2.006 sec/batch), lr: 0.100000
2019-03-22 12:29:55,933 2019-03-22 12:29:55: step 69/50000, loss = 0.465153 (2.019 sec/batch), lr: 0.100000
2019-03-22 12:29:57,945 2019-03-22 12:29:57: step 70/50000, loss = 0.464189 (2.008 sec/batch), lr: 0.100000
2019-03-22 12:29:59,982 2019-03-22 12:29:59: step 71/50000, loss = 0.463159 (2.033 sec/batch), lr: 0.100000
2019-03-22 12:30:01,919 2019-03-22 12:30:01: step 72/50000, loss = 0.462030 (1.933 sec/batch), lr: 0.100000
2019-03-22 12:30:03,899 2019-03-22 12:30:03: step 73/50000, loss = 0.460857 (1.976 sec/batch), lr: 0.100000
2019-03-22 12:30:06,135 2019-03-22 12:30:06: step 74/50000, loss = 0.459639 (2.232 sec/batch), lr: 0.100000
2019-03-22 12:30:08,353 2019-03-22 12:30:08: step 75/50000, loss = 0.458340 (2.214 sec/batch), lr: 0.100000
2019-03-22 12:30:10,292 2019-03-22 12:30:10: step 76/50000, loss = 0.456956 (1.935 sec/batch), lr: 0.100000
2019-03-22 12:30:12,300 2019-03-22 12:30:12: step 77/50000, loss = 0.455484 (2.004 sec/batch), lr: 0.100000
2019-03-22 12:30:14,401 2019-03-22 12:30:14: step 78/50000, loss = 0.453867 (2.097 sec/batch), lr: 0.100000
2019-03-22 12:30:16,394 2019-03-22 12:30:16: step 79/50000, loss = 0.452135 (1.989 sec/batch), lr: 0.100000
2019-03-22 12:30:18,326 2019-03-22 12:30:18: step 80/50000, loss = 0.450278 (1.928 sec/batch), lr: 0.100000
2019-03-22 12:30:20,314 2019-03-22 12:30:20: step 81/50000, loss = 0.448145 (1.985 sec/batch), lr: 0.100000
2019-03-22 12:30:22,309 2019-03-22 12:30:22: step 82/50000, loss = 0.445793 (1.991 sec/batch), lr: 0.100000
2019-03-22 12:30:24,260 2019-03-22 12:30:24: step 83/50000, loss = 0.443093 (1.946 sec/batch), lr: 0.100000
2019-03-22 12:30:26,200 2019-03-22 12:30:26: step 84/50000, loss = 0.440128 (1.937 sec/batch), lr: 0.100000
2019-03-22 12:30:28,229 2019-03-22 12:30:28: step 85/50000, loss = 0.436678 (2.025 sec/batch), lr: 0.100000
2019-03-22 12:30:30,240 2019-03-22 12:30:30: step 86/50000, loss = 0.432805 (2.007 sec/batch), lr: 0.100000
2019-03-22 12:30:32,235 2019-03-22 12:30:32: step 87/50000, loss = 0.428524 (1.991 sec/batch), lr: 0.100000
2019-03-22 12:30:34,167 2019-03-22 12:30:34: step 88/50000, loss = 0.423648 (1.929 sec/batch), lr: 0.100000
2019-03-22 12:30:36,203 2019-03-22 12:30:36: step 89/50000, loss = 0.418244 (2.032 sec/batch), lr: 0.100000
2019-03-22 12:30:38,154 2019-03-22 12:30:38: step 90/50000, loss = 0.412071 (1.947 sec/batch), lr: 0.100000
2019-03-22 12:30:40,266 2019-03-22 12:30:40: step 91/50000, loss = 0.404843 (2.108 sec/batch), lr: 0.100000
2019-03-22 12:30:42,192 2019-03-22 12:30:42: step 92/50000, loss = 0.396693 (1.922 sec/batch), lr: 0.100000
2019-03-22 12:30:44,250 2019-03-22 12:30:44: step 93/50000, loss = 0.387133 (2.054 sec/batch), lr: 0.100000
2019-03-22 12:30:46,246 2019-03-22 12:30:46: step 94/50000, loss = 0.375862 (1.991 sec/batch), lr: 0.100000
2019-03-22 12:30:48,237 2019-03-22 12:30:48: step 95/50000, loss = 0.362300 (1.988 sec/batch), lr: 0.100000
2019-03-22 12:30:50,239 2019-03-22 12:30:50: step 96/50000, loss = 0.345698 (1.998 sec/batch), lr: 0.100000
2019-03-22 12:30:52,180 2019-03-22 12:30:52: step 97/50000, loss = 0.325754 (1.937 sec/batch), lr: 0.100000
2019-03-22 12:30:54,137 2019-03-22 12:30:54: step 98/50000, loss = 0.301125 (1.953 sec/batch), lr: 0.100000
2019-03-22 12:30:56,089 2019-03-22 12:30:56: step 99/50000, loss = 0.269496 (1.949 sec/batch), lr: 0.100000
2019-03-22 12:30:58,142 2019-03-22 12:30:58: step 100/50000, loss = 0.232064 (2.049 sec/batch), lr: 0.100000
2019-03-22 12:30:59,046 step 100: Full loss = 0.402957, Edge acc. = 0.2500
2019-03-22 12:31:01,027 2019-03-22 12:31:01: step 101/50000, loss = 0.201478 (1.975 sec/batch), lr: 0.100000
2019-03-22 12:31:02,975 2019-03-22 12:31:02: step 102/50000, loss = 0.254893 (1.944 sec/batch), lr: 0.100000
2019-03-22 12:31:04,940 2019-03-22 12:31:04: step 103/50000, loss = 0.201757 (1.961 sec/batch), lr: 0.100000
2019-03-22 12:31:06,909 2019-03-22 12:31:06: step 104/50000, loss = 0.241998 (1.965 sec/batch), lr: 0.100000
2019-03-22 12:31:08,851 2019-03-22 12:31:08: step 105/50000, loss = 0.202470 (1.938 sec/batch), lr: 0.100000
2019-03-22 12:31:10,777 2019-03-22 12:31:10: step 106/50000, loss = 0.232953 (1.922 sec/batch), lr: 0.100000
2019-03-22 12:31:12,740 2019-03-22 12:31:12: step 107/50000, loss = 0.203843 (1.960 sec/batch), lr: 0.100000
2019-03-22 12:31:14,744 2019-03-22 12:31:14: step 108/50000, loss = 0.226324 (2.001 sec/batch), lr: 0.100000
2019-03-22 12:31:16,677 2019-03-22 12:31:16: step 109/50000, loss = 0.204783 (1.929 sec/batch), lr: 0.100000
2019-03-22 12:31:18,687 2019-03-22 12:31:18: step 110/50000, loss = 0.220697 (2.007 sec/batch), lr: 0.100000
2019-03-22 12:31:20,668 2019-03-22 12:31:20: step 111/50000, loss = 0.206131 (1.978 sec/batch), lr: 0.100000
2019-03-22 12:31:22,631 2019-03-22 12:31:22: step 112/50000, loss = 0.216384 (1.959 sec/batch), lr: 0.100000
2019-03-22 12:31:24,638 2019-03-22 12:31:24: step 113/50000, loss = 0.206928 (2.004 sec/batch), lr: 0.100000
2019-03-22 12:31:26,652 2019-03-22 12:31:26: step 114/50000, loss = 0.212855 (2.011 sec/batch), lr: 0.100000
2019-03-22 12:31:28,633 2019-03-22 12:31:28: step 115/50000, loss = 0.208027 (1.977 sec/batch), lr: 0.100000
2019-03-22 12:31:30,619 2019-03-22 12:31:30: step 116/50000, loss = 0.210087 (1.982 sec/batch), lr: 0.100000
2019-03-22 12:31:32,631 2019-03-22 12:31:32: step 117/50000, loss = 0.208700 (2.008 sec/batch), lr: 0.100000
2019-03-22 12:31:34,599 2019-03-22 12:31:34: step 118/50000, loss = 0.207849 (1.964 sec/batch), lr: 0.100000
2019-03-22 12:31:36,484 2019-03-22 12:31:36: step 119/50000, loss = 0.209117 (1.882 sec/batch), lr: 0.100000
2019-03-22 12:31:38,484 2019-03-22 12:31:38: step 120/50000, loss = 0.205655 (1.996 sec/batch), lr: 0.100000
2019-03-22 12:31:40,369 2019-03-22 12:31:40: step 121/50000, loss = 0.209764 (1.880 sec/batch), lr: 0.100000
2019-03-22 12:31:42,274 2019-03-22 12:31:42: step 122/50000, loss = 0.204094 (1.902 sec/batch), lr: 0.100000
2019-03-22 12:31:44,377 2019-03-22 12:31:44: step 123/50000, loss = 0.209972 (2.099 sec/batch), lr: 0.100000
2019-03-22 12:31:46,377 2019-03-22 12:31:46: step 124/50000, loss = 0.202724 (1.996 sec/batch), lr: 0.100000
2019-03-22 12:31:48,328 2019-03-22 12:31:48: step 125/50000, loss = 0.209832 (1.944 sec/batch), lr: 0.100000
2019-03-22 12:31:50,362 2019-03-22 12:31:50: step 126/50000, loss = 0.201474 (2.029 sec/batch), lr: 0.100000
2019-03-22 12:31:52,299 2019-03-22 12:31:52: step 127/50000, loss = 0.210137 (1.933 sec/batch), lr: 0.100000
2019-03-22 12:31:54,295 2019-03-22 12:31:54: step 128/50000, loss = 0.200411 (1.992 sec/batch), lr: 0.100000
2019-03-22 12:31:56,306 2019-03-22 12:31:56: step 129/50000, loss = 0.209869 (2.008 sec/batch), lr: 0.100000
2019-03-22 12:31:58,280 2019-03-22 12:31:58: step 130/50000, loss = 0.199276 (1.969 sec/batch), lr: 0.100000
2019-03-22 12:32:00,246 2019-03-22 12:32:00: step 131/50000, loss = 0.210070 (1.962 sec/batch), lr: 0.100000
2019-03-22 12:32:02,243 2019-03-22 12:32:02: step 132/50000, loss = 0.198330 (1.993 sec/batch), lr: 0.100000
2019-03-22 12:32:04,152 2019-03-22 12:32:04: step 133/50000, loss = 0.209668 (1.905 sec/batch), lr: 0.100000
2019-03-22 12:32:06,132 2019-03-22 12:32:06: step 134/50000, loss = 0.197473 (1.976 sec/batch), lr: 0.100000
2019-03-22 12:32:08,042 2019-03-22 12:32:08: step 135/50000, loss = 0.209641 (1.905 sec/batch), lr: 0.100000
2019-03-22 12:32:10,064 2019-03-22 12:32:10: step 136/50000, loss = 0.196615 (2.019 sec/batch), lr: 0.100000
2019-03-22 12:32:12,008 2019-03-22 12:32:12: step 137/50000, loss = 0.209255 (1.940 sec/batch), lr: 0.100000
2019-03-22 12:32:14,002 2019-03-22 12:32:13: step 138/50000, loss = 0.195802 (1.990 sec/batch), lr: 0.100000
2019-03-22 12:32:16,010 2019-03-22 12:32:16: step 139/50000, loss = 0.209239 (2.004 sec/batch), lr: 0.100000
2019-03-22 12:32:17,945 2019-03-22 12:32:17: step 140/50000, loss = 0.195106 (1.931 sec/batch), lr: 0.100000
2019-03-22 12:32:19,964 2019-03-22 12:32:19: step 141/50000, loss = 0.208770 (2.015 sec/batch), lr: 0.100000
2019-03-22 12:32:21,950 2019-03-22 12:32:21: step 142/50000, loss = 0.194361 (1.982 sec/batch), lr: 0.100000
2019-03-22 12:32:23,908 2019-03-22 12:32:23: step 143/50000, loss = 0.208742 (1.952 sec/batch), lr: 0.100000
2019-03-22 12:32:25,994 2019-03-22 12:32:25: step 144/50000, loss = 0.193741 (2.082 sec/batch), lr: 0.100000
2019-03-22 12:32:27,962 2019-03-22 12:32:27: step 145/50000, loss = 0.208204 (1.964 sec/batch), lr: 0.100000
2019-03-22 12:32:30,036 2019-03-22 12:32:30: step 146/50000, loss = 0.193047 (2.069 sec/batch), lr: 0.100000
2019-03-22 12:32:32,033 2019-03-22 12:32:32: step 147/50000, loss = 0.208118 (1.992 sec/batch), lr: 0.100000
2019-03-22 12:32:34,170 2019-03-22 12:32:34: step 148/50000, loss = 0.192437 (2.132 sec/batch), lr: 0.100000
2019-03-22 12:32:36,395 2019-03-22 12:32:36: step 149/50000, loss = 0.207575 (2.222 sec/batch), lr: 0.100000
2019-03-22 12:32:38,485 2019-03-22 12:32:38: step 150/50000, loss = 0.191815 (2.086 sec/batch), lr: 0.100000
2019-03-22 12:32:40,470 2019-03-22 12:32:40: step 151/50000, loss = 0.207562 (1.981 sec/batch), lr: 0.100000
2019-03-22 12:32:42,452 2019-03-22 12:32:42: step 152/50000, loss = 0.191181 (1.978 sec/batch), lr: 0.100000
2019-03-22 12:32:44,422 2019-03-22 12:32:44: step 153/50000, loss = 0.207068 (1.966 sec/batch), lr: 0.100000
2019-03-22 12:32:46,388 2019-03-22 12:32:46: step 154/50000, loss = 0.190490 (1.963 sec/batch), lr: 0.100000
2019-03-22 12:32:48,353 2019-03-22 12:32:48: step 155/50000, loss = 0.207079 (1.962 sec/batch), lr: 0.100000
2019-03-22 12:32:50,334 2019-03-22 12:32:50: step 156/50000, loss = 0.189899 (1.977 sec/batch), lr: 0.100000
2019-03-22 12:32:52,308 2019-03-22 12:32:52: step 157/50000, loss = 0.206563 (1.970 sec/batch), lr: 0.100000
2019-03-22 12:32:54,284 2019-03-22 12:32:54: step 158/50000, loss = 0.189249 (1.973 sec/batch), lr: 0.100000
2019-03-22 12:32:56,274 2019-03-22 12:32:56: step 159/50000, loss = 0.206563 (1.987 sec/batch), lr: 0.100000
2019-03-22 12:32:58,278 2019-03-22 12:32:58: step 160/50000, loss = 0.188757 (1.999 sec/batch), lr: 0.100000
2019-03-22 12:33:00,311 2019-03-22 12:33:00: step 161/50000, loss = 0.206235 (2.030 sec/batch), lr: 0.100000
2019-03-22 12:33:02,269 2019-03-22 12:33:02: step 162/50000, loss = 0.188195 (1.954 sec/batch), lr: 0.100000
2019-03-22 12:33:04,328 2019-03-22 12:33:04: step 163/50000, loss = 0.205681 (2.055 sec/batch), lr: 0.100000
2019-03-22 12:33:06,218 2019-03-22 12:33:06: step 164/50000, loss = 0.187681 (1.886 sec/batch), lr: 0.100000
2019-03-22 12:33:08,185 2019-03-22 12:33:08: step 165/50000, loss = 0.205679 (1.963 sec/batch), lr: 0.100000
2019-03-22 12:33:10,186 2019-03-22 12:33:10: step 166/50000, loss = 0.187139 (1.997 sec/batch), lr: 0.100000
2019-03-22 12:33:12,148 2019-03-22 12:33:12: step 167/50000, loss = 0.205090 (1.959 sec/batch), lr: 0.100000
2019-03-22 12:33:14,118 2019-03-22 12:33:14: step 168/50000, loss = 0.186654 (1.965 sec/batch), lr: 0.100000
2019-03-22 12:33:16,390 2019-03-22 12:33:16: step 169/50000, loss = 0.204978 (2.269 sec/batch), lr: 0.100000
2019-03-22 12:33:18,595 2019-03-22 12:33:18: step 170/50000, loss = 0.186207 (2.201 sec/batch), lr: 0.100000
2019-03-22 12:33:20,794 2019-03-22 12:33:20: step 171/50000, loss = 0.204450 (2.195 sec/batch), lr: 0.100000
2019-03-22 12:33:22,769 2019-03-22 12:33:22: step 172/50000, loss = 0.185731 (1.970 sec/batch), lr: 0.100000
2019-03-22 12:33:24,752 2019-03-22 12:33:24: step 173/50000, loss = 0.204452 (1.980 sec/batch), lr: 0.100000
2019-03-22 12:33:26,721 2019-03-22 12:33:26: step 174/50000, loss = 0.185173 (1.965 sec/batch), lr: 0.100000
2019-03-22 12:33:28,660 2019-03-22 12:33:28: step 175/50000, loss = 0.203963 (1.935 sec/batch), lr: 0.100000
2019-03-22 12:33:30,614 2019-03-22 12:33:30: step 176/50000, loss = 0.184742 (1.950 sec/batch), lr: 0.100000
2019-03-22 12:33:32,786 2019-03-22 12:33:32: step 177/50000, loss = 0.203636 (2.167 sec/batch), lr: 0.100000
2019-03-22 12:33:34,761 2019-03-22 12:33:34: step 178/50000, loss = 0.184352 (1.971 sec/batch), lr: 0.100000
2019-03-22 12:33:36,701 2019-03-22 12:33:36: step 179/50000, loss = 0.203531 (1.936 sec/batch), lr: 0.100000
2019-03-22 12:33:38,707 2019-03-22 12:33:38: step 180/50000, loss = 0.183919 (2.003 sec/batch), lr: 0.100000
2019-03-22 12:33:40,688 2019-03-22 12:33:40: step 181/50000, loss = 0.202965 (1.977 sec/batch), lr: 0.100000
2019-03-22 12:33:42,630 2019-03-22 12:33:42: step 182/50000, loss = 0.183512 (1.938 sec/batch), lr: 0.100000
2019-03-22 12:33:44,638 2019-03-22 12:33:44: step 183/50000, loss = 0.202836 (2.005 sec/batch), lr: 0.100000
2019-03-22 12:33:46,701 2019-03-22 12:33:46: step 184/50000, loss = 0.183078 (2.059 sec/batch), lr: 0.100000
2019-03-22 12:33:48,710 2019-03-22 12:33:48: step 185/50000, loss = 0.202272 (2.005 sec/batch), lr: 0.100000
2019-03-22 12:33:50,697 2019-03-22 12:33:50: step 186/50000, loss = 0.182689 (1.984 sec/batch), lr: 0.100000
2019-03-22 12:33:52,689 2019-03-22 12:33:52: step 187/50000, loss = 0.201920 (1.988 sec/batch), lr: 0.100000
2019-03-22 12:33:54,705 2019-03-22 12:33:54: step 188/50000, loss = 0.182296 (2.012 sec/batch), lr: 0.100000
2019-03-22 12:33:56,673 2019-03-22 12:33:56: step 189/50000, loss = 0.201809 (1.964 sec/batch), lr: 0.100000
2019-03-22 12:33:58,650 2019-03-22 12:33:58: step 190/50000, loss = 0.181865 (1.973 sec/batch), lr: 0.100000
2019-03-22 12:34:00,694 2019-03-22 12:34:00: step 191/50000, loss = 0.201255 (2.040 sec/batch), lr: 0.100000
2019-03-22 12:34:02,660 2019-03-22 12:34:02: step 192/50000, loss = 0.181495 (1.962 sec/batch), lr: 0.100000
2019-03-22 12:34:04,770 2019-03-22 12:34:04: step 193/50000, loss = 0.201124 (2.106 sec/batch), lr: 0.100000
2019-03-22 12:34:06,710 2019-03-22 12:34:06: step 194/50000, loss = 0.181063 (1.936 sec/batch), lr: 0.100000
2019-03-22 12:34:08,748 2019-03-22 12:34:08: step 195/50000, loss = 0.200569 (2.034 sec/batch), lr: 0.100000
2019-03-22 12:34:10,774 2019-03-22 12:34:10: step 196/50000, loss = 0.180717 (2.023 sec/batch), lr: 0.100000
2019-03-22 12:34:12,656 2019-03-22 12:34:12: step 197/50000, loss = 0.200322 (1.878 sec/batch), lr: 0.100000
2019-03-22 12:34:14,609 2019-03-22 12:34:14: step 198/50000, loss = 0.180270 (1.950 sec/batch), lr: 0.100000
2019-03-22 12:34:16,667 2019-03-22 12:34:16: step 199/50000, loss = 0.200256 (2.053 sec/batch), lr: 0.100000
2019-03-22 12:34:18,675 2019-03-22 12:34:18: step 200/50000, loss = 0.179890 (2.004 sec/batch), lr: 0.100000
2019-03-22 12:34:19,583 step 200: Full loss = 0.399502, Edge acc. = 0.2857
2019-03-22 12:34:21,529 2019-03-22 12:34:21: step 201/50000, loss = 0.199751 (1.940 sec/batch), lr: 0.100000
2019-03-22 12:34:23,840 2019-03-22 12:34:23: step 202/50000, loss = 0.179489 (2.307 sec/batch), lr: 0.100000
2019-03-22 12:34:26,030 2019-03-22 12:34:26: step 203/50000, loss = 0.199415 (2.187 sec/batch), lr: 0.100000
2019-03-22 12:34:28,337 2019-03-22 12:34:28: step 204/50000, loss = 0.179082 (2.303 sec/batch), lr: 0.100000
2019-03-22 12:34:30,534 2019-03-22 12:34:30: step 205/50000, loss = 0.199337 (2.193 sec/batch), lr: 0.100000
2019-03-22 12:34:32,466 2019-03-22 12:34:32: step 206/50000, loss = 0.178751 (1.929 sec/batch), lr: 0.100000
2019-03-22 12:34:34,568 2019-03-22 12:34:34: step 207/50000, loss = 0.198804 (2.098 sec/batch), lr: 0.100000
2019-03-22 12:34:36,545 2019-03-22 12:34:36: step 208/50000, loss = 0.178380 (1.973 sec/batch), lr: 0.100000
2019-03-22 12:34:38,525 2019-03-22 12:34:38: step 209/50000, loss = 0.198491 (1.975 sec/batch), lr: 0.100000
2019-03-22 12:34:40,460 2019-03-22 12:34:40: step 210/50000, loss = 0.177975 (1.932 sec/batch), lr: 0.100000
2019-03-22 12:34:42,418 2019-03-22 12:34:42: step 211/50000, loss = 0.198443 (1.954 sec/batch), lr: 0.100000
2019-03-22 12:34:44,400 2019-03-22 12:34:44: step 212/50000, loss = 0.177601 (1.978 sec/batch), lr: 0.100000
2019-03-22 12:34:46,708 2019-03-22 12:34:46: step 213/50000, loss = 0.197942 (2.304 sec/batch), lr: 0.100000
2019-03-22 12:34:48,958 2019-03-22 12:34:48: step 214/50000, loss = 0.177166 (2.246 sec/batch), lr: 0.100000
2019-03-22 12:34:51,108 2019-03-22 12:34:51: step 215/50000, loss = 0.197579 (2.146 sec/batch), lr: 0.100000
2019-03-22 12:34:53,365 2019-03-22 12:34:53: step 216/50000, loss = 0.176881 (2.253 sec/batch), lr: 0.100000
2019-03-22 12:34:55,622 2019-03-22 12:34:55: step 217/50000, loss = 0.197556 (2.253 sec/batch), lr: 0.100000
2019-03-22 12:34:57,881 2019-03-22 12:34:57: step 218/50000, loss = 0.176278 (2.255 sec/batch), lr: 0.100000
2019-03-22 12:34:59,891 2019-03-22 12:34:59: step 219/50000, loss = 0.197056 (2.006 sec/batch), lr: 0.100000
2019-03-22 12:35:01,851 2019-03-22 12:35:01: step 220/50000, loss = 0.175932 (1.956 sec/batch), lr: 0.100000
2019-03-22 12:35:03,785 2019-03-22 12:35:03: step 221/50000, loss = 0.196731 (1.931 sec/batch), lr: 0.100000
2019-03-22 12:35:05,944 2019-03-22 12:35:05: step 222/50000, loss = 0.175447 (2.155 sec/batch), lr: 0.100000
2019-03-22 12:35:07,911 2019-03-22 12:35:07: step 223/50000, loss = 0.196692 (1.963 sec/batch), lr: 0.100000
2019-03-22 12:35:09,836 2019-03-22 12:35:09: step 224/50000, loss = 0.174985 (1.922 sec/batch), lr: 0.100000
2019-03-22 12:35:11,947 2019-03-22 12:35:11: step 225/50000, loss = 0.196161 (2.107 sec/batch), lr: 0.100000
2019-03-22 12:35:13,937 2019-03-22 12:35:13: step 226/50000, loss = 0.174568 (1.986 sec/batch), lr: 0.100000
2019-03-22 12:35:15,918 2019-03-22 12:35:15: step 227/50000, loss = 0.195943 (1.977 sec/batch), lr: 0.100000
2019-03-22 12:35:17,910 2019-03-22 12:35:17: step 228/50000, loss = 0.174133 (1.988 sec/batch), lr: 0.100000
2019-03-22 12:35:19,975 2019-03-22 12:35:19: step 229/50000, loss = 0.195655 (2.061 sec/batch), lr: 0.100000
2019-03-22 12:35:22,246 2019-03-22 12:35:22: step 230/50000, loss = 0.173631 (2.267 sec/batch), lr: 0.100000
2019-03-22 12:35:24,403 2019-03-22 12:35:24: step 231/50000, loss = 0.195671 (2.154 sec/batch), lr: 0.100000
2019-03-22 12:35:26,598 2019-03-22 12:35:26: step 232/50000, loss = 0.173227 (2.191 sec/batch), lr: 0.100000
2019-03-22 12:35:28,863 2019-03-22 12:35:28: step 233/50000, loss = 0.195170 (2.261 sec/batch), lr: 0.100000
2019-03-22 12:35:31,071 2019-03-22 12:35:31: step 234/50000, loss = 0.172740 (2.204 sec/batch), lr: 0.100000
2019-03-22 12:35:33,374 2019-03-22 12:35:33: step 235/50000, loss = 0.195110 (2.300 sec/batch), lr: 0.100000
2019-03-22 12:35:35,613 2019-03-22 12:35:35: step 236/50000, loss = 0.172392 (2.235 sec/batch), lr: 0.100000
2019-03-22 12:35:37,714 2019-03-22 12:35:37: step 237/50000, loss = 0.194588 (2.097 sec/batch), lr: 0.100000
2019-03-22 12:35:39,584 2019-03-22 12:35:39: step 238/50000, loss = 0.171973 (1.867 sec/batch), lr: 0.100000
2019-03-22 12:35:41,551 2019-03-22 12:35:41: step 239/50000, loss = 0.194288 (1.963 sec/batch), lr: 0.100000
2019-03-22 12:35:43,541 2019-03-22 12:35:43: step 240/50000, loss = 0.171615 (1.986 sec/batch), lr: 0.100000
2019-03-22 12:35:45,556 2019-03-22 12:35:45: step 241/50000, loss = 0.194268 (2.012 sec/batch), lr: 0.100000
2019-03-22 12:35:47,533 2019-03-22 12:35:47: step 242/50000, loss = 0.171185 (1.973 sec/batch), lr: 0.100000
2019-03-22 12:35:49,528 2019-03-22 12:35:49: step 243/50000, loss = 0.193708 (1.990 sec/batch), lr: 0.100000
2019-03-22 12:35:51,610 2019-03-22 12:35:51: step 244/50000, loss = 0.170885 (2.078 sec/batch), lr: 0.100000
2019-03-22 12:35:53,607 2019-03-22 12:35:53: step 245/50000, loss = 0.193372 (1.993 sec/batch), lr: 0.100000
2019-03-22 12:35:55,684 2019-03-22 12:35:55: step 246/50000, loss = 0.170563 (2.074 sec/batch), lr: 0.100000
2019-03-22 12:35:57,755 2019-03-22 12:35:57: step 247/50000, loss = 0.193073 (2.067 sec/batch), lr: 0.100000
2019-03-22 12:35:59,704 2019-03-22 12:35:59: step 248/50000, loss = 0.170123 (1.945 sec/batch), lr: 0.100000
2019-03-22 12:36:01,794 2019-03-22 12:36:01: step 249/50000, loss = 0.193082 (2.086 sec/batch), lr: 0.100000
2019-03-22 12:36:03,723 2019-03-22 12:36:03: step 250/50000, loss = 0.169745 (1.925 sec/batch), lr: 0.100000
2019-03-22 12:36:05,937 2019-03-22 12:36:05: step 251/50000, loss = 0.192523 (2.210 sec/batch), lr: 0.100000
2019-03-22 12:36:07,802 2019-03-22 12:36:07: step 252/50000, loss = 0.169390 (1.861 sec/batch), lr: 0.100000
2019-03-22 12:36:09,785 2019-03-22 12:36:09: step 253/50000, loss = 0.192448 (1.980 sec/batch), lr: 0.100000
2019-03-22 12:36:11,813 2019-03-22 12:36:11: step 254/50000, loss = 0.169043 (2.024 sec/batch), lr: 0.100000
2019-03-22 12:36:13,745 2019-03-22 12:36:13: step 255/50000, loss = 0.191859 (1.928 sec/batch), lr: 0.100000
2019-03-22 12:36:15,749 2019-03-22 12:36:15: step 256/50000, loss = 0.168728 (1.998 sec/batch), lr: 0.100000
2019-03-22 12:36:17,672 2019-03-22 12:36:17: step 257/50000, loss = 0.191470 (1.919 sec/batch), lr: 0.100000
2019-03-22 12:36:19,670 2019-03-22 12:36:19: step 258/50000, loss = 0.168453 (1.995 sec/batch), lr: 0.100000
2019-03-22 12:36:21,612 2019-03-22 12:36:21: step 259/50000, loss = 0.191107 (1.938 sec/batch), lr: 0.100000
2019-03-22 12:36:23,676 2019-03-22 12:36:23: step 260/50000, loss = 0.168120 (2.061 sec/batch), lr: 0.100000
2019-03-22 12:36:25,606 2019-03-22 12:36:25: step 261/50000, loss = 0.191036 (1.926 sec/batch), lr: 0.100000
2019-03-22 12:36:27,559 2019-03-22 12:36:27: step 262/50000, loss = 0.167893 (1.949 sec/batch), lr: 0.100000
2019-03-22 12:36:29,525 2019-03-22 12:36:29: step 263/50000, loss = 0.190459 (1.962 sec/batch), lr: 0.100000
2019-03-22 12:36:31,481 2019-03-22 12:36:31: step 264/50000, loss = 0.167535 (1.953 sec/batch), lr: 0.100000
2019-03-22 12:36:33,425 2019-03-22 12:36:33: step 265/50000, loss = 0.190166 (1.940 sec/batch), lr: 0.100000
2019-03-22 12:36:35,395 2019-03-22 12:36:35: step 266/50000, loss = 0.167247 (1.966 sec/batch), lr: 0.100000
2019-03-22 12:36:37,334 2019-03-22 12:36:37: step 267/50000, loss = 0.190166 (1.936 sec/batch), lr: 0.100000
2019-03-22 12:36:39,284 2019-03-22 12:36:39: step 268/50000, loss = 0.166868 (1.947 sec/batch), lr: 0.100000
2019-03-22 12:36:41,316 2019-03-22 12:36:41: step 269/50000, loss = 0.189624 (2.028 sec/batch), lr: 0.100000
2019-03-22 12:36:43,272 2019-03-22 12:36:43: step 270/50000, loss = 0.166549 (1.953 sec/batch), lr: 0.100000
2019-03-22 12:36:45,405 2019-03-22 12:36:45: step 271/50000, loss = 0.189324 (2.129 sec/batch), lr: 0.100000
2019-03-22 12:36:47,593 2019-03-22 12:36:47: step 272/50000, loss = 0.166269 (2.184 sec/batch), lr: 0.100000
2019-03-22 12:36:49,880 2019-03-22 12:36:49: step 273/50000, loss = 0.189286 (2.284 sec/batch), lr: 0.100000
2019-03-22 12:36:52,150 2019-03-22 12:36:52: step 274/50000, loss = 0.166010 (2.266 sec/batch), lr: 0.100000
2019-03-22 12:36:54,168 2019-03-22 12:36:54: step 275/50000, loss = 0.188690 (2.013 sec/batch), lr: 0.100000
2019-03-22 12:36:56,150 2019-03-22 12:36:56: step 276/50000, loss = 0.165722 (1.978 sec/batch), lr: 0.100000
2019-03-22 12:36:58,172 2019-03-22 12:36:58: step 277/50000, loss = 0.188624 (2.019 sec/batch), lr: 0.100000
2019-03-22 12:37:00,105 2019-03-22 12:37:00: step 278/50000, loss = 0.165472 (1.929 sec/batch), lr: 0.100000
2019-03-22 12:37:02,060 2019-03-22 12:37:02: step 279/50000, loss = 0.188019 (1.951 sec/batch), lr: 0.100000
2019-03-22 12:37:04,313 2019-03-22 12:37:04: step 280/50000, loss = 0.165232 (2.249 sec/batch), lr: 0.100000
2019-03-22 12:37:06,505 2019-03-22 12:37:06: step 281/50000, loss = 0.187785 (2.188 sec/batch), lr: 0.100000
2019-03-22 12:37:08,681 2019-03-22 12:37:08: step 282/50000, loss = 0.164834 (2.173 sec/batch), lr: 0.100000
2019-03-22 12:37:10,925 2019-03-22 12:37:10: step 283/50000, loss = 0.187806 (2.240 sec/batch), lr: 0.100000
2019-03-22 12:37:13,095 2019-03-22 12:37:13: step 284/50000, loss = 0.164512 (2.165 sec/batch), lr: 0.100000
2019-03-22 12:37:15,404 2019-03-22 12:37:15: step 285/50000, loss = 0.187262 (2.306 sec/batch), lr: 0.100000
2019-03-22 12:37:17,672 2019-03-22 12:37:17: step 286/50000, loss = 0.164168 (2.264 sec/batch), lr: 0.100000
2019-03-22 12:37:19,874 2019-03-22 12:37:19: step 287/50000, loss = 0.187206 (2.199 sec/batch), lr: 0.100000
2019-03-22 12:37:22,140 2019-03-22 12:37:22: step 288/50000, loss = 0.163937 (2.262 sec/batch), lr: 0.100000
2019-03-22 12:37:24,324 2019-03-22 12:37:24: step 289/50000, loss = 0.186606 (2.180 sec/batch), lr: 0.100000
2019-03-22 12:37:26,582 2019-03-22 12:37:26: step 290/50000, loss = 0.163633 (2.254 sec/batch), lr: 0.100000
2019-03-22 12:37:28,777 2019-03-22 12:37:28: step 291/50000, loss = 0.186363 (2.192 sec/batch), lr: 0.100000
2019-03-22 12:37:31,121 2019-03-22 12:37:31: step 292/50000, loss = 0.163352 (2.340 sec/batch), lr: 0.100000
2019-03-22 12:37:33,364 2019-03-22 12:37:33: step 293/50000, loss = 0.186039 (2.240 sec/batch), lr: 0.100000
2019-03-22 12:37:35,634 2019-03-22 12:37:35: step 294/50000, loss = 0.163059 (2.265 sec/batch), lr: 0.100000
2019-03-22 12:37:37,903 2019-03-22 12:37:37: step 295/50000, loss = 0.185978 (2.266 sec/batch), lr: 0.100000
2019-03-22 12:37:40,061 2019-03-22 12:37:40: step 296/50000, loss = 0.162866 (2.154 sec/batch), lr: 0.100000
2019-03-22 12:37:42,269 2019-03-22 12:37:42: step 297/50000, loss = 0.185318 (2.203 sec/batch), lr: 0.100000
2019-03-22 12:37:44,506 2019-03-22 12:37:44: step 298/50000, loss = 0.162659 (2.233 sec/batch), lr: 0.100000
2019-03-22 12:37:46,782 2019-03-22 12:37:46: step 299/50000, loss = 0.185208 (2.271 sec/batch), lr: 0.100000
2019-03-22 12:37:49,077 2019-03-22 12:37:49: step 300/50000, loss = 0.162460 (2.292 sec/batch), lr: 0.100000
2019-03-22 12:37:50,207 step 300: Full loss = 0.369151, Edge acc. = 0.3571
2019-03-22 12:37:52,341 2019-03-22 12:37:52: step 301/50000, loss = 0.184576 (2.127 sec/batch), lr: 0.050000
2019-03-22 12:37:54,592 2019-03-22 12:37:54: step 302/50000, loss = 0.159554 (2.247 sec/batch), lr: 0.050000
2019-03-22 12:37:56,838 2019-03-22 12:37:56: step 303/50000, loss = 0.161479 (2.242 sec/batch), lr: 0.050000
2019-03-22 12:37:59,010 2019-03-22 12:37:59: step 304/50000, loss = 0.159618 (2.168 sec/batch), lr: 0.050000
2019-03-22 12:38:01,101 2019-03-22 12:38:01: step 305/50000, loss = 0.160649 (2.088 sec/batch), lr: 0.050000
2019-03-22 12:38:03,069 2019-03-22 12:38:03: step 306/50000, loss = 0.159657 (1.964 sec/batch), lr: 0.050000
2019-03-22 12:38:05,082 2019-03-22 12:38:05: step 307/50000, loss = 0.159980 (2.009 sec/batch), lr: 0.050000
2019-03-22 12:38:07,110 2019-03-22 12:38:07: step 308/50000, loss = 0.159679 (2.024 sec/batch), lr: 0.050000
2019-03-22 12:38:09,120 2019-03-22 12:38:09: step 309/50000, loss = 0.159368 (2.007 sec/batch), lr: 0.050000
2019-03-22 12:38:11,127 2019-03-22 12:38:11: step 310/50000, loss = 0.159666 (2.003 sec/batch), lr: 0.050000
2019-03-22 12:38:13,173 2019-03-22 12:38:13: step 311/50000, loss = 0.158800 (2.042 sec/batch), lr: 0.050000
2019-03-22 12:38:15,186 2019-03-22 12:38:15: step 312/50000, loss = 0.159639 (2.009 sec/batch), lr: 0.050000
2019-03-22 12:38:17,202 2019-03-22 12:38:17: step 313/50000, loss = 0.158236 (2.012 sec/batch), lr: 0.050000
2019-03-22 12:38:19,125 2019-03-22 12:38:19: step 314/50000, loss = 0.159606 (1.919 sec/batch), lr: 0.050000
2019-03-22 12:38:21,273 2019-03-22 12:38:21: step 315/50000, loss = 0.157728 (2.144 sec/batch), lr: 0.050000
2019-03-22 12:38:23,179 2019-03-22 12:38:23: step 316/50000, loss = 0.159499 (1.902 sec/batch), lr: 0.050000
2019-03-22 12:38:25,150 2019-03-22 12:38:25: step 317/50000, loss = 0.157302 (1.967 sec/batch), lr: 0.050000
2019-03-22 12:38:27,054 2019-03-22 12:38:27: step 318/50000, loss = 0.159399 (1.900 sec/batch), lr: 0.050000
2019-03-22 12:38:28,988 2019-03-22 12:38:28: step 319/50000, loss = 0.156863 (1.930 sec/batch), lr: 0.050000
2019-03-22 12:38:30,986 2019-03-22 12:38:30: step 320/50000, loss = 0.159284 (1.994 sec/batch), lr: 0.050000
2019-03-22 12:38:32,990 2019-03-22 12:38:32: step 321/50000, loss = 0.156485 (2.001 sec/batch), lr: 0.050000
2019-03-22 12:38:34,961 2019-03-22 12:38:34: step 322/50000, loss = 0.159172 (1.967 sec/batch), lr: 0.050000
2019-03-22 12:38:36,974 2019-03-22 12:38:36: step 323/50000, loss = 0.156071 (2.009 sec/batch), lr: 0.050000
2019-03-22 12:38:38,889 2019-03-22 12:38:38: step 324/50000, loss = 0.159011 (1.912 sec/batch), lr: 0.050000
2019-03-22 12:38:40,997 2019-03-22 12:38:40: step 325/50000, loss = 0.155724 (2.105 sec/batch), lr: 0.050000
2019-03-22 12:38:42,919 2019-03-22 12:38:42: step 326/50000, loss = 0.158838 (1.918 sec/batch), lr: 0.050000
2019-03-22 12:38:44,874 2019-03-22 12:38:44: step 327/50000, loss = 0.155404 (1.951 sec/batch), lr: 0.050000
2019-03-22 12:38:47,069 2019-03-22 12:38:47: step 328/50000, loss = 0.158660 (2.191 sec/batch), lr: 0.050000
2019-03-22 12:38:49,283 2019-03-22 12:38:49: step 329/50000, loss = 0.155096 (2.210 sec/batch), lr: 0.050000
2019-03-22 12:38:51,460 2019-03-22 12:38:51: step 330/50000, loss = 0.158457 (2.173 sec/batch), lr: 0.050000
2019-03-22 12:38:53,781 2019-03-22 12:38:53: step 331/50000, loss = 0.154797 (2.317 sec/batch), lr: 0.050000
2019-03-22 12:38:55,917 2019-03-22 12:38:55: step 332/50000, loss = 0.158286 (2.132 sec/batch), lr: 0.050000
2019-03-22 12:38:58,217 2019-03-22 12:38:58: step 333/50000, loss = 0.154496 (2.297 sec/batch), lr: 0.050000
2019-03-22 12:39:00,406 2019-03-22 12:39:00: step 334/50000, loss = 0.158083 (2.186 sec/batch), lr: 0.050000
2019-03-22 12:39:02,579 2019-03-22 12:39:02: step 335/50000, loss = 0.154201 (2.169 sec/batch), lr: 0.050000
2019-03-22 12:39:04,871 2019-03-22 12:39:04: step 336/50000, loss = 0.157901 (2.289 sec/batch), lr: 0.050000
2019-03-22 12:39:07,119 2019-03-22 12:39:07: step 337/50000, loss = 0.153941 (2.244 sec/batch), lr: 0.050000
2019-03-22 12:39:09,308 2019-03-22 12:39:09: step 338/50000, loss = 0.157673 (2.185 sec/batch), lr: 0.050000
2019-03-22 12:39:11,555 2019-03-22 12:39:11: step 339/50000, loss = 0.153661 (2.243 sec/batch), lr: 0.050000
2019-03-22 12:39:13,752 2019-03-22 12:39:13: step 340/50000, loss = 0.157486 (2.194 sec/batch), lr: 0.050000
2019-03-22 12:39:15,942 2019-03-22 12:39:15: step 341/50000, loss = 0.153412 (2.186 sec/batch), lr: 0.050000
2019-03-22 12:39:18,169 2019-03-22 12:39:18: step 342/50000, loss = 0.157287 (2.224 sec/batch), lr: 0.050000
2019-03-22 12:39:20,361 2019-03-22 12:39:20: step 343/50000, loss = 0.153166 (2.188 sec/batch), lr: 0.050000
2019-03-22 12:39:22,313 2019-03-22 12:39:22: step 344/50000, loss = 0.157107 (1.948 sec/batch), lr: 0.050000
2019-03-22 12:39:24,249 2019-03-22 12:39:24: step 345/50000, loss = 0.152913 (1.932 sec/batch), lr: 0.050000
2019-03-22 12:39:26,247 2019-03-22 12:39:26: step 346/50000, loss = 0.156924 (1.994 sec/batch), lr: 0.050000
2019-03-22 12:39:28,250 2019-03-22 12:39:28: step 347/50000, loss = 0.152647 (1.999 sec/batch), lr: 0.050000
2019-03-22 12:39:30,225 2019-03-22 12:39:30: step 348/50000, loss = 0.156751 (1.971 sec/batch), lr: 0.050000
2019-03-22 12:39:32,165 2019-03-22 12:39:32: step 349/50000, loss = 0.152402 (1.936 sec/batch), lr: 0.050000
2019-03-22 12:39:34,141 2019-03-22 12:39:34: step 350/50000, loss = 0.156605 (1.973 sec/batch), lr: 0.050000
2019-03-22 12:39:36,420 2019-03-22 12:39:36: step 351/50000, loss = 0.152133 (2.274 sec/batch), lr: 0.050000
2019-03-22 12:39:38,619 2019-03-22 12:39:38: step 352/50000, loss = 0.156405 (2.196 sec/batch), lr: 0.050000
2019-03-22 12:39:40,765 2019-03-22 12:39:40: step 353/50000, loss = 0.151899 (2.143 sec/batch), lr: 0.050000
2019-03-22 12:39:42,721 2019-03-22 12:39:42: step 354/50000, loss = 0.156237 (1.952 sec/batch), lr: 0.050000
2019-03-22 12:39:44,660 2019-03-22 12:39:44: step 355/50000, loss = 0.151627 (1.935 sec/batch), lr: 0.050000
2019-03-22 12:39:46,708 2019-03-22 12:39:46: step 356/50000, loss = 0.156098 (2.043 sec/batch), lr: 0.050000
2019-03-22 12:39:48,762 2019-03-22 12:39:48: step 357/50000, loss = 0.151368 (2.050 sec/batch), lr: 0.050000
2019-03-22 12:39:50,770 2019-03-22 12:39:50: step 358/50000, loss = 0.155911 (2.004 sec/batch), lr: 0.050000
2019-03-22 12:39:52,770 2019-03-22 12:39:52: step 359/50000, loss = 0.151137 (1.996 sec/batch), lr: 0.050000
2019-03-22 12:39:54,745 2019-03-22 12:39:54: step 360/50000, loss = 0.155722 (1.972 sec/batch), lr: 0.050000
2019-03-22 12:39:56,743 2019-03-22 12:39:56: step 361/50000, loss = 0.150905 (1.995 sec/batch), lr: 0.050000
2019-03-22 12:39:58,745 2019-03-22 12:39:58: step 362/50000, loss = 0.155533 (1.998 sec/batch), lr: 0.050000
2019-03-22 12:40:00,713 2019-03-22 12:40:00: step 363/50000, loss = 0.150661 (1.965 sec/batch), lr: 0.050000
2019-03-22 12:40:02,626 2019-03-22 12:40:02: step 364/50000, loss = 0.155347 (1.908 sec/batch), lr: 0.050000
2019-03-22 12:40:04,632 2019-03-22 12:40:04: step 365/50000, loss = 0.150435 (2.003 sec/batch), lr: 0.050000
2019-03-22 12:40:06,603 2019-03-22 12:40:06: step 366/50000, loss = 0.155141 (1.967 sec/batch), lr: 0.050000
2019-03-22 12:40:08,718 2019-03-22 12:40:08: step 367/50000, loss = 0.150192 (2.111 sec/batch), lr: 0.050000
2019-03-22 12:40:10,705 2019-03-22 12:40:10: step 368/50000, loss = 0.154961 (1.984 sec/batch), lr: 0.050000
2019-03-22 12:40:12,668 2019-03-22 12:40:12: step 369/50000, loss = 0.149985 (1.959 sec/batch), lr: 0.050000
2019-03-22 12:40:14,682 2019-03-22 12:40:14: step 370/50000, loss = 0.154739 (2.010 sec/batch), lr: 0.050000
2019-03-22 12:40:16,784 2019-03-22 12:40:16: step 371/50000, loss = 0.149766 (2.098 sec/batch), lr: 0.050000
2019-03-22 12:40:18,724 2019-03-22 12:40:18: step 372/50000, loss = 0.154547 (1.937 sec/batch), lr: 0.050000
2019-03-22 12:40:20,696 2019-03-22 12:40:20: step 373/50000, loss = 0.149570 (1.968 sec/batch), lr: 0.050000
2019-03-22 12:40:22,785 2019-03-22 12:40:22: step 374/50000, loss = 0.154329 (2.085 sec/batch), lr: 0.050000
2019-03-22 12:40:24,732 2019-03-22 12:40:24: step 375/50000, loss = 0.149319 (1.943 sec/batch), lr: 0.050000
2019-03-22 12:40:26,731 2019-03-22 12:40:26: step 376/50000, loss = 0.154131 (1.995 sec/batch), lr: 0.050000
2019-03-22 12:40:28,735 2019-03-22 12:40:28: step 377/50000, loss = 0.149151 (2.000 sec/batch), lr: 0.050000
2019-03-22 12:40:30,697 2019-03-22 12:40:30: step 378/50000, loss = 0.153957 (1.957 sec/batch), lr: 0.050000
2019-03-22 12:40:32,676 2019-03-22 12:40:32: step 379/50000, loss = 0.148904 (1.976 sec/batch), lr: 0.050000
2019-03-22 12:40:34,725 2019-03-22 12:40:34: step 380/50000, loss = 0.153762 (2.045 sec/batch), lr: 0.050000
2019-03-22 12:40:36,696 2019-03-22 12:40:36: step 381/50000, loss = 0.148702 (1.966 sec/batch), lr: 0.050000
2019-03-22 12:40:38,679 2019-03-22 12:40:38: step 382/50000, loss = 0.153538 (1.980 sec/batch), lr: 0.050000
2019-03-22 12:40:40,651 2019-03-22 12:40:40: step 383/50000, loss = 0.148497 (1.968 sec/batch), lr: 0.050000
2019-03-22 12:40:42,789 2019-03-22 12:40:42: step 384/50000, loss = 0.153339 (2.133 sec/batch), lr: 0.050000
2019-03-22 12:40:44,661 2019-03-22 12:40:44: step 385/50000, loss = 0.148264 (1.868 sec/batch), lr: 0.050000
2019-03-22 12:40:46,657 2019-03-22 12:40:46: step 386/50000, loss = 0.153189 (1.992 sec/batch), lr: 0.050000
2019-03-22 12:40:48,649 2019-03-22 12:40:48: step 387/50000, loss = 0.148053 (1.988 sec/batch), lr: 0.050000
2019-03-22 12:40:50,609 2019-03-22 12:40:50: step 388/50000, loss = 0.153009 (1.956 sec/batch), lr: 0.050000
2019-03-22 12:40:52,556 2019-03-22 12:40:52: step 389/50000, loss = 0.147838 (1.944 sec/batch), lr: 0.050000
2019-03-22 12:40:54,517 2019-03-22 12:40:54: step 390/50000, loss = 0.152825 (1.956 sec/batch), lr: 0.050000
2019-03-22 12:40:56,525 2019-03-22 12:40:56: step 391/50000, loss = 0.147648 (2.005 sec/batch), lr: 0.050000
2019-03-22 12:40:58,473 2019-03-22 12:40:58: step 392/50000, loss = 0.152641 (1.944 sec/batch), lr: 0.050000
2019-03-22 12:41:00,533 2019-03-22 12:41:00: step 393/50000, loss = 0.147452 (2.056 sec/batch), lr: 0.050000
2019-03-22 12:41:02,562 2019-03-22 12:41:02: step 394/50000, loss = 0.152452 (2.025 sec/batch), lr: 0.050000
2019-03-22 12:41:04,538 2019-03-22 12:41:04: step 395/50000, loss = 0.147278 (1.972 sec/batch), lr: 0.050000
2019-03-22 12:41:06,562 2019-03-22 12:41:06: step 396/50000, loss = 0.152238 (2.020 sec/batch), lr: 0.050000
2019-03-22 12:41:08,589 2019-03-22 12:41:08: step 397/50000, loss = 0.147098 (2.023 sec/batch), lr: 0.050000
2019-03-22 12:41:10,656 2019-03-22 12:41:10: step 398/50000, loss = 0.152054 (2.063 sec/batch), lr: 0.050000
2019-03-22 12:41:12,577 2019-03-22 12:41:12: step 399/50000, loss = 0.146947 (1.917 sec/batch), lr: 0.050000
2019-03-22 12:41:14,657 2019-03-22 12:41:14: step 400/50000, loss = 0.151843 (2.077 sec/batch), lr: 0.050000
2019-03-22 12:41:15,559 step 400: Full loss = 0.293552, Edge acc. = 0.3571
2019-03-22 12:41:17,451 2019-03-22 12:41:17: step 401/50000, loss = 0.146776 (1.886 sec/batch), lr: 0.050000
2019-03-22 12:41:19,450 2019-03-22 12:41:19: step 402/50000, loss = 0.151664 (1.995 sec/batch), lr: 0.050000
2019-03-22 12:41:21,497 2019-03-22 12:41:21: step 403/50000, loss = 0.146583 (2.043 sec/batch), lr: 0.050000
2019-03-22 12:41:23,438 2019-03-22 12:41:23: step 404/50000, loss = 0.151488 (1.937 sec/batch), lr: 0.050000
2019-03-22 12:41:25,388 2019-03-22 12:41:25: step 405/50000, loss = 0.146403 (1.946 sec/batch), lr: 0.050000
2019-03-22 12:41:27,334 2019-03-22 12:41:27: step 406/50000, loss = 0.151297 (1.943 sec/batch), lr: 0.050000
2019-03-22 12:41:29,481 2019-03-22 12:41:29: step 407/50000, loss = 0.146217 (2.143 sec/batch), lr: 0.050000
2019-03-22 12:41:31,405 2019-03-22 12:41:31: step 408/50000, loss = 0.151143 (1.920 sec/batch), lr: 0.050000
2019-03-22 12:41:33,358 2019-03-22 12:41:33: step 409/50000, loss = 0.146044 (1.950 sec/batch), lr: 0.050000
2019-03-22 12:41:35,416 2019-03-22 12:41:35: step 410/50000, loss = 0.150960 (2.054 sec/batch), lr: 0.050000
2019-03-22 12:41:37,357 2019-03-22 12:41:37: step 411/50000, loss = 0.145864 (1.936 sec/batch), lr: 0.050000
2019-03-22 12:41:39,397 2019-03-22 12:41:39: step 412/50000, loss = 0.150793 (2.037 sec/batch), lr: 0.050000
2019-03-22 12:41:41,436 2019-03-22 12:41:41: step 413/50000, loss = 0.145685 (2.035 sec/batch), lr: 0.050000
2019-03-22 12:41:43,377 2019-03-22 12:41:43: step 414/50000, loss = 0.150599 (1.938 sec/batch), lr: 0.050000
2019-03-22 12:41:45,305 2019-03-22 12:41:45: step 415/50000, loss = 0.145517 (1.924 sec/batch), lr: 0.050000
2019-03-22 12:41:47,335 2019-03-22 12:41:47: step 416/50000, loss = 0.150428 (2.026 sec/batch), lr: 0.050000
2019-03-22 12:41:49,393 2019-03-22 12:41:49: step 417/50000, loss = 0.145332 (2.055 sec/batch), lr: 0.050000
2019-03-22 12:41:51,423 2019-03-22 12:41:51: step 418/50000, loss = 0.150250 (2.026 sec/batch), lr: 0.050000
2019-03-22 12:41:53,369 2019-03-22 12:41:53: step 419/50000, loss = 0.145167 (1.942 sec/batch), lr: 0.050000
2019-03-22 12:41:55,299 2019-03-22 12:41:55: step 420/50000, loss = 0.150062 (1.926 sec/batch), lr: 0.050000
2019-03-22 12:41:57,272 2019-03-22 12:41:57: step 421/50000, loss = 0.144986 (1.969 sec/batch), lr: 0.050000
2019-03-22 12:41:59,328 2019-03-22 12:41:59: step 422/50000, loss = 0.149899 (2.052 sec/batch), lr: 0.050000
2019-03-22 12:42:01,285 2019-03-22 12:42:01: step 423/50000, loss = 0.144803 (1.953 sec/batch), lr: 0.050000
2019-03-22 12:42:03,267 2019-03-22 12:42:03: step 424/50000, loss = 0.149741 (1.978 sec/batch), lr: 0.050000
2019-03-22 12:42:05,190 2019-03-22 12:42:05: step 425/50000, loss = 0.144626 (1.919 sec/batch), lr: 0.050000
2019-03-22 12:42:07,220 2019-03-22 12:42:07: step 426/50000, loss = 0.149586 (2.026 sec/batch), lr: 0.050000
2019-03-22 12:42:09,196 2019-03-22 12:42:09: step 427/50000, loss = 0.144448 (1.972 sec/batch), lr: 0.050000
2019-03-22 12:42:11,141 2019-03-22 12:42:11: step 428/50000, loss = 0.149383 (1.941 sec/batch), lr: 0.050000
2019-03-22 12:42:13,151 2019-03-22 12:42:13: step 429/50000, loss = 0.144323 (2.006 sec/batch), lr: 0.050000
2019-03-22 12:42:15,098 2019-03-22 12:42:15: step 430/50000, loss = 0.149210 (1.944 sec/batch), lr: 0.050000
2019-03-22 12:42:17,034 2019-03-22 12:42:17: step 431/50000, loss = 0.144117 (1.931 sec/batch), lr: 0.050000
2019-03-22 12:42:18,957 2019-03-22 12:42:18: step 432/50000, loss = 0.149073 (1.920 sec/batch), lr: 0.050000
2019-03-22 12:42:20,973 2019-03-22 12:42:20: step 433/50000, loss = 0.143985 (2.012 sec/batch), lr: 0.050000
2019-03-22 12:42:22,860 2019-03-22 12:42:22: step 434/50000, loss = 0.148861 (1.884 sec/batch), lr: 0.050000
2019-03-22 12:42:24,942 2019-03-22 12:42:24: step 435/50000, loss = 0.143791 (2.079 sec/batch), lr: 0.050000
2019-03-22 12:42:26,900 2019-03-22 12:42:26: step 436/50000, loss = 0.148722 (1.954 sec/batch), lr: 0.050000
2019-03-22 12:42:28,884 2019-03-22 12:42:28: step 437/50000, loss = 0.143643 (1.980 sec/batch), lr: 0.050000
2019-03-22 12:42:30,906 2019-03-22 12:42:30: step 438/50000, loss = 0.148532 (2.018 sec/batch), lr: 0.050000
2019-03-22 12:42:32,920 2019-03-22 12:42:32: step 439/50000, loss = 0.143433 (2.010 sec/batch), lr: 0.050000
2019-03-22 12:42:34,846 2019-03-22 12:42:34: step 440/50000, loss = 0.148378 (1.922 sec/batch), lr: 0.050000
2019-03-22 12:42:36,830 2019-03-22 12:42:36: step 441/50000, loss = 0.143290 (1.980 sec/batch), lr: 0.050000
2019-03-22 12:42:38,803 2019-03-22 12:42:38: step 442/50000, loss = 0.148224 (1.970 sec/batch), lr: 0.050000
2019-03-22 12:42:40,805 2019-03-22 12:42:40: step 443/50000, loss = 0.143100 (1.998 sec/batch), lr: 0.050000
2019-03-22 12:42:42,821 2019-03-22 12:42:42: step 444/50000, loss = 0.148065 (2.012 sec/batch), lr: 0.050000
2019-03-22 12:42:44,741 2019-03-22 12:42:44: step 445/50000, loss = 0.142927 (1.917 sec/batch), lr: 0.050000
2019-03-22 12:42:46,749 2019-03-22 12:42:46: step 446/50000, loss = 0.147914 (2.003 sec/batch), lr: 0.050000
2019-03-22 12:42:48,740 2019-03-22 12:42:48: step 447/50000, loss = 0.142718 (1.987 sec/batch), lr: 0.050000
2019-03-22 12:42:50,695 2019-03-22 12:42:50: step 448/50000, loss = 0.147785 (1.952 sec/batch), lr: 0.050000
2019-03-22 12:42:52,718 2019-03-22 12:42:52: step 449/50000, loss = 0.142533 (2.018 sec/batch), lr: 0.050000
2019-03-22 12:42:54,686 2019-03-22 12:42:54: step 450/50000, loss = 0.147644 (1.964 sec/batch), lr: 0.050000
2019-03-22 12:42:56,721 2019-03-22 12:42:56: step 451/50000, loss = 0.142342 (2.031 sec/batch), lr: 0.050000
2019-03-22 12:42:58,700 2019-03-22 12:42:58: step 452/50000, loss = 0.147505 (1.975 sec/batch), lr: 0.050000
2019-03-22 12:43:00,725 2019-03-22 12:43:00: step 453/50000, loss = 0.142157 (2.022 sec/batch), lr: 0.050000
2019-03-22 12:43:02,688 2019-03-22 12:43:02: step 454/50000, loss = 0.147328 (1.959 sec/batch), lr: 0.050000
2019-03-22 12:43:04,605 2019-03-22 12:43:04: step 455/50000, loss = 0.142005 (1.913 sec/batch), lr: 0.050000
2019-03-22 12:43:06,708 2019-03-22 12:43:06: step 456/50000, loss = 0.147183 (2.100 sec/batch), lr: 0.050000
2019-03-22 12:43:08,706 2019-03-22 12:43:08: step 457/50000, loss = 0.141812 (1.993 sec/batch), lr: 0.050000
2019-03-22 12:43:10,628 2019-03-22 12:43:10: step 458/50000, loss = 0.147040 (1.919 sec/batch), lr: 0.050000
2019-03-22 12:43:12,735 2019-03-22 12:43:12: step 459/50000, loss = 0.141649 (2.104 sec/batch), lr: 0.050000
2019-03-22 12:43:14,644 2019-03-22 12:43:14: step 460/50000, loss = 0.146873 (1.906 sec/batch), lr: 0.050000
2019-03-22 12:43:16,597 2019-03-22 12:43:16: step 461/50000, loss = 0.141444 (1.949 sec/batch), lr: 0.050000
2019-03-22 12:43:18,718 2019-03-22 12:43:18: step 462/50000, loss = 0.146745 (2.118 sec/batch), lr: 0.050000
2019-03-22 12:43:20,719 2019-03-22 12:43:20: step 463/50000, loss = 0.141296 (1.996 sec/batch), lr: 0.050000
2019-03-22 12:43:22,748 2019-03-22 12:43:22: step 464/50000, loss = 0.146567 (2.026 sec/batch), lr: 0.050000
2019-03-22 12:43:24,723 2019-03-22 12:43:24: step 465/50000, loss = 0.141169 (1.972 sec/batch), lr: 0.050000
2019-03-22 12:43:26,727 2019-03-22 12:43:26: step 466/50000, loss = 0.146377 (2.000 sec/batch), lr: 0.050000
2019-03-22 12:43:28,806 2019-03-22 12:43:28: step 467/50000, loss = 0.140998 (2.075 sec/batch), lr: 0.050000
2019-03-22 12:43:30,779 2019-03-22 12:43:30: step 468/50000, loss = 0.146227 (1.969 sec/batch), lr: 0.050000
2019-03-22 12:43:32,768 2019-03-22 12:43:32: step 469/50000, loss = 0.140846 (1.985 sec/batch), lr: 0.050000
2019-03-22 12:43:34,721 2019-03-22 12:43:34: step 470/50000, loss = 0.146042 (1.950 sec/batch), lr: 0.050000
2019-03-22 12:43:36,688 2019-03-22 12:43:36: step 471/50000, loss = 0.140729 (1.963 sec/batch), lr: 0.050000
2019-03-22 12:43:38,649 2019-03-22 12:43:38: step 472/50000, loss = 0.145860 (1.957 sec/batch), lr: 0.050000
2019-03-22 12:43:40,602 2019-03-22 12:43:40: step 473/50000, loss = 0.140552 (1.949 sec/batch), lr: 0.050000
2019-03-22 12:43:42,626 2019-03-22 12:43:42: step 474/50000, loss = 0.145698 (2.020 sec/batch), lr: 0.050000
2019-03-22 12:43:44,608 2019-03-22 12:43:44: step 475/50000, loss = 0.140401 (1.979 sec/batch), lr: 0.050000
2019-03-22 12:43:46,761 2019-03-22 12:43:46: step 476/50000, loss = 0.145527 (2.149 sec/batch), lr: 0.050000
2019-03-22 12:43:49,041 2019-03-22 12:43:49: step 477/50000, loss = 0.140266 (2.276 sec/batch), lr: 0.050000
2019-03-22 12:43:50,957 2019-03-22 12:43:50: step 478/50000, loss = 0.145366 (1.912 sec/batch), lr: 0.050000
2019-03-22 12:43:53,260 2019-03-22 12:43:53: step 479/50000, loss = 0.140106 (2.299 sec/batch), lr: 0.050000
2019-03-22 12:43:55,409 2019-03-22 12:43:55: step 480/50000, loss = 0.145189 (2.145 sec/batch), lr: 0.050000
2019-03-22 12:43:57,572 2019-03-22 12:43:57: step 481/50000, loss = 0.139969 (2.159 sec/batch), lr: 0.050000
2019-03-22 12:43:59,677 2019-03-22 12:43:59: step 482/50000, loss = 0.145043 (2.102 sec/batch), lr: 0.050000
2019-03-22 12:44:01,657 2019-03-22 12:44:01: step 483/50000, loss = 0.139807 (1.976 sec/batch), lr: 0.050000
2019-03-22 12:44:03,587 2019-03-22 12:44:03: step 484/50000, loss = 0.144883 (1.926 sec/batch), lr: 0.050000
2019-03-22 12:44:05,861 2019-03-22 12:44:05: step 485/50000, loss = 0.139694 (2.270 sec/batch), lr: 0.050000
2019-03-22 12:44:08,126 2019-03-22 12:44:08: step 486/50000, loss = 0.144721 (2.261 sec/batch), lr: 0.050000
2019-03-22 12:44:10,383 2019-03-22 12:44:10: step 487/50000, loss = 0.139515 (2.253 sec/batch), lr: 0.050000
2019-03-22 12:44:12,630 2019-03-22 12:44:12: step 488/50000, loss = 0.144588 (2.244 sec/batch), lr: 0.050000
2019-03-22 12:44:14,873 2019-03-22 12:44:14: step 489/50000, loss = 0.139363 (2.239 sec/batch), lr: 0.050000
2019-03-22 12:44:17,096 2019-03-22 12:44:17: step 490/50000, loss = 0.144421 (2.219 sec/batch), lr: 0.050000
2019-03-22 12:44:19,456 2019-03-22 12:44:19: step 491/50000, loss = 0.139221 (2.356 sec/batch), lr: 0.050000
2019-03-22 12:44:21,740 2019-03-22 12:44:21: step 492/50000, loss = 0.144269 (2.281 sec/batch), lr: 0.050000
2019-03-22 12:44:24,010 2019-03-22 12:44:24: step 493/50000, loss = 0.139049 (2.266 sec/batch), lr: 0.050000
2019-03-22 12:44:25,979 2019-03-22 12:44:25: step 494/50000, loss = 0.144128 (1.964 sec/batch), lr: 0.050000
2019-03-22 12:44:27,995 2019-03-22 12:44:27: step 495/50000, loss = 0.138908 (2.013 sec/batch), lr: 0.050000
2019-03-22 12:44:29,965 2019-03-22 12:44:29: step 496/50000, loss = 0.143959 (1.966 sec/batch), lr: 0.050000
2019-03-22 12:44:31,883 2019-03-22 12:44:31: step 497/50000, loss = 0.138758 (1.915 sec/batch), lr: 0.050000
2019-03-22 12:44:33,928 2019-03-22 12:44:33: step 498/50000, loss = 0.143816 (2.041 sec/batch), lr: 0.050000
2019-03-22 12:44:35,921 2019-03-22 12:44:35: step 499/50000, loss = 0.138602 (1.989 sec/batch), lr: 0.050000
2019-03-22 12:44:37,992 2019-03-22 12:44:37: step 500/50000, loss = 0.143690 (2.067 sec/batch), lr: 0.050000
2019-03-22 12:44:39,146 step 500: Full loss = 0.276875, Edge acc. = 0.3571
2019-03-22 12:44:41,156 2019-03-22 12:44:41: step 501/50000, loss = 0.138437 (2.004 sec/batch), lr: 0.050000
2019-03-22 12:44:43,095 2019-03-22 12:44:43: step 502/50000, loss = 0.143548 (1.935 sec/batch), lr: 0.050000
2019-03-22 12:45:44,892 2019-03-22 12:45:44: step 1/50000, loss = 0.477961 (1.860 sec/batch), lr: 1.000000
2019-03-22 12:45:46,915 2019-03-22 12:45:46: step 2/50000, loss = 0.485306 (2.019 sec/batch), lr: 1.000000
2019-03-22 12:45:48,924 2019-03-22 12:45:48: step 3/50000, loss = 0.482536 (2.004 sec/batch), lr: 1.000000
2019-03-22 12:45:50,965 2019-03-22 12:45:50: step 4/50000, loss = 0.479265 (2.035 sec/batch), lr: 1.000000
2019-03-22 12:45:53,015 2019-03-22 12:45:53: step 5/50000, loss = 0.474763 (2.046 sec/batch), lr: 1.000000
2019-03-22 12:45:54,995 2019-03-22 12:45:54: step 6/50000, loss = 0.469349 (1.979 sec/batch), lr: 1.000000
2019-03-22 12:45:57,004 2019-03-22 12:45:57: step 7/50000, loss = 0.462302 (2.006 sec/batch), lr: 1.000000
2019-03-22 12:45:59,096 2019-03-22 12:45:59: step 8/50000, loss = 0.449353 (2.088 sec/batch), lr: 1.000000
2019-03-22 12:46:01,116 2019-03-22 12:46:01: step 9/50000, loss = 0.419134 (2.016 sec/batch), lr: 1.000000
2019-03-22 12:46:03,107 2019-03-22 12:46:03: step 10/50000, loss = 0.317714 (1.987 sec/batch), lr: 1.000000
2019-03-22 12:46:04,066 step 10: Full loss = 0.522863, Edge acc. = 0.1786
2019-03-22 12:46:05,997 2019-03-22 12:46:05: step 11/50000, loss = 0.261432 (1.925 sec/batch), lr: 1.000000
2019-03-22 12:46:07,947 2019-03-22 12:46:07: step 12/50000, loss = 0.410087 (1.946 sec/batch), lr: 1.000000
2019-03-22 12:46:09,942 2019-03-22 12:46:09: step 13/50000, loss = 0.221696 (1.991 sec/batch), lr: 1.000000
2019-03-22 12:46:11,938 2019-03-22 12:46:11: step 14/50000, loss = 0.383713 (1.993 sec/batch), lr: 1.000000
2019-03-22 12:46:13,998 2019-03-22 12:46:13: step 15/50000, loss = 0.357103 (2.056 sec/batch), lr: 1.000000
2019-03-22 12:46:16,004 2019-03-22 12:46:16: step 16/50000, loss = 0.416568 (2.001 sec/batch), lr: 1.000000
2019-03-22 12:46:18,016 2019-03-22 12:46:18: step 17/50000, loss = 0.197211 (2.009 sec/batch), lr: 1.000000
2019-03-22 12:46:20,050 2019-03-22 12:46:20: step 18/50000, loss = 0.280224 (2.030 sec/batch), lr: 1.000000
2019-03-22 12:46:22,122 2019-03-22 12:46:22: step 19/50000, loss = 0.187007 (2.068 sec/batch), lr: 1.000000
2019-03-22 12:46:24,171 2019-03-22 12:46:24: step 20/50000, loss = 0.186047 (2.046 sec/batch), lr: 1.000000
2019-03-22 12:46:25,294 step 20: Full loss = 0.417785, Edge acc. = 0.2143
2019-03-22 12:46:27,146 2019-03-22 12:46:27: step 21/50000, loss = 0.208892 (1.845 sec/batch), lr: 1.000000
2019-03-22 12:46:29,218 2019-03-22 12:46:29: step 22/50000, loss = 0.168241 (2.068 sec/batch), lr: 1.000000
2019-03-22 12:46:31,214 2019-03-22 12:46:31: step 23/50000, loss = 0.370324 (1.992 sec/batch), lr: 1.000000
2019-03-22 12:46:33,302 2019-03-22 12:46:33: step 24/50000, loss = 0.163279 (2.084 sec/batch), lr: 1.000000
2019-03-22 12:46:35,271 2019-03-22 12:46:35: step 25/50000, loss = 0.183479 (1.965 sec/batch), lr: 1.000000
2019-03-22 12:46:37,416 2019-03-22 12:46:37: step 26/50000, loss = 0.252912 (2.141 sec/batch), lr: 1.000000
2019-03-22 12:46:39,460 2019-03-22 12:46:39: step 27/50000, loss = 0.318762 (2.040 sec/batch), lr: 1.000000
2019-03-22 12:46:41,520 2019-03-22 12:46:41: step 28/50000, loss = 0.195183 (2.056 sec/batch), lr: 1.000000
2019-03-22 12:46:43,636 2019-03-22 12:46:43: step 29/50000, loss = 0.308675 (2.112 sec/batch), lr: 1.000000
2019-03-22 12:46:45,622 2019-03-22 12:46:45: step 30/50000, loss = 0.178916 (1.982 sec/batch), lr: 1.000000
2019-03-22 12:46:46,571 step 30: Full loss = 0.582016, Edge acc. = 0.2500
2019-03-22 12:46:48,613 2019-03-22 12:46:48: step 31/50000, loss = 0.291008 (2.035 sec/batch), lr: 1.000000
2019-03-22 12:46:50,621 2019-03-22 12:46:50: step 32/50000, loss = 0.174030 (2.004 sec/batch), lr: 1.000000
2019-03-22 12:46:52,595 2019-03-22 12:46:52: step 33/50000, loss = 0.274207 (1.970 sec/batch), lr: 1.000000
2019-03-22 12:46:54,651 2019-03-22 12:46:54: step 34/50000, loss = 0.168446 (2.052 sec/batch), lr: 1.000000
2019-03-22 12:46:56,694 2019-03-22 12:46:56: step 35/50000, loss = 0.262891 (2.039 sec/batch), lr: 1.000000
2019-03-22 12:46:58,776 2019-03-22 12:46:58: step 36/50000, loss = 0.160429 (2.077 sec/batch), lr: 1.000000
2019-03-22 12:47:00,775 2019-03-22 12:47:00: step 37/50000, loss = 0.249313 (1.996 sec/batch), lr: 1.000000
2019-03-22 12:47:02,959 2019-03-22 12:47:02: step 38/50000, loss = 0.156501 (2.180 sec/batch), lr: 1.000000
2019-03-22 12:47:04,968 2019-03-22 12:47:04: step 39/50000, loss = 0.242578 (2.005 sec/batch), lr: 1.000000
2019-03-22 12:47:06,967 2019-03-22 12:47:06: step 40/50000, loss = 0.149531 (1.994 sec/batch), lr: 1.000000
2019-03-22 12:47:08,023 step 40: Full loss = 0.456853, Edge acc. = 0.3214
2019-03-22 12:47:09,829 2019-03-22 12:47:09: step 41/50000, loss = 0.228427 (1.800 sec/batch), lr: 1.000000
2019-03-22 12:47:11,855 2019-03-22 12:47:11: step 42/50000, loss = 0.143096 (2.023 sec/batch), lr: 1.000000
2019-03-22 12:47:13,904 2019-03-22 12:47:13: step 43/50000, loss = 0.222421 (2.045 sec/batch), lr: 1.000000
2019-03-22 12:47:15,850 2019-03-22 12:47:15: step 44/50000, loss = 0.136436 (1.943 sec/batch), lr: 1.000000
2019-03-22 12:47:17,822 2019-03-22 12:47:17: step 45/50000, loss = 0.213942 (1.968 sec/batch), lr: 1.000000
2019-03-22 12:47:19,915 2019-03-22 12:47:19: step 46/50000, loss = 0.131383 (2.089 sec/batch), lr: 1.000000
2019-03-22 12:47:21,901 2019-03-22 12:47:21: step 47/50000, loss = 0.207441 (1.982 sec/batch), lr: 1.000000
2019-03-22 12:47:23,910 2019-03-22 12:47:23: step 48/50000, loss = 0.125156 (2.006 sec/batch), lr: 1.000000
2019-03-22 12:47:25,881 2019-03-22 12:47:25: step 49/50000, loss = 0.196758 (1.967 sec/batch), lr: 1.000000
2019-03-22 12:47:27,921 2019-03-22 12:47:27: step 50/50000, loss = 0.121898 (2.036 sec/batch), lr: 1.000000
2019-03-22 12:47:28,872 step 50: Full loss = 0.388371, Edge acc. = 0.4643
2019-03-22 12:47:30,800 2019-03-22 12:47:30: step 51/50000, loss = 0.194185 (1.922 sec/batch), lr: 1.000000
2019-03-22 12:47:32,801 2019-03-22 12:47:32: step 52/50000, loss = 0.115180 (1.997 sec/batch), lr: 1.000000
2019-03-22 12:47:34,803 2019-03-22 12:47:34: step 53/50000, loss = 0.185400 (1.998 sec/batch), lr: 1.000000
2019-03-22 12:47:36,798 2019-03-22 12:47:36: step 54/50000, loss = 0.109623 (1.991 sec/batch), lr: 1.000000
2019-03-22 12:47:38,853 2019-03-22 12:47:38: step 55/50000, loss = 0.185008 (2.051 sec/batch), lr: 1.000000
2019-03-22 12:47:40,859 2019-03-22 12:47:40: step 56/50000, loss = 0.103654 (2.002 sec/batch), lr: 1.000000
2019-03-22 12:47:42,845 2019-03-22 12:47:42: step 57/50000, loss = 0.174180 (1.981 sec/batch), lr: 1.000000
2019-03-22 12:47:44,892 2019-03-22 12:47:44: step 58/50000, loss = 0.102490 (2.043 sec/batch), lr: 1.000000
2019-03-22 12:47:46,883 2019-03-22 12:47:46: step 59/50000, loss = 0.177782 (1.987 sec/batch), lr: 1.000000
2019-03-22 12:47:49,040 2019-03-22 12:47:49: step 60/50000, loss = 0.099051 (2.153 sec/batch), lr: 1.000000
2019-03-22 12:47:49,984 step 60: Full loss = 0.336049, Edge acc. = 0.6071
2019-03-22 12:47:52,164 2019-03-22 12:47:52: step 61/50000, loss = 0.168024 (2.159 sec/batch), lr: 1.000000
2019-03-22 12:47:54,415 2019-03-22 12:47:54: step 62/50000, loss = 0.094458 (2.247 sec/batch), lr: 1.000000
2019-03-22 12:47:56,628 2019-03-22 12:47:56: step 63/50000, loss = 0.174054 (2.209 sec/batch), lr: 1.000000
2019-03-22 12:47:58,939 2019-03-22 12:47:58: step 64/50000, loss = 0.091803 (2.308 sec/batch), lr: 1.000000
2019-03-22 12:48:01,188 2019-03-22 12:48:01: step 65/50000, loss = 0.163579 (2.245 sec/batch), lr: 1.000000
2019-03-22 12:48:03,514 2019-03-22 12:48:03: step 66/50000, loss = 0.088115 (2.322 sec/batch), lr: 1.000000
2019-03-22 12:48:05,641 2019-03-22 12:48:05: step 67/50000, loss = 0.161990 (2.123 sec/batch), lr: 1.000000
2019-03-22 12:48:07,991 2019-03-22 12:48:07: step 68/50000, loss = 0.085923 (2.346 sec/batch), lr: 1.000000
2019-03-22 12:48:10,187 2019-03-22 12:48:10: step 69/50000, loss = 0.157882 (2.193 sec/batch), lr: 1.000000
2019-03-22 12:48:12,499 2019-03-22 12:48:12: step 70/50000, loss = 0.083313 (2.307 sec/batch), lr: 1.000000
2019-03-22 12:48:13,677 step 70: Full loss = 0.329566, Edge acc. = 0.6786
2019-03-22 12:48:15,901 2019-03-22 12:48:15: step 71/50000, loss = 0.164783 (2.217 sec/batch), lr: 1.000000
2019-03-22 12:48:18,112 2019-03-22 12:48:18: step 72/50000, loss = 0.083774 (2.208 sec/batch), lr: 1.000000
2019-03-22 12:48:20,236 2019-03-22 12:48:20: step 73/50000, loss = 0.154107 (2.121 sec/batch), lr: 1.000000
2019-03-22 12:48:22,330 2019-03-22 12:48:22: step 74/50000, loss = 0.080241 (2.089 sec/batch), lr: 1.000000
2019-03-22 12:48:24,626 2019-03-22 12:48:24: step 75/50000, loss = 0.157355 (2.293 sec/batch), lr: 1.000000
2019-03-22 12:48:26,878 2019-03-22 12:48:26: step 76/50000, loss = 0.078385 (2.248 sec/batch), lr: 1.000000
2019-03-22 12:48:29,113 2019-03-22 12:48:29: step 77/50000, loss = 0.149188 (2.231 sec/batch), lr: 1.000000
2019-03-22 12:48:31,309 2019-03-22 12:48:31: step 78/50000, loss = 0.079084 (2.193 sec/batch), lr: 1.000000
2019-03-22 12:48:33,567 2019-03-22 12:48:33: step 79/50000, loss = 0.148637 (2.254 sec/batch), lr: 1.000000
2019-03-22 12:48:35,825 2019-03-22 12:48:35: step 80/50000, loss = 0.075642 (2.255 sec/batch), lr: 1.000000
2019-03-22 12:48:37,022 step 80: Full loss = 0.268083, Edge acc. = 0.6786
2019-03-22 12:48:39,113 2019-03-22 12:48:39: step 81/50000, loss = 0.134041 (2.084 sec/batch), lr: 1.000000
2019-03-22 12:48:41,301 2019-03-22 12:48:41: step 82/50000, loss = 0.093591 (2.185 sec/batch), lr: 1.000000
2019-03-22 12:48:43,360 2019-03-22 12:48:43: step 83/50000, loss = 0.134375 (2.055 sec/batch), lr: 1.000000
2019-03-22 12:48:45,304 2019-03-22 12:48:45: step 84/50000, loss = 0.079520 (1.940 sec/batch), lr: 1.000000
2019-03-22 12:48:47,368 2019-03-22 12:48:47: step 85/50000, loss = 0.148218 (2.061 sec/batch), lr: 1.000000
2019-03-22 12:48:49,411 2019-03-22 12:48:49: step 86/50000, loss = 0.076435 (2.039 sec/batch), lr: 1.000000
2019-03-22 12:48:51,506 2019-03-22 12:48:51: step 87/50000, loss = 0.141311 (2.091 sec/batch), lr: 1.000000
2019-03-22 12:48:53,513 2019-03-22 12:48:53: step 88/50000, loss = 0.075499 (2.003 sec/batch), lr: 1.000000
2019-03-22 12:48:55,599 2019-03-22 12:48:55: step 89/50000, loss = 0.143110 (2.083 sec/batch), lr: 1.000000
2019-03-22 12:48:57,679 2019-03-22 12:48:57: step 90/50000, loss = 0.073472 (2.076 sec/batch), lr: 1.000000
2019-03-22 12:48:58,631 step 90: Full loss = 0.270072, Edge acc. = 0.7143
2019-03-22 12:49:00,571 2019-03-22 12:49:00: step 91/50000, loss = 0.135036 (1.934 sec/batch), lr: 1.000000
2019-03-22 12:49:02,570 2019-03-22 12:49:02: step 92/50000, loss = 0.074782 (1.996 sec/batch), lr: 1.000000
2019-03-22 12:49:04,677 2019-03-22 12:49:04: step 93/50000, loss = 0.141911 (2.104 sec/batch), lr: 1.000000
2019-03-22 12:49:06,708 2019-03-22 12:49:06: step 94/50000, loss = 0.071642 (2.027 sec/batch), lr: 1.000000
2019-03-22 12:49:08,690 2019-03-22 12:49:08: step 95/50000, loss = 0.133154 (1.978 sec/batch), lr: 1.000000
2019-03-22 12:49:10,744 2019-03-22 12:49:10: step 96/50000, loss = 0.076163 (2.050 sec/batch), lr: 1.000000
2019-03-22 12:49:12,788 2019-03-22 12:49:12: step 97/50000, loss = 0.129165 (2.041 sec/batch), lr: 1.000000
2019-03-22 12:49:14,780 2019-03-22 12:49:14: step 98/50000, loss = 0.071541 (1.987 sec/batch), lr: 1.000000
2019-03-22 12:49:16,755 2019-03-22 12:49:16: step 99/50000, loss = 0.137354 (1.972 sec/batch), lr: 1.000000
2019-03-22 12:49:18,816 2019-03-22 12:49:18: step 100/50000, loss = 0.070604 (2.057 sec/batch), lr: 1.000000
2019-03-22 12:49:19,769 step 100: Full loss = 0.258732, Edge acc. = 0.7500
2019-03-22 12:49:21,710 2019-03-22 12:49:21: step 101/50000, loss = 0.129366 (1.934 sec/batch), lr: 1.000000
2019-03-22 12:49:23,717 2019-03-22 12:49:23: step 102/50000, loss = 0.066986 (2.004 sec/batch), lr: 1.000000
2019-03-22 12:49:25,760 2019-03-22 12:49:25: step 103/50000, loss = 0.136073 (2.039 sec/batch), lr: 1.000000
2019-03-22 12:49:27,824 2019-03-22 12:49:27: step 104/50000, loss = 0.069359 (2.060 sec/batch), lr: 1.000000
2019-03-22 12:49:29,839 2019-03-22 12:49:29: step 105/50000, loss = 0.128798 (2.011 sec/batch), lr: 1.000000
2019-03-22 12:49:31,873 2019-03-22 12:49:31: step 106/50000, loss = 0.067927 (2.030 sec/batch), lr: 1.000000
2019-03-22 12:49:34,022 2019-03-22 12:49:34: step 107/50000, loss = 0.123815 (2.145 sec/batch), lr: 1.000000
2019-03-22 12:49:36,015 2019-03-22 12:49:36: step 108/50000, loss = 0.073485 (1.989 sec/batch), lr: 1.000000
2019-03-22 12:49:38,007 2019-03-22 12:49:38: step 109/50000, loss = 0.125795 (1.989 sec/batch), lr: 1.000000
2019-03-22 12:49:40,026 2019-03-22 12:49:40: step 110/50000, loss = 0.068016 (2.015 sec/batch), lr: 1.000000
2019-03-22 12:49:41,011 step 110: Full loss = 0.245570, Edge acc. = 0.7500
2019-03-22 12:49:42,999 2019-03-22 12:49:42: step 111/50000, loss = 0.122785 (1.982 sec/batch), lr: 1.000000
2019-03-22 12:49:44,991 2019-03-22 12:49:44: step 112/50000, loss = 0.067286 (1.989 sec/batch), lr: 1.000000
2019-03-22 12:49:46,877 2019-03-22 12:49:46: step 113/50000, loss = 0.126250 (1.882 sec/batch), lr: 1.000000
2019-03-22 12:49:49,017 2019-03-22 12:49:49: step 114/50000, loss = 0.064532 (2.136 sec/batch), lr: 1.000000
2019-03-22 12:49:51,020 2019-03-22 12:49:51: step 115/50000, loss = 0.106183 (1.999 sec/batch), lr: 1.000000
2019-03-22 12:49:53,009 2019-03-22 12:49:53: step 116/50000, loss = 0.087709 (1.985 sec/batch), lr: 1.000000
2019-03-22 12:49:55,022 2019-03-22 12:49:55: step 117/50000, loss = 0.105724 (2.009 sec/batch), lr: 1.000000
2019-03-22 12:49:56,969 2019-03-22 12:49:56: step 118/50000, loss = 0.072658 (1.943 sec/batch), lr: 1.000000
2019-03-22 12:49:58,964 2019-03-22 12:49:58: step 119/50000, loss = 0.123349 (1.991 sec/batch), lr: 1.000000
2019-03-22 12:50:01,053 2019-03-22 12:50:01: step 120/50000, loss = 0.068314 (2.085 sec/batch), lr: 1.000000
2019-03-22 12:50:02,024 step 120: Full loss = 0.240329, Edge acc. = 0.7500
2019-03-22 12:50:04,018 2019-03-22 12:50:04: step 121/50000, loss = 0.120164 (1.988 sec/batch), lr: 1.000000
2019-03-22 12:50:05,939 2019-03-22 12:50:05: step 122/50000, loss = 0.066154 (1.917 sec/batch), lr: 1.000000
2019-03-22 12:50:07,942 2019-03-22 12:50:07: step 123/50000, loss = 0.114706 (2.000 sec/batch), lr: 1.000000
2019-03-22 12:50:09,977 2019-03-22 12:50:09: step 124/50000, loss = 0.066053 (2.031 sec/batch), lr: 1.000000
2019-03-22 12:50:12,027 2019-03-22 12:50:12: step 125/50000, loss = 0.116662 (2.047 sec/batch), lr: 1.000000
2019-03-22 12:50:14,022 2019-03-22 12:50:14: step 126/50000, loss = 0.062588 (1.991 sec/batch), lr: 1.000000
2019-03-22 12:50:16,032 2019-03-22 12:50:16: step 127/50000, loss = 0.117449 (2.007 sec/batch), lr: 1.000000
2019-03-22 12:50:18,135 2019-03-22 12:50:18: step 128/50000, loss = 0.069666 (2.098 sec/batch), lr: 1.000000
2019-03-22 12:50:20,126 2019-03-22 12:50:20: step 129/50000, loss = 0.115478 (1.987 sec/batch), lr: 1.000000
2019-03-22 12:50:22,166 2019-03-22 12:50:22: step 130/50000, loss = 0.063598 (2.036 sec/batch), lr: 1.000000
2019-03-22 12:50:23,117 step 130: Full loss = 0.224782, Edge acc. = 0.7500
2019-03-22 12:50:25,108 2019-03-22 12:50:25: step 131/50000, loss = 0.112391 (1.984 sec/batch), lr: 1.000000
2019-03-22 12:50:27,133 2019-03-22 12:50:27: step 132/50000, loss = 0.065064 (2.021 sec/batch), lr: 1.000000
2019-03-22 12:50:29,161 2019-03-22 12:50:29: step 133/50000, loss = 0.113664 (2.024 sec/batch), lr: 1.000000
2019-03-22 12:50:31,186 2019-03-22 12:50:31: step 134/50000, loss = 0.061492 (2.022 sec/batch), lr: 1.000000
2019-03-22 12:50:33,272 2019-03-22 12:50:33: step 135/50000, loss = 0.104646 (2.082 sec/batch), lr: 1.000000
2019-03-22 12:50:35,331 2019-03-22 12:50:35: step 136/50000, loss = 0.072398 (2.055 sec/batch), lr: 1.000000
2019-03-22 12:50:37,353 2019-03-22 12:50:37: step 137/50000, loss = 0.104206 (2.019 sec/batch), lr: 1.000000
2019-03-22 12:50:39,487 2019-03-22 12:50:39: step 138/50000, loss = 0.064221 (2.131 sec/batch), lr: 1.000000
2019-03-22 12:50:41,747 2019-03-22 12:50:41: step 139/50000, loss = 0.107939 (2.255 sec/batch), lr: 1.000000
2019-03-22 12:50:43,855 2019-03-22 12:50:43: step 140/50000, loss = 0.064093 (2.104 sec/batch), lr: 1.000000
2019-03-22 12:50:44,853 step 140: Full loss = 0.218158, Edge acc. = 0.7500
2019-03-22 12:50:46,818 2019-03-22 12:50:46: step 141/50000, loss = 0.109079 (1.959 sec/batch), lr: 1.000000
2019-03-22 12:50:48,821 2019-03-22 12:50:48: step 142/50000, loss = 0.060989 (1.999 sec/batch), lr: 1.000000
2019-03-22 12:50:50,857 2019-03-22 12:50:50: step 143/50000, loss = 0.100121 (2.032 sec/batch), lr: 1.000000
2019-03-22 12:50:52,887 2019-03-22 12:50:52: step 144/50000, loss = 0.073384 (2.026 sec/batch), lr: 1.000000
2019-03-22 12:50:54,863 2019-03-22 12:50:54: step 145/50000, loss = 0.096833 (1.972 sec/batch), lr: 1.000000
2019-03-22 12:50:56,888 2019-03-22 12:50:56: step 146/50000, loss = 0.065898 (2.021 sec/batch), lr: 1.000000
2019-03-22 12:50:59,075 2019-03-22 12:50:59: step 147/50000, loss = 0.102363 (2.182 sec/batch), lr: 1.000000
2019-03-22 12:51:01,095 2019-03-22 12:51:01: step 148/50000, loss = 0.066221 (2.016 sec/batch), lr: 1.000000
2019-03-22 12:51:03,172 2019-03-22 12:51:03: step 149/50000, loss = 0.106778 (2.074 sec/batch), lr: 1.000000
2019-03-22 12:51:05,236 2019-03-22 12:51:05: step 150/50000, loss = 0.062041 (2.060 sec/batch), lr: 1.000000
2019-03-22 12:51:06,198 step 150: Full loss = 0.203570, Edge acc. = 0.8214
2019-03-22 12:51:08,135 2019-03-22 12:51:08: step 151/50000, loss = 0.101785 (1.931 sec/batch), lr: 1.000000
2019-03-22 12:51:10,165 2019-03-22 12:51:10: step 152/50000, loss = 0.064223 (2.026 sec/batch), lr: 1.000000
2019-03-22 12:51:12,142 2019-03-22 12:51:12: step 153/50000, loss = 0.104347 (1.973 sec/batch), lr: 1.000000
2019-03-22 12:51:14,269 2019-03-22 12:51:14: step 154/50000, loss = 0.059840 (2.124 sec/batch), lr: 1.000000
2019-03-22 12:51:16,302 2019-03-22 12:51:16: step 155/50000, loss = 0.096572 (2.029 sec/batch), lr: 1.000000
2019-03-22 12:51:18,255 2019-03-22 12:51:18: step 156/50000, loss = 0.070854 (1.951 sec/batch), lr: 1.000000
2019-03-22 12:51:20,187 2019-03-22 12:51:20: step 157/50000, loss = 0.094601 (1.929 sec/batch), lr: 1.000000
2019-03-22 12:51:22,252 2019-03-22 12:51:22: step 158/50000, loss = 0.062001 (2.061 sec/batch), lr: 1.000000
2019-03-22 12:51:24,305 2019-03-22 12:51:24: step 159/50000, loss = 0.099479 (2.048 sec/batch), lr: 1.000000
2019-03-22 12:51:26,317 2019-03-22 12:51:26: step 160/50000, loss = 0.063764 (2.008 sec/batch), lr: 1.000000
2019-03-22 12:51:27,324 step 160: Full loss = 0.198073, Edge acc. = 0.8214
2019-03-22 12:51:29,260 2019-03-22 12:51:29: step 161/50000, loss = 0.099036 (1.930 sec/batch), lr: 1.000000
2019-03-22 12:51:31,416 2019-03-22 12:51:31: step 162/50000, loss = 0.059682 (2.152 sec/batch), lr: 1.000000
2019-03-22 12:51:33,319 2019-03-22 12:51:33: step 163/50000, loss = 0.093196 (1.900 sec/batch), lr: 1.000000
2019-03-22 12:51:35,410 2019-03-22 12:51:35: step 164/50000, loss = 0.070923 (2.087 sec/batch), lr: 1.000000
2019-03-22 12:51:37,332 2019-03-22 12:51:37: step 165/50000, loss = 0.091336 (1.919 sec/batch), lr: 1.000000
2019-03-22 12:51:39,406 2019-03-22 12:51:39: step 166/50000, loss = 0.061761 (2.070 sec/batch), lr: 1.000000
2019-03-22 12:51:41,483 2019-03-22 12:51:41: step 167/50000, loss = 0.097688 (2.073 sec/batch), lr: 1.000000
2019-03-22 12:51:43,531 2019-03-22 12:51:43: step 168/50000, loss = 0.062276 (2.044 sec/batch), lr: 1.000000
2019-03-22 12:51:45,612 2019-03-22 12:51:45: step 169/50000, loss = 0.095618 (2.077 sec/batch), lr: 1.000000
2019-03-22 12:51:47,571 2019-03-22 12:51:47: step 170/50000, loss = 0.062096 (1.956 sec/batch), lr: 1.000000
2019-03-22 12:51:48,534 step 170: Full loss = 0.183520, Edge acc. = 0.8214
2019-03-22 12:51:50,480 2019-03-22 12:51:50: step 171/50000, loss = 0.091760 (1.941 sec/batch), lr: 1.000000
2019-03-22 12:51:52,583 2019-03-22 12:51:52: step 172/50000, loss = 0.064719 (2.099 sec/batch), lr: 1.000000
2019-03-22 12:51:54,655 2019-03-22 12:51:54: step 173/50000, loss = 0.093997 (2.068 sec/batch), lr: 1.000000
2019-03-22 12:51:56,694 2019-03-22 12:51:56: step 174/50000, loss = 0.059249 (2.035 sec/batch), lr: 1.000000
2019-03-22 12:51:58,791 2019-03-22 12:51:58: step 175/50000, loss = 0.091576 (2.093 sec/batch), lr: 1.000000
2019-03-22 12:52:00,868 2019-03-22 12:52:00: step 176/50000, loss = 0.065631 (2.073 sec/batch), lr: 1.000000
2019-03-22 12:52:02,892 2019-03-22 12:52:02: step 177/50000, loss = 0.091816 (2.020 sec/batch), lr: 1.000000
2019-03-22 12:52:04,994 2019-03-22 12:52:04: step 178/50000, loss = 0.058820 (2.098 sec/batch), lr: 1.000000
2019-03-22 12:52:07,008 2019-03-22 12:52:07: step 179/50000, loss = 0.092929 (2.010 sec/batch), lr: 1.000000
2019-03-22 12:52:09,074 2019-03-22 12:52:09: step 180/50000, loss = 0.065065 (2.062 sec/batch), lr: 1.000000
2019-03-22 12:52:10,055 step 180: Full loss = 0.181163, Edge acc. = 0.8571
2019-03-22 12:52:12,006 2019-03-22 12:52:12: step 181/50000, loss = 0.090582 (1.945 sec/batch), lr: 1.000000
2019-03-22 12:52:14,059 2019-03-22 12:52:14: step 182/50000, loss = 0.058521 (2.049 sec/batch), lr: 1.000000
2019-03-22 12:52:16,109 2019-03-22 12:52:16: step 183/50000, loss = 0.091964 (2.047 sec/batch), lr: 1.000000
2019-03-22 12:52:18,110 2019-03-22 12:52:18: step 184/50000, loss = 0.063781 (1.997 sec/batch), lr: 1.000000
2019-03-22 12:52:20,148 2019-03-22 12:52:20: step 185/50000, loss = 0.089284 (2.034 sec/batch), lr: 1.000000
2019-03-22 12:52:22,253 2019-03-22 12:52:22: step 186/50000, loss = 0.058095 (2.101 sec/batch), lr: 1.000000
2019-03-22 12:52:24,278 2019-03-22 12:52:24: step 187/50000, loss = 0.091416 (2.020 sec/batch), lr: 1.000000
2019-03-22 12:52:26,261 2019-03-22 12:52:26: step 188/50000, loss = 0.064539 (1.980 sec/batch), lr: 1.000000
2019-03-22 12:52:28,283 2019-03-22 12:52:28: step 189/50000, loss = 0.088939 (2.016 sec/batch), lr: 1.000000
2019-03-22 12:52:30,308 2019-03-22 12:52:30: step 190/50000, loss = 0.056473 (2.021 sec/batch), lr: 1.000000
2019-03-22 12:52:31,241 step 190: Full loss = 0.181014, Edge acc. = 0.8571
2019-03-22 12:52:33,137 2019-03-22 12:52:33: step 191/50000, loss = 0.090507 (1.890 sec/batch), lr: 1.000000
2019-03-22 12:52:35,207 2019-03-22 12:52:35: step 192/50000, loss = 0.065029 (2.067 sec/batch), lr: 1.000000
2019-03-22 12:52:37,149 2019-03-22 12:52:37: step 193/50000, loss = 0.085409 (1.937 sec/batch), lr: 1.000000
2019-03-22 12:52:39,230 2019-03-22 12:52:39: step 194/50000, loss = 0.057680 (2.078 sec/batch), lr: 1.000000
2019-03-22 12:52:41,196 2019-03-22 12:52:41: step 195/50000, loss = 0.092136 (1.961 sec/batch), lr: 1.000000
2019-03-22 12:52:43,301 2019-03-22 12:52:43: step 196/50000, loss = 0.061063 (2.101 sec/batch), lr: 1.000000
2019-03-22 12:52:45,263 2019-03-22 12:52:45: step 197/50000, loss = 0.089489 (1.958 sec/batch), lr: 1.000000
2019-03-22 12:52:47,352 2019-03-22 12:52:47: step 198/50000, loss = 0.059784 (2.085 sec/batch), lr: 1.000000
2019-03-22 12:52:49,345 2019-03-22 12:52:49: step 199/50000, loss = 0.085537 (1.989 sec/batch), lr: 1.000000
2019-03-22 12:52:51,363 2019-03-22 12:52:51: step 200/50000, loss = 0.061378 (2.014 sec/batch), lr: 1.000000
2019-03-22 12:52:52,390 step 200: Full loss = 0.169546, Edge acc. = 0.8929
2019-03-22 12:52:54,389 2019-03-22 12:52:54: step 201/50000, loss = 0.084773 (1.992 sec/batch), lr: 1.000000
2019-03-22 12:52:56,445 2019-03-22 12:52:56: step 202/50000, loss = 0.060487 (2.053 sec/batch), lr: 1.000000
2019-03-22 12:52:58,457 2019-03-22 12:52:58: step 203/50000, loss = 0.083064 (2.009 sec/batch), lr: 1.000000
2019-03-22 12:53:00,498 2019-03-22 12:53:00: step 204/50000, loss = 0.060809 (2.036 sec/batch), lr: 1.000000
2019-03-22 12:53:02,543 2019-03-22 12:53:02: step 205/50000, loss = 0.085748 (2.042 sec/batch), lr: 1.000000
2019-03-22 12:53:04,525 2019-03-22 12:53:04: step 206/50000, loss = 0.058299 (1.979 sec/batch), lr: 1.000000
2019-03-22 12:53:06,518 2019-03-22 12:53:06: step 207/50000, loss = 0.091683 (1.989 sec/batch), lr: 1.000000
2019-03-22 12:53:08,542 2019-03-22 12:53:08: step 208/50000, loss = 0.055917 (2.020 sec/batch), lr: 1.000000
2019-03-22 12:53:10,562 2019-03-22 12:53:10: step 209/50000, loss = 0.087138 (2.016 sec/batch), lr: 1.000000
2019-03-22 12:53:12,638 2019-03-22 12:53:12: step 210/50000, loss = 0.059861 (2.072 sec/batch), lr: 1.000000
2019-03-22 12:53:13,633 step 210: Full loss = 0.172451, Edge acc. = 0.8929
2019-03-22 12:53:15,602 2019-03-22 12:53:15: step 211/50000, loss = 0.086225 (1.963 sec/batch), lr: 1.000000
2019-03-22 12:53:17,584 2019-03-22 12:53:17: step 212/50000, loss = 0.056638 (1.978 sec/batch), lr: 1.000000
2019-03-22 12:53:19,603 2019-03-22 12:53:19: step 213/50000, loss = 0.083959 (2.015 sec/batch), lr: 1.000000
2019-03-22 12:53:21,668 2019-03-22 12:53:21: step 214/50000, loss = 0.062512 (2.061 sec/batch), lr: 1.000000
2019-03-22 12:53:23,697 2019-03-22 12:53:23: step 215/50000, loss = 0.083802 (2.025 sec/batch), lr: 1.000000
2019-03-22 12:53:25,700 2019-03-22 12:53:25: step 216/50000, loss = 0.056579 (1.999 sec/batch), lr: 1.000000
2019-03-22 12:53:27,727 2019-03-22 12:53:27: step 217/50000, loss = 0.078473 (2.023 sec/batch), lr: 1.000000
2019-03-22 12:53:29,758 2019-03-22 12:53:29: step 218/50000, loss = 0.070613 (2.027 sec/batch), lr: 1.000000
2019-03-22 12:53:31,806 2019-03-22 12:53:31: step 219/50000, loss = 0.077447 (2.044 sec/batch), lr: 1.000000
2019-03-22 12:53:33,860 2019-03-22 12:53:33: step 220/50000, loss = 0.059035 (2.050 sec/batch), lr: 1.000000
2019-03-22 12:53:34,826 step 220: Full loss = 0.174167, Edge acc. = 0.8929
2019-03-22 12:53:36,787 2019-03-22 12:53:36: step 221/50000, loss = 0.087083 (1.955 sec/batch), lr: 1.000000
2019-03-22 12:53:38,861 2019-03-22 12:53:38: step 222/50000, loss = 0.058926 (2.071 sec/batch), lr: 1.000000
2019-03-22 12:53:40,742 2019-03-22 12:53:40: step 223/50000, loss = 0.082676 (1.877 sec/batch), lr: 1.000000
2019-03-22 12:53:42,694 2019-03-22 12:53:42: step 224/50000, loss = 0.058992 (1.948 sec/batch), lr: 1.000000
2019-03-22 12:53:44,719 2019-03-22 12:53:44: step 225/50000, loss = 0.079636 (2.021 sec/batch), lr: 1.000000
2019-03-22 12:53:46,739 2019-03-22 12:53:46: step 226/50000, loss = 0.060234 (2.016 sec/batch), lr: 1.000000
2019-03-22 12:53:48,783 2019-03-22 12:53:48: step 227/50000, loss = 0.080325 (2.040 sec/batch), lr: 1.000000
2019-03-22 12:53:50,856 2019-03-22 12:53:50: step 228/50000, loss = 0.058782 (2.070 sec/batch), lr: 1.000000
2019-03-22 12:53:52,795 2019-03-22 12:53:52: step 229/50000, loss = 0.085984 (1.935 sec/batch), lr: 1.000000
2019-03-22 12:53:54,808 2019-03-22 12:53:54: step 230/50000, loss = 0.055447 (2.009 sec/batch), lr: 1.000000
2019-03-22 12:53:55,774 step 230: Full loss = 0.170362, Edge acc. = 0.8929
2019-03-22 12:53:57,725 2019-03-22 12:53:57: step 231/50000, loss = 0.085181 (1.944 sec/batch), lr: 1.000000
2019-03-22 12:53:59,711 2019-03-22 12:53:59: step 232/50000, loss = 0.057346 (1.983 sec/batch), lr: 1.000000
2019-03-22 12:54:01,795 2019-03-22 12:54:01: step 233/50000, loss = 0.084225 (2.080 sec/batch), lr: 1.000000
2019-03-22 12:54:03,779 2019-03-22 12:54:03: step 234/50000, loss = 0.055438 (1.980 sec/batch), lr: 1.000000
2019-03-22 12:54:05,857 2019-03-22 12:54:05: step 235/50000, loss = 0.076649 (2.074 sec/batch), lr: 1.000000
2019-03-22 12:54:07,834 2019-03-22 12:54:07: step 236/50000, loss = 0.065106 (1.974 sec/batch), lr: 1.000000
2019-03-22 12:54:09,893 2019-03-22 12:54:09: step 237/50000, loss = 0.078455 (2.055 sec/batch), lr: 1.000000
2019-03-22 12:54:11,997 2019-03-22 12:54:11: step 238/50000, loss = 0.055983 (2.100 sec/batch), lr: 1.000000
2019-03-22 12:54:13,996 2019-03-22 12:54:13: step 239/50000, loss = 0.081486 (1.995 sec/batch), lr: 1.000000
2019-03-22 12:54:16,036 2019-03-22 12:54:16: step 240/50000, loss = 0.059843 (2.036 sec/batch), lr: 1.000000
2019-03-22 12:54:17,010 step 240: Full loss = 0.162825, Edge acc. = 0.9286
2019-03-22 12:54:18,970 2019-03-22 12:54:18: step 241/50000, loss = 0.081413 (1.953 sec/batch), lr: 1.000000
2019-03-22 12:54:20,935 2019-03-22 12:54:20: step 242/50000, loss = 0.054909 (1.962 sec/batch), lr: 1.000000
2019-03-22 12:54:22,906 2019-03-22 12:54:22: step 243/50000, loss = 0.074642 (1.967 sec/batch), lr: 1.000000
2019-03-22 12:54:24,917 2019-03-22 12:54:24: step 244/50000, loss = 0.069212 (2.007 sec/batch), lr: 1.000000
2019-03-22 12:54:26,979 2019-03-22 12:54:26: step 245/50000, loss = 0.074353 (2.059 sec/batch), lr: 1.000000
2019-03-22 12:54:28,993 2019-03-22 12:54:28: step 246/50000, loss = 0.058707 (2.010 sec/batch), lr: 1.000000
2019-03-22 12:54:31,001 2019-03-22 12:54:30: step 247/50000, loss = 0.081113 (2.004 sec/batch), lr: 1.000000
2019-03-22 12:54:33,088 2019-03-22 12:54:33: step 248/50000, loss = 0.058609 (2.084 sec/batch), lr: 1.000000
2019-03-22 12:54:35,088 2019-03-22 12:54:35: step 249/50000, loss = 0.080450 (1.996 sec/batch), lr: 1.000000
2019-03-22 12:54:37,172 2019-03-22 12:54:37: step 250/50000, loss = 0.057058 (2.080 sec/batch), lr: 1.000000
2019-03-22 12:54:38,103 step 250: Full loss = 0.156717, Edge acc. = 0.9286
2019-03-22 12:54:40,035 2019-03-22 12:54:40: step 251/50000, loss = 0.078358 (1.926 sec/batch), lr: 1.000000
2019-03-22 12:54:41,928 2019-03-22 12:54:41: step 252/50000, loss = 0.057949 (1.889 sec/batch), lr: 1.000000
2019-03-22 12:54:43,899 2019-03-22 12:54:43: step 253/50000, loss = 0.077960 (1.968 sec/batch), lr: 1.000000
2019-03-22 12:54:45,890 2019-03-22 12:54:45: step 254/50000, loss = 0.057423 (1.987 sec/batch), lr: 1.000000
2019-03-22 12:54:47,911 2019-03-22 12:54:47: step 255/50000, loss = 0.076063 (2.018 sec/batch), lr: 1.000000
2019-03-22 12:54:49,928 2019-03-22 12:54:49: step 256/50000, loss = 0.057808 (2.013 sec/batch), lr: 1.000000
2019-03-22 12:54:51,953 2019-03-22 12:54:51: step 257/50000, loss = 0.076474 (2.021 sec/batch), lr: 1.000000
2019-03-22 12:54:53,970 2019-03-22 12:54:53: step 258/50000, loss = 0.057480 (2.013 sec/batch), lr: 1.000000
2019-03-22 12:54:56,043 2019-03-22 12:54:56: step 259/50000, loss = 0.074084 (2.070 sec/batch), lr: 1.000000
2019-03-22 12:54:58,004 2019-03-22 12:54:58: step 260/50000, loss = 0.058298 (1.957 sec/batch), lr: 1.000000
2019-03-22 12:54:58,986 step 260: Full loss = 0.149237, Edge acc. = 0.9286
2019-03-22 12:55:00,989 2019-03-22 12:55:00: step 261/50000, loss = 0.074619 (1.997 sec/batch), lr: 1.000000
2019-03-22 12:55:02,950 2019-03-22 12:55:02: step 262/50000, loss = 0.057900 (1.957 sec/batch), lr: 1.000000
2019-03-22 12:55:04,973 2019-03-22 12:55:04: step 263/50000, loss = 0.073447 (2.021 sec/batch), lr: 1.000000
2019-03-22 12:55:06,922 2019-03-22 12:55:06: step 264/50000, loss = 0.057666 (1.946 sec/batch), lr: 1.000000
2019-03-22 12:55:08,889 2019-03-22 12:55:08: step 265/50000, loss = 0.075090 (1.964 sec/batch), lr: 1.000000
2019-03-22 12:55:11,031 2019-03-22 12:55:11: step 266/50000, loss = 0.056399 (2.138 sec/batch), lr: 1.000000
2019-03-22 12:55:13,063 2019-03-22 12:55:13: step 267/50000, loss = 0.081552 (2.028 sec/batch), lr: 1.000000
2019-03-22 12:55:15,079 2019-03-22 12:55:15: step 268/50000, loss = 0.054028 (2.013 sec/batch), lr: 1.000000
2019-03-22 12:55:17,085 2019-03-22 12:55:17: step 269/50000, loss = 0.078047 (2.002 sec/batch), lr: 1.000000
2019-03-22 12:55:19,078 2019-03-22 12:55:19: step 270/50000, loss = 0.056709 (1.989 sec/batch), lr: 1.000000
2019-03-22 12:55:20,101 step 270: Full loss = 0.157176, Edge acc. = 0.9286
2019-03-22 12:55:22,095 2019-03-22 12:55:22: step 271/50000, loss = 0.078588 (1.987 sec/batch), lr: 1.000000
2019-03-22 12:55:24,107 2019-03-22 12:55:24: step 272/50000, loss = 0.054731 (2.008 sec/batch), lr: 1.000000
2019-03-22 12:55:26,169 2019-03-22 12:55:26: step 273/50000, loss = 0.071481 (2.058 sec/batch), lr: 1.000000
2019-03-22 12:55:28,174 2019-03-22 12:55:28: step 274/50000, loss = 0.062939 (2.001 sec/batch), lr: 1.000000
2019-03-22 12:55:30,261 2019-03-22 12:55:30: step 275/50000, loss = 0.075867 (2.083 sec/batch), lr: 1.000000
2019-03-22 12:55:32,320 2019-03-22 12:55:32: step 276/50000, loss = 0.055231 (2.055 sec/batch), lr: 1.000000
2019-03-22 12:55:34,320 2019-03-22 12:55:34: step 277/50000, loss = 0.075113 (1.997 sec/batch), lr: 1.000000
2019-03-22 12:55:36,404 2019-03-22 12:55:36: step 278/50000, loss = 0.058990 (2.079 sec/batch), lr: 1.000000
2019-03-22 12:55:38,315 2019-03-22 12:55:38: step 279/50000, loss = 0.075782 (1.907 sec/batch), lr: 1.000000
2019-03-22 12:55:40,446 2019-03-22 12:55:40: step 280/50000, loss = 0.054113 (2.127 sec/batch), lr: 1.000000
2019-03-22 12:55:41,392 step 280: Full loss = 0.144022, Edge acc. = 0.9286
2019-03-22 12:55:43,330 2019-03-22 12:55:43: step 281/50000, loss = 0.072011 (1.932 sec/batch), lr: 1.000000
2019-03-22 12:55:45,355 2019-03-22 12:55:45: step 282/50000, loss = 0.062452 (2.022 sec/batch), lr: 1.000000
2019-03-22 12:55:47,339 2019-03-22 12:55:47: step 283/50000, loss = 0.073703 (1.980 sec/batch), lr: 1.000000
2019-03-22 12:55:49,352 2019-03-22 12:55:49: step 284/50000, loss = 0.054048 (2.009 sec/batch), lr: 1.000000
2019-03-22 12:55:51,349 2019-03-22 12:55:51: step 285/50000, loss = 0.074286 (1.994 sec/batch), lr: 1.000000
2019-03-22 12:55:53,410 2019-03-22 12:55:53: step 286/50000, loss = 0.059587 (2.057 sec/batch), lr: 1.000000
2019-03-22 12:55:55,395 2019-03-22 12:55:55: step 287/50000, loss = 0.074786 (1.981 sec/batch), lr: 1.000000
2019-03-22 12:55:57,402 2019-03-22 12:55:57: step 288/50000, loss = 0.053187 (2.004 sec/batch), lr: 1.000000
2019-03-22 12:55:59,431 2019-03-22 12:55:59: step 289/50000, loss = 0.073836 (2.025 sec/batch), lr: 1.000000
2019-03-22 12:56:01,418 2019-03-22 12:56:01: step 290/50000, loss = 0.060871 (1.983 sec/batch), lr: 1.000000
2019-03-22 12:56:02,450 step 290: Full loss = 0.145290, Edge acc. = 0.9286
2019-03-22 12:56:04,371 2019-03-22 12:56:04: step 291/50000, loss = 0.072645 (1.915 sec/batch), lr: 1.000000
2019-03-22 12:56:06,442 2019-03-22 12:56:06: step 292/50000, loss = 0.057325 (2.067 sec/batch), lr: 1.000000
2019-03-22 12:56:08,487 2019-03-22 12:56:08: step 293/50000, loss = 0.070735 (2.041 sec/batch), lr: 1.000000
2019-03-22 12:56:10,504 2019-03-22 12:56:10: step 294/50000, loss = 0.057232 (2.014 sec/batch), lr: 1.000000
2019-03-22 12:56:12,608 2019-03-22 12:56:12: step 295/50000, loss = 0.070743 (2.100 sec/batch), lr: 1.000000
2019-03-22 12:56:14,599 2019-03-22 12:56:14: step 296/50000, loss = 0.056414 (1.987 sec/batch), lr: 1.000000
2019-03-22 12:56:16,642 2019-03-22 12:56:16: step 297/50000, loss = 0.072244 (2.039 sec/batch), lr: 1.000000
2019-03-22 12:56:18,597 2019-03-22 12:56:18: step 298/50000, loss = 0.056733 (1.951 sec/batch), lr: 1.000000
2019-03-22 12:56:20,545 2019-03-22 12:56:20: step 299/50000, loss = 0.070026 (1.945 sec/batch), lr: 1.000000
2019-03-22 12:56:22,603 2019-03-22 12:56:22: step 300/50000, loss = 0.056285 (2.054 sec/batch), lr: 1.000000
2019-03-22 12:56:23,569 step 300: Full loss = 0.141059, Edge acc. = 0.9286
2019-03-22 12:56:25,521 2019-03-22 12:56:25: step 301/50000, loss = 0.070530 (1.945 sec/batch), lr: 0.500000
2019-03-22 12:56:27,573 2019-03-22 12:56:27: step 302/50000, loss = 0.050250 (2.049 sec/batch), lr: 0.500000
2019-03-22 12:56:29,602 2019-03-22 12:56:29: step 303/50000, loss = 0.052373 (2.025 sec/batch), lr: 0.500000
2019-03-22 12:56:31,622 2019-03-22 12:56:31: step 304/50000, loss = 0.050333 (2.016 sec/batch), lr: 0.500000
2019-03-22 12:56:33,620 2019-03-22 12:56:33: step 305/50000, loss = 0.051120 (1.996 sec/batch), lr: 0.500000
2019-03-22 12:56:35,527 2019-03-22 12:56:35: step 306/50000, loss = 0.050859 (1.904 sec/batch), lr: 0.500000
2019-03-22 12:56:37,685 2019-03-22 12:56:37: step 307/50000, loss = 0.050616 (2.155 sec/batch), lr: 0.500000
2019-03-22 12:56:39,525 2019-03-22 12:56:39: step 308/50000, loss = 0.050820 (1.837 sec/batch), lr: 0.500000
2019-03-22 12:56:41,468 2019-03-22 12:56:41: step 309/50000, loss = 0.049968 (1.940 sec/batch), lr: 0.500000
2019-03-22 12:56:43,520 2019-03-22 12:56:43: step 310/50000, loss = 0.050982 (2.048 sec/batch), lr: 0.500000
2019-03-22 12:56:44,559 step 310: Full loss = 0.099302, Edge acc. = 0.9286
2019-03-22 12:56:46,395 2019-03-22 12:56:46: step 311/50000, loss = 0.049651 (1.830 sec/batch), lr: 0.500000
2019-03-22 12:56:48,494 2019-03-22 12:56:48: step 312/50000, loss = 0.051056 (2.095 sec/batch), lr: 0.500000
2019-03-22 12:56:50,482 2019-03-22 12:56:50: step 313/50000, loss = 0.049421 (1.985 sec/batch), lr: 0.500000
2019-03-22 12:56:52,665 2019-03-22 12:56:52: step 314/50000, loss = 0.051097 (2.180 sec/batch), lr: 0.500000
2019-03-22 12:56:54,588 2019-03-22 12:56:54: step 315/50000, loss = 0.049219 (1.919 sec/batch), lr: 0.500000
2019-03-22 12:56:56,603 2019-03-22 12:56:56: step 316/50000, loss = 0.050729 (2.011 sec/batch), lr: 0.500000
2019-03-22 12:56:58,653 2019-03-22 12:56:58: step 317/50000, loss = 0.048976 (2.045 sec/batch), lr: 0.500000
2019-03-22 12:57:00,656 2019-03-22 12:57:00: step 318/50000, loss = 0.051432 (2.000 sec/batch), lr: 0.500000
2019-03-22 12:57:02,707 2019-03-22 12:57:02: step 319/50000, loss = 0.048870 (2.047 sec/batch), lr: 0.500000
2019-03-22 12:57:04,738 2019-03-22 12:57:04: step 320/50000, loss = 0.051157 (2.027 sec/batch), lr: 0.500000
2019-03-22 12:57:05,735 step 320: Full loss = 0.097418, Edge acc. = 0.9286
2019-03-22 12:57:07,728 2019-03-22 12:57:07: step 321/50000, loss = 0.048709 (1.986 sec/batch), lr: 0.500000
2019-03-22 12:57:09,714 2019-03-22 12:57:09: step 322/50000, loss = 0.053262 (1.982 sec/batch), lr: 0.500000
2019-03-22 12:57:11,838 2019-03-22 12:57:11: step 323/50000, loss = 0.047710 (2.121 sec/batch), lr: 0.500000
2019-03-22 12:57:13,872 2019-03-22 12:57:13: step 324/50000, loss = 0.052108 (2.030 sec/batch), lr: 0.500000
2019-03-22 12:57:15,819 2019-03-22 12:57:15: step 325/50000, loss = 0.048602 (1.943 sec/batch), lr: 0.500000
2019-03-22 12:57:17,793 2019-03-22 12:57:17: step 326/50000, loss = 0.052752 (1.970 sec/batch), lr: 0.500000
2019-03-22 12:57:19,778 2019-03-22 12:57:19: step 327/50000, loss = 0.047417 (1.982 sec/batch), lr: 0.500000
2019-03-22 12:57:21,804 2019-03-22 12:57:21: step 328/50000, loss = 0.052454 (2.022 sec/batch), lr: 0.500000
2019-03-22 12:57:23,815 2019-03-22 12:57:23: step 329/50000, loss = 0.047921 (2.007 sec/batch), lr: 0.500000
2019-03-22 12:57:25,900 2019-03-22 12:57:25: step 330/50000, loss = 0.053147 (2.081 sec/batch), lr: 0.500000
2019-03-22 12:57:26,866 step 330: Full loss = 0.093939, Edge acc. = 0.9286
2019-03-22 12:57:28,768 2019-03-22 12:57:28: step 331/50000, loss = 0.046970 (1.896 sec/batch), lr: 0.500000
2019-03-22 12:57:30,885 2019-03-22 12:57:30: step 332/50000, loss = 0.052203 (2.112 sec/batch), lr: 0.500000
2019-03-22 12:57:32,923 2019-03-22 12:57:32: step 333/50000, loss = 0.048428 (2.034 sec/batch), lr: 0.500000
2019-03-22 12:57:34,878 2019-03-22 12:57:34: step 334/50000, loss = 0.052662 (1.952 sec/batch), lr: 0.500000
2019-03-22 12:57:36,987 2019-03-22 12:57:36: step 335/50000, loss = 0.046828 (2.105 sec/batch), lr: 0.500000
2019-03-22 12:57:38,961 2019-03-22 12:57:38: step 336/50000, loss = 0.051749 (1.970 sec/batch), lr: 0.500000
2019-03-22 12:57:41,043 2019-03-22 12:57:41: step 337/50000, loss = 0.048271 (2.078 sec/batch), lr: 0.500000
2019-03-22 12:57:43,071 2019-03-22 12:57:43: step 338/50000, loss = 0.052409 (2.024 sec/batch), lr: 0.500000
2019-03-22 12:57:45,022 2019-03-22 12:57:45: step 339/50000, loss = 0.046874 (1.947 sec/batch), lr: 0.500000
2019-03-22 12:57:46,988 2019-03-22 12:57:46: step 340/50000, loss = 0.051974 (1.962 sec/batch), lr: 0.500000
2019-03-22 12:57:48,029 step 340: Full loss = 0.096375, Edge acc. = 0.9286
2019-03-22 12:57:49,877 2019-03-22 12:57:49: step 341/50000, loss = 0.048188 (1.842 sec/batch), lr: 0.500000
2019-03-22 12:57:51,914 2019-03-22 12:57:51: step 342/50000, loss = 0.052464 (2.032 sec/batch), lr: 0.500000
2019-03-22 12:57:53,928 2019-03-22 12:57:53: step 343/50000, loss = 0.046589 (2.011 sec/batch), lr: 0.500000
2019-03-22 12:57:55,996 2019-03-22 12:57:55: step 344/50000, loss = 0.052086 (2.064 sec/batch), lr: 0.500000
2019-03-22 12:57:58,025 2019-03-22 12:57:58: step 345/50000, loss = 0.047766 (2.025 sec/batch), lr: 0.500000
2019-03-22 12:58:00,085 2019-03-22 12:58:00: step 346/50000, loss = 0.052080 (2.056 sec/batch), lr: 0.500000
2019-03-22 12:58:02,051 2019-03-22 12:58:02: step 347/50000, loss = 0.047314 (1.962 sec/batch), lr: 0.500000
2019-03-22 12:58:04,032 2019-03-22 12:58:04: step 348/50000, loss = 0.051285 (1.977 sec/batch), lr: 0.500000
2019-03-22 12:58:06,096 2019-03-22 12:58:06: step 349/50000, loss = 0.047389 (2.060 sec/batch), lr: 0.500000
2019-03-22 12:58:08,105 2019-03-22 12:58:08: step 350/50000, loss = 0.051502 (2.006 sec/batch), lr: 0.500000
2019-03-22 12:58:09,110 step 350: Full loss = 0.094430, Edge acc. = 0.9286
2019-03-22 12:58:11,021 2019-03-22 12:58:11: step 351/50000, loss = 0.047215 (1.905 sec/batch), lr: 0.500000
2019-03-22 12:58:13,002 2019-03-22 12:58:12: step 352/50000, loss = 0.053042 (1.977 sec/batch), lr: 0.500000
2019-03-22 12:58:14,976 2019-03-22 12:58:14: step 353/50000, loss = 0.046470 (1.970 sec/batch), lr: 0.500000
2019-03-22 12:58:16,967 2019-03-22 12:58:16: step 354/50000, loss = 0.052096 (1.988 sec/batch), lr: 0.500000
2019-03-22 12:58:19,030 2019-03-22 12:58:19: step 355/50000, loss = 0.047189 (2.059 sec/batch), lr: 0.500000
2019-03-22 12:58:21,038 2019-03-22 12:58:21: step 356/50000, loss = 0.052706 (2.004 sec/batch), lr: 0.500000
2019-03-22 12:58:23,078 2019-03-22 12:58:23: step 357/50000, loss = 0.046368 (2.036 sec/batch), lr: 0.500000
2019-03-22 12:58:25,148 2019-03-22 12:58:25: step 358/50000, loss = 0.051892 (2.067 sec/batch), lr: 0.500000
2019-03-22 12:58:27,136 2019-03-22 12:58:27: step 359/50000, loss = 0.047063 (1.984 sec/batch), lr: 0.500000
2019-03-22 12:58:29,259 2019-03-22 12:58:29: step 360/50000, loss = 0.052552 (2.119 sec/batch), lr: 0.500000
2019-03-22 12:58:30,169 step 360: Full loss = 0.092425, Edge acc. = 0.9286
2019-03-22 12:58:32,169 2019-03-22 12:58:32: step 361/50000, loss = 0.046213 (1.993 sec/batch), lr: 0.500000
2019-03-22 12:58:34,243 2019-03-22 12:58:34: step 362/50000, loss = 0.051797 (2.071 sec/batch), lr: 0.500000
2019-03-22 12:58:36,210 2019-03-22 12:58:36: step 363/50000, loss = 0.047319 (1.962 sec/batch), lr: 0.500000
2019-03-22 12:58:38,195 2019-03-22 12:58:38: step 364/50000, loss = 0.052364 (1.982 sec/batch), lr: 0.500000
2019-03-22 12:58:40,320 2019-03-22 12:58:40: step 365/50000, loss = 0.046254 (2.121 sec/batch), lr: 0.500000
2019-03-22 12:58:42,341 2019-03-22 12:58:42: step 366/50000, loss = 0.051423 (2.017 sec/batch), lr: 0.500000
2019-03-22 12:58:44,324 2019-03-22 12:58:44: step 367/50000, loss = 0.047427 (1.979 sec/batch), lr: 0.500000
2019-03-22 12:58:46,398 2019-03-22 12:58:46: step 368/50000, loss = 0.052128 (2.071 sec/batch), lr: 0.500000
2019-03-22 12:58:48,322 2019-03-22 12:58:48: step 369/50000, loss = 0.046184 (1.920 sec/batch), lr: 0.500000
2019-03-22 12:58:50,322 2019-03-22 12:58:50: step 370/50000, loss = 0.052130 (1.996 sec/batch), lr: 0.500000
2019-03-22 12:58:51,332 step 370: Full loss = 0.093667, Edge acc. = 0.9286
2019-03-22 12:58:53,313 2019-03-22 12:58:53: step 371/50000, loss = 0.046833 (1.974 sec/batch), lr: 0.500000
2019-03-22 12:58:55,401 2019-03-22 12:58:55: step 372/50000, loss = 0.051635 (2.084 sec/batch), lr: 0.500000
2019-03-22 12:58:57,387 2019-03-22 12:58:57: step 373/50000, loss = 0.046901 (1.983 sec/batch), lr: 0.500000
2019-03-22 12:58:59,433 2019-03-22 12:58:59: step 374/50000, loss = 0.050768 (2.042 sec/batch), lr: 0.500000
2019-03-22 12:59:01,514 2019-03-22 12:59:01: step 375/50000, loss = 0.046805 (2.077 sec/batch), lr: 0.500000
2019-03-22 12:59:03,603 2019-03-22 12:59:03: step 376/50000, loss = 0.051148 (2.086 sec/batch), lr: 0.500000
2019-03-22 12:59:05,629 2019-03-22 12:59:05: step 377/50000, loss = 0.046518 (2.022 sec/batch), lr: 0.500000
2019-03-22 12:59:07,633 2019-03-22 12:59:07: step 378/50000, loss = 0.052436 (2.001 sec/batch), lr: 0.500000
2019-03-22 12:59:09,653 2019-03-22 12:59:09: step 379/50000, loss = 0.045533 (2.016 sec/batch), lr: 0.500000
2019-03-22 12:59:11,750 2019-03-22 12:59:11: step 380/50000, loss = 0.051945 (2.093 sec/batch), lr: 0.500000
2019-03-22 12:59:12,696 step 380: Full loss = 0.092933, Edge acc. = 0.9286
2019-03-22 12:59:14,639 2019-03-22 12:59:14: step 381/50000, loss = 0.046466 (1.936 sec/batch), lr: 0.500000
2019-03-22 12:59:16,606 2019-03-22 12:59:16: step 382/50000, loss = 0.052346 (1.963 sec/batch), lr: 0.500000
2019-03-22 12:59:18,719 2019-03-22 12:59:18: step 383/50000, loss = 0.045812 (2.110 sec/batch), lr: 0.500000
2019-03-22 12:59:20,731 2019-03-22 12:59:20: step 384/50000, loss = 0.050974 (2.008 sec/batch), lr: 0.500000
2019-03-22 12:59:22,741 2019-03-22 12:59:22: step 385/50000, loss = 0.047276 (2.006 sec/batch), lr: 0.500000
2019-03-22 12:59:24,856 2019-03-22 12:59:24: step 386/50000, loss = 0.051768 (2.111 sec/batch), lr: 0.500000
2019-03-22 12:59:26,903 2019-03-22 12:59:26: step 387/50000, loss = 0.045741 (2.043 sec/batch), lr: 0.500000
2019-03-22 12:59:28,923 2019-03-22 12:59:28: step 388/50000, loss = 0.051512 (2.017 sec/batch), lr: 0.500000
2019-03-22 12:59:31,001 2019-03-22 12:59:30: step 389/50000, loss = 0.046866 (2.074 sec/batch), lr: 0.500000
2019-03-22 12:59:33,053 2019-03-22 12:59:33: step 390/50000, loss = 0.051708 (2.048 sec/batch), lr: 0.500000
2019-03-22 12:59:33,998 step 390: Full loss = 0.091841, Edge acc. = 0.9286
2019-03-22 12:59:35,873 2019-03-22 12:59:35: step 391/50000, loss = 0.045921 (1.870 sec/batch), lr: 0.500000
2019-03-22 12:59:38,006 2019-03-22 12:59:38: step 392/50000, loss = 0.050789 (2.129 sec/batch), lr: 0.500000
2019-03-22 12:59:40,001 2019-03-22 12:59:39: step 393/50000, loss = 0.046867 (1.991 sec/batch), lr: 0.500000
2019-03-22 12:59:42,127 2019-03-22 12:59:42: step 394/50000, loss = 0.051653 (2.122 sec/batch), lr: 0.500000
2019-03-22 12:59:44,137 2019-03-22 12:59:44: step 395/50000, loss = 0.045682 (2.006 sec/batch), lr: 0.500000
2019-03-22 12:59:46,191 2019-03-22 12:59:46: step 396/50000, loss = 0.051611 (2.051 sec/batch), lr: 0.500000
2019-03-22 12:59:48,222 2019-03-22 12:59:48: step 397/50000, loss = 0.046328 (2.027 sec/batch), lr: 0.500000
2019-03-22 12:59:50,266 2019-03-22 12:59:50: step 398/50000, loss = 0.051787 (2.040 sec/batch), lr: 0.500000
2019-03-22 12:59:52,277 2019-03-22 12:59:52: step 399/50000, loss = 0.045347 (2.008 sec/batch), lr: 0.500000
2019-03-22 12:59:54,327 2019-03-22 12:59:54: step 400/50000, loss = 0.051045 (2.046 sec/batch), lr: 0.500000
2019-03-22 12:59:55,273 step 400: Full loss = 0.094587, Edge acc. = 0.9286
2019-03-22 12:59:57,180 2019-03-22 12:59:57: step 401/50000, loss = 0.047294 (1.901 sec/batch), lr: 0.500000
2019-03-22 12:59:59,183 2019-03-22 12:59:59: step 402/50000, loss = 0.051121 (1.998 sec/batch), lr: 0.500000
2019-03-22 13:00:01,226 2019-03-22 13:00:01: step 403/50000, loss = 0.045924 (2.040 sec/batch), lr: 0.500000
2019-03-22 13:00:03,194 2019-03-22 13:00:03: step 404/50000, loss = 0.050426 (1.963 sec/batch), lr: 0.500000
2019-03-22 13:00:05,254 2019-03-22 13:00:05: step 405/50000, loss = 0.046852 (2.056 sec/batch), lr: 0.500000
2019-03-22 13:00:07,211 2019-03-22 13:00:07: step 406/50000, loss = 0.050818 (1.954 sec/batch), lr: 0.500000
2019-03-22 13:00:09,269 2019-03-22 13:00:09: step 407/50000, loss = 0.046419 (2.055 sec/batch), lr: 0.500000
2019-03-22 13:00:11,257 2019-03-22 13:00:11: step 408/50000, loss = 0.050282 (1.984 sec/batch), lr: 0.500000
2019-03-22 13:00:13,217 2019-03-22 13:00:13: step 409/50000, loss = 0.046481 (1.956 sec/batch), lr: 0.500000
2019-03-22 13:00:15,274 2019-03-22 13:00:15: step 410/50000, loss = 0.050027 (2.053 sec/batch), lr: 0.500000
2019-03-22 13:00:16,238 step 410: Full loss = 0.092508, Edge acc. = 0.9643
2019-03-22 13:00:18,190 2019-03-22 13:00:18: step 411/50000, loss = 0.046254 (1.946 sec/batch), lr: 0.500000
2019-03-22 13:00:20,229 2019-03-22 13:00:20: step 412/50000, loss = 0.050298 (2.035 sec/batch), lr: 0.500000
2019-03-22 13:00:22,248 2019-03-22 13:00:22: step 413/50000, loss = 0.046294 (2.016 sec/batch), lr: 0.500000
2019-03-22 13:00:24,309 2019-03-22 13:00:24: step 414/50000, loss = 0.050356 (2.056 sec/batch), lr: 0.500000
2019-03-22 13:00:26,350 2019-03-22 13:00:26: step 415/50000, loss = 0.046124 (2.037 sec/batch), lr: 0.500000
2019-03-22 13:00:28,427 2019-03-22 13:00:28: step 416/50000, loss = 0.049809 (2.073 sec/batch), lr: 0.500000
2019-03-22 13:00:30,450 2019-03-22 13:00:30: step 417/50000, loss = 0.046041 (2.019 sec/batch), lr: 0.500000
2019-03-22 13:00:32,452 2019-03-22 13:00:32: step 418/50000, loss = 0.050551 (1.999 sec/batch), lr: 0.500000
2019-03-22 13:00:34,420 2019-03-22 13:00:34: step 419/50000, loss = 0.045868 (1.964 sec/batch), lr: 0.500000
2019-03-22 13:00:36,444 2019-03-22 13:00:36: step 420/50000, loss = 0.050101 (2.020 sec/batch), lr: 0.500000
2019-03-22 13:00:37,399 step 420: Full loss = 0.091781, Edge acc. = 0.9643
2019-03-22 13:00:39,385 2019-03-22 13:00:39: step 421/50000, loss = 0.045891 (1.980 sec/batch), lr: 0.500000
2019-03-22 13:00:41,387 2019-03-22 13:00:41: step 422/50000, loss = 0.050087 (1.998 sec/batch), lr: 0.500000
2019-03-22 13:00:43,440 2019-03-22 13:00:43: step 423/50000, loss = 0.045867 (2.049 sec/batch), lr: 0.500000
2019-03-22 13:00:45,582 2019-03-22 13:00:45: step 424/50000, loss = 0.051972 (2.139 sec/batch), lr: 0.500000
2019-03-22 13:00:47,508 2019-03-22 13:00:47: step 425/50000, loss = 0.045324 (1.922 sec/batch), lr: 0.500000
2019-03-22 13:00:49,563 2019-03-22 13:00:49: step 426/50000, loss = 0.050262 (2.052 sec/batch), lr: 0.500000
2019-03-22 13:00:51,549 2019-03-22 13:00:51: step 427/50000, loss = 0.046140 (1.982 sec/batch), lr: 0.500000
2019-03-22 13:00:53,667 2019-03-22 13:00:53: step 428/50000, loss = 0.051057 (2.115 sec/batch), lr: 0.500000
2019-03-22 13:00:55,623 2019-03-22 13:00:55: step 429/50000, loss = 0.045072 (1.952 sec/batch), lr: 0.500000
2019-03-22 13:00:57,639 2019-03-22 13:00:57: step 430/50000, loss = 0.051381 (2.013 sec/batch), lr: 0.500000
2019-03-22 13:00:58,634 step 430: Full loss = 0.091060, Edge acc. = 0.9643
2019-03-22 13:01:00,627 2019-03-22 13:01:00: step 431/50000, loss = 0.045530 (1.987 sec/batch), lr: 0.500000
2019-03-22 13:01:02,640 2019-03-22 13:01:02: step 432/50000, loss = 0.051748 (2.009 sec/batch), lr: 0.500000
2019-03-22 13:01:04,727 2019-03-22 13:01:04: step 433/50000, loss = 0.044640 (2.083 sec/batch), lr: 0.500000
2019-03-22 13:01:06,736 2019-03-22 13:01:06: step 434/50000, loss = 0.050846 (2.005 sec/batch), lr: 0.500000
2019-03-22 13:01:08,750 2019-03-22 13:01:08: step 435/50000, loss = 0.046394 (2.010 sec/batch), lr: 0.500000
2019-03-22 13:01:10,861 2019-03-22 13:01:10: step 436/50000, loss = 0.050993 (2.107 sec/batch), lr: 0.500000
2019-03-22 13:01:12,923 2019-03-22 13:01:12: step 437/50000, loss = 0.045170 (2.058 sec/batch), lr: 0.500000
2019-03-22 13:01:14,944 2019-03-22 13:01:14: step 438/50000, loss = 0.050320 (2.017 sec/batch), lr: 0.500000
2019-03-22 13:01:17,044 2019-03-22 13:01:17: step 439/50000, loss = 0.046528 (2.096 sec/batch), lr: 0.500000
2019-03-22 13:01:19,049 2019-03-22 13:01:19: step 440/50000, loss = 0.050855 (2.002 sec/batch), lr: 0.500000
2019-03-22 13:01:19,988 step 440: Full loss = 0.089917, Edge acc. = 0.9643
2019-03-22 13:01:21,901 2019-03-22 13:01:21: step 441/50000, loss = 0.044959 (1.906 sec/batch), lr: 0.500000
2019-03-22 13:01:23,975 2019-03-22 13:01:23: step 442/50000, loss = 0.051156 (2.070 sec/batch), lr: 0.500000
2019-03-22 13:01:25,945 2019-03-22 13:01:25: step 443/50000, loss = 0.045862 (1.966 sec/batch), lr: 0.500000
2019-03-22 13:01:28,054 2019-03-22 13:01:28: step 444/50000, loss = 0.050999 (2.106 sec/batch), lr: 0.500000
2019-03-22 13:01:30,064 2019-03-22 13:01:30: step 445/50000, loss = 0.044690 (2.006 sec/batch), lr: 0.500000
2019-03-22 13:01:32,142 2019-03-22 13:01:32: step 446/50000, loss = 0.050075 (2.074 sec/batch), lr: 0.500000
2019-03-22 13:01:34,118 2019-03-22 13:01:34: step 447/50000, loss = 0.047077 (1.972 sec/batch), lr: 0.500000
2019-03-22 13:01:36,241 2019-03-22 13:01:36: step 448/50000, loss = 0.050365 (2.120 sec/batch), lr: 0.500000
2019-03-22 13:01:38,234 2019-03-22 13:01:38: step 449/50000, loss = 0.045049 (1.989 sec/batch), lr: 0.500000
2019-03-22 13:01:40,227 2019-03-22 13:01:40: step 450/50000, loss = 0.051334 (1.989 sec/batch), lr: 0.500000
2019-03-22 13:01:41,207 step 450: Full loss = 0.091522, Edge acc. = 0.9286
2019-03-22 13:01:43,152 2019-03-22 13:01:43: step 451/50000, loss = 0.045761 (1.939 sec/batch), lr: 0.500000
2019-03-22 13:01:45,199 2019-03-22 13:01:45: step 452/50000, loss = 0.051046 (2.044 sec/batch), lr: 0.500000
2019-03-22 13:01:47,232 2019-03-22 13:01:47: step 453/50000, loss = 0.044423 (2.033 sec/batch), lr: 0.500000
2019-03-22 13:01:49,204 2019-03-22 13:01:49: step 454/50000, loss = 0.051651 (1.968 sec/batch), lr: 0.500000
2019-03-22 13:01:51,250 2019-03-22 13:01:51: step 455/50000, loss = 0.045575 (2.043 sec/batch), lr: 0.500000
2019-03-22 13:01:53,312 2019-03-22 13:01:53: step 456/50000, loss = 0.050631 (2.058 sec/batch), lr: 0.500000
2019-03-22 13:01:55,341 2019-03-22 13:01:55: step 457/50000, loss = 0.044578 (2.025 sec/batch), lr: 0.500000
2019-03-22 13:01:57,340 2019-03-22 13:01:57: step 458/50000, loss = 0.051821 (1.996 sec/batch), lr: 0.500000
2019-03-22 13:01:59,383 2019-03-22 13:01:59: step 459/50000, loss = 0.045253 (2.039 sec/batch), lr: 0.500000
2019-03-22 13:02:01,471 2019-03-22 13:02:01: step 460/50000, loss = 0.050872 (2.084 sec/batch), lr: 0.500000
2019-03-22 13:02:02,401 step 460: Full loss = 0.089021, Edge acc. = 0.9643
2019-03-22 13:02:04,422 2019-03-22 13:02:04: step 461/50000, loss = 0.044510 (2.015 sec/batch), lr: 0.500000
2019-03-22 13:02:06,357 2019-03-22 13:02:06: step 462/50000, loss = 0.051588 (1.931 sec/batch), lr: 0.500000
2019-03-22 13:02:08,493 2019-03-22 13:02:08: step 463/50000, loss = 0.045308 (2.132 sec/batch), lr: 0.500000
2019-03-22 13:02:10,360 2019-03-22 13:02:10: step 464/50000, loss = 0.051170 (1.863 sec/batch), lr: 0.500000
2019-03-22 13:02:12,373 2019-03-22 13:02:12: step 465/50000, loss = 0.044239 (2.009 sec/batch), lr: 0.500000
2019-03-22 13:02:14,420 2019-03-22 13:02:14: step 466/50000, loss = 0.052033 (2.044 sec/batch), lr: 0.500000
2019-03-22 13:02:16,422 2019-03-22 13:02:16: step 467/50000, loss = 0.044998 (1.997 sec/batch), lr: 0.500000
2019-03-22 13:02:18,446 2019-03-22 13:02:18: step 468/50000, loss = 0.050926 (2.020 sec/batch), lr: 0.500000
2019-03-22 13:02:20,482 2019-03-22 13:02:20: step 469/50000, loss = 0.044479 (2.032 sec/batch), lr: 0.500000
2019-03-22 13:02:22,519 2019-03-22 13:02:22: step 470/50000, loss = 0.050939 (2.034 sec/batch), lr: 0.500000
2019-03-22 13:02:23,458 step 470: Full loss = 0.090805, Edge acc. = 0.9286
2019-03-22 13:02:25,399 2019-03-22 13:02:25: step 471/50000, loss = 0.045403 (1.935 sec/batch), lr: 0.500000
2019-03-22 13:02:27,402 2019-03-22 13:02:27: step 472/50000, loss = 0.050717 (1.999 sec/batch), lr: 0.500000
2019-03-22 13:02:29,450 2019-03-22 13:02:29: step 473/50000, loss = 0.044642 (2.044 sec/batch), lr: 0.500000
2019-03-22 13:02:31,549 2019-03-22 13:02:31: step 474/50000, loss = 0.050142 (2.095 sec/batch), lr: 0.500000
2019-03-22 13:02:33,574 2019-03-22 13:02:33: step 475/50000, loss = 0.046237 (2.022 sec/batch), lr: 0.500000
2019-03-22 13:02:35,635 2019-03-22 13:02:35: step 476/50000, loss = 0.050352 (2.056 sec/batch), lr: 0.500000
2019-03-22 13:02:37,634 2019-03-22 13:02:37: step 477/50000, loss = 0.044619 (1.996 sec/batch), lr: 0.500000
2019-03-22 13:02:39,628 2019-03-22 13:02:39: step 478/50000, loss = 0.050251 (1.990 sec/batch), lr: 0.500000
2019-03-22 13:02:41,638 2019-03-22 13:02:41: step 479/50000, loss = 0.046001 (2.006 sec/batch), lr: 0.500000
2019-03-22 13:02:43,612 2019-03-22 13:02:43: step 480/50000, loss = 0.050440 (1.971 sec/batch), lr: 0.500000
2019-03-22 13:02:44,551 step 480: Full loss = 0.088664, Edge acc. = 0.9286
2019-03-22 13:02:46,480 2019-03-22 13:02:46: step 481/50000, loss = 0.044332 (1.923 sec/batch), lr: 0.500000
2019-03-22 13:02:48,519 2019-03-22 13:02:48: step 482/50000, loss = 0.049664 (2.035 sec/batch), lr: 0.500000
2019-03-22 13:02:50,557 2019-03-22 13:02:50: step 483/50000, loss = 0.046995 (2.034 sec/batch), lr: 0.500000
2019-03-22 13:02:52,601 2019-03-22 13:02:52: step 484/50000, loss = 0.049409 (2.040 sec/batch), lr: 0.500000
2019-03-22 13:02:54,653 2019-03-22 13:02:54: step 485/50000, loss = 0.044862 (2.048 sec/batch), lr: 0.500000
2019-03-22 13:02:56,718 2019-03-22 13:02:56: step 486/50000, loss = 0.050407 (2.061 sec/batch), lr: 0.500000
2019-03-22 13:02:58,686 2019-03-22 13:02:58: step 487/50000, loss = 0.045868 (1.964 sec/batch), lr: 0.500000
2019-03-22 13:03:00,766 2019-03-22 13:03:00: step 488/50000, loss = 0.049737 (2.076 sec/batch), lr: 0.500000
2019-03-22 13:03:02,772 2019-03-22 13:03:02: step 489/50000, loss = 0.045621 (2.003 sec/batch), lr: 0.500000
2019-03-22 13:03:04,776 2019-03-22 13:03:04: step 490/50000, loss = 0.048776 (2.000 sec/batch), lr: 0.500000
2019-03-22 13:03:05,801 step 490: Full loss = 0.091166, Edge acc. = 0.9286
2019-03-22 13:03:07,706 2019-03-22 13:03:07: step 491/50000, loss = 0.045583 (1.898 sec/batch), lr: 0.500000
2019-03-22 13:03:09,690 2019-03-22 13:03:09: step 492/50000, loss = 0.049193 (1.981 sec/batch), lr: 0.500000
2019-03-22 13:03:11,743 2019-03-22 13:03:11: step 493/50000, loss = 0.045592 (2.050 sec/batch), lr: 0.500000
2019-03-22 13:03:14,383 2019-03-22 13:03:14: step 494/50000, loss = 0.048779 (1.932 sec/batch), lr: 0.500000
2019-03-22 13:03:16,427 2019-03-22 13:03:16: step 495/50000, loss = 0.045243 (2.041 sec/batch), lr: 0.500000
2019-03-22 13:03:18,486 2019-03-22 13:03:18: step 496/50000, loss = 0.049208 (2.055 sec/batch), lr: 0.500000
2019-03-22 13:03:20,422 2019-03-22 13:03:20: step 497/50000, loss = 0.045219 (1.932 sec/batch), lr: 0.500000
2019-03-22 13:03:22,586 2019-03-22 13:03:22: step 498/50000, loss = 0.050348 (2.161 sec/batch), lr: 0.500000
2019-03-22 13:03:24,624 2019-03-22 13:03:24: step 499/50000, loss = 0.044113 (2.034 sec/batch), lr: 0.500000
2019-03-22 13:03:26,627 2019-03-22 13:03:26: step 500/50000, loss = 0.050300 (1.999 sec/batch), lr: 0.500000
2019-03-22 13:03:27,590 step 500: Full loss = 0.090861, Edge acc. = 0.9286
2019-03-22 13:03:29,555 2019-03-22 13:03:29: step 501/50000, loss = 0.045430 (1.958 sec/batch), lr: 0.500000
2019-03-22 13:03:31,528 2019-03-22 13:03:31: step 502/50000, loss = 0.050172 (1.969 sec/batch), lr: 0.500000
2019-03-22 13:03:33,625 2019-03-22 13:03:33: step 503/50000, loss = 0.044649 (2.094 sec/batch), lr: 0.500000
2019-03-22 13:03:35,608 2019-03-22 13:03:35: step 504/50000, loss = 0.048981 (1.978 sec/batch), lr: 0.500000
2019-03-22 13:03:37,702 2019-03-22 13:03:37: step 505/50000, loss = 0.046623 (2.091 sec/batch), lr: 0.500000
2019-03-22 13:03:39,645 2019-03-22 13:03:39: step 506/50000, loss = 0.049680 (1.939 sec/batch), lr: 0.500000
2019-03-22 13:03:41,628 2019-03-22 13:03:41: step 507/50000, loss = 0.044104 (1.980 sec/batch), lr: 0.500000
2019-03-22 13:03:43,660 2019-03-22 13:03:43: step 508/50000, loss = 0.050398 (2.028 sec/batch), lr: 0.500000
2019-03-22 13:03:45,705 2019-03-22 13:03:45: step 509/50000, loss = 0.045503 (2.042 sec/batch), lr: 0.500000
2019-03-22 13:03:47,692 2019-03-22 13:03:47: step 510/50000, loss = 0.050243 (1.983 sec/batch), lr: 0.500000
2019-03-22 13:03:48,707 step 510: Full loss = 0.087971, Edge acc. = 0.9643
2019-03-22 13:03:50,647 2019-03-22 13:03:50: step 511/50000, loss = 0.043985 (1.934 sec/batch), lr: 0.500000
2019-03-22 13:03:52,708 2019-03-22 13:03:52: step 512/50000, loss = 0.049955 (2.057 sec/batch), lr: 0.500000
2019-03-22 13:03:54,788 2019-03-22 13:03:54: step 513/50000, loss = 0.045675 (2.076 sec/batch), lr: 0.500000
2019-03-22 13:03:56,834 2019-03-22 13:03:56: step 514/50000, loss = 0.049700 (2.042 sec/batch), lr: 0.500000
2019-03-22 13:03:58,810 2019-03-22 13:03:58: step 515/50000, loss = 0.045531 (1.972 sec/batch), lr: 0.500000
2019-03-22 13:04:00,806 2019-03-22 13:04:00: step 516/50000, loss = 0.048466 (1.992 sec/batch), lr: 0.500000
2019-03-22 13:04:02,795 2019-03-22 13:04:02: step 517/50000, loss = 0.045565 (1.985 sec/batch), lr: 0.500000
2019-03-22 13:04:04,799 2019-03-22 13:04:04: step 518/50000, loss = 0.048473 (2.000 sec/batch), lr: 0.500000
2019-03-22 13:04:06,896 2019-03-22 13:04:06: step 519/50000, loss = 0.045408 (2.093 sec/batch), lr: 0.500000
2019-03-22 13:04:08,789 2019-03-22 13:04:08: step 520/50000, loss = 0.048542 (1.890 sec/batch), lr: 0.500000
2019-03-22 13:04:09,799 step 520: Full loss = 0.089972, Edge acc. = 0.9286
2019-03-22 13:04:11,667 2019-03-22 13:04:11: step 521/50000, loss = 0.044986 (1.862 sec/batch), lr: 0.500000
2019-03-22 13:04:13,809 2019-03-22 13:04:13: step 522/50000, loss = 0.048717 (2.137 sec/batch), lr: 0.500000
2019-03-22 13:04:15,794 2019-03-22 13:04:15: step 523/50000, loss = 0.045008 (1.981 sec/batch), lr: 0.500000
2019-03-22 13:04:17,873 2019-03-22 13:04:17: step 524/50000, loss = 0.050311 (2.075 sec/batch), lr: 0.500000
2019-03-22 13:04:19,930 2019-03-22 13:04:19: step 525/50000, loss = 0.044064 (2.053 sec/batch), lr: 0.500000
2019-03-22 13:04:21,943 2019-03-22 13:04:21: step 526/50000, loss = 0.050453 (2.009 sec/batch), lr: 0.500000
2019-03-22 13:04:23,941 2019-03-22 13:04:23: step 527/50000, loss = 0.044488 (1.994 sec/batch), lr: 0.500000
2019-03-22 13:04:25,948 2019-03-22 13:04:25: step 528/50000, loss = 0.050849 (2.003 sec/batch), lr: 0.500000
2019-03-22 13:04:27,981 2019-03-22 13:04:27: step 529/50000, loss = 0.044114 (2.029 sec/batch), lr: 0.500000
2019-03-22 13:04:30,077 2019-03-22 13:04:30: step 530/50000, loss = 0.050075 (2.092 sec/batch), lr: 0.500000
2019-03-22 13:04:31,017 step 530: Full loss = 0.089290, Edge acc. = 0.9286
2019-03-22 13:04:32,980 2019-03-22 13:04:32: step 531/50000, loss = 0.044645 (1.956 sec/batch), lr: 0.500000
2019-03-22 13:04:34,989 2019-03-22 13:04:34: step 532/50000, loss = 0.050535 (2.005 sec/batch), lr: 0.500000
2019-03-22 13:04:37,091 2019-03-22 13:04:37: step 533/50000, loss = 0.043889 (2.098 sec/batch), lr: 0.500000
2019-03-22 13:04:39,168 2019-03-22 13:04:39: step 534/50000, loss = 0.049525 (2.073 sec/batch), lr: 0.500000
2019-03-22 13:04:41,210 2019-03-22 13:04:41: step 535/50000, loss = 0.045404 (2.039 sec/batch), lr: 0.500000
2019-03-22 13:04:43,260 2019-03-22 13:04:43: step 536/50000, loss = 0.049823 (2.046 sec/batch), lr: 0.500000
2019-03-22 13:04:45,304 2019-03-22 13:04:45: step 537/50000, loss = 0.044190 (2.040 sec/batch), lr: 0.500000
2019-03-22 13:04:47,307 2019-03-22 13:04:47: step 538/50000, loss = 0.049530 (1.999 sec/batch), lr: 0.500000
2019-03-22 13:04:49,348 2019-03-22 13:04:49: step 539/50000, loss = 0.045352 (2.038 sec/batch), lr: 0.500000
2019-03-22 13:04:51,379 2019-03-22 13:04:51: step 540/50000, loss = 0.049818 (2.028 sec/batch), lr: 0.500000
2019-03-22 13:04:52,376 step 540: Full loss = 0.087684, Edge acc. = 0.9286
2019-03-22 13:04:54,364 2019-03-22 13:04:54: step 541/50000, loss = 0.043842 (1.981 sec/batch), lr: 0.500000
2019-03-22 13:04:56,290 2019-03-22 13:04:56: step 542/50000, loss = 0.049719 (1.922 sec/batch), lr: 0.500000
2019-03-22 13:04:58,299 2019-03-22 13:04:58: step 543/50000, loss = 0.045390 (2.006 sec/batch), lr: 0.500000
2019-03-22 13:05:00,320 2019-03-22 13:05:00: step 544/50000, loss = 0.049826 (2.017 sec/batch), lr: 0.500000
2019-03-22 13:05:02,376 2019-03-22 13:05:02: step 545/50000, loss = 0.043672 (2.052 sec/batch), lr: 0.500000
2019-03-22 13:05:04,418 2019-03-22 13:05:04: step 546/50000, loss = 0.049652 (2.038 sec/batch), lr: 0.500000
2019-03-22 13:05:06,412 2019-03-22 13:05:06: step 547/50000, loss = 0.045492 (1.990 sec/batch), lr: 0.500000
2019-03-22 13:05:08,391 2019-03-22 13:05:08: step 548/50000, loss = 0.049675 (1.975 sec/batch), lr: 0.500000
2019-03-22 13:05:10,464 2019-03-22 13:05:10: step 549/50000, loss = 0.043721 (2.070 sec/batch), lr: 0.500000
2019-03-22 13:05:12,396 2019-03-22 13:05:12: step 550/50000, loss = 0.049618 (1.928 sec/batch), lr: 0.500000
2019-03-22 13:05:13,346 step 550: Full loss = 0.089870, Edge acc. = 0.9286
2019-03-22 13:05:15,302 2019-03-22 13:05:15: step 551/50000, loss = 0.044935 (1.949 sec/batch), lr: 0.500000
2019-03-22 13:05:17,330 2019-03-22 13:05:17: step 552/50000, loss = 0.049353 (2.024 sec/batch), lr: 0.500000
2019-03-22 13:05:19,300 2019-03-22 13:05:19: step 553/50000, loss = 0.044912 (1.966 sec/batch), lr: 0.500000
2019-03-22 13:05:21,447 2019-03-22 13:05:21: step 554/50000, loss = 0.048536 (2.143 sec/batch), lr: 0.500000
2019-03-22 13:05:23,427 2019-03-22 13:05:23: step 555/50000, loss = 0.044734 (1.976 sec/batch), lr: 0.500000
2019-03-22 13:05:25,450 2019-03-22 13:05:25: step 556/50000, loss = 0.048662 (2.019 sec/batch), lr: 0.500000
2019-03-22 13:05:27,541 2019-03-22 13:05:27: step 557/50000, loss = 0.044686 (2.087 sec/batch), lr: 0.500000
2019-03-22 13:05:29,553 2019-03-22 13:05:29: step 558/50000, loss = 0.048231 (2.009 sec/batch), lr: 0.500000
2019-03-22 13:05:31,563 2019-03-22 13:05:31: step 559/50000, loss = 0.044775 (2.005 sec/batch), lr: 0.500000
2019-03-22 13:05:33,557 2019-03-22 13:05:33: step 560/50000, loss = 0.050509 (1.990 sec/batch), lr: 0.500000
2019-03-22 13:05:34,504 step 560: Full loss = 0.087445, Edge acc. = 0.9286
2019-03-22 13:05:36,432 2019-03-22 13:05:36: step 561/50000, loss = 0.043722 (1.922 sec/batch), lr: 0.500000
2019-03-22 13:05:38,434 2019-03-22 13:05:38: step 562/50000, loss = 0.049355 (1.999 sec/batch), lr: 0.500000
2019-03-22 13:05:40,455 2019-03-22 13:05:40: step 563/50000, loss = 0.045447 (2.016 sec/batch), lr: 0.500000
2019-03-22 13:05:42,467 2019-03-22 13:05:42: step 564/50000, loss = 0.049309 (2.008 sec/batch), lr: 0.500000
2019-03-22 13:05:44,525 2019-03-22 13:05:44: step 565/50000, loss = 0.044294 (2.054 sec/batch), lr: 0.500000
2019-03-22 13:05:46,669 2019-03-22 13:05:46: step 566/50000, loss = 0.048429 (2.140 sec/batch), lr: 0.500000
2019-03-22 13:05:48,745 2019-03-22 13:05:48: step 567/50000, loss = 0.046166 (2.072 sec/batch), lr: 0.500000
2019-03-22 13:05:50,749 2019-03-22 13:05:50: step 568/50000, loss = 0.048478 (2.001 sec/batch), lr: 0.500000
2019-03-22 13:05:52,755 2019-03-22 13:05:52: step 569/50000, loss = 0.044174 (2.002 sec/batch), lr: 0.500000
2019-03-22 13:05:54,786 2019-03-22 13:05:54: step 570/50000, loss = 0.049361 (2.027 sec/batch), lr: 0.500000
2019-03-22 13:05:55,756 step 570: Full loss = 0.089901, Edge acc. = 1.0000
2019-03-22 13:05:57,688 2019-03-22 13:05:57: step 571/50000, loss = 0.044950 (1.925 sec/batch), lr: 0.500000
2019-03-22 13:05:59,663 2019-03-22 13:05:59: step 572/50000, loss = 0.049479 (1.971 sec/batch), lr: 0.500000
2019-03-22 13:06:01,746 2019-03-22 13:06:01: step 573/50000, loss = 0.043564 (2.079 sec/batch), lr: 0.500000
2019-03-22 13:06:03,759 2019-03-22 13:06:03: step 574/50000, loss = 0.049254 (2.009 sec/batch), lr: 0.500000
2019-03-22 13:06:05,767 2019-03-22 13:06:05: step 575/50000, loss = 0.045546 (2.005 sec/batch), lr: 0.500000
2019-03-22 13:06:07,747 2019-03-22 13:06:07: step 576/50000, loss = 0.049033 (1.976 sec/batch), lr: 0.500000
2019-03-22 13:06:09,830 2019-03-22 13:06:09: step 577/50000, loss = 0.043721 (2.080 sec/batch), lr: 0.500000
2019-03-22 13:06:11,899 2019-03-22 13:06:11: step 578/50000, loss = 0.049531 (2.065 sec/batch), lr: 0.500000
2019-03-22 13:06:13,927 2019-03-22 13:06:13: step 579/50000, loss = 0.045006 (2.019 sec/batch), lr: 0.500000
2019-03-22 13:06:16,016 2019-03-22 13:06:16: step 580/50000, loss = 0.048972 (2.085 sec/batch), lr: 0.500000
2019-03-22 13:06:16,894 step 580: Full loss = 0.089138, Edge acc. = 1.0000
2019-03-22 13:06:18,805 2019-03-22 13:06:18: step 581/50000, loss = 0.044569 (1.905 sec/batch), lr: 0.500000
2019-03-22 13:06:20,858 2019-03-22 13:06:20: step 582/50000, loss = 0.048454 (2.049 sec/batch), lr: 0.500000
2019-03-22 13:06:22,912 2019-03-22 13:06:22: step 583/50000, loss = 0.044222 (2.050 sec/batch), lr: 0.500000
2019-03-22 13:06:24,940 2019-03-22 13:06:24: step 584/50000, loss = 0.048915 (2.024 sec/batch), lr: 0.500000
2019-03-22 13:06:27,018 2019-03-22 13:06:27: step 585/50000, loss = 0.044214 (2.075 sec/batch), lr: 0.500000
2019-03-22 13:06:29,065 2019-03-22 13:06:29: step 586/50000, loss = 0.048355 (2.043 sec/batch), lr: 0.500000
2019-03-22 13:06:31,065 2019-03-22 13:06:31: step 587/50000, loss = 0.044038 (1.996 sec/batch), lr: 0.500000
2019-03-22 13:06:33,066 2019-03-22 13:06:33: step 588/50000, loss = 0.049094 (1.997 sec/batch), lr: 0.500000
2019-03-22 13:06:35,055 2019-03-22 13:06:35: step 589/50000, loss = 0.044465 (1.985 sec/batch), lr: 0.500000
2019-03-22 13:06:37,057 2019-03-22 13:06:37: step 590/50000, loss = 0.048534 (1.999 sec/batch), lr: 0.500000
2019-03-22 13:06:38,018 step 590: Full loss = 0.088695, Edge acc. = 0.9643
2019-03-22 13:06:39,964 2019-03-22 13:06:39: step 591/50000, loss = 0.044348 (1.940 sec/batch), lr: 0.500000
2019-03-22 13:06:41,948 2019-03-22 13:06:41: step 592/50000, loss = 0.050103 (1.980 sec/batch), lr: 0.500000
2019-03-22 13:06:44,022 2019-03-22 13:06:44: step 593/50000, loss = 0.043110 (2.070 sec/batch), lr: 0.500000
2019-03-22 13:06:45,986 2019-03-22 13:06:45: step 594/50000, loss = 0.050198 (1.960 sec/batch), lr: 0.500000
2019-03-22 13:06:47,999 2019-03-22 13:06:47: step 595/50000, loss = 0.044060 (2.010 sec/batch), lr: 0.500000
2019-03-22 13:06:50,008 2019-03-22 13:06:50: step 596/50000, loss = 0.050070 (2.005 sec/batch), lr: 0.500000
2019-03-22 13:06:52,110 2019-03-22 13:06:52: step 597/50000, loss = 0.043928 (2.098 sec/batch), lr: 0.500000
2019-03-22 13:06:54,102 2019-03-22 13:06:54: step 598/50000, loss = 0.048314 (1.985 sec/batch), lr: 0.500000
2019-03-22 13:06:56,103 2019-03-22 13:06:56: step 599/50000, loss = 0.046052 (1.997 sec/batch), lr: 0.500000
2019-03-22 13:06:58,124 2019-03-22 13:06:58: step 600/50000, loss = 0.048803 (2.021 sec/batch), lr: 0.500000
2019-03-22 13:06:59,068 step 600: Full loss = 0.087656, Edge acc. = 0.9643
2019-03-22 13:07:01,073 2019-03-22 13:07:01: step 601/50000, loss = 0.043828 (1.999 sec/batch), lr: 0.250000
2019-03-22 13:07:03,017 2019-03-22 13:07:03: step 602/50000, loss = 0.041455 (1.941 sec/batch), lr: 0.250000
2019-03-22 13:07:05,055 2019-03-22 13:07:05: step 603/50000, loss = 0.041127 (2.033 sec/batch), lr: 0.250000
2019-03-22 13:07:07,096 2019-03-22 13:07:07: step 604/50000, loss = 0.042480 (2.038 sec/batch), lr: 0.250000
2019-03-22 13:07:09,098 2019-03-22 13:07:09: step 605/50000, loss = 0.040898 (1.997 sec/batch), lr: 0.250000
2019-03-22 13:07:11,117 2019-03-22 13:07:11: step 606/50000, loss = 0.042420 (2.016 sec/batch), lr: 0.250000
2019-03-22 13:07:13,129 2019-03-22 13:07:13: step 607/50000, loss = 0.040874 (2.007 sec/batch), lr: 0.250000
2019-03-22 13:07:15,163 2019-03-22 13:07:15: step 608/50000, loss = 0.042302 (2.031 sec/batch), lr: 0.250000
2019-03-22 13:07:17,225 2019-03-22 13:07:17: step 609/50000, loss = 0.040752 (2.058 sec/batch), lr: 0.250000
2019-03-22 13:07:19,309 2019-03-22 13:07:19: step 610/50000, loss = 0.042159 (2.081 sec/batch), lr: 0.250000
2019-03-22 13:07:20,247 step 610: Full loss = 0.081654, Edge acc. = 0.9286
2019-03-22 13:07:22,169 2019-03-22 13:07:22: step 611/50000, loss = 0.040827 (1.916 sec/batch), lr: 0.250000
2019-03-22 13:07:24,199 2019-03-22 13:07:24: step 612/50000, loss = 0.042174 (2.026 sec/batch), lr: 0.250000
2019-03-22 13:07:26,219 2019-03-22 13:07:26: step 613/50000, loss = 0.040688 (2.016 sec/batch), lr: 0.250000
2019-03-22 13:07:28,236 2019-03-22 13:07:28: step 614/50000, loss = 0.042187 (2.013 sec/batch), lr: 0.250000
2019-03-22 13:07:30,261 2019-03-22 13:07:30: step 615/50000, loss = 0.040737 (2.022 sec/batch), lr: 0.250000
2019-03-22 13:07:32,302 2019-03-22 13:07:32: step 616/50000, loss = 0.042175 (2.038 sec/batch), lr: 0.250000
2019-03-22 13:07:34,293 2019-03-22 13:07:34: step 617/50000, loss = 0.040625 (1.987 sec/batch), lr: 0.250000
2019-03-22 13:07:36,261 2019-03-22 13:07:36: step 618/50000, loss = 0.041995 (1.965 sec/batch), lr: 0.250000
2019-03-22 13:07:38,222 2019-03-22 13:07:38: step 619/50000, loss = 0.040747 (1.957 sec/batch), lr: 0.250000
2019-03-22 13:07:40,187 2019-03-22 13:07:40: step 620/50000, loss = 0.041955 (1.962 sec/batch), lr: 0.250000
2019-03-22 13:07:41,127 step 620: Full loss = 0.081320, Edge acc. = 0.9286
2019-03-22 13:07:43,127 2019-03-22 13:07:43: step 621/50000, loss = 0.040660 (1.993 sec/batch), lr: 0.250000
2019-03-22 13:07:45,123 2019-03-22 13:07:45: step 622/50000, loss = 0.042060 (1.992 sec/batch), lr: 0.250000
2019-03-22 13:07:47,051 2019-03-22 13:07:47: step 623/50000, loss = 0.040838 (1.924 sec/batch), lr: 0.250000
2019-03-22 13:07:49,012 2019-03-22 13:07:49: step 624/50000, loss = 0.041865 (1.958 sec/batch), lr: 0.250000
2019-03-22 13:07:51,084 2019-03-22 13:07:51: step 625/50000, loss = 0.040676 (2.068 sec/batch), lr: 0.250000
2019-03-22 13:07:53,078 2019-03-22 13:07:53: step 626/50000, loss = 0.041840 (1.991 sec/batch), lr: 0.250000
2019-03-22 13:07:55,164 2019-03-22 13:07:55: step 627/50000, loss = 0.040623 (2.082 sec/batch), lr: 0.250000
2019-03-22 13:07:57,167 2019-03-22 13:07:57: step 628/50000, loss = 0.041965 (2.000 sec/batch), lr: 0.250000
2019-03-22 13:07:59,210 2019-03-22 13:07:59: step 629/50000, loss = 0.040915 (2.039 sec/batch), lr: 0.250000
2019-03-22 13:08:01,239 2019-03-22 13:08:01: step 630/50000, loss = 0.041769 (2.024 sec/batch), lr: 0.250000
2019-03-22 13:08:02,165 step 630: Full loss = 0.081437, Edge acc. = 0.9643
2019-03-22 13:08:04,111 2019-03-22 13:08:04: step 631/50000, loss = 0.040719 (1.940 sec/batch), lr: 0.250000
2019-03-22 13:08:06,092 2019-03-22 13:08:06: step 632/50000, loss = 0.041786 (1.978 sec/batch), lr: 0.250000
2019-03-22 13:08:08,064 2019-03-22 13:08:08: step 633/50000, loss = 0.040514 (1.968 sec/batch), lr: 0.250000
2019-03-22 13:08:10,113 2019-03-22 13:08:10: step 634/50000, loss = 0.041786 (2.045 sec/batch), lr: 0.250000
2019-03-22 13:08:12,124 2019-03-22 13:08:12: step 635/50000, loss = 0.040566 (2.007 sec/batch), lr: 0.250000
2019-03-22 13:08:14,103 2019-03-22 13:08:14: step 636/50000, loss = 0.041885 (1.975 sec/batch), lr: 0.250000
2019-03-22 13:08:16,258 2019-03-22 13:08:16: step 637/50000, loss = 0.040689 (2.151 sec/batch), lr: 0.250000
2019-03-22 13:08:18,304 2019-03-22 13:08:18: step 638/50000, loss = 0.041822 (2.042 sec/batch), lr: 0.250000
2019-03-22 13:08:20,279 2019-03-22 13:08:20: step 639/50000, loss = 0.040688 (1.971 sec/batch), lr: 0.250000
2019-03-22 13:08:22,370 2019-03-22 13:08:22: step 640/50000, loss = 0.041804 (2.087 sec/batch), lr: 0.250000
2019-03-22 13:08:23,347 step 640: Full loss = 0.081058, Edge acc. = 0.9643
2019-03-22 13:08:25,236 2019-03-22 13:08:25: step 641/50000, loss = 0.040529 (1.883 sec/batch), lr: 0.250000
2019-03-22 13:08:27,246 2019-03-22 13:08:27: step 642/50000, loss = 0.041700 (2.006 sec/batch), lr: 0.250000
2019-03-22 13:08:29,230 2019-03-22 13:08:29: step 643/50000, loss = 0.040687 (1.980 sec/batch), lr: 0.250000
2019-03-22 13:08:31,227 2019-03-22 13:08:31: step 644/50000, loss = 0.041732 (1.993 sec/batch), lr: 0.250000
2019-03-22 13:08:33,380 2019-03-22 13:08:33: step 645/50000, loss = 0.040726 (2.150 sec/batch), lr: 0.250000
2019-03-22 13:08:35,353 2019-03-22 13:08:35: step 646/50000, loss = 0.041703 (1.969 sec/batch), lr: 0.250000
2019-03-22 13:08:37,369 2019-03-22 13:08:37: step 647/50000, loss = 0.040752 (2.012 sec/batch), lr: 0.250000
2019-03-22 13:08:39,313 2019-03-22 13:08:39: step 648/50000, loss = 0.041556 (1.941 sec/batch), lr: 0.250000
2019-03-22 13:08:41,405 2019-03-22 13:08:41: step 649/50000, loss = 0.040528 (2.086 sec/batch), lr: 0.250000
2019-03-22 13:08:43,398 2019-03-22 13:08:43: step 650/50000, loss = 0.041778 (1.988 sec/batch), lr: 0.250000
2019-03-22 13:08:44,394 step 650: Full loss = 0.081393, Edge acc. = 0.9643
2019-03-22 13:08:46,282 2019-03-22 13:08:46: step 651/50000, loss = 0.040697 (1.885 sec/batch), lr: 0.250000
2019-03-22 13:08:48,253 2019-03-22 13:08:48: step 652/50000, loss = 0.041786 (1.967 sec/batch), lr: 0.250000
2019-03-22 13:08:50,240 2019-03-22 13:08:50: step 653/50000, loss = 0.040771 (1.983 sec/batch), lr: 0.250000
2019-03-22 13:08:52,282 2019-03-22 13:08:52: step 654/50000, loss = 0.041511 (2.039 sec/batch), lr: 0.250000
2019-03-22 13:08:54,335 2019-03-22 13:08:54: step 655/50000, loss = 0.040518 (2.048 sec/batch), lr: 0.250000
2019-03-22 13:08:56,357 2019-03-22 13:08:56: step 656/50000, loss = 0.041650 (2.018 sec/batch), lr: 0.250000
2019-03-22 13:08:58,384 2019-03-22 13:08:58: step 657/50000, loss = 0.040576 (2.024 sec/batch), lr: 0.250000
2019-03-22 13:09:00,404 2019-03-22 13:09:00: step 658/50000, loss = 0.041651 (2.016 sec/batch), lr: 0.250000
2019-03-22 13:09:02,438 2019-03-22 13:09:02: step 659/50000, loss = 0.040644 (2.030 sec/batch), lr: 0.250000
2019-03-22 13:09:04,401 2019-03-22 13:09:04: step 660/50000, loss = 0.041609 (1.959 sec/batch), lr: 0.250000
2019-03-22 13:09:05,421 step 660: Full loss = 0.081301, Edge acc. = 0.9643
2019-03-22 13:09:07,245 2019-03-22 13:09:07: step 661/50000, loss = 0.040651 (1.817 sec/batch), lr: 0.250000
2019-03-22 13:09:09,263 2019-03-22 13:09:09: step 662/50000, loss = 0.041496 (2.014 sec/batch), lr: 0.250000
2019-03-22 13:09:11,190 2019-03-22 13:09:11: step 663/50000, loss = 0.040530 (1.924 sec/batch), lr: 0.250000
2019-03-22 13:09:13,275 2019-03-22 13:09:13: step 664/50000, loss = 0.041730 (2.081 sec/batch), lr: 0.250000
2019-03-22 13:09:15,307 2019-03-22 13:09:15: step 665/50000, loss = 0.040584 (2.028 sec/batch), lr: 0.250000
2019-03-22 13:09:17,325 2019-03-22 13:09:17: step 666/50000, loss = 0.041616 (2.015 sec/batch), lr: 0.250000
2019-03-22 13:09:19,299 2019-03-22 13:09:19: step 667/50000, loss = 0.040518 (1.970 sec/batch), lr: 0.250000
2019-03-22 13:09:21,292 2019-03-22 13:09:21: step 668/50000, loss = 0.041527 (1.989 sec/batch), lr: 0.250000
2019-03-22 13:09:23,326 2019-03-22 13:09:23: step 669/50000, loss = 0.040757 (2.030 sec/batch), lr: 0.250000
2019-03-22 13:09:25,347 2019-03-22 13:09:25: step 670/50000, loss = 0.041459 (2.017 sec/batch), lr: 0.250000
2019-03-22 13:09:26,350 step 670: Full loss = 0.081421, Edge acc. = 0.9643
2019-03-22 13:09:28,264 2019-03-22 13:09:28: step 671/50000, loss = 0.040710 (1.908 sec/batch), lr: 0.250000
2019-03-22 13:09:30,235 2019-03-22 13:09:30: step 672/50000, loss = 0.041427 (1.967 sec/batch), lr: 0.250000
2019-03-22 13:09:32,320 2019-03-22 13:09:32: step 673/50000, loss = 0.040585 (2.081 sec/batch), lr: 0.250000
2019-03-22 13:09:34,298 2019-03-22 13:09:34: step 674/50000, loss = 0.041571 (1.974 sec/batch), lr: 0.250000
2019-03-22 13:09:36,326 2019-03-22 13:09:36: step 675/50000, loss = 0.040669 (2.025 sec/batch), lr: 0.250000
2019-03-22 13:09:38,323 2019-03-22 13:09:38: step 676/50000, loss = 0.041562 (1.993 sec/batch), lr: 0.250000
2019-03-22 13:09:40,321 2019-03-22 13:09:40: step 677/50000, loss = 0.040482 (1.995 sec/batch), lr: 0.250000
2019-03-22 13:09:42,255 2019-03-22 13:09:42: step 678/50000, loss = 0.041436 (1.930 sec/batch), lr: 0.250000
2019-03-22 13:09:44,238 2019-03-22 13:09:44: step 679/50000, loss = 0.040594 (1.979 sec/batch), lr: 0.250000
2019-03-22 13:09:46,238 2019-03-22 13:09:46: step 680/50000, loss = 0.041517 (1.996 sec/batch), lr: 0.250000
2019-03-22 13:09:47,235 step 680: Full loss = 0.080904, Edge acc. = 0.9643
2019-03-22 13:09:49,175 2019-03-22 13:09:49: step 681/50000, loss = 0.040452 (1.934 sec/batch), lr: 0.250000
2019-03-22 13:09:51,182 2019-03-22 13:09:51: step 682/50000, loss = 0.041551 (2.003 sec/batch), lr: 0.250000
2019-03-22 13:09:53,166 2019-03-22 13:09:53: step 683/50000, loss = 0.040613 (1.980 sec/batch), lr: 0.250000
2019-03-22 13:09:55,173 2019-03-22 13:09:55: step 684/50000, loss = 0.041389 (2.003 sec/batch), lr: 0.250000
2019-03-22 13:09:57,197 2019-03-22 13:09:57: step 685/50000, loss = 0.040575 (2.021 sec/batch), lr: 0.250000
2019-03-22 13:09:59,170 2019-03-22 13:09:59: step 686/50000, loss = 0.041436 (1.969 sec/batch), lr: 0.250000
2019-03-22 13:10:01,308 2019-03-22 13:10:01: step 687/50000, loss = 0.040501 (2.134 sec/batch), lr: 0.250000
2019-03-22 13:10:03,538 2019-03-22 13:10:03: step 688/50000, loss = 0.041457 (2.226 sec/batch), lr: 0.250000
2019-03-22 13:10:05,809 2019-03-22 13:10:05: step 689/50000, loss = 0.040457 (2.268 sec/batch), lr: 0.250000
2019-03-22 13:10:08,047 2019-03-22 13:10:08: step 690/50000, loss = 0.041513 (2.228 sec/batch), lr: 0.250000
2019-03-22 13:10:09,210 step 690: Full loss = 0.080684, Edge acc. = 0.9643
2019-03-22 13:10:11,358 2019-03-22 13:10:11: step 691/50000, loss = 0.040342 (2.142 sec/batch), lr: 0.250000
2019-03-22 13:10:13,567 2019-03-22 13:10:13: step 692/50000, loss = 0.041479 (2.205 sec/batch), lr: 0.250000
2019-03-22 13:10:15,842 2019-03-22 13:10:15: step 693/50000, loss = 0.040416 (2.271 sec/batch), lr: 0.250000
2019-03-22 13:10:17,998 2019-03-22 13:10:17: step 694/50000, loss = 0.041679 (2.153 sec/batch), lr: 0.250000
2019-03-22 13:10:20,212 2019-03-22 13:10:20: step 695/50000, loss = 0.040411 (2.210 sec/batch), lr: 0.250000
2019-03-22 13:10:22,399 2019-03-22 13:10:22: step 696/50000, loss = 0.041511 (2.184 sec/batch), lr: 0.250000
2019-03-22 13:10:24,610 2019-03-22 13:10:24: step 697/50000, loss = 0.040511 (2.207 sec/batch), lr: 0.250000
2019-03-22 13:10:26,790 2019-03-22 13:10:26: step 698/50000, loss = 0.041428 (2.176 sec/batch), lr: 0.250000
2019-03-22 13:10:28,792 2019-03-22 13:10:28: step 699/50000, loss = 0.040431 (1.998 sec/batch), lr: 0.250000
2019-03-22 13:10:30,783 2019-03-22 13:10:30: step 700/50000, loss = 0.041416 (1.987 sec/batch), lr: 0.250000
2019-03-22 13:10:31,680 step 700: Full loss = 0.080564, Edge acc. = 0.9643
2019-03-22 13:10:33,664 2019-03-22 13:10:33: step 701/50000, loss = 0.040282 (1.977 sec/batch), lr: 0.250000
2019-03-22 13:10:35,722 2019-03-22 13:10:35: step 702/50000, loss = 0.041560 (2.055 sec/batch), lr: 0.250000
2019-03-22 13:10:37,711 2019-03-22 13:10:37: step 703/50000, loss = 0.040320 (1.985 sec/batch), lr: 0.250000
2019-03-22 13:10:39,760 2019-03-22 13:10:39: step 704/50000, loss = 0.042001 (2.045 sec/batch), lr: 0.250000
2019-03-22 13:10:41,757 2019-03-22 13:10:41: step 705/50000, loss = 0.040283 (1.993 sec/batch), lr: 0.250000
2019-03-22 13:10:43,762 2019-03-22 13:10:43: step 706/50000, loss = 0.041520 (2.001 sec/batch), lr: 0.250000
2019-03-22 13:10:45,861 2019-03-22 13:10:45: step 707/50000, loss = 0.040388 (2.095 sec/batch), lr: 0.250000
2019-03-22 13:10:47,827 2019-03-22 13:10:47: step 708/50000, loss = 0.041502 (1.962 sec/batch), lr: 0.250000
2019-03-22 13:10:49,823 2019-03-22 13:10:49: step 709/50000, loss = 0.040491 (1.992 sec/batch), lr: 0.250000
2019-03-22 13:10:51,786 2019-03-22 13:10:51: step 710/50000, loss = 0.041488 (1.959 sec/batch), lr: 0.250000
2019-03-22 13:10:52,732 step 710: Full loss = 0.080707, Edge acc. = 0.9643
2019-03-22 13:10:54,623 2019-03-22 13:10:54: step 711/50000, loss = 0.040354 (1.885 sec/batch), lr: 0.250000
2019-03-22 13:10:56,601 2019-03-22 13:10:56: step 712/50000, loss = 0.041350 (1.974 sec/batch), lr: 0.250000
2019-03-22 13:10:58,598 2019-03-22 13:10:58: step 713/50000, loss = 0.040344 (1.994 sec/batch), lr: 0.250000
2019-03-22 13:11:00,630 2019-03-22 13:11:00: step 714/50000, loss = 0.041882 (2.028 sec/batch), lr: 0.250000
2019-03-22 13:11:02,605 2019-03-22 13:11:02: step 715/50000, loss = 0.040054 (1.971 sec/batch), lr: 0.250000
2019-03-22 13:11:04,583 2019-03-22 13:11:04: step 716/50000, loss = 0.041628 (1.975 sec/batch), lr: 0.250000
2019-03-22 13:11:06,548 2019-03-22 13:11:06: step 717/50000, loss = 0.040334 (1.961 sec/batch), lr: 0.250000
2019-03-22 13:11:08,597 2019-03-22 13:11:08: step 718/50000, loss = 0.041814 (2.045 sec/batch), lr: 0.250000
2019-03-22 13:11:10,671 2019-03-22 13:11:10: step 719/50000, loss = 0.040254 (2.071 sec/batch), lr: 0.250000
2019-03-22 13:11:12,665 2019-03-22 13:11:12: step 720/50000, loss = 0.041915 (1.990 sec/batch), lr: 0.250000
2019-03-22 13:11:13,659 step 720: Full loss = 0.080076, Edge acc. = 0.9643
2019-03-22 13:11:15,579 2019-03-22 13:11:15: step 721/50000, loss = 0.040038 (1.914 sec/batch), lr: 0.250000
2019-03-22 13:11:17,587 2019-03-22 13:11:17: step 722/50000, loss = 0.041636 (2.004 sec/batch), lr: 0.250000
2019-03-22 13:11:19,595 2019-03-22 13:11:19: step 723/50000, loss = 0.040406 (2.005 sec/batch), lr: 0.250000
2019-03-22 13:11:21,565 2019-03-22 13:11:21: step 724/50000, loss = 0.041773 (1.967 sec/batch), lr: 0.250000
2019-03-22 13:11:23,519 2019-03-22 13:11:23: step 725/50000, loss = 0.039985 (1.950 sec/batch), lr: 0.250000
2019-03-22 13:11:25,551 2019-03-22 13:11:25: step 726/50000, loss = 0.041753 (2.027 sec/batch), lr: 0.250000
2019-03-22 13:11:27,515 2019-03-22 13:11:27: step 727/50000, loss = 0.040344 (1.960 sec/batch), lr: 0.250000
2019-03-22 13:11:29,559 2019-03-22 13:11:29: step 728/50000, loss = 0.041900 (2.041 sec/batch), lr: 0.250000
2019-03-22 13:11:31,613 2019-03-22 13:11:31: step 729/50000, loss = 0.039929 (2.050 sec/batch), lr: 0.250000
2019-03-22 13:11:33,611 2019-03-22 13:11:33: step 730/50000, loss = 0.041692 (1.994 sec/batch), lr: 0.250000
2019-03-22 13:11:34,555 step 730: Full loss = 0.080730, Edge acc. = 0.9643
2019-03-22 13:11:36,414 2019-03-22 13:11:36: step 731/50000, loss = 0.040365 (1.853 sec/batch), lr: 0.250000
2019-03-22 13:11:38,354 2019-03-22 13:11:38: step 732/50000, loss = 0.041579 (1.935 sec/batch), lr: 0.250000
2019-03-22 13:11:40,537 2019-03-22 13:11:40: step 733/50000, loss = 0.040216 (2.179 sec/batch), lr: 0.250000
2019-03-22 13:11:42,547 2019-03-22 13:11:42: step 734/50000, loss = 0.041878 (2.006 sec/batch), lr: 0.250000
2019-03-22 13:11:44,527 2019-03-22 13:11:44: step 735/50000, loss = 0.039947 (1.976 sec/batch), lr: 0.250000
2019-03-22 13:12:22,270 2019-03-22 13:12:22: step 1/50000, loss = 0.477961 (1.940 sec/batch), lr: 1.000000
2019-03-22 13:12:24,327 2019-03-22 13:12:24: step 2/50000, loss = 0.485306 (2.052 sec/batch), lr: 1.000000
2019-03-22 13:12:26,334 2019-03-22 13:12:26: step 3/50000, loss = 0.482536 (2.003 sec/batch), lr: 1.000000
2019-03-22 13:12:28,303 2019-03-22 13:12:28: step 4/50000, loss = 0.479265 (1.965 sec/batch), lr: 1.000000
2019-03-22 13:12:30,274 2019-03-22 13:12:30: step 5/50000, loss = 0.474763 (1.967 sec/batch), lr: 1.000000
2019-03-22 13:12:32,241 2019-03-22 13:12:32: step 6/50000, loss = 0.469349 (1.962 sec/batch), lr: 1.000000
2019-03-22 13:12:34,172 2019-03-22 13:12:34: step 7/50000, loss = 0.462302 (1.928 sec/batch), lr: 1.000000
2019-03-22 13:12:36,114 2019-03-22 13:12:36: step 8/50000, loss = 0.449353 (1.938 sec/batch), lr: 1.000000
2019-03-22 13:12:38,073 2019-03-22 13:12:38: step 9/50000, loss = 0.419134 (1.955 sec/batch), lr: 1.000000
2019-03-22 13:12:40,041 2019-03-22 13:12:40: step 10/50000, loss = 0.317714 (1.964 sec/batch), lr: 1.000000
2019-03-22 13:12:40,898 step 10: Full loss = 0.522863, Edge acc. = 0.1786
2019-03-22 13:12:42,822 2019-03-22 13:12:42: step 11/50000, loss = 0.261432 (1.917 sec/batch), lr: 1.000000
2019-03-22 13:12:44,789 2019-03-22 13:12:44: step 12/50000, loss = 0.410087 (1.963 sec/batch), lr: 1.000000
2019-03-22 13:12:46,692 2019-03-22 13:12:46: step 13/50000, loss = 0.221696 (1.899 sec/batch), lr: 1.000000
2019-03-22 13:12:48,677 2019-03-22 13:12:48: step 14/50000, loss = 0.383713 (1.981 sec/batch), lr: 1.000000
2019-03-22 13:12:50,665 2019-03-22 13:12:50: step 15/50000, loss = 0.357103 (1.985 sec/batch), lr: 1.000000
2019-03-22 13:12:52,659 2019-03-22 13:12:52: step 16/50000, loss = 0.416568 (1.990 sec/batch), lr: 1.000000
2019-03-22 13:12:54,718 2019-03-22 13:12:54: step 17/50000, loss = 0.197211 (2.055 sec/batch), lr: 1.000000
2019-03-22 13:12:56,655 2019-03-22 13:12:56: step 18/50000, loss = 0.280224 (1.933 sec/batch), lr: 1.000000
2019-03-22 13:12:58,646 2019-03-22 13:12:58: step 19/50000, loss = 0.187007 (1.988 sec/batch), lr: 1.000000
2019-03-22 13:13:00,618 2019-03-22 13:13:00: step 20/50000, loss = 0.186047 (1.968 sec/batch), lr: 1.000000
2019-03-22 13:13:01,872 step 20: Full loss = 0.417785, Edge acc. = 0.2143
2019-03-22 13:13:03,749 2019-03-22 13:13:03: step 21/50000, loss = 0.208892 (1.870 sec/batch), lr: 1.000000
2019-03-22 13:13:05,730 2019-03-22 13:13:05: step 22/50000, loss = 0.168241 (1.977 sec/batch), lr: 1.000000
2019-03-22 13:13:07,722 2019-03-22 13:13:07: step 23/50000, loss = 0.370324 (1.987 sec/batch), lr: 1.000000
2019-03-22 13:13:09,682 2019-03-22 13:13:09: step 24/50000, loss = 0.163279 (1.956 sec/batch), lr: 1.000000
2019-03-22 13:13:11,623 2019-03-22 13:13:11: step 25/50000, loss = 0.183479 (1.937 sec/batch), lr: 1.000000
2019-03-22 13:13:13,611 2019-03-22 13:13:13: step 26/50000, loss = 0.252912 (1.985 sec/batch), lr: 1.000000
2019-03-22 13:13:15,580 2019-03-22 13:13:15: step 27/50000, loss = 0.318762 (1.965 sec/batch), lr: 1.000000
2019-03-22 13:13:17,604 2019-03-22 13:13:17: step 28/50000, loss = 0.195183 (2.020 sec/batch), lr: 1.000000
2019-03-22 13:13:19,491 2019-03-22 13:13:19: step 29/50000, loss = 0.308675 (1.884 sec/batch), lr: 1.000000
2019-03-22 13:13:21,502 2019-03-22 13:13:21: step 30/50000, loss = 0.178916 (2.006 sec/batch), lr: 1.000000
2019-03-22 13:13:22,471 step 30: Full loss = 0.582016, Edge acc. = 0.2500
2019-03-22 13:13:24,282 2019-03-22 13:13:24: step 31/50000, loss = 0.291008 (1.806 sec/batch), lr: 1.000000
2019-03-22 13:13:26,205 2019-03-22 13:13:26: step 32/50000, loss = 0.174030 (1.919 sec/batch), lr: 1.000000
2019-03-22 13:13:28,152 2019-03-22 13:13:28: step 33/50000, loss = 0.274207 (1.943 sec/batch), lr: 1.000000
2019-03-22 13:13:30,089 2019-03-22 13:13:30: step 34/50000, loss = 0.168446 (1.933 sec/batch), lr: 1.000000
2019-03-22 13:13:31,973 2019-03-22 13:13:31: step 35/50000, loss = 0.262891 (1.881 sec/batch), lr: 1.000000
2019-03-22 13:13:33,957 2019-03-22 13:13:33: step 36/50000, loss = 0.160429 (1.980 sec/batch), lr: 1.000000
2019-03-22 13:13:35,951 2019-03-22 13:13:35: step 37/50000, loss = 0.249313 (1.990 sec/batch), lr: 1.000000
2019-03-22 13:13:37,931 2019-03-22 13:13:37: step 38/50000, loss = 0.156501 (1.977 sec/batch), lr: 1.000000
2019-03-22 13:13:39,835 2019-03-22 13:13:39: step 39/50000, loss = 0.242578 (1.900 sec/batch), lr: 1.000000
2019-03-22 13:13:41,782 2019-03-22 13:13:41: step 40/50000, loss = 0.149531 (1.944 sec/batch), lr: 1.000000
2019-03-22 13:13:42,671 step 40: Full loss = 0.456853, Edge acc. = 0.3214
2019-03-22 13:13:44,603 2019-03-22 13:13:44: step 41/50000, loss = 0.228427 (1.926 sec/batch), lr: 1.000000
2019-03-22 13:13:46,526 2019-03-22 13:13:46: step 42/50000, loss = 0.143096 (1.919 sec/batch), lr: 1.000000
2019-03-22 13:13:48,565 2019-03-22 13:13:48: step 43/50000, loss = 0.222421 (2.035 sec/batch), lr: 1.000000
2019-03-22 13:13:50,489 2019-03-22 13:13:50: step 44/50000, loss = 0.136436 (1.920 sec/batch), lr: 1.000000
2019-03-22 13:13:52,453 2019-03-22 13:13:52: step 45/50000, loss = 0.213942 (1.960 sec/batch), lr: 1.000000
2019-03-22 13:13:54,403 2019-03-22 13:13:54: step 46/50000, loss = 0.131383 (1.946 sec/batch), lr: 1.000000
2019-03-22 13:13:56,330 2019-03-22 13:13:56: step 47/50000, loss = 0.207441 (1.923 sec/batch), lr: 1.000000
2019-03-22 13:13:58,338 2019-03-22 13:13:58: step 48/50000, loss = 0.125156 (2.004 sec/batch), lr: 1.000000
2019-03-22 13:14:00,322 2019-03-22 13:14:00: step 49/50000, loss = 0.196758 (1.980 sec/batch), lr: 1.000000
2019-03-22 13:14:02,268 2019-03-22 13:14:02: step 50/50000, loss = 0.121898 (1.939 sec/batch), lr: 1.000000
2019-03-22 13:14:03,179 step 50: Full loss = 0.388371, Edge acc. = 0.4643
2019-03-22 13:14:05,076 2019-03-22 13:14:05: step 51/50000, loss = 0.194185 (1.891 sec/batch), lr: 1.000000
2019-03-22 13:14:07,066 2019-03-22 13:14:07: step 52/50000, loss = 0.115180 (1.986 sec/batch), lr: 1.000000
2019-03-22 13:14:09,034 2019-03-22 13:14:09: step 53/50000, loss = 0.185400 (1.964 sec/batch), lr: 1.000000
2019-03-22 13:14:10,940 2019-03-22 13:14:10: step 54/50000, loss = 0.109623 (1.902 sec/batch), lr: 1.000000
2019-03-22 13:14:12,981 2019-03-22 13:14:12: step 55/50000, loss = 0.185008 (2.037 sec/batch), lr: 1.000000
2019-03-22 13:14:14,892 2019-03-22 13:14:14: step 56/50000, loss = 0.103654 (1.907 sec/batch), lr: 1.000000
2019-03-22 13:14:16,927 2019-03-22 13:14:16: step 57/50000, loss = 0.174180 (2.031 sec/batch), lr: 1.000000
2019-03-22 13:14:18,901 2019-03-22 13:14:18: step 58/50000, loss = 0.102490 (1.970 sec/batch), lr: 1.000000
2019-03-22 13:14:20,846 2019-03-22 13:14:20: step 59/50000, loss = 0.177782 (1.942 sec/batch), lr: 1.000000
2019-03-22 13:14:22,770 2019-03-22 13:14:22: step 60/50000, loss = 0.099051 (1.920 sec/batch), lr: 1.000000
2019-03-22 13:14:23,706 step 60: Full loss = 0.336049, Edge acc. = 0.6071
2019-03-22 13:14:25,579 2019-03-22 13:14:25: step 61/50000, loss = 0.168024 (1.867 sec/batch), lr: 1.000000
2019-03-22 13:14:27,471 2019-03-22 13:14:27: step 62/50000, loss = 0.094458 (1.889 sec/batch), lr: 1.000000
2019-03-22 13:14:29,449 2019-03-22 13:14:29: step 63/50000, loss = 0.174054 (1.974 sec/batch), lr: 1.000000
2019-03-22 13:14:31,405 2019-03-22 13:14:31: step 64/50000, loss = 0.091803 (1.952 sec/batch), lr: 1.000000
2019-03-22 13:14:33,396 2019-03-22 13:14:33: step 65/50000, loss = 0.163579 (1.988 sec/batch), lr: 1.000000
2019-03-22 13:14:35,323 2019-03-22 13:14:35: step 66/50000, loss = 0.088115 (1.923 sec/batch), lr: 1.000000
2019-03-22 13:14:37,330 2019-03-22 13:14:37: step 67/50000, loss = 0.161990 (2.003 sec/batch), lr: 1.000000
2019-03-22 13:14:39,302 2019-03-22 13:14:39: step 68/50000, loss = 0.085923 (1.968 sec/batch), lr: 1.000000
2019-03-22 13:14:41,268 2019-03-22 13:14:41: step 69/50000, loss = 0.157882 (1.963 sec/batch), lr: 1.000000
2019-03-22 13:14:43,215 2019-03-22 13:14:43: step 70/50000, loss = 0.083313 (1.943 sec/batch), lr: 1.000000
2019-03-22 13:14:44,132 step 70: Full loss = 0.329566, Edge acc. = 0.6786
2019-03-22 13:14:46,024 2019-03-22 13:14:46: step 71/50000, loss = 0.164783 (1.886 sec/batch), lr: 1.000000
2019-03-22 13:14:48,012 2019-03-22 13:14:48: step 72/50000, loss = 0.083774 (1.985 sec/batch), lr: 1.000000
2019-03-22 13:14:50,027 2019-03-22 13:14:50: step 73/50000, loss = 0.154107 (2.011 sec/batch), lr: 1.000000
2019-03-22 13:14:51,932 2019-03-22 13:14:51: step 74/50000, loss = 0.080241 (1.902 sec/batch), lr: 1.000000
2019-03-22 13:14:53,882 2019-03-22 13:14:53: step 75/50000, loss = 0.157355 (1.946 sec/batch), lr: 1.000000
2019-03-22 13:14:55,924 2019-03-22 13:14:55: step 76/50000, loss = 0.078385 (2.038 sec/batch), lr: 1.000000
2019-03-22 13:14:57,885 2019-03-22 13:14:57: step 77/50000, loss = 0.149188 (1.957 sec/batch), lr: 1.000000
2019-03-22 13:14:59,795 2019-03-22 13:14:59: step 78/50000, loss = 0.079084 (1.906 sec/batch), lr: 1.000000
2019-03-22 13:15:01,752 2019-03-22 13:15:01: step 79/50000, loss = 0.148637 (1.953 sec/batch), lr: 1.000000
2019-03-22 13:15:03,729 2019-03-22 13:15:03: step 80/50000, loss = 0.075642 (1.973 sec/batch), lr: 1.000000
2019-03-22 13:15:04,624 step 80: Full loss = 0.268083, Edge acc. = 0.6786
2019-03-22 13:15:06,578 2019-03-22 13:15:06: step 81/50000, loss = 0.134041 (1.948 sec/batch), lr: 1.000000
2019-03-22 13:15:08,524 2019-03-22 13:15:08: step 82/50000, loss = 0.093591 (1.942 sec/batch), lr: 1.000000
2019-03-22 13:15:10,489 2019-03-22 13:15:10: step 83/50000, loss = 0.134375 (1.962 sec/batch), lr: 1.000000
2019-03-22 13:15:12,430 2019-03-22 13:15:12: step 84/50000, loss = 0.079520 (1.937 sec/batch), lr: 1.000000
2019-03-22 13:15:14,426 2019-03-22 13:15:14: step 85/50000, loss = 0.148218 (1.992 sec/batch), lr: 1.000000
2019-03-22 13:15:16,416 2019-03-22 13:15:16: step 86/50000, loss = 0.076435 (1.986 sec/batch), lr: 1.000000
2019-03-22 13:15:18,369 2019-03-22 13:15:18: step 87/50000, loss = 0.141311 (1.949 sec/batch), lr: 1.000000
2019-03-22 13:15:20,364 2019-03-22 13:15:20: step 88/50000, loss = 0.075499 (1.991 sec/batch), lr: 1.000000
2019-03-22 13:15:22,261 2019-03-22 13:15:22: step 89/50000, loss = 0.143110 (1.893 sec/batch), lr: 1.000000
2019-03-22 13:15:24,220 2019-03-22 13:15:24: step 90/50000, loss = 0.073472 (1.955 sec/batch), lr: 1.000000
2019-03-22 13:15:25,112 step 90: Full loss = 0.270072, Edge acc. = 0.7143
2019-03-22 13:15:26,996 2019-03-22 13:15:26: step 91/50000, loss = 0.135036 (1.878 sec/batch), lr: 1.000000
2019-03-22 13:15:28,922 2019-03-22 13:15:28: step 92/50000, loss = 0.074782 (1.922 sec/batch), lr: 1.000000
2019-03-22 13:15:30,806 2019-03-22 13:15:30: step 93/50000, loss = 0.141911 (1.881 sec/batch), lr: 1.000000
2019-03-22 13:15:32,729 2019-03-22 13:15:32: step 94/50000, loss = 0.071642 (1.920 sec/batch), lr: 1.000000
2019-03-22 13:15:34,748 2019-03-22 13:15:34: step 95/50000, loss = 0.133154 (2.015 sec/batch), lr: 1.000000
2019-03-22 13:15:36,697 2019-03-22 13:15:36: step 96/50000, loss = 0.076163 (1.945 sec/batch), lr: 1.000000
2019-03-22 13:15:38,616 2019-03-22 13:15:38: step 97/50000, loss = 0.129165 (1.916 sec/batch), lr: 1.000000
2019-03-22 13:15:40,679 2019-03-22 13:15:40: step 98/50000, loss = 0.071541 (2.060 sec/batch), lr: 1.000000
2019-03-22 13:15:42,488 2019-03-22 13:15:42: step 99/50000, loss = 0.137354 (1.805 sec/batch), lr: 1.000000
2019-03-22 13:15:44,496 2019-03-22 13:15:44: step 100/50000, loss = 0.070604 (2.004 sec/batch), lr: 1.000000
2019-03-22 13:15:45,452 step 100: Full loss = 0.258732, Edge acc. = 0.7500
2019-03-22 13:15:47,347 2019-03-22 13:15:47: step 101/50000, loss = 0.129366 (1.889 sec/batch), lr: 0.500000
2019-03-22 13:16:39,066 2019-03-22 13:16:39: step 1/50000, loss = 0.477961 (1.941 sec/batch), lr: 1.000000
2019-03-22 13:16:41,212 2019-03-22 13:16:41: step 2/50000, loss = 0.485306 (2.142 sec/batch), lr: 1.000000
2019-03-22 13:16:43,128 2019-03-22 13:16:43: step 3/50000, loss = 0.482536 (1.913 sec/batch), lr: 1.000000
2019-03-22 13:16:45,120 2019-03-22 13:16:45: step 4/50000, loss = 0.479265 (1.987 sec/batch), lr: 1.000000
2019-03-22 13:16:47,125 2019-03-22 13:16:47: step 5/50000, loss = 0.474763 (2.001 sec/batch), lr: 1.000000
2019-03-22 13:16:49,118 2019-03-22 13:16:49: step 6/50000, loss = 0.469349 (1.988 sec/batch), lr: 1.000000
2019-03-22 13:16:51,115 2019-03-22 13:16:51: step 7/50000, loss = 0.462302 (1.993 sec/batch), lr: 1.000000
2019-03-22 13:16:53,056 2019-03-22 13:16:53: step 8/50000, loss = 0.449353 (1.937 sec/batch), lr: 1.000000
2019-03-22 13:16:55,188 2019-03-22 13:16:55: step 9/50000, loss = 0.419134 (2.128 sec/batch), lr: 1.000000
2019-03-22 13:16:57,126 2019-03-22 13:16:57: step 10/50000, loss = 0.317714 (1.934 sec/batch), lr: 1.000000
2019-03-22 13:16:58,043 step 10: Full loss = 0.522863, Edge acc. = 0.1786
2019-03-22 13:16:59,983 2019-03-22 13:16:59: step 11/50000, loss = 0.261432 (1.934 sec/batch), lr: 1.000000
2019-03-22 13:17:02,031 2019-03-22 13:17:02: step 12/50000, loss = 0.410087 (2.044 sec/batch), lr: 1.000000
2019-03-22 13:17:03,972 2019-03-22 13:17:03: step 13/50000, loss = 0.221696 (1.936 sec/batch), lr: 1.000000
2019-03-22 13:17:05,878 2019-03-22 13:17:05: step 14/50000, loss = 0.383713 (1.902 sec/batch), lr: 1.000000
2019-03-22 13:17:07,879 2019-03-22 13:17:07: step 15/50000, loss = 0.357103 (1.997 sec/batch), lr: 1.000000
2019-03-22 13:17:10,016 2019-03-22 13:17:10: step 16/50000, loss = 0.416568 (2.133 sec/batch), lr: 1.000000
2019-03-22 13:17:11,965 2019-03-22 13:17:11: step 17/50000, loss = 0.197211 (1.944 sec/batch), lr: 1.000000
2019-03-22 13:17:13,954 2019-03-22 13:17:13: step 18/50000, loss = 0.280224 (1.986 sec/batch), lr: 1.000000
2019-03-22 13:18:16,213 2019-03-22 13:18:16: step 1/50000, loss = 0.477961 (1.941 sec/batch), lr: 1.000000
2019-03-22 13:19:00,310 2019-03-22 13:19:00: step 1/50000, loss = 0.477961 (2.156 sec/batch), lr: 1.000000
2019-03-22 13:19:02,295 2019-03-22 13:19:02: step 2/50000, loss = 0.485306 (1.981 sec/batch), lr: 1.000000
2019-03-22 14:11:56,680 2019-03-22 14:11:56: step 1/50000, loss = 0.477961 (2.125 sec/batch), lr: 1.000000
2019-03-22 14:11:58,761 2019-03-22 14:11:58: step 2/50000, loss = 0.481246 (2.078 sec/batch), lr: 1.000000
2019-03-22 14:13:41,385 2019-03-22 14:13:41: step 1/50000, loss = 0.477961 (2.149 sec/batch), lr: 1.000000
2019-03-22 14:13:43,637 2019-03-22 14:13:43: step 2/50000, loss = 0.481246 (2.249 sec/batch), lr: 1.000000
2019-03-22 14:13:45,913 2019-03-22 14:13:45: step 3/50000, loss = 0.467547 (2.272 sec/batch), lr: 1.000000
2019-03-22 14:13:47,952 2019-03-22 14:13:47: step 4/50000, loss = 0.424445 (2.036 sec/batch), lr: 1.000000
2019-03-22 14:13:50,086 2019-03-22 14:13:50: step 5/50000, loss = 0.382073 (2.130 sec/batch), lr: 1.000000
2019-03-22 14:16:01,726 2019-03-22 14:16:01: step 1/50000, loss = 0.477961 (2.263 sec/batch), lr: 1.000000
2019-03-22 14:16:03,828 2019-03-22 14:16:03: step 2/50000, loss = 0.482616 (2.098 sec/batch), lr: 1.000000
2019-03-22 14:18:37,395 2019-03-22 14:18:37: step 1/50000, loss = 0.477961 (2.051 sec/batch), lr: 1.000000
2019-03-22 14:18:39,494 2019-03-22 14:18:39: step 2/50000, loss = 0.499408 (2.094 sec/batch), lr: 1.000000
2019-03-22 14:18:41,628 2019-03-22 14:18:41: step 3/50000, loss = 0.497135 (2.131 sec/batch), lr: 1.000000
2019-03-22 14:18:43,703 2019-03-22 14:18:43: step 4/50000, loss = 0.489081 (2.070 sec/batch), lr: 1.000000
2019-03-22 14:18:45,826 2019-03-22 14:18:45: step 5/50000, loss = 0.498142 (2.118 sec/batch), lr: 1.000000
2019-03-22 14:18:47,895 2019-03-22 14:18:47: step 6/50000, loss = 0.498219 (2.064 sec/batch), lr: 1.000000
2019-03-22 14:18:49,966 2019-03-22 14:18:49: step 7/50000, loss = 0.497408 (2.067 sec/batch), lr: 1.000000
2019-03-22 14:18:52,014 2019-03-22 14:18:52: step 8/50000, loss = 0.485851 (2.043 sec/batch), lr: 1.000000
2019-03-22 14:18:54,142 2019-03-22 14:18:54: step 9/50000, loss = 0.467376 (2.123 sec/batch), lr: 1.000000
2019-03-22 14:18:56,224 2019-03-22 14:18:56: step 10/50000, loss = 0.483372 (2.078 sec/batch), lr: 1.000000
2019-03-22 14:18:57,356 step 10: Full loss = 0.994317, Edge acc. = 0.1786
2019-03-22 14:18:59,395 2019-03-22 14:18:59: step 11/50000, loss = 0.497159 (2.032 sec/batch), lr: 1.000000
2019-03-22 14:19:01,491 2019-03-22 14:19:01: step 12/50000, loss = 0.445089 (2.091 sec/batch), lr: 1.000000
2019-03-22 14:19:03,605 2019-03-22 14:19:03: step 13/50000, loss = 0.493520 (2.110 sec/batch), lr: 1.000000
2019-03-22 14:19:05,618 2019-03-22 14:19:05: step 14/50000, loss = 0.442919 (2.011 sec/batch), lr: 1.000000
2019-03-22 14:19:07,623 2019-03-22 14:19:07: step 15/50000, loss = 0.360744 (2.002 sec/batch), lr: 1.000000
2019-03-22 14:19:09,646 2019-03-22 14:19:09: step 16/50000, loss = 0.495527 (2.022 sec/batch), lr: 1.000000
2019-03-22 14:19:11,779 2019-03-22 14:19:11: step 17/50000, loss = 0.431585 (2.129 sec/batch), lr: 1.000000
2019-03-22 14:19:13,879 2019-03-22 14:19:13: step 18/50000, loss = 0.470053 (2.096 sec/batch), lr: 1.000000
2019-03-22 14:19:15,936 2019-03-22 14:19:15: step 19/50000, loss = 0.333193 (2.052 sec/batch), lr: 1.000000
2019-03-22 14:19:18,095 2019-03-22 14:19:18: step 20/50000, loss = 0.490804 (2.154 sec/batch), lr: 1.000000
2019-03-22 14:19:19,084 step 20: Full loss = 0.911095, Edge acc. = 0.3214
2019-03-22 14:19:21,062 2019-03-22 14:19:21: step 21/50000, loss = 0.455548 (1.972 sec/batch), lr: 1.000000
2019-03-22 14:19:23,146 2019-03-22 14:19:23: step 22/50000, loss = 0.496303 (2.078 sec/batch), lr: 1.000000
2019-03-22 14:19:25,230 2019-03-22 14:19:25: step 23/50000, loss = 0.405391 (2.084 sec/batch), lr: 1.000000
2019-03-22 14:19:27,260 2019-03-22 14:19:27: step 24/50000, loss = 0.496626 (2.026 sec/batch), lr: 1.000000
2019-03-22 14:19:29,496 2019-03-22 14:19:29: step 25/50000, loss = 0.498671 (2.231 sec/batch), lr: 1.000000
2019-03-22 14:19:31,579 2019-03-22 14:19:31: step 26/50000, loss = 0.494412 (2.079 sec/batch), lr: 1.000000
2019-03-22 14:19:33,609 2019-03-22 14:19:33: step 27/50000, loss = 0.475752 (2.026 sec/batch), lr: 1.000000
2019-03-22 14:19:35,663 2019-03-22 14:19:35: step 28/50000, loss = 0.350464 (2.049 sec/batch), lr: 1.000000
2019-03-22 14:19:37,782 2019-03-22 14:19:37: step 29/50000, loss = 0.498443 (2.114 sec/batch), lr: 1.000000
2019-03-22 14:19:39,882 2019-03-22 14:19:39: step 30/50000, loss = 0.448802 (2.096 sec/batch), lr: 1.000000
2019-03-22 14:19:40,906 step 30: Full loss = 0.964192, Edge acc. = 0.0357
2019-03-22 14:19:42,875 2019-03-22 14:19:42: step 31/50000, loss = 0.482096 (1.962 sec/batch), lr: 1.000000
2019-03-22 14:19:44,947 2019-03-22 14:19:44: step 32/50000, loss = 0.404538 (2.068 sec/batch), lr: 1.000000
2019-03-22 14:19:47,059 2019-03-22 14:19:47: step 33/50000, loss = 0.494625 (2.102 sec/batch), lr: 1.000000
2019-03-22 14:19:49,296 2019-03-22 14:19:49: step 34/50000, loss = 0.499848 (2.233 sec/batch), lr: 1.000000
2019-03-22 14:19:51,330 2019-03-22 14:19:51: step 35/50000, loss = 0.479591 (2.030 sec/batch), lr: 1.000000
2019-03-22 14:19:53,402 2019-03-22 14:19:53: step 36/50000, loss = 0.496863 (2.068 sec/batch), lr: 1.000000
2019-03-22 14:19:55,379 2019-03-22 14:19:55: step 37/50000, loss = 0.486580 (1.972 sec/batch), lr: 1.000000
2019-03-22 14:19:57,463 2019-03-22 14:19:57: step 38/50000, loss = 0.486687 (2.081 sec/batch), lr: 1.000000
2019-03-22 14:19:59,528 2019-03-22 14:19:59: step 39/50000, loss = 0.469730 (2.061 sec/batch), lr: 1.000000
2019-03-22 14:20:01,626 2019-03-22 14:20:01: step 40/50000, loss = 0.467603 (2.094 sec/batch), lr: 1.000000
2019-03-22 14:20:02,608 step 40: Full loss = 0.807762, Edge acc. = 0.0357
2019-03-22 14:20:04,583 2019-03-22 14:20:04: step 41/50000, loss = 0.403881 (1.968 sec/batch), lr: 1.000000
2019-03-22 14:20:06,710 2019-03-22 14:20:06: step 42/50000, loss = 0.497156 (2.123 sec/batch), lr: 1.000000
2019-03-22 14:20:08,924 2019-03-22 14:20:08: step 43/50000, loss = 0.429721 (2.210 sec/batch), lr: 1.000000
2019-03-22 14:20:11,114 2019-03-22 14:20:11: step 44/50000, loss = 0.481331 (2.187 sec/batch), lr: 1.000000
2019-03-22 14:20:13,112 2019-03-22 14:20:13: step 45/50000, loss = 0.470510 (1.993 sec/batch), lr: 1.000000
2019-03-22 14:20:15,086 2019-03-22 14:20:15: step 46/50000, loss = 0.476602 (1.971 sec/batch), lr: 1.000000
2019-03-22 14:20:17,439 2019-03-22 14:20:17: step 47/50000, loss = 0.470682 (2.349 sec/batch), lr: 1.000000
2019-03-22 14:20:19,452 2019-03-22 14:20:19: step 48/50000, loss = 0.458615 (2.009 sec/batch), lr: 1.000000
2019-03-22 14:20:21,432 2019-03-22 14:20:21: step 49/50000, loss = 0.459232 (1.975 sec/batch), lr: 1.000000
2019-03-22 14:20:23,420 2019-03-22 14:20:23: step 50/50000, loss = 0.371385 (1.984 sec/batch), lr: 1.000000
2019-03-22 14:20:24,404 step 50: Full loss = 0.997019, Edge acc. = 0.2857
2019-03-22 14:20:26,341 2019-03-22 14:20:26: step 51/50000, loss = 0.498509 (1.931 sec/batch), lr: 1.000000
2019-03-22 14:20:28,331 2019-03-22 14:20:28: step 52/50000, loss = 0.320565 (1.986 sec/batch), lr: 1.000000
2019-03-22 14:20:30,323 2019-03-22 14:20:30: step 53/50000, loss = 0.486444 (1.988 sec/batch), lr: 1.000000
2019-03-22 14:20:32,346 2019-03-22 14:20:32: step 54/50000, loss = 0.436314 (2.019 sec/batch), lr: 1.000000
2019-03-22 14:20:34,283 2019-03-22 14:20:34: step 55/50000, loss = 0.496040 (1.933 sec/batch), lr: 1.000000
2019-03-22 14:20:36,299 2019-03-22 14:20:36: step 56/50000, loss = 0.482208 (2.013 sec/batch), lr: 1.000000
2019-03-22 14:20:38,318 2019-03-22 14:20:38: step 57/50000, loss = 0.472043 (2.014 sec/batch), lr: 1.000000
2019-03-22 14:20:40,335 2019-03-22 14:20:40: step 58/50000, loss = 0.461939 (2.013 sec/batch), lr: 1.000000
2019-03-22 14:20:42,297 2019-03-22 14:20:42: step 59/50000, loss = 0.460267 (1.959 sec/batch), lr: 1.000000
2019-03-22 14:20:44,292 2019-03-22 14:20:44: step 60/50000, loss = 0.474814 (1.991 sec/batch), lr: 1.000000
2019-03-22 14:20:45,480 step 60: Full loss = 0.876185, Edge acc. = 0.3571
2019-03-22 14:20:47,687 2019-03-22 14:20:47: step 61/50000, loss = 0.438092 (2.202 sec/batch), lr: 1.000000
2019-03-22 14:20:49,875 2019-03-22 14:20:49: step 62/50000, loss = 0.498229 (2.184 sec/batch), lr: 1.000000
2019-03-22 14:20:52,093 2019-03-22 14:20:52: step 63/50000, loss = 0.293908 (2.202 sec/batch), lr: 1.000000
2019-03-22 14:20:54,349 2019-03-22 14:20:54: step 64/50000, loss = 0.498320 (2.253 sec/batch), lr: 1.000000
2019-03-22 14:20:56,574 2019-03-22 14:20:56: step 65/50000, loss = 0.471950 (2.221 sec/batch), lr: 1.000000
2019-03-22 14:20:58,534 2019-03-22 14:20:58: step 66/50000, loss = 0.488489 (1.956 sec/batch), lr: 1.000000
2019-03-22 14:21:00,507 2019-03-22 14:21:00: step 67/50000, loss = 0.495838 (1.969 sec/batch), lr: 1.000000
2019-03-22 14:21:02,489 2019-03-22 14:21:02: step 68/50000, loss = 0.435075 (1.978 sec/batch), lr: 1.000000
2019-03-22 14:21:04,504 2019-03-22 14:21:04: step 69/50000, loss = 0.496417 (2.011 sec/batch), lr: 1.000000
2019-03-22 14:21:06,491 2019-03-22 14:21:06: step 70/50000, loss = 0.484661 (1.984 sec/batch), lr: 1.000000
2019-03-22 14:21:07,446 step 70: Full loss = 0.885213, Edge acc. = 0.2857
2019-03-22 14:21:09,333 2019-03-22 14:21:09: step 71/50000, loss = 0.442607 (1.884 sec/batch), lr: 1.000000
2019-03-22 14:21:11,531 2019-03-22 14:21:11: step 72/50000, loss = 0.282428 (2.193 sec/batch), lr: 1.000000
2019-03-22 14:21:13,508 2019-03-22 14:21:13: step 73/50000, loss = 0.433373 (1.974 sec/batch), lr: 1.000000
2019-03-22 14:21:15,521 2019-03-22 14:21:15: step 74/50000, loss = 0.497435 (2.009 sec/batch), lr: 1.000000
2019-03-22 14:21:17,573 2019-03-22 14:21:17: step 75/50000, loss = 0.440681 (2.047 sec/batch), lr: 1.000000
2019-03-22 14:21:19,608 2019-03-22 14:21:19: step 76/50000, loss = 0.416629 (2.031 sec/batch), lr: 1.000000
2019-03-22 14:21:21,599 2019-03-22 14:21:21: step 77/50000, loss = 0.421332 (1.987 sec/batch), lr: 1.000000
2019-03-22 14:21:23,599 2019-03-22 14:21:23: step 78/50000, loss = 0.495452 (1.996 sec/batch), lr: 1.000000
2019-03-22 14:21:25,561 2019-03-22 14:21:25: step 79/50000, loss = 0.360607 (1.959 sec/batch), lr: 1.000000
2019-03-22 14:21:27,618 2019-03-22 14:21:27: step 80/50000, loss = 0.498629 (2.053 sec/batch), lr: 1.000000
2019-03-22 14:21:28,577 step 80: Full loss = 0.950519, Edge acc. = 0.2857
2019-03-22 14:21:30,571 2019-03-22 14:21:30: step 81/50000, loss = 0.475259 (1.988 sec/batch), lr: 1.000000
2019-03-22 14:22:13,155 2019-03-22 14:22:13: step 1/50000, loss = 0.477961 (1.952 sec/batch), lr: 1.000000
2019-03-22 14:22:15,276 2019-03-22 14:22:15: step 2/50000, loss = 0.402244 (2.117 sec/batch), lr: 1.000000
2019-03-22 14:22:17,266 2019-03-22 14:22:17: step 3/50000, loss = 0.479750 (1.985 sec/batch), lr: 1.000000
2019-03-22 14:22:19,464 2019-03-22 14:22:19: step 4/50000, loss = 0.358502 (2.194 sec/batch), lr: 1.000000
2019-03-22 14:22:21,550 2019-03-22 14:22:21: step 5/50000, loss = 0.489648 (2.081 sec/batch), lr: 1.000000
2019-03-22 14:22:23,534 2019-03-22 14:22:23: step 6/50000, loss = 0.407945 (1.980 sec/batch), lr: 1.000000
2019-03-22 14:22:25,579 2019-03-22 14:22:25: step 7/50000, loss = 0.499398 (2.040 sec/batch), lr: 1.000000
2019-03-22 14:22:27,779 2019-03-22 14:22:27: step 8/50000, loss = 0.498974 (2.196 sec/batch), lr: 1.000000
2019-03-22 14:22:29,697 2019-03-22 14:22:29: step 9/50000, loss = 0.498584 (1.914 sec/batch), lr: 1.000000
2019-03-22 14:22:31,659 2019-03-22 14:22:31: step 10/50000, loss = 0.497951 (1.958 sec/batch), lr: 1.000000
2019-03-22 14:22:32,546 step 10: Full loss = 0.993911, Edge acc. = 0.1429
2019-03-22 14:22:34,551 2019-03-22 14:22:34: step 11/50000, loss = 0.496955 (2.001 sec/batch), lr: 1.000000
2019-03-22 14:22:36,789 2019-03-22 14:22:36: step 12/50000, loss = 0.495284 (2.234 sec/batch), lr: 1.000000
2019-03-22 14:22:38,988 2019-03-22 14:22:38: step 13/50000, loss = 0.492586 (2.194 sec/batch), lr: 1.000000
2019-03-22 14:22:41,073 2019-03-22 14:22:41: step 14/50000, loss = 0.486164 (2.081 sec/batch), lr: 1.000000
2019-03-22 14:22:42,990 2019-03-22 14:22:42: step 15/50000, loss = 0.465965 (1.912 sec/batch), lr: 1.000000
2019-03-22 14:22:44,992 2019-03-22 14:22:44: step 16/50000, loss = 0.373170 (1.998 sec/batch), lr: 1.000000
2019-03-22 14:22:46,984 2019-03-22 14:22:46: step 17/50000, loss = 0.496011 (1.988 sec/batch), lr: 1.000000
2019-03-22 14:22:48,887 2019-03-22 14:22:48: step 18/50000, loss = 0.495536 (1.898 sec/batch), lr: 1.000000
2019-03-22 14:22:50,990 2019-03-22 14:22:50: step 19/50000, loss = 0.494946 (2.098 sec/batch), lr: 1.000000
2019-03-22 14:22:52,968 2019-03-22 14:22:52: step 20/50000, loss = 0.494164 (1.974 sec/batch), lr: 1.000000
2019-03-22 14:22:54,361 step 20: Full loss = 0.986117, Edge acc. = 0.1429
2019-03-22 14:22:56,459 2019-03-22 14:22:56: step 21/50000, loss = 0.493058 (2.091 sec/batch), lr: 1.000000
2019-03-22 14:22:58,648 2019-03-22 14:22:58: step 22/50000, loss = 0.491392 (2.185 sec/batch), lr: 1.000000
2019-03-22 14:23:00,694 2019-03-22 14:23:00: step 23/50000, loss = 0.488537 (2.042 sec/batch), lr: 1.000000
2019-03-22 14:23:02,632 2019-03-22 14:23:02: step 24/50000, loss = 0.482146 (1.933 sec/batch), lr: 1.000000
2019-03-22 14:23:04,582 2019-03-22 14:23:04: step 25/50000, loss = 0.458221 (1.945 sec/batch), lr: 1.000000
2019-03-22 14:23:06,692 2019-03-22 14:23:06: step 26/50000, loss = 0.291756 (2.102 sec/batch), lr: 1.000000
2019-03-22 14:23:08,794 2019-03-22 14:23:08: step 27/50000, loss = 0.495982 (2.099 sec/batch), lr: 1.000000
2019-03-22 14:23:10,827 2019-03-22 14:23:10: step 28/50000, loss = 0.485516 (2.030 sec/batch), lr: 1.000000
2019-03-22 14:23:12,731 2019-03-22 14:23:12: step 29/50000, loss = 0.389772 (1.900 sec/batch), lr: 1.000000
2019-03-22 14:23:14,649 2019-03-22 14:23:14: step 30/50000, loss = 0.498314 (1.914 sec/batch), lr: 1.000000
2019-03-22 14:23:15,614 step 30: Full loss = 0.996404, Edge acc. = 0.1429
2019-03-22 14:23:17,520 2019-03-22 14:23:17: step 31/50000, loss = 0.498202 (1.900 sec/batch), lr: 1.000000
2019-03-22 14:23:19,537 2019-03-22 14:23:19: step 32/50000, loss = 0.498071 (2.013 sec/batch), lr: 1.000000
2019-03-22 14:23:21,472 2019-03-22 14:23:21: step 33/50000, loss = 0.497908 (1.930 sec/batch), lr: 1.000000
2019-03-22 14:23:23,464 2019-03-22 14:23:23: step 34/50000, loss = 0.497683 (1.989 sec/batch), lr: 1.000000
2019-03-22 14:23:25,379 2019-03-22 14:23:25: step 35/50000, loss = 0.497349 (1.911 sec/batch), lr: 1.000000
2019-03-22 14:23:27,446 2019-03-22 14:23:27: step 36/50000, loss = 0.496860 (2.057 sec/batch), lr: 1.000000
2019-03-22 14:23:29,520 2019-03-22 14:23:29: step 37/50000, loss = 0.496175 (2.069 sec/batch), lr: 1.000000
2019-03-22 14:23:31,469 2019-03-22 14:23:31: step 38/50000, loss = 0.495242 (1.945 sec/batch), lr: 1.000000
2019-03-22 14:23:33,428 2019-03-22 14:23:33: step 39/50000, loss = 0.493900 (1.954 sec/batch), lr: 1.000000
2019-03-22 14:23:35,436 2019-03-22 14:23:35: step 40/50000, loss = 0.491782 (2.003 sec/batch), lr: 1.000000
2019-03-22 14:23:36,400 step 40: Full loss = 0.975982, Edge acc. = 0.1071
2019-03-22 14:23:38,339 2019-03-22 14:23:38: step 41/50000, loss = 0.487991 (1.933 sec/batch), lr: 1.000000
2019-03-22 14:23:40,301 2019-03-22 14:23:40: step 42/50000, loss = 0.480308 (1.957 sec/batch), lr: 1.000000
2019-03-22 14:23:42,422 2019-03-22 14:23:42: step 43/50000, loss = 0.455486 (2.120 sec/batch), lr: 1.000000
2019-03-22 14:23:44,399 2019-03-22 14:23:44: step 44/50000, loss = 0.340372 (1.972 sec/batch), lr: 1.000000
2019-03-22 14:23:46,394 2019-03-22 14:23:46: step 45/50000, loss = 0.499063 (1.991 sec/batch), lr: 1.000000
2019-03-22 14:23:48,406 2019-03-22 14:23:48: step 46/50000, loss = 0.497889 (2.007 sec/batch), lr: 1.000000
2019-03-22 14:23:50,395 2019-03-22 14:23:50: step 47/50000, loss = 0.496306 (1.985 sec/batch), lr: 1.000000
2019-03-22 14:23:52,587 2019-03-22 14:23:52: step 48/50000, loss = 0.492983 (2.188 sec/batch), lr: 1.000000
2019-03-22 14:23:54,812 2019-03-22 14:23:54: step 49/50000, loss = 0.483368 (2.220 sec/batch), lr: 1.000000
2019-03-22 14:23:57,046 2019-03-22 14:23:57: step 50/50000, loss = 0.462342 (2.230 sec/batch), lr: 1.000000
2019-03-22 14:23:58,140 step 50: Full loss = 0.998498, Edge acc. = 0.1429
2019-03-22 14:24:00,004 2019-03-22 14:23:59: step 51/50000, loss = 0.499249 (1.857 sec/batch), lr: 1.000000
2019-03-22 14:24:01,971 2019-03-22 14:24:01: step 52/50000, loss = 0.498498 (1.963 sec/batch), lr: 1.000000
2019-03-22 14:24:04,261 2019-03-22 14:24:04: step 53/50000, loss = 0.496252 (2.286 sec/batch), lr: 1.000000
2019-03-22 14:24:06,439 2019-03-22 14:24:06: step 54/50000, loss = 0.493189 (2.174 sec/batch), lr: 1.000000
2019-03-22 14:24:08,660 2019-03-22 14:24:08: step 55/50000, loss = 0.485246 (2.217 sec/batch), lr: 1.000000
2019-03-22 14:24:10,874 2019-03-22 14:24:10: step 56/50000, loss = 0.442801 (2.207 sec/batch), lr: 1.000000
2019-03-22 14:24:13,075 2019-03-22 14:24:13: step 57/50000, loss = 0.487722 (2.196 sec/batch), lr: 1.000000
2019-03-22 14:24:15,199 2019-03-22 14:24:15: step 58/50000, loss = 0.480530 (2.120 sec/batch), lr: 1.000000
2019-03-22 14:24:17,418 2019-03-22 14:24:17: step 59/50000, loss = 0.454750 (2.215 sec/batch), lr: 1.000000
2019-03-22 14:24:19,420 2019-03-22 14:24:19: step 60/50000, loss = 0.434033 (1.998 sec/batch), lr: 1.000000
2019-03-22 14:24:20,345 step 60: Full loss = 0.996227, Edge acc. = 0.1429
2019-03-22 14:24:22,275 2019-03-22 14:24:22: step 61/50000, loss = 0.498113 (1.923 sec/batch), lr: 1.000000
2019-03-22 14:24:24,208 2019-03-22 14:24:24: step 62/50000, loss = 0.483432 (1.929 sec/batch), lr: 1.000000
2019-03-22 14:24:26,204 2019-03-22 14:24:26: step 63/50000, loss = 0.478029 (1.992 sec/batch), lr: 1.000000
2019-03-22 14:24:28,171 2019-03-22 14:24:28: step 64/50000, loss = 0.367197 (1.962 sec/batch), lr: 1.000000
2019-03-22 14:24:30,143 2019-03-22 14:24:30: step 65/50000, loss = 0.497183 (1.968 sec/batch), lr: 1.000000
2019-03-22 14:24:32,127 2019-03-22 14:24:32: step 66/50000, loss = 0.497052 (1.979 sec/batch), lr: 1.000000
2019-03-22 14:24:34,070 2019-03-22 14:24:34: step 67/50000, loss = 0.496935 (1.939 sec/batch), lr: 1.000000
2019-03-22 14:24:36,018 2019-03-22 14:24:36: step 68/50000, loss = 0.496807 (1.944 sec/batch), lr: 1.000000
2019-03-22 14:24:37,998 2019-03-22 14:24:37: step 69/50000, loss = 0.496671 (1.975 sec/batch), lr: 1.000000
2019-03-22 14:24:39,960 2019-03-22 14:24:39: step 70/50000, loss = 0.496523 (1.958 sec/batch), lr: 1.000000
2019-03-22 14:24:40,975 step 70: Full loss = 0.992725, Edge acc. = 0.1071
2019-03-22 14:24:42,880 2019-03-22 14:24:42: step 71/50000, loss = 0.496363 (1.898 sec/batch), lr: 1.000000
2019-03-22 14:24:44,864 2019-03-22 14:24:44: step 72/50000, loss = 0.496187 (1.979 sec/batch), lr: 1.000000
2019-03-22 14:24:46,835 2019-03-22 14:24:46: step 73/50000, loss = 0.495989 (1.967 sec/batch), lr: 1.000000
2019-03-22 14:24:48,856 2019-03-22 14:24:48: step 74/50000, loss = 0.495768 (2.016 sec/batch), lr: 1.000000
2019-03-22 14:24:50,867 2019-03-22 14:24:50: step 75/50000, loss = 0.495518 (2.008 sec/batch), lr: 1.000000
2019-03-22 14:24:52,859 2019-03-22 14:24:52: step 76/50000, loss = 0.495229 (1.987 sec/batch), lr: 1.000000
2019-03-22 14:24:54,781 2019-03-22 14:24:54: step 77/50000, loss = 0.494896 (1.919 sec/batch), lr: 1.000000
2019-03-22 14:24:56,745 2019-03-22 14:24:56: step 78/50000, loss = 0.494504 (1.959 sec/batch), lr: 1.000000
2019-03-22 14:24:58,679 2019-03-22 14:24:58: step 79/50000, loss = 0.494034 (1.930 sec/batch), lr: 1.000000
2019-03-22 14:25:00,670 2019-03-22 14:25:00: step 80/50000, loss = 0.493472 (1.986 sec/batch), lr: 1.000000
2019-03-22 14:25:01,589 step 80: Full loss = 0.985915, Edge acc. = 0.0714
2019-03-22 14:25:03,494 2019-03-22 14:25:03: step 81/50000, loss = 0.492958 (1.899 sec/batch), lr: 1.000000
2019-03-22 14:25:05,451 2019-03-22 14:25:05: step 82/50000, loss = 0.492316 (1.952 sec/batch), lr: 1.000000
2019-03-22 14:25:07,400 2019-03-22 14:25:07: step 83/50000, loss = 0.491261 (1.945 sec/batch), lr: 1.000000
2019-03-22 14:26:29,827 2019-03-22 14:26:29: step 1/50000, loss = 0.477961 (1.873 sec/batch), lr: 1.000000
2019-03-22 14:26:31,838 2019-03-22 14:26:31: step 2/50000, loss = 0.465427 (2.005 sec/batch), lr: 1.000000
2019-03-22 14:26:33,822 2019-03-22 14:26:33: step 3/50000, loss = 0.414751 (1.980 sec/batch), lr: 1.000000
2019-03-22 14:26:35,703 2019-03-22 14:26:35: step 4/50000, loss = 0.243257 (1.862 sec/batch), lr: 1.000000
2019-03-22 14:26:37,661 2019-03-22 14:26:37: step 5/50000, loss = 0.474148 (1.954 sec/batch), lr: 1.000000
2019-03-22 14:26:39,598 2019-03-22 14:26:39: step 6/50000, loss = 0.426491 (1.933 sec/batch), lr: 1.000000
2019-03-22 14:26:41,554 2019-03-22 14:26:41: step 7/50000, loss = 0.317110 (1.952 sec/batch), lr: 1.000000
2019-03-22 14:26:43,460 2019-03-22 14:26:43: step 8/50000, loss = 0.363730 (1.902 sec/batch), lr: 1.000000
2019-03-22 14:26:45,318 2019-03-22 14:26:45: step 9/50000, loss = 0.241390 (1.854 sec/batch), lr: 1.000000
2019-03-22 14:26:47,221 2019-03-22 14:26:47: step 10/50000, loss = 0.430094 (1.898 sec/batch), lr: 1.000000
2019-03-22 14:26:48,124 step 10: Full loss = 0.662492, Edge acc. = 0.1429
2019-03-22 14:26:50,021 2019-03-22 14:26:50: step 11/50000, loss = 0.331246 (1.890 sec/batch), lr: 1.000000
2019-03-22 14:26:51,983 2019-03-22 14:26:51: step 12/50000, loss = 0.491466 (1.959 sec/batch), lr: 1.000000
2019-03-22 14:26:53,942 2019-03-22 14:26:53: step 13/50000, loss = 0.461228 (1.954 sec/batch), lr: 1.000000
2019-03-22 14:26:55,850 2019-03-22 14:26:55: step 14/50000, loss = 0.383366 (1.904 sec/batch), lr: 1.000000
2019-03-22 14:26:57,765 2019-03-22 14:26:57: step 15/50000, loss = 0.365801 (1.910 sec/batch), lr: 1.000000
2019-03-22 14:26:59,706 2019-03-22 14:26:59: step 16/50000, loss = 0.441269 (1.937 sec/batch), lr: 1.000000
2019-03-22 14:27:01,588 2019-03-22 14:27:01: step 17/50000, loss = 0.266515 (1.878 sec/batch), lr: 1.000000
2019-03-22 14:27:03,492 2019-03-22 14:27:03: step 18/50000, loss = 0.252503 (1.900 sec/batch), lr: 1.000000
2019-03-22 14:27:05,444 2019-03-22 14:27:05: step 19/50000, loss = 0.372770 (1.948 sec/batch), lr: 1.000000
2019-03-22 14:27:07,374 2019-03-22 14:27:07: step 20/50000, loss = 0.339708 (1.926 sec/batch), lr: 1.000000
2019-03-22 14:27:08,586 step 20: Full loss = 0.822045, Edge acc. = 0.1786
2019-03-22 14:27:10,547 2019-03-22 14:27:10: step 21/50000, loss = 0.411022 (1.954 sec/batch), lr: 1.000000
2019-03-22 14:27:12,351 2019-03-22 14:27:12: step 22/50000, loss = 0.250794 (1.800 sec/batch), lr: 1.000000
2019-03-22 14:27:14,341 2019-03-22 14:27:14: step 23/50000, loss = 0.367663 (1.985 sec/batch), lr: 1.000000
2019-03-22 14:27:16,300 2019-03-22 14:27:16: step 24/50000, loss = 0.368954 (1.954 sec/batch), lr: 1.000000
2019-03-22 14:27:18,249 2019-03-22 14:27:18: step 25/50000, loss = 0.466275 (1.945 sec/batch), lr: 1.000000
2019-03-22 14:27:20,136 2019-03-22 14:27:20: step 26/50000, loss = 0.419602 (1.883 sec/batch), lr: 1.000000
2019-03-22 14:27:22,035 2019-03-22 14:27:22: step 27/50000, loss = 0.459670 (1.895 sec/batch), lr: 1.000000
2019-03-22 14:27:24,080 2019-03-22 14:27:24: step 28/50000, loss = 0.460195 (2.041 sec/batch), lr: 1.000000
2019-03-22 14:27:26,055 2019-03-22 14:27:26: step 29/50000, loss = 0.380658 (1.972 sec/batch), lr: 1.000000
2019-03-22 14:27:28,233 2019-03-22 14:27:28: step 30/50000, loss = 0.384209 (2.174 sec/batch), lr: 1.000000
2019-03-22 14:27:29,372 step 30: Full loss = 0.720303, Edge acc. = 0.1429
2019-03-22 14:27:31,475 2019-03-22 14:27:31: step 31/50000, loss = 0.360151 (2.097 sec/batch), lr: 1.000000
2019-03-22 14:27:33,689 2019-03-22 14:27:33: step 32/50000, loss = 0.402296 (2.210 sec/batch), lr: 1.000000
2019-03-22 14:27:35,891 2019-03-22 14:27:35: step 33/50000, loss = 0.264103 (2.198 sec/batch), lr: 1.000000
2019-03-22 14:27:38,160 2019-03-22 14:27:38: step 34/50000, loss = 0.453246 (2.265 sec/batch), lr: 1.000000
2019-03-22 14:27:40,092 2019-03-22 14:27:40: step 35/50000, loss = 0.402005 (1.928 sec/batch), lr: 1.000000
2019-03-22 14:27:42,059 2019-03-22 14:27:42: step 36/50000, loss = 0.403638 (1.962 sec/batch), lr: 1.000000
2019-03-22 14:27:43,955 2019-03-22 14:27:43: step 37/50000, loss = 0.295152 (1.892 sec/batch), lr: 1.000000
2019-03-22 14:27:46,039 2019-03-22 14:27:46: step 38/50000, loss = 0.431911 (2.079 sec/batch), lr: 1.000000
2019-03-22 14:27:47,896 2019-03-22 14:27:47: step 39/50000, loss = 0.365384 (1.853 sec/batch), lr: 1.000000
2019-03-22 14:27:49,780 2019-03-22 14:27:49: step 40/50000, loss = 0.389210 (1.880 sec/batch), lr: 1.000000
2019-03-22 14:27:50,658 step 40: Full loss = 0.671765, Edge acc. = 0.0357
2019-03-22 14:27:52,581 2019-03-22 14:27:52: step 41/50000, loss = 0.335883 (1.916 sec/batch), lr: 1.000000
2019-03-22 14:27:54,508 2019-03-22 14:27:54: step 42/50000, loss = 0.333899 (1.924 sec/batch), lr: 1.000000
2019-03-22 14:27:56,427 2019-03-22 14:27:56: step 43/50000, loss = 0.416987 (1.914 sec/batch), lr: 1.000000
2019-03-22 14:27:58,351 2019-03-22 14:27:58: step 44/50000, loss = 0.275216 (1.921 sec/batch), lr: 1.000000
2019-03-22 14:28:00,250 2019-03-22 14:28:00: step 45/50000, loss = 0.263215 (1.894 sec/batch), lr: 1.000000
2019-03-22 14:28:02,123 2019-03-22 14:28:02: step 46/50000, loss = 0.442379 (1.869 sec/batch), lr: 1.000000
2019-03-22 14:28:04,056 2019-03-22 14:28:04: step 47/50000, loss = 0.301409 (1.929 sec/batch), lr: 1.000000
2019-03-22 14:28:06,042 2019-03-22 14:28:06: step 48/50000, loss = 0.278528 (1.981 sec/batch), lr: 1.000000
2019-03-22 14:28:08,254 2019-03-22 14:28:08: step 49/50000, loss = 0.212546 (2.208 sec/batch), lr: 1.000000
2019-03-22 14:28:10,427 2019-03-22 14:28:10: step 50/50000, loss = 0.392466 (2.169 sec/batch), lr: 1.000000
2019-03-22 14:28:11,600 step 50: Full loss = 0.418243, Edge acc. = 0.2500
2019-03-22 14:28:13,604 2019-03-22 14:28:13: step 51/50000, loss = 0.209122 (1.997 sec/batch), lr: 1.000000
2019-03-22 14:28:15,622 2019-03-22 14:28:15: step 52/50000, loss = 0.396268 (2.013 sec/batch), lr: 1.000000
2019-03-22 14:28:17,500 2019-03-22 14:28:17: step 53/50000, loss = 0.289195 (1.874 sec/batch), lr: 1.000000
2019-03-22 14:28:19,475 2019-03-22 14:28:19: step 54/50000, loss = 0.277144 (1.972 sec/batch), lr: 1.000000
2019-03-22 14:28:21,407 2019-03-22 14:28:21: step 55/50000, loss = 0.381756 (1.927 sec/batch), lr: 1.000000
2019-03-22 14:28:23,428 2019-03-22 14:28:23: step 56/50000, loss = 0.292024 (2.017 sec/batch), lr: 1.000000
2019-03-22 14:28:25,327 2019-03-22 14:28:25: step 57/50000, loss = 0.346095 (1.895 sec/batch), lr: 1.000000
2019-03-22 14:28:27,199 2019-03-22 14:28:27: step 58/50000, loss = 0.180282 (1.869 sec/batch), lr: 1.000000
2019-03-22 14:28:29,408 2019-03-22 14:28:29: step 59/50000, loss = 0.162307 (2.204 sec/batch), lr: 1.000000
2019-03-22 14:28:31,510 2019-03-22 14:28:31: step 60/50000, loss = 0.350858 (2.098 sec/batch), lr: 1.000000
2019-03-22 14:28:32,621 step 60: Full loss = 0.621781, Edge acc. = 0.0357
2019-03-22 14:28:34,683 2019-03-22 14:28:34: step 61/50000, loss = 0.310891 (2.056 sec/batch), lr: 1.000000
2019-03-22 14:28:36,679 2019-03-22 14:28:36: step 62/50000, loss = 0.296139 (1.991 sec/batch), lr: 1.000000
2019-03-22 14:28:38,581 2019-03-22 14:28:38: step 63/50000, loss = 0.187837 (1.898 sec/batch), lr: 1.000000
2019-03-22 14:28:40,441 2019-03-22 14:28:40: step 64/50000, loss = 0.334673 (1.856 sec/batch), lr: 1.000000
2019-03-22 14:28:42,341 2019-03-22 14:28:42: step 65/50000, loss = 0.266383 (1.895 sec/batch), lr: 1.000000
2019-03-22 14:28:44,381 2019-03-22 14:28:44: step 66/50000, loss = 0.293406 (2.036 sec/batch), lr: 1.000000
2019-03-22 14:28:46,283 2019-03-22 14:28:46: step 67/50000, loss = 0.226534 (1.898 sec/batch), lr: 1.000000
2019-03-22 14:28:48,287 2019-03-22 14:28:48: step 68/50000, loss = 0.316685 (1.999 sec/batch), lr: 1.000000
2019-03-22 14:28:50,200 2019-03-22 14:28:50: step 69/50000, loss = 0.181677 (1.910 sec/batch), lr: 1.000000
2019-03-22 14:28:52,266 2019-03-22 14:28:52: step 70/50000, loss = 0.283514 (2.061 sec/batch), lr: 1.000000
2019-03-22 14:28:53,131 step 70: Full loss = 0.370207, Edge acc. = 0.2143
2019-03-22 14:28:55,055 2019-03-22 14:28:55: step 71/50000, loss = 0.185103 (1.917 sec/batch), lr: 1.000000
2019-03-22 14:28:56,980 2019-03-22 14:28:56: step 72/50000, loss = 0.320819 (1.920 sec/batch), lr: 1.000000
2019-03-22 14:28:58,868 2019-03-22 14:28:58: step 73/50000, loss = 0.160896 (1.885 sec/batch), lr: 1.000000
2019-03-22 14:29:00,882 2019-03-22 14:29:00: step 74/50000, loss = 0.274604 (2.009 sec/batch), lr: 1.000000
2019-03-22 14:29:02,851 2019-03-22 14:29:02: step 75/50000, loss = 0.150778 (1.965 sec/batch), lr: 1.000000
2019-03-22 14:29:04,755 2019-03-22 14:29:04: step 76/50000, loss = 0.297188 (1.896 sec/batch), lr: 1.000000
2019-03-22 14:29:06,679 2019-03-22 14:29:06: step 77/50000, loss = 0.144084 (1.921 sec/batch), lr: 1.000000
2019-03-22 14:29:08,610 2019-03-22 14:29:08: step 78/50000, loss = 0.291775 (1.927 sec/batch), lr: 1.000000
2019-03-22 14:29:10,470 2019-03-22 14:29:10: step 79/50000, loss = 0.155165 (1.856 sec/batch), lr: 1.000000
2019-03-22 14:29:12,409 2019-03-22 14:29:12: step 80/50000, loss = 0.341802 (1.934 sec/batch), lr: 1.000000
2019-03-22 14:29:13,344 step 80: Full loss = 0.623206, Edge acc. = 0.3214
2019-03-22 14:29:15,217 2019-03-22 14:29:15: step 81/50000, loss = 0.311603 (1.866 sec/batch), lr: 1.000000
2019-03-22 14:29:17,277 2019-03-22 14:29:17: step 82/50000, loss = 0.153702 (2.056 sec/batch), lr: 1.000000
2019-03-22 14:29:19,210 2019-03-22 14:29:19: step 83/50000, loss = 0.279634 (1.928 sec/batch), lr: 1.000000
2019-03-22 14:29:21,116 2019-03-22 14:29:21: step 84/50000, loss = 0.147967 (1.902 sec/batch), lr: 1.000000
2019-03-22 14:29:23,045 2019-03-22 14:29:23: step 85/50000, loss = 0.310553 (1.925 sec/batch), lr: 1.000000
2019-03-22 14:29:24,943 2019-03-22 14:29:24: step 86/50000, loss = 0.134665 (1.894 sec/batch), lr: 1.000000
2019-03-22 14:29:26,957 2019-03-22 14:29:26: step 87/50000, loss = 0.530888 (2.009 sec/batch), lr: 1.000000
2019-03-22 14:29:29,100 2019-03-22 14:29:29: step 88/50000, loss = 0.313771 (2.139 sec/batch), lr: 1.000000
2019-03-22 14:29:31,226 2019-03-22 14:29:31: step 89/50000, loss = 0.396506 (2.122 sec/batch), lr: 1.000000
2019-03-22 14:29:33,396 2019-03-22 14:29:33: step 90/50000, loss = 0.390620 (2.166 sec/batch), lr: 1.000000
2019-03-22 14:29:34,564 step 90: Full loss = 0.696052, Edge acc. = 0.0000
2019-03-22 14:29:36,692 2019-03-22 14:29:36: step 91/50000, loss = 0.348026 (2.121 sec/batch), lr: 1.000000
2019-03-22 14:29:38,831 2019-03-22 14:29:38: step 92/50000, loss = 0.368792 (2.135 sec/batch), lr: 1.000000
2019-03-22 14:29:40,962 2019-03-22 14:29:40: step 93/50000, loss = 0.353620 (2.127 sec/batch), lr: 1.000000
2019-03-22 14:29:43,103 2019-03-22 14:29:43: step 94/50000, loss = 0.345235 (2.136 sec/batch), lr: 1.000000
2019-03-22 14:29:45,208 2019-03-22 14:29:45: step 95/50000, loss = 0.378583 (2.102 sec/batch), lr: 1.000000
2019-03-22 14:29:47,150 2019-03-22 14:29:47: step 96/50000, loss = 0.378562 (1.938 sec/batch), lr: 1.000000
2019-03-22 14:29:49,070 2019-03-22 14:29:49: step 97/50000, loss = 0.382356 (1.916 sec/batch), lr: 1.000000
2019-03-22 14:29:51,008 2019-03-22 14:29:51: step 98/50000, loss = 0.360982 (1.933 sec/batch), lr: 1.000000
2019-03-22 14:29:52,973 2019-03-22 14:29:52: step 99/50000, loss = 0.328854 (1.961 sec/batch), lr: 1.000000
2019-03-22 14:29:55,125 2019-03-22 14:29:55: step 100/50000, loss = 0.385976 (2.147 sec/batch), lr: 1.000000
2019-03-22 14:29:56,318 step 100: Full loss = 0.726398, Edge acc. = 0.0357
