2019-03-16 19:12:07,997 2019-03-16 19:12:07: step 1/50000, loss = 0.358880 (30.832 sec/batch), lr: 1.000000
2019-03-16 19:12:25,151 2019-03-16 19:12:25: step 2/50000, loss = 0.450220 (17.050 sec/batch), lr: 1.000000
2019-03-16 19:12:39,783 2019-03-16 19:12:39: step 3/50000, loss = 0.451454 (14.622 sec/batch), lr: 1.000000
2019-03-16 19:12:51,915 2019-03-16 19:12:51: step 4/50000, loss = 0.449583 (12.123 sec/batch), lr: 1.000000
2019-03-16 19:13:02,745 2019-03-16 19:13:02: step 5/50000, loss = 0.445848 (10.767 sec/batch), lr: 1.000000
2019-03-16 19:13:12,941 2019-03-16 19:13:12: step 6/50000, loss = 0.439902 (10.137 sec/batch), lr: 1.000000
2019-03-16 19:13:22,319 2019-03-16 19:13:22: step 7/50000, loss = 0.418149 (9.324 sec/batch), lr: 1.000000
2019-03-16 19:13:31,044 2019-03-16 19:13:31: step 8/50000, loss = 0.232231 (8.717 sec/batch), lr: 1.000000
2019-03-16 19:13:38,772 2019-03-16 19:13:38: step 9/50000, loss = 0.388474 (7.687 sec/batch), lr: 1.000000
2019-03-16 19:13:46,099 2019-03-16 19:13:46: step 10/50000, loss = 0.247081 (7.287 sec/batch), lr: 1.000000
2019-03-16 19:13:53,066 2019-03-16 19:13:53: step 11/50000, loss = 0.392674 (6.930 sec/batch), lr: 1.000000
2019-03-16 19:13:59,622 2019-03-16 19:13:59: step 12/50000, loss = 0.220874 (6.524 sec/batch), lr: 1.000000
2019-03-16 19:14:05,885 2019-03-16 19:14:05: step 13/50000, loss = 0.391958 (6.229 sec/batch), lr: 1.000000
2019-03-16 19:14:11,929 2019-03-16 19:14:11: step 14/50000, loss = 0.226244 (6.012 sec/batch), lr: 1.000000
2019-03-16 19:14:17,988 2019-03-16 19:14:17: step 15/50000, loss = 0.335051 (6.029 sec/batch), lr: 1.000000
2019-03-16 19:14:23,326 2019-03-16 19:14:23: step 16/50000, loss = 0.226147 (5.299 sec/batch), lr: 1.000000
2019-03-16 19:14:28,788 2019-03-16 19:14:28: step 17/50000, loss = 0.359756 (5.433 sec/batch), lr: 1.000000
2019-03-16 19:14:33,713 2019-03-16 19:14:33: step 18/50000, loss = 0.224932 (4.900 sec/batch), lr: 1.000000
2019-03-16 19:14:38,516 2019-03-16 19:14:38: step 19/50000, loss = 0.357195 (4.779 sec/batch), lr: 1.000000
2019-03-16 19:14:43,246 2019-03-16 19:14:43: step 20/50000, loss = 0.225946 (4.706 sec/batch), lr: 1.000000
2019-03-16 19:14:47,548 2019-03-16 19:14:47: step 21/50000, loss = 0.612347 (4.296 sec/batch), lr: 1.000000
2019-03-16 19:14:51,799 2019-03-16 19:14:51: step 22/50000, loss = 0.409537 (4.244 sec/batch), lr: 1.000000
2019-03-16 19:14:55,862 2019-03-16 19:14:55: step 23/50000, loss = 0.253447 (4.057 sec/batch), lr: 1.000000
2019-03-16 19:15:00,002 2019-03-16 19:15:00: step 24/50000, loss = 0.417081 (4.119 sec/batch), lr: 1.000000
2019-03-16 19:15:03,961 2019-03-16 19:15:03: step 25/50000, loss = 0.218869 (3.940 sec/batch), lr: 1.000000
2019-03-16 19:15:07,612 2019-03-16 19:15:07: step 26/50000, loss = 0.228641 (3.633 sec/batch), lr: 1.000000
2019-03-16 19:15:11,242 2019-03-16 19:15:11: step 27/50000, loss = 0.330441 (3.624 sec/batch), lr: 1.000000
2019-03-16 19:15:14,704 2019-03-16 19:15:14: step 28/50000, loss = 0.228561 (3.446 sec/batch), lr: 1.000000
2019-03-16 19:15:18,145 2019-03-16 19:15:18: step 29/50000, loss = 0.369663 (3.423 sec/batch), lr: 1.000000
2019-03-16 19:15:21,639 2019-03-16 19:15:21: step 30/50000, loss = 0.214170 (3.479 sec/batch), lr: 1.000000
2019-03-16 19:15:24,947 2019-03-16 19:15:24: step 31/50000, loss = 0.357791 (3.292 sec/batch), lr: 1.000000
2019-03-16 19:15:28,053 2019-03-16 19:15:28: step 32/50000, loss = 0.217392 (3.090 sec/batch), lr: 1.000000
2019-03-16 19:15:31,144 2019-03-16 19:15:31: step 33/50000, loss = 0.349471 (3.077 sec/batch), lr: 1.000000
2019-03-16 19:15:34,206 2019-03-16 19:15:34: step 34/50000, loss = 0.218092 (3.047 sec/batch), lr: 1.000000
2019-03-16 19:15:37,133 2019-03-16 19:15:37: step 35/50000, loss = 0.333245 (2.912 sec/batch), lr: 1.000000
2019-03-16 19:15:39,837 2019-03-16 19:15:39: step 36/50000, loss = 0.221650 (2.691 sec/batch), lr: 1.000000
2019-03-16 19:15:42,715 2019-03-16 19:15:42: step 37/50000, loss = 0.323047 (2.865 sec/batch), lr: 1.000000
2019-03-16 19:15:45,401 2019-03-16 19:15:45: step 38/50000, loss = 0.220462 (2.680 sec/batch), lr: 1.000000
2019-03-16 19:15:47,920 2019-03-16 19:15:47: step 39/50000, loss = 0.322980 (2.515 sec/batch), lr: 1.000000
2019-03-16 19:15:50,611 2019-03-16 19:15:50: step 40/50000, loss = 0.226801 (2.686 sec/batch), lr: 1.000000
2019-03-16 19:15:53,229 2019-03-16 19:15:53: step 41/50000, loss = 0.301846 (2.605 sec/batch), lr: 1.000000
2019-03-16 19:15:55,733 2019-03-16 19:15:55: step 42/50000, loss = 0.221162 (2.493 sec/batch), lr: 1.000000
2019-03-16 19:15:58,200 2019-03-16 19:15:58: step 43/50000, loss = 0.303582 (2.455 sec/batch), lr: 1.000000
2019-03-16 19:16:00,598 2019-03-16 19:16:00: step 44/50000, loss = 0.203082 (2.385 sec/batch), lr: 1.000000
2019-03-16 19:16:02,936 2019-03-16 19:16:02: step 45/50000, loss = 0.292004 (2.327 sec/batch), lr: 1.000000
2019-03-16 19:16:05,213 2019-03-16 19:16:05: step 46/50000, loss = 0.205974 (2.266 sec/batch), lr: 1.000000
2019-03-16 19:16:07,150 2019-03-16 19:16:07: step 47/50000, loss = 0.287341 (1.927 sec/batch), lr: 1.000000
2019-03-16 19:16:09,145 2019-03-16 19:16:09: step 48/50000, loss = 0.208671 (1.986 sec/batch), lr: 1.000000
2019-03-16 19:16:11,259 2019-03-16 19:16:11: step 49/50000, loss = 0.284327 (2.104 sec/batch), lr: 1.000000
2019-03-16 19:16:13,090 2019-03-16 19:16:13: step 50/50000, loss = 0.213675 (1.822 sec/batch), lr: 1.000000
2019-03-16 19:16:15,055 2019-03-16 19:16:15: step 51/50000, loss = 0.277926 (1.960 sec/batch), lr: 1.000000
2019-03-16 19:16:17,033 2019-03-16 19:16:17: step 52/50000, loss = 0.216406 (1.969 sec/batch), lr: 1.000000
2019-03-16 19:16:18,844 2019-03-16 19:16:18: step 53/50000, loss = 0.273115 (1.801 sec/batch), lr: 1.000000
2019-03-16 19:16:20,522 2019-03-16 19:16:20: step 54/50000, loss = 0.217773 (1.669 sec/batch), lr: 1.000000
2019-03-16 19:16:22,307 2019-03-16 19:16:22: step 55/50000, loss = 0.269574 (1.776 sec/batch), lr: 1.000000
2019-03-16 19:16:24,092 2019-03-16 19:16:24: step 56/50000, loss = 0.205983 (1.776 sec/batch), lr: 1.000000
2019-03-16 19:16:25,711 2019-03-16 19:16:25: step 57/50000, loss = 0.269657 (1.610 sec/batch), lr: 1.000000
2019-03-16 19:16:27,358 2019-03-16 19:16:27: step 58/50000, loss = 0.203581 (1.640 sec/batch), lr: 1.000000
2019-03-16 19:16:28,966 2019-03-16 19:16:28: step 59/50000, loss = 0.250828 (1.599 sec/batch), lr: 1.000000
2019-03-16 19:16:30,455 2019-03-16 19:16:30: step 60/50000, loss = 0.208756 (1.484 sec/batch), lr: 1.000000
2019-03-16 19:16:31,936 2019-03-16 19:16:31: step 61/50000, loss = 0.257753 (1.477 sec/batch), lr: 1.000000
2019-03-16 19:16:33,388 2019-03-16 19:16:33: step 62/50000, loss = 0.197235 (1.444 sec/batch), lr: 1.000000
2019-03-16 19:16:34,871 2019-03-16 19:16:34: step 63/50000, loss = 0.244394 (1.474 sec/batch), lr: 1.000000
2019-03-16 19:16:36,272 2019-03-16 19:16:36: step 64/50000, loss = 0.200187 (1.394 sec/batch), lr: 1.000000
2019-03-16 19:16:37,727 2019-03-16 19:16:37: step 65/50000, loss = 0.247503 (1.447 sec/batch), lr: 1.000000
2019-03-16 19:16:39,084 2019-03-16 19:16:39: step 66/50000, loss = 0.197308 (1.350 sec/batch), lr: 1.000000
2019-03-16 19:16:40,357 2019-03-16 19:16:40: step 67/50000, loss = 0.234141 (1.262 sec/batch), lr: 1.000000
2019-03-16 19:16:41,840 2019-03-16 19:16:41: step 68/50000, loss = 0.211310 (1.476 sec/batch), lr: 1.000000
2019-03-16 19:16:42,989 2019-03-16 19:16:42: step 69/50000, loss = 0.238600 (1.143 sec/batch), lr: 1.000000
2019-03-16 19:16:43,999 2019-03-16 19:16:43: step 70/50000, loss = 0.194052 (1.005 sec/batch), lr: 1.000000
2019-03-16 19:16:44,934 2019-03-16 19:16:44: step 71/50000, loss = 0.229315 (0.929 sec/batch), lr: 1.000000
2019-03-16 19:16:45,850 2019-03-16 19:16:45: step 72/50000, loss = 0.184296 (0.911 sec/batch), lr: 1.000000
2019-03-16 19:16:46,674 2019-03-16 19:16:46: step 73/50000, loss = 0.220333 (0.820 sec/batch), lr: 1.000000
2019-03-16 19:16:47,522 2019-03-16 19:16:47: step 74/50000, loss = 0.197678 (0.846 sec/batch), lr: 1.000000
2019-03-16 19:16:48,333 2019-03-16 19:16:48: step 75/50000, loss = 0.196413 (0.808 sec/batch), lr: 1.000000
2019-03-16 19:16:49,097 2019-03-16 19:16:49: step 76/50000, loss = 0.203008 (0.761 sec/batch), lr: 1.000000
2019-03-16 19:16:49,914 2019-03-16 19:16:49: step 77/50000, loss = 0.198581 (0.811 sec/batch), lr: 1.000000
2019-03-16 19:16:50,628 2019-03-16 19:16:50: step 78/50000, loss = 0.206175 (0.710 sec/batch), lr: 1.000000
2019-03-16 19:16:51,357 2019-03-16 19:16:51: step 79/50000, loss = 0.202596 (0.724 sec/batch), lr: 1.000000
2019-03-16 19:16:52,069 2019-03-16 19:16:52: step 80/50000, loss = 0.198210 (0.707 sec/batch), lr: 1.000000
2019-03-16 19:16:52,654 2019-03-16 19:16:52: step 81/50000, loss = 0.205227 (0.581 sec/batch), lr: 1.000000
2019-03-16 19:16:53,261 2019-03-16 19:16:53: step 82/50000, loss = 0.201607 (0.602 sec/batch), lr: 1.000000
2019-03-16 19:16:53,890 2019-03-16 19:16:53: step 83/50000, loss = 0.209047 (0.626 sec/batch), lr: 1.000000
2019-03-16 19:16:54,427 2019-03-16 19:16:54: step 84/50000, loss = 0.196870 (0.533 sec/batch), lr: 1.000000
2019-03-16 19:16:54,961 2019-03-16 19:16:54: step 85/50000, loss = 0.197478 (0.530 sec/batch), lr: 1.000000
2019-03-16 19:16:55,496 2019-03-16 19:16:55: step 86/50000, loss = 0.186906 (0.531 sec/batch), lr: 1.000000
2019-03-16 19:16:55,949 2019-03-16 19:16:55: step 87/50000, loss = 0.190666 (0.450 sec/batch), lr: 1.000000
2019-03-16 19:16:56,401 2019-03-16 19:16:56: step 88/50000, loss = 0.189202 (0.448 sec/batch), lr: 1.000000
2019-03-16 19:16:56,761 2019-03-16 19:16:56: step 89/50000, loss = 0.180124 (0.356 sec/batch), lr: 1.000000
2019-03-16 19:16:57,138 2019-03-16 19:16:57: step 90/50000, loss = 0.186125 (0.373 sec/batch), lr: 1.000000
2019-03-16 19:16:57,497 2019-03-16 19:16:57: step 91/50000, loss = 0.149336 (0.355 sec/batch), lr: 1.000000
2019-03-16 19:16:57,813 2019-03-16 19:16:57: step 92/50000, loss = 0.180833 (0.313 sec/batch), lr: 1.000000
2019-03-16 19:16:58,119 2019-03-16 19:16:58: step 93/50000, loss = 0.159464 (0.303 sec/batch), lr: 1.000000
2019-03-16 19:16:58,381 2019-03-16 19:16:58: step 94/50000, loss = 0.167422 (0.259 sec/batch), lr: 1.000000
2019-03-16 19:16:58,634 2019-03-16 19:16:58: step 95/50000, loss = 0.143067 (0.250 sec/batch), lr: 1.000000
2019-03-16 19:16:58,842 2019-03-16 19:16:58: step 96/50000, loss = 0.170385 (0.206 sec/batch), lr: 1.000000
2019-03-16 19:16:58,995 2019-03-16 19:16:58: step 97/50000, loss = 0.107000 (0.151 sec/batch), lr: 1.000000
2019-03-16 19:16:59,121 2019-03-16 19:16:59: step 98/50000, loss = 0.096483 (0.123 sec/batch), lr: 1.000000
2019-03-16 19:16:59,218 2019-03-16 19:16:59: step 99/50000, loss = 0.079346 (0.096 sec/batch), lr: 1.000000
2019-03-16 19:16:59,289 2019-03-16 19:16:59: step 100/50000, loss = 0.049876 (0.071 sec/batch), lr: 1.000000
2019-03-16 19:17:25,047 step 100: Full loss = 0.186479, Edge acc. = 0.2268
2019-03-16 19:17:25,193 2019-03-16 19:17:25: step 101/50000, loss = 0.124666 (0.087 sec/batch), lr: 1.000000
2019-03-16 19:17:25,306 2019-03-16 19:17:25: step 102/50000, loss = 0.062719 (0.111 sec/batch), lr: 1.000000
2019-03-16 19:17:25,434 2019-03-16 19:17:25: step 103/50000, loss = 0.095820 (0.126 sec/batch), lr: 1.000000
2019-03-16 19:17:25,623 2019-03-16 19:17:25: step 104/50000, loss = 0.148733 (0.187 sec/batch), lr: 1.000000
2019-03-16 19:17:25,868 2019-03-16 19:17:25: step 105/50000, loss = 0.141038 (0.242 sec/batch), lr: 1.000000
2019-03-16 19:17:26,124 2019-03-16 19:17:26: step 106/50000, loss = 0.184070 (0.254 sec/batch), lr: 1.000000
2019-03-16 19:17:26,425 2019-03-16 19:17:26: step 107/50000, loss = 0.144522 (0.297 sec/batch), lr: 1.000000
2019-03-16 19:17:26,728 2019-03-16 19:17:26: step 108/50000, loss = 0.179935 (0.301 sec/batch), lr: 1.000000
2019-03-16 19:17:27,078 2019-03-16 19:17:27: step 109/50000, loss = 0.145876 (0.346 sec/batch), lr: 1.000000
2019-03-16 19:17:27,461 2019-03-16 19:17:27: step 110/50000, loss = 0.195000 (0.380 sec/batch), lr: 1.000000
2019-03-16 19:17:27,833 2019-03-16 19:17:27: step 111/50000, loss = 0.189170 (0.368 sec/batch), lr: 1.000000
2019-03-16 19:17:28,283 2019-03-16 19:17:28: step 112/50000, loss = 0.173561 (0.446 sec/batch), lr: 1.000000
2019-03-16 19:17:28,733 2019-03-16 19:17:28: step 113/50000, loss = 0.189910 (0.446 sec/batch), lr: 1.000000
2019-03-16 19:17:29,266 2019-03-16 19:17:29: step 114/50000, loss = 0.183258 (0.529 sec/batch), lr: 1.000000
2019-03-16 19:17:29,797 2019-03-16 19:17:29: step 115/50000, loss = 0.190391 (0.526 sec/batch), lr: 1.000000
2019-03-16 19:17:30,325 2019-03-16 19:17:30: step 116/50000, loss = 0.171963 (0.523 sec/batch), lr: 1.000000
2019-03-16 19:17:30,933 2019-03-16 19:17:30: step 117/50000, loss = 0.185032 (0.604 sec/batch), lr: 1.000000
2019-03-16 19:17:31,561 2019-03-16 19:17:31: step 118/50000, loss = 0.205632 (0.623 sec/batch), lr: 1.000000
2019-03-16 19:17:32,195 2019-03-16 19:17:32: step 119/50000, loss = 0.205087 (0.629 sec/batch), lr: 1.000000
2019-03-16 19:17:32,903 2019-03-16 19:17:32: step 120/50000, loss = 0.179957 (0.702 sec/batch), lr: 1.000000
2019-03-16 19:17:33,636 2019-03-16 19:17:33: step 121/50000, loss = 0.210963 (0.728 sec/batch), lr: 1.000000
2019-03-16 19:17:34,357 2019-03-16 19:17:34: step 122/50000, loss = 0.185026 (0.716 sec/batch), lr: 1.000000
2019-03-16 19:17:35,182 2019-03-16 19:17:35: step 123/50000, loss = 0.205227 (0.819 sec/batch), lr: 1.000000
2019-03-16 19:17:35,981 2019-03-16 19:17:35: step 124/50000, loss = 0.197350 (0.792 sec/batch), lr: 1.000000
2019-03-16 19:17:36,820 2019-03-16 19:17:36: step 125/50000, loss = 0.216058 (0.834 sec/batch), lr: 1.000000
2019-03-16 19:17:37,776 2019-03-16 19:17:37: step 126/50000, loss = 0.189051 (0.950 sec/batch), lr: 1.000000
2019-03-16 19:17:38,752 2019-03-16 19:17:38: step 127/50000, loss = 0.219750 (0.969 sec/batch), lr: 1.000000
2019-03-16 19:17:39,792 2019-03-16 19:17:39: step 128/50000, loss = 0.200347 (1.034 sec/batch), lr: 1.000000
2019-03-16 19:17:40,883 2019-03-16 19:17:40: step 129/50000, loss = 0.199965 (1.084 sec/batch), lr: 1.000000
2019-03-16 19:17:41,987 2019-03-16 19:17:41: step 130/50000, loss = 0.214675 (1.097 sec/batch), lr: 1.000000
2019-03-16 19:17:43,159 2019-03-16 19:17:43: step 131/50000, loss = 0.191578 (1.164 sec/batch), lr: 1.000000
2019-03-16 19:17:44,311 2019-03-16 19:17:44: step 132/50000, loss = 0.201979 (1.149 sec/batch), lr: 1.000000
2019-03-16 19:17:45,541 2019-03-16 19:17:45: step 133/50000, loss = 0.279419 (1.223 sec/batch), lr: 1.000000
2019-03-16 19:17:46,863 2019-03-16 19:17:46: step 134/50000, loss = 0.219659 (1.315 sec/batch), lr: 1.000000
2019-03-16 19:17:48,205 2019-03-16 19:17:48: step 135/50000, loss = 0.227019 (1.335 sec/batch), lr: 1.000000
2019-03-16 19:17:49,564 2019-03-16 19:17:49: step 136/50000, loss = 0.224730 (1.352 sec/batch), lr: 1.000000
2019-03-16 19:17:50,893 2019-03-16 19:17:50: step 137/50000, loss = 0.216799 (1.321 sec/batch), lr: 1.000000
2019-03-16 19:17:52,354 2019-03-16 19:17:52: step 138/50000, loss = 0.230966 (1.453 sec/batch), lr: 1.000000
2019-03-16 19:17:53,842 2019-03-16 19:17:53: step 139/50000, loss = 0.197436 (1.484 sec/batch), lr: 1.000000
2019-03-16 19:17:55,339 2019-03-16 19:17:55: step 140/50000, loss = 0.243840 (1.489 sec/batch), lr: 1.000000
2019-03-16 19:17:56,971 2019-03-16 19:17:56: step 141/50000, loss = 0.193714 (1.623 sec/batch), lr: 1.000000
2019-03-16 19:17:58,613 2019-03-16 19:17:58: step 142/50000, loss = 0.240130 (1.634 sec/batch), lr: 1.000000
2019-03-16 19:18:00,127 2019-03-16 19:18:00: step 143/50000, loss = 0.200061 (1.507 sec/batch), lr: 1.000000
2019-03-16 19:18:01,850 2019-03-16 19:18:01: step 144/50000, loss = 0.232404 (1.714 sec/batch), lr: 1.000000
2019-03-16 19:18:03,597 2019-03-16 19:18:03: step 145/50000, loss = 0.205461 (1.742 sec/batch), lr: 1.000000
2019-03-16 19:18:05,373 2019-03-16 19:18:05: step 146/50000, loss = 0.237089 (1.771 sec/batch), lr: 1.000000
2019-03-16 19:18:07,131 2019-03-16 19:18:07: step 147/50000, loss = 0.206519 (1.751 sec/batch), lr: 1.000000
2019-03-16 19:18:08,943 2019-03-16 19:18:08: step 148/50000, loss = 0.238588 (1.805 sec/batch), lr: 1.000000
2019-03-16 19:18:10,654 2019-03-16 19:18:10: step 149/50000, loss = 0.205329 (1.701 sec/batch), lr: 1.000000
2019-03-16 19:18:12,342 2019-03-16 19:18:12: step 150/50000, loss = 0.235488 (1.684 sec/batch), lr: 1.000000
2019-03-16 19:18:14,243 2019-03-16 19:18:14: step 151/50000, loss = 0.192972 (1.896 sec/batch), lr: 1.000000
2019-03-16 19:18:16,225 2019-03-16 19:18:16: step 152/50000, loss = 0.240839 (1.977 sec/batch), lr: 1.000000
2019-03-16 19:18:18,367 2019-03-16 19:18:18: step 153/50000, loss = 0.203747 (2.131 sec/batch), lr: 1.000000
2019-03-16 19:18:20,553 2019-03-16 19:18:20: step 154/50000, loss = 0.227943 (2.176 sec/batch), lr: 1.000000
2019-03-16 19:18:22,814 2019-03-16 19:18:22: step 155/50000, loss = 0.198094 (2.250 sec/batch), lr: 1.000000
2019-03-16 19:18:24,973 2019-03-16 19:18:24: step 156/50000, loss = 0.231243 (2.148 sec/batch), lr: 1.000000
2019-03-16 19:18:27,462 2019-03-16 19:18:27: step 157/50000, loss = 0.211749 (2.478 sec/batch), lr: 1.000000
2019-03-16 19:18:29,883 2019-03-16 19:18:29: step 158/50000, loss = 0.243249 (2.410 sec/batch), lr: 1.000000
2019-03-16 19:18:32,307 2019-03-16 19:18:32: step 159/50000, loss = 0.196360 (2.411 sec/batch), lr: 1.000000
2019-03-16 19:18:34,912 2019-03-16 19:18:34: step 160/50000, loss = 0.243047 (2.592 sec/batch), lr: 1.000000
2019-03-16 19:18:37,587 2019-03-16 19:18:37: step 161/50000, loss = 0.210208 (2.664 sec/batch), lr: 1.000000
2019-03-16 19:18:40,268 2019-03-16 19:18:40: step 162/50000, loss = 0.237557 (2.668 sec/batch), lr: 1.000000
2019-03-16 19:18:43,087 2019-03-16 19:18:43: step 163/50000, loss = 0.210357 (2.807 sec/batch), lr: 1.000000
2019-03-16 19:18:45,850 2019-03-16 19:18:45: step 164/50000, loss = 0.235420 (2.750 sec/batch), lr: 1.000000
2019-03-16 19:18:48,871 2019-03-16 19:18:48: step 165/50000, loss = 0.211411 (3.006 sec/batch), lr: 1.000000
2019-03-16 19:18:51,982 2019-03-16 19:18:51: step 166/50000, loss = 0.239783 (3.106 sec/batch), lr: 1.000000
2019-03-16 19:18:55,010 2019-03-16 19:18:55: step 167/50000, loss = 0.207752 (3.014 sec/batch), lr: 1.000000
2019-03-16 19:18:58,223 2019-03-16 19:18:58: step 168/50000, loss = 0.232487 (3.198 sec/batch), lr: 1.000000
2019-03-16 19:19:01,457 2019-03-16 19:19:01: step 169/50000, loss = 0.210993 (3.219 sec/batch), lr: 1.000000
2019-03-16 19:19:04,861 2019-03-16 19:19:04: step 170/50000, loss = 0.224188 (3.388 sec/batch), lr: 1.000000
2019-03-16 19:19:08,343 2019-03-16 19:19:08: step 171/50000, loss = 0.211967 (3.464 sec/batch), lr: 1.000000
2019-03-16 19:19:11,749 2019-03-16 19:19:11: step 172/50000, loss = 0.234914 (3.389 sec/batch), lr: 1.000000
2019-03-16 19:19:15,469 2019-03-16 19:19:15: step 173/50000, loss = 0.209848 (3.701 sec/batch), lr: 1.000000
2019-03-16 19:19:19,207 2019-03-16 19:19:19: step 174/50000, loss = 0.230362 (3.719 sec/batch), lr: 1.000000
2019-03-16 19:19:23,215 2019-03-16 19:19:23: step 175/50000, loss = 0.208979 (3.987 sec/batch), lr: 1.000000
2019-03-16 19:19:27,347 2019-03-16 19:19:27: step 176/50000, loss = 0.229285 (4.112 sec/batch), lr: 1.000000
2019-03-16 19:19:31,574 2019-03-16 19:19:31: step 177/50000, loss = 0.206600 (4.206 sec/batch), lr: 1.000000
2019-03-16 19:19:35,732 2019-03-16 19:19:35: step 178/50000, loss = 0.223485 (4.137 sec/batch), lr: 1.000000
2019-03-16 19:19:40,126 2019-03-16 19:19:40: step 179/50000, loss = 0.212789 (4.372 sec/batch), lr: 1.000000
2019-03-16 19:19:44,835 2019-03-16 19:19:44: step 180/50000, loss = 0.234562 (4.684 sec/batch), lr: 1.000000
2019-03-16 19:19:49,782 2019-03-16 19:19:49: step 181/50000, loss = 0.209069 (4.920 sec/batch), lr: 1.000000
2019-03-16 19:19:54,726 2019-03-16 19:19:54: step 182/50000, loss = 0.232596 (4.921 sec/batch), lr: 1.000000
2019-03-16 19:19:59,945 2019-03-16 19:19:59: step 183/50000, loss = 0.212923 (5.195 sec/batch), lr: 1.000000
2019-03-16 19:20:05,325 2019-03-16 19:20:05: step 184/50000, loss = 0.231308 (5.375 sec/batch), lr: 1.000000
2019-03-16 19:20:10,958 2019-03-16 19:20:10: step 185/50000, loss = 0.216237 (5.605 sec/batch), lr: 1.000000
2019-03-16 19:20:17,015 2019-03-16 19:20:17: step 186/50000, loss = 0.242984 (6.024 sec/batch), lr: 1.000000
2019-03-16 19:20:23,359 2019-03-16 19:20:23: step 187/50000, loss = 0.208565 (6.337 sec/batch), lr: 1.000000
2019-03-16 19:20:29,882 2019-03-16 19:20:29: step 188/50000, loss = 0.240659 (6.486 sec/batch), lr: 1.000000
2019-03-16 19:20:36,824 2019-03-16 19:20:36: step 189/50000, loss = 0.211498 (6.904 sec/batch), lr: 1.000000
2019-03-16 19:20:44,164 2019-03-16 19:20:44: step 190/50000, loss = 0.236506 (7.293 sec/batch), lr: 1.000000
2019-03-16 19:20:51,865 2019-03-16 19:20:51: step 191/50000, loss = 0.225975 (7.657 sec/batch), lr: 1.000000
2019-03-16 19:21:00,457 2019-03-16 19:21:00: step 192/50000, loss = 0.239911 (8.543 sec/batch), lr: 1.000000
2019-03-16 19:21:09,877 2019-03-16 19:21:09: step 193/50000, loss = 0.210310 (9.365 sec/batch), lr: 1.000000
2019-03-16 19:21:20,046 2019-03-16 19:21:20: step 194/50000, loss = 0.253347 (10.108 sec/batch), lr: 1.000000
2019-03-16 19:21:30,618 2019-03-16 19:21:30: step 195/50000, loss = 0.218555 (10.507 sec/batch), lr: 1.000000
2019-03-16 19:21:42,891 2019-03-16 19:21:42: step 196/50000, loss = 0.218778 (12.201 sec/batch), lr: 1.000000
2019-03-16 19:21:57,115 2019-03-16 19:21:57: step 197/50000, loss = 0.269504 (14.140 sec/batch), lr: 1.000000
2019-03-16 19:22:13,993 2019-03-16 19:22:13: step 198/50000, loss = 0.238333 (16.781 sec/batch), lr: 1.000000
2019-03-16 19:22:35,925 2019-03-16 19:22:35: step 199/50000, loss = 0.228495 (21.800 sec/batch), lr: 1.000000
2019-03-16 19:22:49,967 2019-03-16 19:22:49: step 200/50000, loss = 0.270388 (13.945 sec/batch), lr: 1.000000
2019-03-16 19:23:15,415 step 200: Full loss = 0.234095, Edge acc. = 0.2544
2019-03-16 19:23:46,059 2019-03-16 19:23:46: step 201/50000, loss = 0.177528 (30.481 sec/batch), lr: 0.500000
2019-03-16 19:24:03,594 2019-03-16 19:24:03: step 202/50000, loss = 0.220092 (17.434 sec/batch), lr: 0.500000
2019-03-16 19:24:17,655 2019-03-16 19:24:17: step 203/50000, loss = 0.224105 (13.981 sec/batch), lr: 0.500000
2019-03-16 19:24:29,670 2019-03-16 19:24:29: step 204/50000, loss = 0.217135 (11.943 sec/batch), lr: 0.500000
2019-03-16 19:24:40,465 2019-03-16 19:24:40: step 205/50000, loss = 0.230141 (10.730 sec/batch), lr: 0.500000
2019-03-16 19:24:50,605 2019-03-16 19:24:50: step 206/50000, loss = 0.214284 (10.081 sec/batch), lr: 0.500000
2019-03-16 19:24:59,981 2019-03-16 19:24:59: step 207/50000, loss = 0.239480 (9.321 sec/batch), lr: 0.500000
2019-03-16 19:25:08,550 2019-03-16 19:25:08: step 208/50000, loss = 0.210779 (8.561 sec/batch), lr: 0.500000
2019-03-16 19:25:16,013 2019-03-16 19:25:16: step 209/50000, loss = 0.224479 (7.422 sec/batch), lr: 0.500000
2019-03-16 19:25:23,282 2019-03-16 19:25:23: step 210/50000, loss = 0.216891 (7.263 sec/batch), lr: 0.500000
2019-03-16 19:25:30,228 2019-03-16 19:25:30: step 211/50000, loss = 0.227901 (6.908 sec/batch), lr: 0.500000
2019-03-16 19:25:36,861 2019-03-16 19:25:36: step 212/50000, loss = 0.208542 (6.597 sec/batch), lr: 0.500000
2019-03-16 19:25:43,206 2019-03-16 19:25:43: step 213/50000, loss = 0.224683 (6.310 sec/batch), lr: 0.500000
2019-03-16 19:25:49,222 2019-03-16 19:25:49: step 214/50000, loss = 0.214630 (6.009 sec/batch), lr: 0.500000
2019-03-16 19:25:54,985 2019-03-16 19:25:54: step 215/50000, loss = 0.222217 (5.733 sec/batch), lr: 0.500000
2019-03-16 19:26:00,382 2019-03-16 19:26:00: step 216/50000, loss = 0.206523 (5.368 sec/batch), lr: 0.500000
2019-03-16 19:26:05,773 2019-03-16 19:26:05: step 217/50000, loss = 0.216320 (5.364 sec/batch), lr: 0.500000
2019-03-16 19:26:11,068 2019-03-16 19:26:11: step 218/50000, loss = 0.203863 (5.272 sec/batch), lr: 0.500000
2019-03-16 19:26:15,895 2019-03-16 19:26:15: step 219/50000, loss = 0.208985 (4.802 sec/batch), lr: 0.500000
2019-03-16 19:26:20,460 2019-03-16 19:26:20: step 220/50000, loss = 0.205918 (4.534 sec/batch), lr: 0.500000
2019-03-16 19:26:24,683 2019-03-16 19:26:24: step 221/50000, loss = 0.224502 (4.202 sec/batch), lr: 0.500000
2019-03-16 19:26:28,973 2019-03-16 19:26:28: step 222/50000, loss = 0.203911 (4.269 sec/batch), lr: 0.500000
2019-03-16 19:26:33,055 2019-03-16 19:26:33: step 223/50000, loss = 0.208508 (4.063 sec/batch), lr: 0.500000
2019-03-16 19:26:36,967 2019-03-16 19:26:36: step 224/50000, loss = 0.196000 (3.892 sec/batch), lr: 0.500000
2019-03-16 19:26:40,833 2019-03-16 19:26:40: step 225/50000, loss = 0.193591 (3.848 sec/batch), lr: 0.500000
2019-03-16 19:26:44,443 2019-03-16 19:26:44: step 226/50000, loss = 0.209790 (3.592 sec/batch), lr: 0.500000
2019-03-16 19:26:48,087 2019-03-16 19:26:48: step 227/50000, loss = 0.205431 (3.638 sec/batch), lr: 0.500000
2019-03-16 19:26:51,539 2019-03-16 19:26:51: step 228/50000, loss = 0.211281 (3.435 sec/batch), lr: 0.500000
2019-03-16 19:26:54,945 2019-03-16 19:26:54: step 229/50000, loss = 0.205434 (3.390 sec/batch), lr: 0.500000
2019-03-16 19:26:58,308 2019-03-16 19:26:58: step 230/50000, loss = 0.199532 (3.348 sec/batch), lr: 0.500000
2019-03-16 19:27:01,495 2019-03-16 19:27:01: step 231/50000, loss = 0.206874 (3.172 sec/batch), lr: 0.500000
2019-03-16 19:27:04,533 2019-03-16 19:27:04: step 232/50000, loss = 0.205285 (3.024 sec/batch), lr: 0.500000
2019-03-16 19:27:07,336 2019-03-16 19:27:07: step 233/50000, loss = 0.202006 (2.792 sec/batch), lr: 0.500000
2019-03-16 19:27:10,079 2019-03-16 19:27:10: step 234/50000, loss = 0.191361 (2.731 sec/batch), lr: 0.500000
2019-03-16 19:27:13,065 2019-03-16 19:27:13: step 235/50000, loss = 0.204767 (2.972 sec/batch), lr: 0.500000
2019-03-16 19:27:15,832 2019-03-16 19:27:15: step 236/50000, loss = 0.200448 (2.755 sec/batch), lr: 0.500000
2019-03-16 19:27:18,660 2019-03-16 19:27:18: step 237/50000, loss = 0.200064 (2.815 sec/batch), lr: 0.500000
2019-03-16 19:27:21,263 2019-03-16 19:27:21: step 238/50000, loss = 0.205735 (2.594 sec/batch), lr: 0.500000
2019-03-16 19:27:23,733 2019-03-16 19:27:23: step 239/50000, loss = 0.203086 (2.459 sec/batch), lr: 0.500000
2019-03-16 19:27:26,241 2019-03-16 19:27:26: step 240/50000, loss = 0.199219 (2.496 sec/batch), lr: 0.500000
2019-03-16 19:27:28,872 2019-03-16 19:27:28: step 241/50000, loss = 0.205367 (2.620 sec/batch), lr: 0.500000
2019-03-16 19:27:31,239 2019-03-16 19:27:31: step 242/50000, loss = 0.201634 (2.356 sec/batch), lr: 0.500000
2019-03-16 19:27:33,531 2019-03-16 19:27:33: step 243/50000, loss = 0.199002 (2.283 sec/batch), lr: 0.500000
2019-03-16 19:27:35,872 2019-03-16 19:27:35: step 244/50000, loss = 0.177656 (2.337 sec/batch), lr: 0.500000
2019-03-16 19:27:37,945 2019-03-16 19:27:37: step 245/50000, loss = 0.190712 (2.064 sec/batch), lr: 0.500000
2019-03-16 19:27:40,036 2019-03-16 19:27:40: step 246/50000, loss = 0.190648 (2.082 sec/batch), lr: 0.500000
2019-03-16 19:27:42,167 2019-03-16 19:27:42: step 247/50000, loss = 0.192226 (2.121 sec/batch), lr: 0.500000
2019-03-16 19:27:44,336 2019-03-16 19:27:44: step 248/50000, loss = 0.187137 (2.158 sec/batch), lr: 0.500000
2019-03-16 19:27:46,418 2019-03-16 19:27:46: step 249/50000, loss = 0.195864 (2.072 sec/batch), lr: 0.500000
2019-03-16 19:27:48,344 2019-03-16 19:27:48: step 250/50000, loss = 0.188439 (1.916 sec/batch), lr: 0.500000
2019-03-16 19:27:50,294 2019-03-16 19:27:50: step 251/50000, loss = 0.190344 (1.940 sec/batch), lr: 0.500000
2019-03-16 19:27:52,206 2019-03-16 19:27:52: step 252/50000, loss = 0.185033 (1.905 sec/batch), lr: 0.500000
2019-03-16 19:27:54,133 2019-03-16 19:27:54: step 253/50000, loss = 0.192223 (1.919 sec/batch), lr: 0.500000
2019-03-16 19:27:55,750 2019-03-16 19:27:55: step 254/50000, loss = 0.194154 (1.610 sec/batch), lr: 0.500000
2019-03-16 19:27:57,488 2019-03-16 19:27:57: step 255/50000, loss = 0.195777 (1.730 sec/batch), lr: 0.500000
2019-03-16 19:27:59,224 2019-03-16 19:27:59: step 256/50000, loss = 0.189466 (1.727 sec/batch), lr: 0.500000
2019-03-16 19:28:00,780 2019-03-16 19:28:00: step 257/50000, loss = 0.194870 (1.550 sec/batch), lr: 0.500000
2019-03-16 19:28:02,211 2019-03-16 19:28:02: step 258/50000, loss = 0.184884 (1.426 sec/batch), lr: 0.500000
2019-03-16 19:28:03,675 2019-03-16 19:28:03: step 259/50000, loss = 0.179252 (1.459 sec/batch), lr: 0.500000
2019-03-16 19:28:04,899 2019-03-16 19:28:04: step 260/50000, loss = 0.191665 (1.221 sec/batch), lr: 0.500000
2019-03-16 19:28:06,178 2019-03-16 19:28:06: step 261/50000, loss = 0.191802 (1.273 sec/batch), lr: 0.500000
2019-03-16 19:28:07,598 2019-03-16 19:28:07: step 262/50000, loss = 0.175359 (1.413 sec/batch), lr: 0.500000
2019-03-16 19:28:08,912 2019-03-16 19:28:08: step 263/50000, loss = 0.187561 (1.307 sec/batch), lr: 0.500000
2019-03-16 19:28:10,101 2019-03-16 19:28:10: step 264/50000, loss = 0.176119 (1.184 sec/batch), lr: 0.500000
2019-03-16 19:28:11,386 2019-03-16 19:28:11: step 265/50000, loss = 0.194858 (1.281 sec/batch), lr: 0.500000
2019-03-16 19:28:12,532 2019-03-16 19:28:12: step 266/50000, loss = 0.177559 (1.140 sec/batch), lr: 0.500000
2019-03-16 19:28:13,757 2019-03-16 19:28:13: step 267/50000, loss = 0.178802 (1.218 sec/batch), lr: 0.500000
2019-03-16 19:28:14,954 2019-03-16 19:28:14: step 268/50000, loss = 0.188116 (1.191 sec/batch), lr: 0.500000
2019-03-16 19:28:16,022 2019-03-16 19:28:16: step 269/50000, loss = 0.183396 (1.064 sec/batch), lr: 0.500000
2019-03-16 19:28:16,994 2019-03-16 19:28:16: step 270/50000, loss = 0.176759 (0.968 sec/batch), lr: 0.500000
2019-03-16 19:28:17,888 2019-03-16 19:28:17: step 271/50000, loss = 0.183659 (0.890 sec/batch), lr: 0.500000
2019-03-16 19:28:18,815 2019-03-16 19:28:18: step 272/50000, loss = 0.167098 (0.922 sec/batch), lr: 0.500000
2019-03-16 19:28:19,752 2019-03-16 19:28:19: step 273/50000, loss = 0.179148 (0.931 sec/batch), lr: 0.500000
2019-03-16 19:28:20,674 2019-03-16 19:28:20: step 274/50000, loss = 0.178209 (0.916 sec/batch), lr: 0.500000
2019-03-16 19:28:21,490 2019-03-16 19:28:21: step 275/50000, loss = 0.170131 (0.812 sec/batch), lr: 0.500000
2019-03-16 19:28:22,307 2019-03-16 19:28:22: step 276/50000, loss = 0.183138 (0.812 sec/batch), lr: 0.500000
2019-03-16 19:28:23,044 2019-03-16 19:28:23: step 277/50000, loss = 0.165259 (0.731 sec/batch), lr: 0.500000
2019-03-16 19:28:23,697 2019-03-16 19:28:23: step 278/50000, loss = 0.179943 (0.650 sec/batch), lr: 0.500000
2019-03-16 19:28:24,318 2019-03-16 19:28:24: step 279/50000, loss = 0.182206 (0.617 sec/batch), lr: 0.500000
2019-03-16 19:28:24,944 2019-03-16 19:28:24: step 280/50000, loss = 0.170915 (0.621 sec/batch), lr: 0.500000
2019-03-16 19:28:25,452 2019-03-16 19:28:25: step 281/50000, loss = 0.183616 (0.506 sec/batch), lr: 0.500000
2019-03-16 19:28:26,032 2019-03-16 19:28:26: step 282/50000, loss = 0.179556 (0.577 sec/batch), lr: 0.500000
2019-03-16 19:28:26,641 2019-03-16 19:28:26: step 283/50000, loss = 0.179204 (0.604 sec/batch), lr: 0.500000
2019-03-16 19:28:27,179 2019-03-16 19:28:27: step 284/50000, loss = 0.178406 (0.534 sec/batch), lr: 0.500000
2019-03-16 19:28:27,708 2019-03-16 19:28:27: step 285/50000, loss = 0.178056 (0.524 sec/batch), lr: 0.500000
2019-03-16 19:28:28,238 2019-03-16 19:28:28: step 286/50000, loss = 0.166056 (0.525 sec/batch), lr: 0.500000
2019-03-16 19:28:28,694 2019-03-16 19:28:28: step 287/50000, loss = 0.174344 (0.453 sec/batch), lr: 0.500000
2019-03-16 19:28:29,119 2019-03-16 19:28:29: step 288/50000, loss = 0.165210 (0.421 sec/batch), lr: 0.500000
2019-03-16 19:28:29,479 2019-03-16 19:28:29: step 289/50000, loss = 0.168317 (0.357 sec/batch), lr: 0.500000
2019-03-16 19:28:29,855 2019-03-16 19:28:29: step 290/50000, loss = 0.172845 (0.372 sec/batch), lr: 0.500000
2019-03-16 19:28:30,204 2019-03-16 19:28:30: step 291/50000, loss = 0.155487 (0.347 sec/batch), lr: 0.500000
2019-03-16 19:28:30,521 2019-03-16 19:28:30: step 292/50000, loss = 0.160640 (0.313 sec/batch), lr: 0.500000
2019-03-16 19:28:30,821 2019-03-16 19:28:30: step 293/50000, loss = 0.140789 (0.297 sec/batch), lr: 0.500000
2019-03-16 19:28:31,081 2019-03-16 19:28:31: step 294/50000, loss = 0.166426 (0.258 sec/batch), lr: 0.500000
2019-03-16 19:28:31,316 2019-03-16 19:28:31: step 295/50000, loss = 0.146708 (0.233 sec/batch), lr: 0.500000
2019-03-16 19:28:31,526 2019-03-16 19:28:31: step 296/50000, loss = 0.153197 (0.208 sec/batch), lr: 0.500000
2019-03-16 19:28:31,677 2019-03-16 19:28:31: step 297/50000, loss = 0.093033 (0.148 sec/batch), lr: 0.500000
2019-03-16 19:28:31,821 2019-03-16 19:28:31: step 298/50000, loss = 0.068823 (0.143 sec/batch), lr: 0.500000
2019-03-16 19:28:31,956 2019-03-16 19:28:31: step 299/50000, loss = 0.060083 (0.132 sec/batch), lr: 0.500000
2019-03-16 19:28:32,038 2019-03-16 19:28:32: step 300/50000, loss = 0.057160 (0.082 sec/batch), lr: 0.500000
2019-03-16 19:28:57,219 step 300: Full loss = 0.189050, Edge acc. = 0.3496
2019-03-16 19:29:27,574 2019-03-16 19:29:27: step 301/50000, loss = 0.294414 (30.132 sec/batch), lr: 0.500000
2019-03-16 19:29:44,315 2019-03-16 19:29:44: step 302/50000, loss = 0.345618 (16.733 sec/batch), lr: 0.500000
2019-03-16 19:29:58,341 2019-03-16 19:29:58: step 303/50000, loss = 0.321689 (14.017 sec/batch), lr: 0.500000
2019-03-16 19:30:10,247 2019-03-16 19:30:10: step 304/50000, loss = 0.295797 (11.897 sec/batch), lr: 0.500000
2019-03-16 19:30:20,860 2019-03-16 19:30:20: step 305/50000, loss = 0.263980 (10.606 sec/batch), lr: 0.500000
2019-03-16 19:30:30,874 2019-03-16 19:30:30: step 306/50000, loss = 0.232656 (9.955 sec/batch), lr: 0.500000
2019-03-16 19:30:40,067 2019-03-16 19:30:40: step 307/50000, loss = 0.222072 (9.143 sec/batch), lr: 0.500000
2019-03-16 19:30:48,631 2019-03-16 19:30:48: step 308/50000, loss = 0.210867 (8.514 sec/batch), lr: 0.500000
2019-03-16 19:30:56,273 2019-03-16 19:30:56: step 309/50000, loss = 0.230117 (7.600 sec/batch), lr: 0.500000
2019-03-16 19:31:03,416 2019-03-16 19:31:03: step 310/50000, loss = 0.219287 (7.105 sec/batch), lr: 0.500000
2019-03-16 19:31:10,245 2019-03-16 19:31:10: step 311/50000, loss = 0.226791 (6.824 sec/batch), lr: 0.500000
2019-03-16 19:31:16,842 2019-03-16 19:31:16: step 312/50000, loss = 0.205107 (6.562 sec/batch), lr: 0.500000
2019-03-16 19:31:23,288 2019-03-16 19:31:23: step 313/50000, loss = 0.228858 (6.439 sec/batch), lr: 0.500000
2019-03-16 19:31:29,236 2019-03-16 19:31:29: step 314/50000, loss = 0.210411 (5.916 sec/batch), lr: 0.500000
2019-03-16 19:31:34,974 2019-03-16 19:31:34: step 315/50000, loss = 0.217346 (5.733 sec/batch), lr: 0.500000
2019-03-16 19:31:40,427 2019-03-16 19:31:40: step 316/50000, loss = 0.206665 (5.424 sec/batch), lr: 0.500000
2019-03-16 19:31:45,854 2019-03-16 19:31:45: step 317/50000, loss = 0.212913 (5.398 sec/batch), lr: 0.500000
2019-03-16 19:31:50,721 2019-03-16 19:31:50: step 318/50000, loss = 0.204469 (4.862 sec/batch), lr: 0.500000
2019-03-16 19:31:55,578 2019-03-16 19:31:55: step 319/50000, loss = 0.208365 (4.832 sec/batch), lr: 0.500000
2019-03-16 19:32:00,187 2019-03-16 19:32:00: step 320/50000, loss = 0.202069 (4.586 sec/batch), lr: 0.500000
2019-03-16 19:32:04,519 2019-03-16 19:32:04: step 321/50000, loss = 0.218783 (4.312 sec/batch), lr: 0.500000
2019-03-16 19:32:08,567 2019-03-16 19:32:08: step 322/50000, loss = 0.201943 (4.027 sec/batch), lr: 0.500000
2019-03-16 19:32:12,716 2019-03-16 19:32:12: step 323/50000, loss = 0.214849 (4.128 sec/batch), lr: 0.500000
2019-03-16 19:32:16,681 2019-03-16 19:32:16: step 324/50000, loss = 0.187377 (3.947 sec/batch), lr: 0.500000
2019-03-16 19:32:20,651 2019-03-16 19:32:20: step 325/50000, loss = 0.199131 (3.965 sec/batch), lr: 0.500000
2019-03-16 19:32:24,293 2019-03-16 19:32:24: step 326/50000, loss = 0.203645 (3.625 sec/batch), lr: 0.500000
2019-03-16 19:32:27,996 2019-03-16 19:32:27: step 327/50000, loss = 0.208547 (3.684 sec/batch), lr: 0.500000
2019-03-16 19:32:31,460 2019-03-16 19:32:31: step 328/50000, loss = 0.201693 (3.449 sec/batch), lr: 0.500000
2019-03-16 19:32:34,846 2019-03-16 19:32:34: step 329/50000, loss = 0.204366 (3.371 sec/batch), lr: 0.500000
2019-03-16 19:32:38,197 2019-03-16 19:32:38: step 330/50000, loss = 0.192444 (3.345 sec/batch), lr: 0.500000
2019-03-16 19:32:41,439 2019-03-16 19:32:41: step 331/50000, loss = 0.203831 (3.236 sec/batch), lr: 0.500000
2019-03-16 19:32:44,578 2019-03-16 19:32:44: step 332/50000, loss = 0.201079 (3.119 sec/batch), lr: 0.500000
2019-03-16 19:32:47,668 2019-03-16 19:32:47: step 333/50000, loss = 0.209622 (3.084 sec/batch), lr: 0.500000
2019-03-16 19:32:50,675 2019-03-16 19:32:50: step 334/50000, loss = 0.193867 (2.995 sec/batch), lr: 0.500000
2019-03-16 19:32:53,583 2019-03-16 19:32:53: step 335/50000, loss = 0.193494 (2.895 sec/batch), lr: 0.500000
2019-03-16 19:32:56,419 2019-03-16 19:32:56: step 336/50000, loss = 0.196347 (2.831 sec/batch), lr: 0.500000
2019-03-16 19:32:59,273 2019-03-16 19:32:59: step 337/50000, loss = 0.201975 (2.840 sec/batch), lr: 0.500000
2019-03-16 19:33:01,946 2019-03-16 19:33:01: step 338/50000, loss = 0.201911 (2.668 sec/batch), lr: 0.500000
2019-03-16 19:33:04,563 2019-03-16 19:33:04: step 339/50000, loss = 0.194109 (2.606 sec/batch), lr: 0.500000
2019-03-16 19:33:07,200 2019-03-16 19:33:07: step 340/50000, loss = 0.196734 (2.632 sec/batch), lr: 0.500000
2019-03-16 19:33:09,722 2019-03-16 19:33:09: step 341/50000, loss = 0.204595 (2.511 sec/batch), lr: 0.500000
2019-03-16 19:33:12,121 2019-03-16 19:33:12: step 342/50000, loss = 0.199064 (2.389 sec/batch), lr: 0.500000
2019-03-16 19:33:14,380 2019-03-16 19:33:14: step 343/50000, loss = 0.198335 (2.249 sec/batch), lr: 0.500000
2019-03-16 19:33:16,598 2019-03-16 19:33:16: step 344/50000, loss = 0.176556 (2.208 sec/batch), lr: 0.500000
2019-03-16 19:33:18,833 2019-03-16 19:33:18: step 345/50000, loss = 0.188111 (2.230 sec/batch), lr: 0.500000
2019-03-16 19:33:21,137 2019-03-16 19:33:21: step 346/50000, loss = 0.181678 (2.294 sec/batch), lr: 0.500000
2019-03-16 19:33:23,135 2019-03-16 19:33:23: step 347/50000, loss = 0.190410 (1.991 sec/batch), lr: 0.500000
2019-03-16 19:33:25,076 2019-03-16 19:33:25: step 348/50000, loss = 0.182868 (1.932 sec/batch), lr: 0.500000
2019-03-16 19:33:27,185 2019-03-16 19:33:27: step 349/50000, loss = 0.187592 (2.099 sec/batch), lr: 0.500000
2019-03-16 19:33:29,098 2019-03-16 19:33:29: step 350/50000, loss = 0.181903 (1.904 sec/batch), lr: 0.500000
2019-03-16 19:33:30,724 2019-03-16 19:33:30: step 351/50000, loss = 0.187844 (1.617 sec/batch), lr: 0.500000
2019-03-16 19:33:32,466 2019-03-16 19:33:32: step 352/50000, loss = 0.181651 (1.738 sec/batch), lr: 0.500000
2019-03-16 19:33:34,095 2019-03-16 19:33:34: step 353/50000, loss = 0.188267 (1.621 sec/batch), lr: 0.500000
2019-03-16 19:33:35,753 2019-03-16 19:33:35: step 354/50000, loss = 0.189682 (1.650 sec/batch), lr: 0.500000
2019-03-16 19:33:37,405 2019-03-16 19:33:37: step 355/50000, loss = 0.187286 (1.644 sec/batch), lr: 0.500000
2019-03-16 19:33:38,997 2019-03-16 19:33:38: step 356/50000, loss = 0.185432 (1.584 sec/batch), lr: 0.500000
2019-03-16 19:33:40,481 2019-03-16 19:33:40: step 357/50000, loss = 0.189387 (1.477 sec/batch), lr: 0.500000
2019-03-16 19:33:42,086 2019-03-16 19:33:42: step 358/50000, loss = 0.181107 (1.598 sec/batch), lr: 0.500000
2019-03-16 19:33:43,632 2019-03-16 19:33:43: step 359/50000, loss = 0.172411 (1.538 sec/batch), lr: 0.500000
2019-03-16 19:33:45,067 2019-03-16 19:33:45: step 360/50000, loss = 0.175592 (1.431 sec/batch), lr: 0.500000
2019-03-16 19:33:46,536 2019-03-16 19:33:46: step 361/50000, loss = 0.193016 (1.464 sec/batch), lr: 0.500000
2019-03-16 19:33:47,825 2019-03-16 19:33:47: step 362/50000, loss = 0.180386 (1.284 sec/batch), lr: 0.500000
2019-03-16 19:33:48,982 2019-03-16 19:33:48: step 363/50000, loss = 0.193188 (1.153 sec/batch), lr: 0.500000
2019-03-16 19:33:50,077 2019-03-16 19:33:50: step 364/50000, loss = 0.178417 (1.090 sec/batch), lr: 0.500000
2019-03-16 19:33:51,170 2019-03-16 19:33:51: step 365/50000, loss = 0.186311 (1.086 sec/batch), lr: 0.500000
2019-03-16 19:33:52,225 2019-03-16 19:33:52: step 366/50000, loss = 0.172185 (1.052 sec/batch), lr: 0.500000
2019-03-16 19:33:53,158 2019-03-16 19:33:53: step 367/50000, loss = 0.185231 (0.931 sec/batch), lr: 0.500000
2019-03-16 19:33:54,139 2019-03-16 19:33:54: step 368/50000, loss = 0.187500 (0.977 sec/batch), lr: 0.500000
2019-03-16 19:33:55,114 2019-03-16 19:33:55: step 369/50000, loss = 0.186476 (0.970 sec/batch), lr: 0.500000
2019-03-16 19:33:56,058 2019-03-16 19:33:56: step 370/50000, loss = 0.179967 (0.939 sec/batch), lr: 0.500000
2019-03-16 19:33:56,897 2019-03-16 19:33:56: step 371/50000, loss = 0.177248 (0.835 sec/batch), lr: 0.500000
2019-03-16 19:33:57,811 2019-03-16 19:33:57: step 372/50000, loss = 0.159763 (0.908 sec/batch), lr: 0.500000
2019-03-16 19:33:58,757 2019-03-16 19:33:58: step 373/50000, loss = 0.169354 (0.942 sec/batch), lr: 0.500000
2019-03-16 19:33:59,681 2019-03-16 19:33:59: step 374/50000, loss = 0.180947 (0.919 sec/batch), lr: 0.500000
2019-03-16 19:34:00,520 2019-03-16 19:34:00: step 375/50000, loss = 0.165333 (0.834 sec/batch), lr: 0.500000
2019-03-16 19:34:01,350 2019-03-16 19:34:01: step 376/50000, loss = 0.180661 (0.825 sec/batch), lr: 0.500000
2019-03-16 19:34:02,089 2019-03-16 19:34:02: step 377/50000, loss = 0.164350 (0.733 sec/batch), lr: 0.500000
2019-03-16 19:34:02,753 2019-03-16 19:34:02: step 378/50000, loss = 0.186538 (0.659 sec/batch), lr: 0.500000
2019-03-16 19:34:03,374 2019-03-16 19:34:03: step 379/50000, loss = 0.171694 (0.618 sec/batch), lr: 0.500000
2019-03-16 19:34:03,918 2019-03-16 19:34:03: step 380/50000, loss = 0.161563 (0.543 sec/batch), lr: 0.500000
2019-03-16 19:34:04,440 2019-03-16 19:34:04: step 381/50000, loss = 0.184735 (0.518 sec/batch), lr: 0.500000
2019-03-16 19:34:04,952 2019-03-16 19:34:04: step 382/50000, loss = 0.183503 (0.509 sec/batch), lr: 0.500000
2019-03-16 19:34:05,548 2019-03-16 19:34:05: step 383/50000, loss = 0.182154 (0.592 sec/batch), lr: 0.500000
2019-03-16 19:34:05,992 2019-03-16 19:34:05: step 384/50000, loss = 0.174537 (0.440 sec/batch), lr: 0.500000
2019-03-16 19:34:06,466 2019-03-16 19:34:06: step 385/50000, loss = 0.181612 (0.471 sec/batch), lr: 0.500000
2019-03-16 19:34:06,954 2019-03-16 19:34:06: step 386/50000, loss = 0.178164 (0.485 sec/batch), lr: 0.500000
2019-03-16 19:34:07,324 2019-03-16 19:34:07: step 387/50000, loss = 0.162791 (0.368 sec/batch), lr: 0.500000
2019-03-16 19:34:07,694 2019-03-16 19:34:07: step 388/50000, loss = 0.163781 (0.367 sec/batch), lr: 0.500000
2019-03-16 19:34:07,991 2019-03-16 19:34:07: step 389/50000, loss = 0.164169 (0.296 sec/batch), lr: 0.500000
2019-03-16 19:34:08,293 2019-03-16 19:34:08: step 390/50000, loss = 0.164680 (0.300 sec/batch), lr: 0.500000
2019-03-16 19:34:08,602 2019-03-16 19:34:08: step 391/50000, loss = 0.146929 (0.306 sec/batch), lr: 0.500000
2019-03-16 19:34:08,893 2019-03-16 19:34:08: step 392/50000, loss = 0.164100 (0.288 sec/batch), lr: 0.500000
2019-03-16 19:34:09,156 2019-03-16 19:34:09: step 393/50000, loss = 0.146988 (0.261 sec/batch), lr: 0.500000
2019-03-16 19:34:09,378 2019-03-16 19:34:09: step 394/50000, loss = 0.164888 (0.220 sec/batch), lr: 0.500000
2019-03-16 19:34:09,588 2019-03-16 19:34:09: step 395/50000, loss = 0.139494 (0.208 sec/batch), lr: 0.500000
2019-03-16 19:34:09,763 2019-03-16 19:34:09: step 396/50000, loss = 0.152528 (0.173 sec/batch), lr: 0.500000
2019-03-16 19:34:09,892 2019-03-16 19:34:09: step 397/50000, loss = 0.105865 (0.127 sec/batch), lr: 0.500000
2019-03-16 19:34:10,012 2019-03-16 19:34:10: step 398/50000, loss = 0.049791 (0.119 sec/batch), lr: 0.500000
2019-03-16 19:34:10,111 2019-03-16 19:34:10: step 399/50000, loss = 0.055353 (0.097 sec/batch), lr: 0.500000
2019-03-16 19:34:10,181 2019-03-16 19:34:10: step 400/50000, loss = 0.022888 (0.070 sec/batch), lr: 0.500000
2019-03-16 19:34:35,292 step 400: Full loss = 0.173642, Edge acc. = 0.3045
2019-03-16 19:34:35,440 2019-03-16 19:34:35: step 401/50000, loss = 0.061556 (0.091 sec/batch), lr: 0.250000
2019-03-16 19:34:35,538 2019-03-16 19:34:35: step 402/50000, loss = 0.040949 (0.096 sec/batch), lr: 0.250000
2019-03-16 19:34:35,635 2019-03-16 19:34:35: step 403/50000, loss = 0.096498 (0.096 sec/batch), lr: 0.250000
2019-03-16 19:34:35,791 2019-03-16 19:34:35: step 404/50000, loss = 0.130617 (0.155 sec/batch), lr: 0.250000
2019-03-16 19:34:35,999 2019-03-16 19:34:35: step 405/50000, loss = 0.133901 (0.205 sec/batch), lr: 0.250000
2019-03-16 19:34:36,226 2019-03-16 19:34:36: step 406/50000, loss = 0.171185 (0.225 sec/batch), lr: 0.250000
2019-03-16 19:34:36,493 2019-03-16 19:34:36: step 407/50000, loss = 0.135769 (0.263 sec/batch), lr: 0.250000
2019-03-16 19:34:36,785 2019-03-16 19:34:36: step 408/50000, loss = 0.180562 (0.290 sec/batch), lr: 0.250000
2019-03-16 19:34:37,136 2019-03-16 19:34:37: step 409/50000, loss = 0.131529 (0.348 sec/batch), lr: 0.250000
2019-03-16 19:34:37,484 2019-03-16 19:34:37: step 410/50000, loss = 0.168950 (0.344 sec/batch), lr: 0.250000
2019-03-16 19:34:37,841 2019-03-16 19:34:37: step 411/50000, loss = 0.165168 (0.354 sec/batch), lr: 0.250000
2019-03-16 19:34:38,262 2019-03-16 19:34:38: step 412/50000, loss = 0.163555 (0.417 sec/batch), lr: 0.250000
2019-03-16 19:34:38,691 2019-03-16 19:34:38: step 413/50000, loss = 0.152858 (0.425 sec/batch), lr: 0.250000
2019-03-16 19:34:39,220 2019-03-16 19:34:39: step 414/50000, loss = 0.166545 (0.524 sec/batch), lr: 0.250000
2019-03-16 19:34:39,737 2019-03-16 19:34:39: step 415/50000, loss = 0.173313 (0.513 sec/batch), lr: 0.250000
2019-03-16 19:34:40,255 2019-03-16 19:34:40: step 416/50000, loss = 0.166648 (0.514 sec/batch), lr: 0.250000
2019-03-16 19:34:40,874 2019-03-16 19:34:40: step 417/50000, loss = 0.170388 (0.614 sec/batch), lr: 0.250000
2019-03-16 19:34:41,495 2019-03-16 19:34:41: step 418/50000, loss = 0.185203 (0.616 sec/batch), lr: 0.250000
2019-03-16 19:34:42,117 2019-03-16 19:34:42: step 419/50000, loss = 0.183372 (0.616 sec/batch), lr: 0.250000
2019-03-16 19:34:42,799 2019-03-16 19:34:42: step 420/50000, loss = 0.168107 (0.678 sec/batch), lr: 0.250000
2019-03-16 19:34:43,504 2019-03-16 19:34:43: step 421/50000, loss = 0.174026 (0.700 sec/batch), lr: 0.250000
2019-03-16 19:34:44,225 2019-03-16 19:34:44: step 422/50000, loss = 0.176911 (0.716 sec/batch), lr: 0.250000
2019-03-16 19:34:45,009 2019-03-16 19:34:45: step 423/50000, loss = 0.176372 (0.779 sec/batch), lr: 0.250000
2019-03-16 19:34:45,737 2019-03-16 19:34:45: step 424/50000, loss = 0.173356 (0.725 sec/batch), lr: 0.250000
2019-03-16 19:34:46,433 2019-03-16 19:34:46: step 425/50000, loss = 0.174679 (0.693 sec/batch), lr: 0.250000
2019-03-16 19:34:47,256 2019-03-16 19:34:47: step 426/50000, loss = 0.157377 (0.819 sec/batch), lr: 0.250000
2019-03-16 19:34:48,168 2019-03-16 19:34:48: step 427/50000, loss = 0.178884 (0.907 sec/batch), lr: 0.250000
2019-03-16 19:34:49,080 2019-03-16 19:34:49: step 428/50000, loss = 0.166707 (0.908 sec/batch), lr: 0.250000
2019-03-16 19:34:50,009 2019-03-16 19:34:50: step 429/50000, loss = 0.175630 (0.925 sec/batch), lr: 0.250000
2019-03-16 19:34:50,926 2019-03-16 19:34:50: step 430/50000, loss = 0.174637 (0.914 sec/batch), lr: 0.250000
2019-03-16 19:34:51,980 2019-03-16 19:34:51: step 431/50000, loss = 0.182467 (1.049 sec/batch), lr: 0.250000
2019-03-16 19:34:53,169 2019-03-16 19:34:53: step 432/50000, loss = 0.174770 (1.184 sec/batch), lr: 0.250000
2019-03-16 19:34:54,331 2019-03-16 19:34:54: step 433/50000, loss = 0.180756 (1.156 sec/batch), lr: 0.250000
2019-03-16 19:34:55,439 2019-03-16 19:34:55: step 434/50000, loss = 0.167937 (1.104 sec/batch), lr: 0.250000
2019-03-16 19:34:56,608 2019-03-16 19:34:56: step 435/50000, loss = 0.183023 (1.165 sec/batch), lr: 0.250000
2019-03-16 19:34:57,777 2019-03-16 19:34:57: step 436/50000, loss = 0.187571 (1.163 sec/batch), lr: 0.250000
2019-03-16 19:34:58,960 2019-03-16 19:34:58: step 437/50000, loss = 0.191097 (1.178 sec/batch), lr: 0.250000
2019-03-16 19:35:00,243 2019-03-16 19:35:00: step 438/50000, loss = 0.173982 (1.277 sec/batch), lr: 0.250000
2019-03-16 19:35:01,683 2019-03-16 19:35:01: step 439/50000, loss = 0.172724 (1.432 sec/batch), lr: 0.250000
2019-03-16 19:35:03,058 2019-03-16 19:35:03: step 440/50000, loss = 0.179245 (1.369 sec/batch), lr: 0.250000
2019-03-16 19:35:04,498 2019-03-16 19:35:04: step 441/50000, loss = 0.173100 (1.437 sec/batch), lr: 0.250000
2019-03-16 19:35:05,976 2019-03-16 19:35:05: step 442/50000, loss = 0.191394 (1.470 sec/batch), lr: 0.250000
2019-03-16 19:35:07,573 2019-03-16 19:35:07: step 443/50000, loss = 0.169391 (1.589 sec/batch), lr: 0.250000
2019-03-16 19:35:09,236 2019-03-16 19:35:09: step 444/50000, loss = 0.171189 (1.656 sec/batch), lr: 0.250000
2019-03-16 19:35:10,687 2019-03-16 19:35:10: step 445/50000, loss = 0.170669 (1.446 sec/batch), lr: 0.250000
2019-03-16 19:35:12,138 2019-03-16 19:35:12: step 446/50000, loss = 0.191390 (1.444 sec/batch), lr: 0.250000
2019-03-16 19:35:13,901 2019-03-16 19:35:13: step 447/50000, loss = 0.170821 (1.755 sec/batch), lr: 0.250000
2019-03-16 19:35:15,704 2019-03-16 19:35:15: step 448/50000, loss = 0.180458 (1.793 sec/batch), lr: 0.250000
2019-03-16 19:35:17,461 2019-03-16 19:35:17: step 449/50000, loss = 0.184662 (1.748 sec/batch), lr: 0.250000
2019-03-16 19:35:19,239 2019-03-16 19:35:19: step 450/50000, loss = 0.180739 (1.771 sec/batch), lr: 0.250000
2019-03-16 19:35:21,036 2019-03-16 19:35:21: step 451/50000, loss = 0.178193 (1.790 sec/batch), lr: 0.250000
2019-03-16 19:35:22,862 2019-03-16 19:35:22: step 452/50000, loss = 0.183674 (1.815 sec/batch), lr: 0.250000
2019-03-16 19:35:24,748 2019-03-16 19:35:24: step 453/50000, loss = 0.187176 (1.876 sec/batch), lr: 0.250000
2019-03-16 19:35:26,815 2019-03-16 19:35:26: step 454/50000, loss = 0.178493 (2.059 sec/batch), lr: 0.250000
2019-03-16 19:35:28,833 2019-03-16 19:35:28: step 455/50000, loss = 0.177031 (2.011 sec/batch), lr: 0.250000
2019-03-16 19:35:30,722 2019-03-16 19:35:30: step 456/50000, loss = 0.183216 (1.886 sec/batch), lr: 0.250000
2019-03-16 19:35:32,921 2019-03-16 19:35:32: step 457/50000, loss = 0.196889 (2.196 sec/batch), lr: 0.250000
2019-03-16 19:35:35,219 2019-03-16 19:35:35: step 458/50000, loss = 0.188949 (2.290 sec/batch), lr: 0.250000
2019-03-16 19:35:37,601 2019-03-16 19:35:37: step 459/50000, loss = 0.183917 (2.379 sec/batch), lr: 0.250000
2019-03-16 19:35:40,066 2019-03-16 19:35:40: step 460/50000, loss = 0.189408 (2.456 sec/batch), lr: 0.250000
2019-03-16 19:35:42,542 2019-03-16 19:35:42: step 461/50000, loss = 0.185802 (2.467 sec/batch), lr: 0.250000
2019-03-16 19:35:45,049 2019-03-16 19:35:45: step 462/50000, loss = 0.192367 (2.496 sec/batch), lr: 0.250000
2019-03-16 19:35:47,823 2019-03-16 19:35:47: step 463/50000, loss = 0.194015 (2.761 sec/batch), lr: 0.250000
2019-03-16 19:35:50,392 2019-03-16 19:35:50: step 464/50000, loss = 0.193603 (2.559 sec/batch), lr: 0.250000
2019-03-16 19:35:53,015 2019-03-16 19:35:53: step 465/50000, loss = 0.181441 (2.619 sec/batch), lr: 0.250000
2019-03-16 19:35:55,756 2019-03-16 19:35:55: step 466/50000, loss = 0.193942 (2.736 sec/batch), lr: 0.250000
2019-03-16 19:35:58,508 2019-03-16 19:35:58: step 467/50000, loss = 0.182275 (2.738 sec/batch), lr: 0.250000
2019-03-16 19:36:01,647 2019-03-16 19:36:01: step 468/50000, loss = 0.192644 (3.125 sec/batch), lr: 0.250000
2019-03-16 19:36:04,863 2019-03-16 19:36:04: step 469/50000, loss = 0.192951 (3.201 sec/batch), lr: 0.250000
2019-03-16 19:36:08,246 2019-03-16 19:36:08: step 470/50000, loss = 0.194181 (3.366 sec/batch), lr: 0.250000
2019-03-16 19:36:11,462 2019-03-16 19:36:11: step 471/50000, loss = 0.187763 (3.203 sec/batch), lr: 0.250000
2019-03-16 19:36:14,747 2019-03-16 19:36:14: step 472/50000, loss = 0.192782 (3.263 sec/batch), lr: 0.250000
2019-03-16 19:36:18,421 2019-03-16 19:36:18: step 473/50000, loss = 0.199285 (3.656 sec/batch), lr: 0.250000
2019-03-16 19:36:22,062 2019-03-16 19:36:22: step 474/50000, loss = 0.185084 (3.622 sec/batch), lr: 0.250000
2019-03-16 19:36:25,917 2019-03-16 19:36:25: step 475/50000, loss = 0.192641 (3.850 sec/batch), lr: 0.250000
2019-03-16 19:36:29,802 2019-03-16 19:36:29: step 476/50000, loss = 0.188056 (3.867 sec/batch), lr: 0.250000
2019-03-16 19:36:33,865 2019-03-16 19:36:33: step 477/50000, loss = 0.194860 (4.044 sec/batch), lr: 0.250000
2019-03-16 19:36:38,220 2019-03-16 19:36:38: step 478/50000, loss = 0.193409 (4.349 sec/batch), lr: 0.250000
2019-03-16 19:36:42,346 2019-03-16 19:36:42: step 479/50000, loss = 0.190435 (4.121 sec/batch), lr: 0.250000
2019-03-16 19:36:46,988 2019-03-16 19:36:46: step 480/50000, loss = 0.200544 (4.620 sec/batch), lr: 0.250000
2019-03-16 19:36:51,846 2019-03-16 19:36:51: step 481/50000, loss = 0.188665 (4.836 sec/batch), lr: 0.250000
2019-03-16 19:36:56,635 2019-03-16 19:36:56: step 482/50000, loss = 0.193592 (4.766 sec/batch), lr: 0.250000
2019-03-16 19:37:01,844 2019-03-16 19:37:01: step 483/50000, loss = 0.202245 (5.183 sec/batch), lr: 0.250000
2019-03-16 19:37:07,244 2019-03-16 19:37:07: step 484/50000, loss = 0.194684 (5.374 sec/batch), lr: 0.250000
2019-03-16 19:37:12,829 2019-03-16 19:37:12: step 485/50000, loss = 0.198911 (5.558 sec/batch), lr: 0.250000
2019-03-16 19:37:18,717 2019-03-16 19:37:18: step 486/50000, loss = 0.204416 (5.861 sec/batch), lr: 0.250000
2019-03-16 19:37:24,921 2019-03-16 19:37:24: step 487/50000, loss = 0.194029 (6.172 sec/batch), lr: 0.250000
2019-03-16 19:37:31,439 2019-03-16 19:37:31: step 488/50000, loss = 0.211773 (6.485 sec/batch), lr: 0.250000
2019-03-16 19:37:38,128 2019-03-16 19:37:38: step 489/50000, loss = 0.202458 (6.657 sec/batch), lr: 0.250000
2019-03-16 19:37:45,229 2019-03-16 19:37:45: step 490/50000, loss = 0.201366 (7.065 sec/batch), lr: 0.250000
2019-03-16 19:37:52,688 2019-03-16 19:37:52: step 491/50000, loss = 0.216349 (7.453 sec/batch), lr: 0.250000
2019-03-16 19:38:01,138 2019-03-16 19:38:01: step 492/50000, loss = 0.206587 (8.404 sec/batch), lr: 0.250000
2019-03-16 19:38:10,408 2019-03-16 19:38:10: step 493/50000, loss = 0.203385 (9.216 sec/batch), lr: 0.250000
2019-03-16 19:38:20,222 2019-03-16 19:38:20: step 494/50000, loss = 0.213474 (9.756 sec/batch), lr: 0.250000
2019-03-16 19:38:30,617 2019-03-16 19:38:30: step 495/50000, loss = 0.222650 (10.338 sec/batch), lr: 0.250000
2019-03-16 19:38:42,364 2019-03-16 19:38:42: step 496/50000, loss = 0.202458 (11.677 sec/batch), lr: 0.250000
2019-03-16 19:38:56,332 2019-03-16 19:38:56: step 497/50000, loss = 0.209394 (13.959 sec/batch), lr: 0.250000
2019-03-16 19:39:12,927 2019-03-16 19:39:12: step 498/50000, loss = 0.219090 (16.505 sec/batch), lr: 0.250000
2019-03-16 19:39:34,580 2019-03-16 19:39:34: step 499/50000, loss = 0.201078 (21.515 sec/batch), lr: 0.250000
2019-03-16 19:39:48,579 2019-03-16 19:39:48: step 500/50000, loss = 0.243099 (13.904 sec/batch), lr: 0.250000
2019-03-16 19:40:13,697 step 500: Full loss = 0.182578, Edge acc. = 0.2832
2019-03-16 19:40:13,837 2019-03-16 19:40:13: step 501/50000, loss = 0.379468 (0.083 sec/batch), lr: 0.250000
2019-03-16 19:40:13,949 2019-03-16 19:40:13: step 502/50000, loss = 0.157196 (0.110 sec/batch), lr: 0.250000
2019-03-16 19:40:14,071 2019-03-16 19:40:14: step 503/50000, loss = 0.134457 (0.120 sec/batch), lr: 0.250000
2019-03-16 19:40:14,219 2019-03-16 19:40:14: step 504/50000, loss = 0.132549 (0.147 sec/batch), lr: 0.250000
2019-03-16 19:40:14,409 2019-03-16 19:40:14: step 505/50000, loss = 0.140119 (0.188 sec/batch), lr: 0.250000
2019-03-16 19:40:14,617 2019-03-16 19:40:14: step 506/50000, loss = 0.164829 (0.206 sec/batch), lr: 0.250000
2019-03-16 19:40:14,875 2019-03-16 19:40:14: step 507/50000, loss = 0.147195 (0.256 sec/batch), lr: 0.250000
2019-03-16 19:40:15,177 2019-03-16 19:40:15: step 508/50000, loss = 0.170963 (0.299 sec/batch), lr: 0.250000
2019-03-16 19:40:15,504 2019-03-16 19:40:15: step 509/50000, loss = 0.145859 (0.324 sec/batch), lr: 0.250000
2019-03-16 19:40:15,836 2019-03-16 19:40:15: step 510/50000, loss = 0.178931 (0.329 sec/batch), lr: 0.250000
2019-03-16 19:40:16,207 2019-03-16 19:40:16: step 511/50000, loss = 0.164901 (0.367 sec/batch), lr: 0.250000
2019-03-16 19:40:16,649 2019-03-16 19:40:16: step 512/50000, loss = 0.162393 (0.438 sec/batch), lr: 0.250000
2019-03-16 19:40:17,098 2019-03-16 19:40:17: step 513/50000, loss = 0.160058 (0.446 sec/batch), lr: 0.250000
2019-03-16 19:40:17,624 2019-03-16 19:40:17: step 514/50000, loss = 0.167119 (0.522 sec/batch), lr: 0.250000
2019-03-16 19:40:18,142 2019-03-16 19:40:18: step 515/50000, loss = 0.183333 (0.514 sec/batch), lr: 0.250000
2019-03-16 19:40:18,631 2019-03-16 19:40:18: step 516/50000, loss = 0.173085 (0.486 sec/batch), lr: 0.250000
2019-03-16 19:40:19,212 2019-03-16 19:40:19: step 517/50000, loss = 0.167196 (0.577 sec/batch), lr: 0.250000
2019-03-16 19:40:19,805 2019-03-16 19:40:19: step 518/50000, loss = 0.187717 (0.589 sec/batch), lr: 0.250000
2019-03-16 19:40:20,410 2019-03-16 19:40:20: step 519/50000, loss = 0.175364 (0.601 sec/batch), lr: 0.250000
2019-03-16 19:40:21,100 2019-03-16 19:40:21: step 520/50000, loss = 0.167278 (0.685 sec/batch), lr: 0.250000
2019-03-16 19:40:21,798 2019-03-16 19:40:21: step 521/50000, loss = 0.159879 (0.695 sec/batch), lr: 0.250000
2019-03-16 19:40:22,482 2019-03-16 19:40:22: step 522/50000, loss = 0.176554 (0.679 sec/batch), lr: 0.250000
2019-03-16 19:40:23,183 2019-03-16 19:40:23: step 523/50000, loss = 0.166345 (0.697 sec/batch), lr: 0.250000
2019-03-16 19:40:24,004 2019-03-16 19:40:24: step 524/50000, loss = 0.164743 (0.816 sec/batch), lr: 0.250000
2019-03-16 19:40:24,848 2019-03-16 19:40:24: step 525/50000, loss = 0.171253 (0.838 sec/batch), lr: 0.250000
2019-03-16 19:40:25,721 2019-03-16 19:40:25: step 526/50000, loss = 0.159489 (0.867 sec/batch), lr: 0.250000
2019-03-16 19:40:26,559 2019-03-16 19:40:26: step 527/50000, loss = 0.177077 (0.832 sec/batch), lr: 0.250000
2019-03-16 19:40:27,524 2019-03-16 19:40:27: step 528/50000, loss = 0.165747 (0.961 sec/batch), lr: 0.250000
2019-03-16 19:40:28,597 2019-03-16 19:40:28: step 529/50000, loss = 0.167470 (1.066 sec/batch), lr: 0.250000
2019-03-16 19:40:29,679 2019-03-16 19:40:29: step 530/50000, loss = 0.176665 (1.075 sec/batch), lr: 0.250000
2019-03-16 19:40:30,892 2019-03-16 19:40:30: step 531/50000, loss = 0.169160 (1.209 sec/batch), lr: 0.250000
2019-03-16 19:40:31,943 2019-03-16 19:40:31: step 532/50000, loss = 0.174794 (1.045 sec/batch), lr: 0.250000
2019-03-16 19:40:33,011 2019-03-16 19:40:33: step 533/50000, loss = 0.179300 (1.062 sec/batch), lr: 0.250000
2019-03-16 19:40:34,235 2019-03-16 19:40:34: step 534/50000, loss = 0.165488 (1.218 sec/batch), lr: 0.250000
2019-03-16 19:40:35,546 2019-03-16 19:40:35: step 535/50000, loss = 0.188955 (1.304 sec/batch), lr: 0.250000
2019-03-16 19:40:36,817 2019-03-16 19:40:36: step 536/50000, loss = 0.165716 (1.264 sec/batch), lr: 0.250000
2019-03-16 19:40:38,017 2019-03-16 19:40:38: step 537/50000, loss = 0.185412 (1.194 sec/batch), lr: 0.250000
2019-03-16 19:40:39,407 2019-03-16 19:40:39: step 538/50000, loss = 0.161634 (1.383 sec/batch), lr: 0.250000
2019-03-16 19:40:40,878 2019-03-16 19:40:40: step 539/50000, loss = 0.176565 (1.463 sec/batch), lr: 0.250000
2019-03-16 19:40:42,250 2019-03-16 19:40:42: step 540/50000, loss = 0.178462 (1.368 sec/batch), lr: 0.250000
2019-03-16 19:40:43,689 2019-03-16 19:40:43: step 541/50000, loss = 0.172964 (1.433 sec/batch), lr: 0.250000
2019-03-16 19:40:45,243 2019-03-16 19:40:45: step 542/50000, loss = 0.183811 (1.547 sec/batch), lr: 0.250000
2019-03-16 19:46:25,930 2019-03-16 19:46:25: step 1/50000, loss = 0.334436 (49.664 sec/batch), lr: 1.000000
2019-03-16 19:46:49,426 2019-03-16 19:46:49: step 2/50000, loss = 0.441510 (23.360 sec/batch), lr: 1.000000
2019-03-16 19:47:07,784 2019-03-16 19:47:07: step 3/50000, loss = 0.454779 (18.342 sec/batch), lr: 1.000000
2019-03-16 19:47:23,302 2019-03-16 19:47:23: step 4/50000, loss = 0.454172 (15.435 sec/batch), lr: 1.000000
2019-03-16 19:47:35,968 2019-03-16 19:47:35: step 5/50000, loss = 0.457554 (12.656 sec/batch), lr: 1.000000
2019-03-16 19:47:47,384 2019-03-16 19:47:47: step 6/50000, loss = 0.446155 (11.349 sec/batch), lr: 1.000000
2019-03-16 19:47:57,897 2019-03-16 19:47:57: step 7/50000, loss = 0.440297 (10.502 sec/batch), lr: 1.000000
2019-03-16 19:48:07,394 2019-03-16 19:48:07: step 8/50000, loss = 0.398086 (9.443 sec/batch), lr: 1.000000
2019-03-16 19:48:16,335 2019-03-16 19:48:16: step 9/50000, loss = 0.281469 (8.890 sec/batch), lr: 1.000000
2019-03-16 19:48:24,462 2019-03-16 19:48:24: step 10/50000, loss = 0.433304 (8.083 sec/batch), lr: 1.000000
2019-03-16 19:48:31,663 2019-03-16 19:48:31: step 11/50000, loss = 0.256254 (7.162 sec/batch), lr: 1.000000
2019-03-16 19:48:38,561 2019-03-16 19:48:38: step 12/50000, loss = 0.431002 (6.860 sec/batch), lr: 1.000000
2019-03-16 19:48:45,021 2019-03-16 19:48:45: step 13/50000, loss = 0.233283 (6.424 sec/batch), lr: 1.000000
2019-03-16 19:48:50,852 2019-03-16 19:48:50: step 14/50000, loss = 0.418979 (5.822 sec/batch), lr: 1.000000
2019-03-16 19:48:56,509 2019-03-16 19:48:56: step 15/50000, loss = 0.226450 (5.650 sec/batch), lr: 1.000000
2019-03-16 19:49:01,850 2019-03-16 19:49:01: step 16/50000, loss = 0.423358 (5.312 sec/batch), lr: 1.000000
2019-03-16 19:49:06,876 2019-03-16 19:49:06: step 17/50000, loss = 0.221973 (4.999 sec/batch), lr: 1.000000
2019-03-16 19:49:11,822 2019-03-16 19:49:11: step 18/50000, loss = 0.402533 (4.920 sec/batch), lr: 1.000000
2019-03-16 19:49:16,109 2019-03-16 19:49:16: step 19/50000, loss = 0.224212 (4.263 sec/batch), lr: 1.000000
2019-03-16 19:49:20,113 2019-03-16 19:49:20: step 20/50000, loss = 0.416662 (3.995 sec/batch), lr: 1.000000
2019-03-16 19:49:24,204 2019-03-16 19:49:24: step 21/50000, loss = 0.208435 (4.069 sec/batch), lr: 1.000000
2019-03-16 19:49:28,168 2019-03-16 19:49:28: step 22/50000, loss = 0.398992 (3.943 sec/batch), lr: 1.000000
2019-03-16 19:49:31,873 2019-03-16 19:49:31: step 23/50000, loss = 0.202782 (3.696 sec/batch), lr: 1.000000
2019-03-16 19:49:35,277 2019-03-16 19:49:35: step 24/50000, loss = 0.395909 (3.385 sec/batch), lr: 1.000000
2019-03-16 19:49:38,557 2019-03-16 19:49:38: step 25/50000, loss = 0.209353 (3.263 sec/batch), lr: 1.000000
2019-03-16 19:49:41,713 2019-03-16 19:49:41: step 26/50000, loss = 0.393705 (3.138 sec/batch), lr: 1.000000
2019-03-16 19:49:44,464 2019-03-16 19:49:44: step 27/50000, loss = 0.210832 (2.735 sec/batch), lr: 1.000000
2019-03-16 19:49:47,182 2019-03-16 19:49:47: step 28/50000, loss = 0.383252 (2.702 sec/batch), lr: 1.000000
2019-03-16 19:49:49,618 2019-03-16 19:49:49: step 29/50000, loss = 0.209505 (2.423 sec/batch), lr: 1.000000
2019-03-16 19:49:51,945 2019-03-16 19:49:51: step 30/50000, loss = 0.364408 (2.316 sec/batch), lr: 1.000000
2019-03-16 19:49:54,250 2019-03-16 19:49:54: step 31/50000, loss = 0.202994 (2.297 sec/batch), lr: 1.000000
2019-03-16 19:49:56,406 2019-03-16 19:49:56: step 32/50000, loss = 0.361012 (2.144 sec/batch), lr: 1.000000
2019-03-16 19:49:58,480 2019-03-16 19:49:58: step 33/50000, loss = 0.215515 (2.062 sec/batch), lr: 1.000000
2019-03-16 19:50:00,176 2019-03-16 19:50:00: step 34/50000, loss = 0.356140 (1.689 sec/batch), lr: 1.000000
2019-03-16 19:50:01,896 2019-03-16 19:50:01: step 35/50000, loss = 0.200577 (1.711 sec/batch), lr: 1.000000
2019-03-16 19:50:03,432 2019-03-16 19:50:03: step 36/50000, loss = 0.338139 (1.529 sec/batch), lr: 1.000000
2019-03-16 19:50:04,943 2019-03-16 19:50:04: step 37/50000, loss = 0.202800 (1.505 sec/batch), lr: 1.000000
2019-03-16 19:50:06,323 2019-03-16 19:50:06: step 38/50000, loss = 0.310444 (1.369 sec/batch), lr: 1.000000
2019-03-16 19:50:07,520 2019-03-16 19:50:07: step 39/50000, loss = 0.189529 (1.191 sec/batch), lr: 1.000000
2019-03-16 19:50:08,485 2019-03-16 19:50:08: step 40/50000, loss = 0.311186 (0.956 sec/batch), lr: 1.000000
2019-03-16 19:50:09,322 2019-03-16 19:50:09: step 41/50000, loss = 0.209785 (0.829 sec/batch), lr: 1.000000
2019-03-16 19:50:10,233 2019-03-16 19:50:10: step 42/50000, loss = 0.296366 (0.903 sec/batch), lr: 1.000000
2019-03-16 19:50:11,037 2019-03-16 19:50:11: step 43/50000, loss = 0.214526 (0.797 sec/batch), lr: 1.000000
2019-03-16 19:50:11,715 2019-03-16 19:50:11: step 44/50000, loss = 0.290485 (0.671 sec/batch), lr: 1.000000
2019-03-16 19:50:12,219 2019-03-16 19:50:12: step 45/50000, loss = 0.239106 (0.497 sec/batch), lr: 1.000000
2019-03-16 19:50:12,666 2019-03-16 19:50:12: step 46/50000, loss = 0.244582 (0.444 sec/batch), lr: 1.000000
2019-03-16 19:50:13,032 2019-03-16 19:50:13: step 47/50000, loss = 0.236469 (0.361 sec/batch), lr: 1.000000
2019-03-16 19:50:13,308 2019-03-16 19:50:13: step 48/50000, loss = 0.208102 (0.272 sec/batch), lr: 1.000000
2019-03-16 19:50:13,514 2019-03-16 19:50:13: step 49/50000, loss = 0.305363 (0.202 sec/batch), lr: 1.000000
2019-03-16 19:50:13,611 2019-03-16 19:50:13: step 50/50000, loss = 0.235603 (0.095 sec/batch), lr: 1.000000
2019-03-16 19:50:13,747 2019-03-16 19:50:13: step 51/50000, loss = 0.232334 (0.131 sec/batch), lr: 1.000000
2019-03-16 19:50:13,964 2019-03-16 19:50:13: step 52/50000, loss = 0.299227 (0.214 sec/batch), lr: 1.000000
2019-03-16 19:50:14,245 2019-03-16 19:50:14: step 53/50000, loss = 0.183647 (0.278 sec/batch), lr: 1.000000
2019-03-16 19:50:14,601 2019-03-16 19:50:14: step 54/50000, loss = 1.589275 (0.354 sec/batch), lr: 1.000000
2019-03-16 19:50:15,062 2019-03-16 19:50:15: step 55/50000, loss = 0.777315 (0.456 sec/batch), lr: 1.000000
2019-03-16 19:50:15,621 2019-03-16 19:50:15: step 56/50000, loss = 0.546938 (0.554 sec/batch), lr: 1.000000
2019-03-16 19:50:16,206 2019-03-16 19:50:16: step 57/50000, loss = 0.509852 (0.581 sec/batch), lr: 1.000000
2019-03-16 19:50:16,907 2019-03-16 19:50:16: step 58/50000, loss = 0.528245 (0.694 sec/batch), lr: 1.000000
2019-03-16 19:50:17,783 2019-03-16 19:50:17: step 59/50000, loss = 0.517118 (0.869 sec/batch), lr: 1.000000
2019-03-16 19:50:18,792 2019-03-16 19:50:18: step 60/50000, loss = 0.473929 (1.001 sec/batch), lr: 1.000000
2019-03-16 19:50:19,861 2019-03-16 19:50:19: step 61/50000, loss = 0.513414 (1.061 sec/batch), lr: 1.000000
2019-03-16 19:50:20,975 2019-03-16 19:50:20: step 62/50000, loss = 0.498474 (1.105 sec/batch), lr: 1.000000
2019-03-16 19:50:22,247 2019-03-16 19:50:22: step 63/50000, loss = 0.489663 (1.264 sec/batch), lr: 1.000000
2019-03-16 19:50:23,766 2019-03-16 19:50:23: step 64/50000, loss = 0.475318 (1.509 sec/batch), lr: 1.000000
2019-03-16 19:50:25,310 2019-03-16 19:50:25: step 65/50000, loss = 0.506935 (1.536 sec/batch), lr: 1.000000
2019-03-16 19:50:27,108 2019-03-16 19:50:27: step 66/50000, loss = 0.505655 (1.786 sec/batch), lr: 1.000000
2019-03-16 19:50:29,121 2019-03-16 19:50:29: step 67/50000, loss = 0.474914 (2.000 sec/batch), lr: 1.000000
2019-03-16 19:50:31,182 2019-03-16 19:50:31: step 68/50000, loss = 0.504115 (2.049 sec/batch), lr: 1.000000
2019-03-16 19:50:33,297 2019-03-16 19:50:33: step 69/50000, loss = 0.478254 (2.099 sec/batch), lr: 1.000000
2019-03-16 19:50:35,967 2019-03-16 19:50:35: step 70/50000, loss = 0.502792 (2.658 sec/batch), lr: 1.000000
2019-03-16 19:50:38,952 2019-03-16 19:50:38: step 71/50000, loss = 0.496659 (2.972 sec/batch), lr: 1.000000
2019-03-16 19:50:42,165 2019-03-16 19:50:42: step 72/50000, loss = 0.483216 (3.196 sec/batch), lr: 1.000000
2019-03-16 19:50:45,065 2019-03-16 19:50:45: step 73/50000, loss = 0.501194 (2.883 sec/batch), lr: 1.000000
2019-03-16 19:50:48,206 2019-03-16 19:50:48: step 74/50000, loss = 0.496975 (3.125 sec/batch), lr: 1.000000
2019-03-16 19:50:51,227 2019-03-16 19:50:51: step 75/50000, loss = 0.500269 (3.003 sec/batch), lr: 1.000000
2019-03-16 19:50:54,461 2019-03-16 19:50:54: step 76/50000, loss = 0.497456 (3.213 sec/batch), lr: 1.000000
2019-03-16 19:50:57,997 2019-03-16 19:50:57: step 77/50000, loss = 0.484657 (3.516 sec/batch), lr: 1.000000
2019-03-16 19:51:01,679 2019-03-16 19:51:01: step 78/50000, loss = 0.499011 (3.662 sec/batch), lr: 1.000000
2019-03-16 19:51:05,996 2019-03-16 19:51:05: step 79/50000, loss = 0.498643 (4.295 sec/batch), lr: 1.000000
2019-03-16 19:51:10,127 2019-03-16 19:51:10: step 80/50000, loss = 0.488899 (4.107 sec/batch), lr: 1.000000
2019-03-16 19:51:14,311 2019-03-16 19:51:14: step 81/50000, loss = 0.497906 (4.160 sec/batch), lr: 1.000000
2019-03-16 19:51:18,998 2019-03-16 19:51:18: step 82/50000, loss = 0.496539 (4.662 sec/batch), lr: 1.000000
2019-03-16 19:51:24,006 2019-03-16 19:51:24: step 83/50000, loss = 0.492421 (4.981 sec/batch), lr: 1.000000
2019-03-16 19:51:29,284 2019-03-16 19:51:29: step 84/50000, loss = 0.483953 (5.248 sec/batch), lr: 1.000000
2019-03-16 19:51:34,857 2019-03-16 19:51:34: step 85/50000, loss = 0.480545 (5.544 sec/batch), lr: 1.000000
2019-03-16 19:51:40,662 2019-03-16 19:51:40: step 86/50000, loss = 0.496197 (5.773 sec/batch), lr: 1.000000
2019-03-16 19:51:46,833 2019-03-16 19:51:46: step 87/50000, loss = 0.492348 (6.136 sec/batch), lr: 1.000000
2019-03-16 19:51:53,667 2019-03-16 19:51:53: step 88/50000, loss = 0.479423 (6.785 sec/batch), lr: 1.000000
2019-03-16 19:52:00,884 2019-03-16 19:52:00: step 89/50000, loss = 0.481952 (7.179 sec/batch), lr: 1.000000
2019-03-16 19:52:08,603 2019-03-16 19:52:08: step 90/50000, loss = 0.486519 (7.676 sec/batch), lr: 1.000000
2019-03-16 19:52:16,870 2019-03-16 19:52:16: step 91/50000, loss = 0.490857 (8.220 sec/batch), lr: 1.000000
2019-03-16 19:52:25,991 2019-03-16 19:52:25: step 92/50000, loss = 0.487266 (9.068 sec/batch), lr: 1.000000
2019-03-16 19:52:36,057 2019-03-16 19:52:36: step 93/50000, loss = 0.484093 (10.007 sec/batch), lr: 1.000000
2019-03-16 19:52:47,112 2019-03-16 19:52:47: step 94/50000, loss = 0.480591 (10.995 sec/batch), lr: 1.000000
2019-03-16 19:52:59,171 2019-03-16 19:52:59: step 95/50000, loss = 0.479636 (11.989 sec/batch), lr: 1.000000
2019-03-16 19:53:13,475 2019-03-16 19:53:13: step 96/50000, loss = 0.467735 (14.220 sec/batch), lr: 1.000000
2019-03-16 19:53:30,444 2019-03-16 19:53:30: step 97/50000, loss = 0.473005 (16.866 sec/batch), lr: 1.000000
2019-03-16 19:53:50,323 2019-03-16 19:53:50: step 98/50000, loss = 0.461504 (19.758 sec/batch), lr: 1.000000
2019-03-16 19:54:18,276 2019-03-16 19:54:18: step 99/50000, loss = 0.443213 (27.790 sec/batch), lr: 1.000000
2019-03-16 19:54:52,018 2019-03-16 19:54:52: step 100/50000, loss = 0.374144 (33.563 sec/batch), lr: 1.000000
2019-03-16 19:55:19,986 step 100: Full loss = 0.261761, Edge acc. = 0.2564
2019-03-16 19:55:20,045 step 100: Dev acc. = 0.403435
2019-03-16 19:56:09,360 2019-03-16 19:56:09: step 101/50000, loss = 0.350054 (49.077 sec/batch), lr: 1.000000
2019-03-16 19:56:32,692 2019-03-16 19:56:32: step 102/50000, loss = 0.452165 (23.170 sec/batch), lr: 1.000000
2019-03-16 19:56:51,388 2019-03-16 19:56:51: step 103/50000, loss = 0.468195 (18.585 sec/batch), lr: 1.000000
2019-03-16 19:57:07,243 2019-03-16 19:57:07: step 104/50000, loss = 0.469867 (15.759 sec/batch), lr: 1.000000
2019-03-16 19:57:19,761 2019-03-16 19:57:19: step 105/50000, loss = 0.476830 (12.443 sec/batch), lr: 1.000000
2019-03-16 19:57:31,073 2019-03-16 19:57:31: step 106/50000, loss = 0.470124 (11.303 sec/batch), lr: 1.000000
2019-03-16 19:57:41,650 2019-03-16 19:57:41: step 107/50000, loss = 0.473205 (10.566 sec/batch), lr: 1.000000
2019-03-16 19:57:51,247 2019-03-16 19:57:51: step 108/50000, loss = 0.472082 (9.540 sec/batch), lr: 1.000000
2019-03-16 19:58:00,216 2019-03-16 19:58:00: step 109/50000, loss = 0.455543 (8.917 sec/batch), lr: 1.000000
2019-03-16 19:58:08,370 2019-03-16 19:58:08: step 110/50000, loss = 0.457280 (8.108 sec/batch), lr: 1.000000
2019-03-16 19:58:15,667 2019-03-16 19:58:15: step 111/50000, loss = 0.445696 (7.287 sec/batch), lr: 1.000000
2019-03-16 19:58:22,545 2019-03-16 19:58:22: step 112/50000, loss = 0.370659 (6.839 sec/batch), lr: 1.000000
2019-03-16 19:58:29,021 2019-03-16 19:58:29: step 113/50000, loss = 0.502483 (6.441 sec/batch), lr: 1.000000
2019-03-16 19:58:35,016 2019-03-16 19:58:35: step 114/50000, loss = 0.476011 (5.961 sec/batch), lr: 1.000000
2019-03-16 19:58:40,535 2019-03-16 19:58:40: step 115/50000, loss = 0.439214 (5.491 sec/batch), lr: 1.000000
2019-03-16 19:58:45,594 2019-03-16 19:58:45: step 116/50000, loss = 0.296417 (5.052 sec/batch), lr: 1.000000
2019-03-16 19:58:50,622 2019-03-16 19:58:50: step 117/50000, loss = 0.320449 (5.001 sec/batch), lr: 1.000000
2019-03-16 19:58:55,527 2019-03-16 19:58:55: step 118/50000, loss = 0.209009 (4.879 sec/batch), lr: 1.000000
2019-03-16 19:59:00,085 2019-03-16 19:59:00: step 119/50000, loss = 0.323555 (4.532 sec/batch), lr: 1.000000
2019-03-16 19:59:04,281 2019-03-16 19:59:04: step 120/50000, loss = 0.679725 (4.173 sec/batch), lr: 1.000000
2019-03-16 19:59:08,319 2019-03-16 19:59:08: step 121/50000, loss = 0.457411 (4.015 sec/batch), lr: 1.000000
2019-03-16 19:59:12,253 2019-03-16 19:59:12: step 122/50000, loss = 0.346217 (3.913 sec/batch), lr: 1.000000
2019-03-16 19:59:15,807 2019-03-16 19:59:15: step 123/50000, loss = 0.289197 (3.533 sec/batch), lr: 1.000000
2019-03-16 19:59:19,137 2019-03-16 19:59:19: step 124/50000, loss = 0.209255 (3.315 sec/batch), lr: 1.000000
2019-03-16 19:59:22,346 2019-03-16 19:59:22: step 125/50000, loss = 0.341569 (3.193 sec/batch), lr: 1.000000
2019-03-16 19:59:25,469 2019-03-16 19:59:25: step 126/50000, loss = 0.216208 (3.106 sec/batch), lr: 1.000000
2019-03-16 19:59:28,524 2019-03-16 19:59:28: step 127/50000, loss = 0.329940 (3.047 sec/batch), lr: 1.000000
2019-03-16 19:59:31,244 2019-03-16 19:59:31: step 128/50000, loss = 0.219378 (2.712 sec/batch), lr: 1.000000
2019-03-16 19:59:33,663 2019-03-16 19:59:33: step 129/50000, loss = 0.325782 (2.406 sec/batch), lr: 1.000000
2019-03-16 19:59:36,096 2019-03-16 19:59:36: step 130/50000, loss = 0.214240 (2.422 sec/batch), lr: 1.000000
2019-03-16 19:59:38,331 2019-03-16 19:59:38: step 131/50000, loss = 0.319086 (2.221 sec/batch), lr: 1.000000
2019-03-16 19:59:40,499 2019-03-16 19:59:40: step 132/50000, loss = 0.227439 (2.160 sec/batch), lr: 1.000000
2019-03-16 19:59:42,612 2019-03-16 19:59:42: step 133/50000, loss = 0.313843 (2.099 sec/batch), lr: 1.000000
2019-03-16 19:59:44,517 2019-03-16 19:59:44: step 134/50000, loss = 0.223351 (1.893 sec/batch), lr: 1.000000
2019-03-16 19:59:46,374 2019-03-16 19:59:46: step 135/50000, loss = 0.300654 (1.850 sec/batch), lr: 1.000000
2019-03-16 19:59:48,038 2019-03-16 19:59:48: step 136/50000, loss = 0.214232 (1.654 sec/batch), lr: 1.000000
2019-03-16 19:59:49,366 2019-03-16 19:59:49: step 137/50000, loss = 0.297049 (1.320 sec/batch), lr: 1.000000
2019-03-16 19:59:50,627 2019-03-16 19:59:50: step 138/50000, loss = 0.207531 (1.255 sec/batch), lr: 1.000000
2019-03-16 19:59:51,709 2019-03-16 19:59:51: step 139/50000, loss = 0.270362 (1.079 sec/batch), lr: 1.000000
2019-03-16 19:59:52,661 2019-03-16 19:59:52: step 140/50000, loss = 0.223649 (0.945 sec/batch), lr: 1.000000
2019-03-16 19:59:53,494 2019-03-16 19:59:53: step 141/50000, loss = 0.281901 (0.827 sec/batch), lr: 1.000000
2019-03-16 19:59:54,309 2019-03-16 19:59:54: step 142/50000, loss = 0.231158 (0.809 sec/batch), lr: 1.000000
2019-03-16 19:59:55,065 2019-03-16 19:59:55: step 143/50000, loss = 0.276201 (0.749 sec/batch), lr: 1.000000
2019-03-16 19:59:55,671 2019-03-16 19:59:55: step 144/50000, loss = 0.252816 (0.601 sec/batch), lr: 1.000000
2019-03-16 19:59:56,205 2019-03-16 19:59:56: step 145/50000, loss = 0.274607 (0.528 sec/batch), lr: 1.000000
2019-03-16 19:59:56,710 2019-03-16 19:59:56: step 146/50000, loss = 0.255707 (0.499 sec/batch), lr: 1.000000
2019-03-16 19:59:57,127 2019-03-16 19:59:57: step 147/50000, loss = 0.233338 (0.412 sec/batch), lr: 1.000000
2019-03-16 19:59:57,454 2019-03-16 19:59:57: step 148/50000, loss = 0.282119 (0.323 sec/batch), lr: 1.000000
2019-03-16 19:59:57,665 2019-03-16 19:59:57: step 149/50000, loss = 0.298075 (0.207 sec/batch), lr: 1.000000
2019-03-16 19:59:57,801 2019-03-16 19:59:57: step 150/50000, loss = 0.569975 (0.133 sec/batch), lr: 1.000000
2019-03-16 20:00:47,441 2019-03-16 20:00:47: step 151/50000, loss = 0.396507 (49.395 sec/batch), lr: 1.000000
2019-03-16 20:01:10,828 2019-03-16 20:01:10: step 152/50000, loss = 0.501317 (23.374 sec/batch), lr: 1.000000
2019-03-16 20:01:29,100 2019-03-16 20:01:29: step 153/50000, loss = 0.511629 (18.168 sec/batch), lr: 1.000000
2019-03-16 20:01:44,737 2019-03-16 20:01:44: step 154/50000, loss = 0.508307 (15.548 sec/batch), lr: 1.000000
2019-03-16 20:01:57,569 2019-03-16 20:01:57: step 155/50000, loss = 0.514085 (12.755 sec/batch), lr: 1.000000
2019-03-16 20:02:09,159 2019-03-16 20:02:09: step 156/50000, loss = 0.505508 (11.578 sec/batch), lr: 1.000000
2019-03-16 20:02:19,661 2019-03-16 20:02:19: step 157/50000, loss = 0.506498 (10.491 sec/batch), lr: 1.000000
2019-03-16 20:02:29,210 2019-03-16 20:02:29: step 158/50000, loss = 0.506659 (9.496 sec/batch), lr: 1.000000
2019-03-16 20:02:37,980 2019-03-16 20:02:37: step 159/50000, loss = 0.490337 (8.721 sec/batch), lr: 1.000000
2019-03-16 20:02:46,076 2019-03-16 20:02:46: step 160/50000, loss = 0.496414 (8.052 sec/batch), lr: 1.000000
2019-03-16 20:02:53,252 2019-03-16 20:02:53: step 161/50000, loss = 0.499164 (7.168 sec/batch), lr: 1.000000
2019-03-16 20:03:00,081 2019-03-16 20:03:00: step 162/50000, loss = 0.493944 (6.794 sec/batch), lr: 1.000000
2019-03-16 20:03:06,359 2019-03-16 20:03:06: step 163/50000, loss = 0.488516 (6.243 sec/batch), lr: 1.000000
2019-03-16 20:03:12,358 2019-03-16 20:03:12: step 164/50000, loss = 0.482041 (5.989 sec/batch), lr: 1.000000
2019-03-16 20:03:18,015 2019-03-16 20:03:18: step 165/50000, loss = 0.482844 (5.627 sec/batch), lr: 1.000000
2019-03-16 20:03:23,137 2019-03-16 20:03:23: step 166/50000, loss = 0.481890 (5.093 sec/batch), lr: 1.000000
2019-03-16 20:03:27,959 2019-03-16 20:03:27: step 167/50000, loss = 0.479195 (4.795 sec/batch), lr: 1.000000
2019-03-16 20:03:32,714 2019-03-16 20:03:32: step 168/50000, loss = 0.460464 (4.729 sec/batch), lr: 1.000000
2019-03-16 20:03:37,278 2019-03-16 20:03:37: step 169/50000, loss = 0.455281 (4.554 sec/batch), lr: 1.000000
2019-03-16 20:03:41,450 2019-03-16 20:03:41: step 170/50000, loss = 0.456317 (4.150 sec/batch), lr: 1.000000
2019-03-16 20:03:45,505 2019-03-16 20:03:45: step 171/50000, loss = 0.423466 (4.032 sec/batch), lr: 1.000000
2019-03-16 20:03:49,213 2019-03-16 20:03:49: step 172/50000, loss = 0.403136 (3.687 sec/batch), lr: 1.000000
2019-03-16 20:03:52,879 2019-03-16 20:03:52: step 173/50000, loss = 0.344991 (3.648 sec/batch), lr: 1.000000
2019-03-16 20:03:56,246 2019-03-16 20:03:56: step 174/50000, loss = 0.224524 (3.349 sec/batch), lr: 1.000000
2019-03-16 20:03:59,519 2019-03-16 20:03:59: step 175/50000, loss = 0.468612 (3.256 sec/batch), lr: 1.000000
2019-03-16 20:04:02,629 2019-03-16 20:04:02: step 176/50000, loss = 0.432637 (3.093 sec/batch), lr: 1.000000
2019-03-16 20:04:05,655 2019-03-16 20:04:05: step 177/50000, loss = 0.200987 (3.018 sec/batch), lr: 1.000000
2019-03-16 20:04:08,487 2019-03-16 20:04:08: step 178/50000, loss = 0.373062 (2.816 sec/batch), lr: 1.000000
2019-03-16 20:04:11,093 2019-03-16 20:04:11: step 179/50000, loss = 0.406548 (2.591 sec/batch), lr: 1.000000
2019-03-16 20:04:13,327 2019-03-16 20:04:13: step 180/50000, loss = 0.549275 (2.220 sec/batch), lr: 1.000000
2019-03-16 20:04:15,481 2019-03-16 20:04:15: step 181/50000, loss = 0.491194 (2.140 sec/batch), lr: 1.000000
2019-03-16 20:04:17,540 2019-03-16 20:04:17: step 182/50000, loss = 0.481221 (2.047 sec/batch), lr: 1.000000
2019-03-16 20:04:19,509 2019-03-16 20:04:19: step 183/50000, loss = 0.439855 (1.956 sec/batch), lr: 1.000000
2019-03-16 20:04:21,269 2019-03-16 20:04:21: step 184/50000, loss = 0.313751 (1.754 sec/batch), lr: 1.000000
2019-03-16 20:04:22,984 2019-03-16 20:04:22: step 185/50000, loss = 0.553442 (1.704 sec/batch), lr: 1.000000
2019-03-16 20:04:24,604 2019-03-16 20:04:24: step 186/50000, loss = 0.619529 (1.610 sec/batch), lr: 1.000000
2019-03-16 20:04:26,106 2019-03-16 20:04:26: step 187/50000, loss = 0.488138 (1.494 sec/batch), lr: 1.000000
2019-03-16 20:04:27,537 2019-03-16 20:04:27: step 188/50000, loss = 0.384822 (1.420 sec/batch), lr: 1.000000
2019-03-16 20:04:28,787 2019-03-16 20:04:28: step 189/50000, loss = 0.224530 (1.241 sec/batch), lr: 1.000000
2019-03-16 20:04:29,868 2019-03-16 20:04:29: step 190/50000, loss = 1.061766 (1.075 sec/batch), lr: 1.000000
2019-03-16 20:04:30,828 2019-03-16 20:04:30: step 191/50000, loss = 0.834552 (0.953 sec/batch), lr: 1.000000
2019-03-16 20:04:31,775 2019-03-16 20:04:31: step 192/50000, loss = 0.485396 (0.939 sec/batch), lr: 1.000000
2019-03-16 20:04:32,594 2019-03-16 20:04:32: step 193/50000, loss = 0.392960 (0.811 sec/batch), lr: 1.000000
2019-03-16 20:04:33,262 2019-03-16 20:04:33: step 194/50000, loss = 0.202052 (0.660 sec/batch), lr: 1.000000
2019-03-16 20:04:33,817 2019-03-16 20:04:33: step 195/50000, loss = 0.649093 (0.549 sec/batch), lr: 1.000000
2019-03-16 20:04:34,331 2019-03-16 20:04:34: step 196/50000, loss = 0.933620 (0.509 sec/batch), lr: 1.000000
2019-03-16 20:04:34,750 2019-03-16 20:04:34: step 197/50000, loss = 0.512789 (0.413 sec/batch), lr: 1.000000
2019-03-16 20:04:35,079 2019-03-16 20:04:35: step 198/50000, loss = 0.354043 (0.324 sec/batch), lr: 1.000000
2019-03-16 20:04:35,289 2019-03-16 20:04:35: step 199/50000, loss = 0.148243 (0.206 sec/batch), lr: 1.000000
2019-03-16 20:04:35,428 2019-03-16 20:04:35: step 200/50000, loss = 0.826097 (0.137 sec/batch), lr: 1.000000
2019-03-16 20:05:03,577 step 200: Full loss = 0.303917, Edge acc. = 0.1131
2019-03-16 20:05:03,638 step 200: Dev acc. = 0.100113
2019-03-16 20:05:03,785 2019-03-16 20:05:03: step 201/50000, loss = 0.560154 (0.143 sec/batch), lr: 0.500000
2019-03-16 20:05:03,997 2019-03-16 20:05:03: step 202/50000, loss = 0.473682 (0.209 sec/batch), lr: 0.500000
2019-03-16 20:05:04,282 2019-03-16 20:05:04: step 203/50000, loss = 0.436327 (0.281 sec/batch), lr: 0.500000
2019-03-16 20:05:04,599 2019-03-16 20:05:04: step 204/50000, loss = 0.378166 (0.313 sec/batch), lr: 0.500000
2019-03-16 20:05:05,019 2019-03-16 20:05:05: step 205/50000, loss = 0.312924 (0.417 sec/batch), lr: 0.500000
2019-03-16 20:05:05,570 2019-03-16 20:05:05: step 206/50000, loss = 0.234792 (0.546 sec/batch), lr: 0.500000
2019-03-16 20:05:06,349 2019-03-16 20:05:06: step 207/50000, loss = 0.207955 (0.773 sec/batch), lr: 0.500000
2019-03-16 20:05:07,166 2019-03-16 20:05:07: step 208/50000, loss = 0.211708 (0.808 sec/batch), lr: 0.500000
2019-03-16 20:05:08,147 2019-03-16 20:05:08: step 209/50000, loss = 0.208846 (0.973 sec/batch), lr: 0.500000
2019-03-16 20:05:09,081 2019-03-16 20:05:09: step 210/50000, loss = 0.206518 (0.928 sec/batch), lr: 0.500000
2019-03-16 20:05:10,101 2019-03-16 20:05:10: step 211/50000, loss = 0.216839 (1.011 sec/batch), lr: 0.500000
2019-03-16 20:05:11,409 2019-03-16 20:05:11: step 212/50000, loss = 0.195933 (1.301 sec/batch), lr: 0.500000
2019-03-16 20:05:12,712 2019-03-16 20:05:12: step 213/50000, loss = 0.222396 (1.300 sec/batch), lr: 0.500000
2019-03-16 20:05:14,329 2019-03-16 20:05:14: step 214/50000, loss = 0.191765 (1.605 sec/batch), lr: 0.500000
2019-03-16 20:05:15,878 2019-03-16 20:05:15: step 215/50000, loss = 0.226626 (1.538 sec/batch), lr: 0.500000
2019-03-16 20:05:17,691 2019-03-16 20:05:17: step 216/50000, loss = 0.212348 (1.806 sec/batch), lr: 0.500000
2019-03-16 20:05:19,592 2019-03-16 20:05:19: step 217/50000, loss = 0.214092 (1.893 sec/batch), lr: 0.500000
2019-03-16 20:05:21,658 2019-03-16 20:05:21: step 218/50000, loss = 0.211630 (2.055 sec/batch), lr: 0.500000
2019-03-16 20:05:23,914 2019-03-16 20:05:23: step 219/50000, loss = 0.218100 (2.245 sec/batch), lr: 0.500000
2019-03-16 20:05:26,126 2019-03-16 20:05:26: step 220/50000, loss = 0.211845 (2.201 sec/batch), lr: 0.500000
2019-03-16 20:05:28,647 2019-03-16 20:05:28: step 221/50000, loss = 0.229769 (2.507 sec/batch), lr: 0.500000
2019-03-16 20:05:31,362 2019-03-16 20:05:31: step 222/50000, loss = 0.195753 (2.700 sec/batch), lr: 0.500000
2019-03-16 20:05:34,031 2019-03-16 20:05:34: step 223/50000, loss = 0.238250 (2.653 sec/batch), lr: 0.500000
2019-03-16 20:05:36,889 2019-03-16 20:05:36: step 224/50000, loss = 0.201067 (2.843 sec/batch), lr: 0.500000
2019-03-16 20:05:39,680 2019-03-16 20:05:39: step 225/50000, loss = 0.236948 (2.776 sec/batch), lr: 0.500000
2019-03-16 20:05:43,032 2019-03-16 20:05:43: step 226/50000, loss = 0.204912 (3.334 sec/batch), lr: 0.500000
2019-03-16 20:05:46,654 2019-03-16 20:05:46: step 227/50000, loss = 0.229596 (3.603 sec/batch), lr: 0.500000
2019-03-16 20:05:50,240 2019-03-16 20:05:50: step 228/50000, loss = 0.205142 (3.569 sec/batch), lr: 0.500000
2019-03-16 20:05:54,135 2019-03-16 20:05:54: step 229/50000, loss = 0.245423 (3.875 sec/batch), lr: 0.500000
2019-03-16 20:05:58,367 2019-03-16 20:05:58: step 230/50000, loss = 0.207442 (4.208 sec/batch), lr: 0.500000
2019-03-16 20:06:02,591 2019-03-16 20:06:02: step 231/50000, loss = 0.251769 (4.202 sec/batch), lr: 0.500000
2019-03-16 20:06:07,023 2019-03-16 20:06:07: step 232/50000, loss = 0.216888 (4.407 sec/batch), lr: 0.500000
2019-03-16 20:06:11,858 2019-03-16 20:06:11: step 233/50000, loss = 0.251007 (4.807 sec/batch), lr: 0.500000
2019-03-16 20:06:16,924 2019-03-16 20:06:16: step 234/50000, loss = 0.207652 (5.038 sec/batch), lr: 0.500000
2019-03-16 20:06:22,394 2019-03-16 20:06:22: step 235/50000, loss = 0.246011 (5.460 sec/batch), lr: 0.500000
2019-03-16 20:06:28,097 2019-03-16 20:06:28: step 236/50000, loss = 0.216308 (5.671 sec/batch), lr: 0.500000
2019-03-16 20:06:34,175 2019-03-16 20:06:34: step 237/50000, loss = 0.245559 (6.044 sec/batch), lr: 0.500000
2019-03-16 20:06:40,813 2019-03-16 20:06:40: step 238/50000, loss = 0.206499 (6.601 sec/batch), lr: 0.500000
2019-03-16 20:06:48,000 2019-03-16 20:06:48: step 239/50000, loss = 0.249997 (7.177 sec/batch), lr: 0.500000
2019-03-16 20:06:55,634 2019-03-16 20:06:55: step 240/50000, loss = 0.209823 (7.592 sec/batch), lr: 0.500000
2019-03-16 20:07:03,665 2019-03-16 20:07:03: step 241/50000, loss = 0.258121 (7.989 sec/batch), lr: 0.500000
2019-03-16 20:07:12,582 2019-03-16 20:07:12: step 242/50000, loss = 0.211351 (8.867 sec/batch), lr: 0.500000
2019-03-16 20:07:22,602 2019-03-16 20:07:22: step 243/50000, loss = 0.260276 (9.961 sec/batch), lr: 0.500000
2019-03-16 20:07:33,631 2019-03-16 20:07:33: step 244/50000, loss = 0.214022 (10.968 sec/batch), lr: 0.500000
2019-03-16 20:07:45,704 2019-03-16 20:07:45: step 245/50000, loss = 0.249142 (12.003 sec/batch), lr: 0.500000
2019-03-16 20:07:59,948 2019-03-16 20:07:59: step 246/50000, loss = 0.229050 (14.159 sec/batch), lr: 0.500000
2019-03-16 20:08:16,785 2019-03-16 20:08:16: step 247/50000, loss = 0.261411 (16.740 sec/batch), lr: 0.500000
2019-03-16 20:08:36,788 2019-03-16 20:08:36: step 248/50000, loss = 0.214975 (19.889 sec/batch), lr: 0.500000
2019-03-16 20:09:04,406 2019-03-16 20:09:04: step 249/50000, loss = 0.260139 (27.464 sec/batch), lr: 0.500000
2019-03-16 20:09:38,023 2019-03-16 20:09:38: step 250/50000, loss = 0.175723 (33.448 sec/batch), lr: 0.500000
2019-03-16 20:09:38,193 2019-03-16 20:09:38: step 251/50000, loss = 1.757442 (0.164 sec/batch), lr: 0.500000
2019-03-16 20:09:38,436 2019-03-16 20:09:38: step 252/50000, loss = 0.160770 (0.238 sec/batch), lr: 0.500000
2019-03-16 20:09:38,783 2019-03-16 20:09:38: step 253/50000, loss = 0.325745 (0.342 sec/batch), lr: 0.500000
2019-03-16 20:09:39,225 2019-03-16 20:09:39: step 254/50000, loss = 0.190130 (0.437 sec/batch), lr: 0.500000
2019-03-16 20:09:39,765 2019-03-16 20:09:39: step 255/50000, loss = 0.258281 (0.533 sec/batch), lr: 0.500000
2019-03-16 20:09:40,404 2019-03-16 20:09:40: step 256/50000, loss = 0.204196 (0.634 sec/batch), lr: 0.500000
2019-03-16 20:09:41,192 2019-03-16 20:09:41: step 257/50000, loss = 0.246303 (0.782 sec/batch), lr: 0.500000
2019-03-16 20:09:42,008 2019-03-16 20:09:42: step 258/50000, loss = 0.206671 (0.809 sec/batch), lr: 0.500000
2019-03-16 20:09:42,980 2019-03-16 20:09:42: step 259/50000, loss = 0.258745 (0.964 sec/batch), lr: 0.500000
2019-03-16 20:09:44,065 2019-03-16 20:09:44: step 260/50000, loss = 0.190678 (1.079 sec/batch), lr: 0.500000
2019-03-16 20:09:45,234 2019-03-16 20:09:45: step 261/50000, loss = 0.242160 (1.159 sec/batch), lr: 0.500000
2019-03-16 20:09:46,553 2019-03-16 20:09:46: step 262/50000, loss = 0.197028 (1.309 sec/batch), lr: 0.500000
2019-03-16 20:09:47,994 2019-03-16 20:09:47: step 263/50000, loss = 0.230452 (1.434 sec/batch), lr: 0.500000
2019-03-16 20:09:49,556 2019-03-16 20:09:49: step 264/50000, loss = 0.184636 (1.555 sec/batch), lr: 0.500000
2019-03-16 20:09:51,081 2019-03-16 20:09:51: step 265/50000, loss = 0.232692 (1.520 sec/batch), lr: 0.500000
2019-03-16 20:09:53,003 2019-03-16 20:09:53: step 266/50000, loss = 0.198318 (1.914 sec/batch), lr: 0.500000
2019-03-16 20:09:55,077 2019-03-16 20:09:55: step 267/50000, loss = 0.221267 (2.065 sec/batch), lr: 0.500000
2019-03-16 20:09:57,201 2019-03-16 20:09:57: step 268/50000, loss = 0.197700 (2.116 sec/batch), lr: 0.500000
2019-03-16 20:09:59,447 2019-03-16 20:09:59: step 269/50000, loss = 0.227397 (2.233 sec/batch), lr: 0.500000
2019-03-16 20:10:01,830 2019-03-16 20:10:01: step 270/50000, loss = 0.198182 (2.369 sec/batch), lr: 0.500000
2019-03-16 20:10:04,411 2019-03-16 20:10:04: step 271/50000, loss = 0.235156 (2.566 sec/batch), lr: 0.500000
2019-03-16 20:10:07,046 2019-03-16 20:10:07: step 272/50000, loss = 0.190012 (2.620 sec/batch), lr: 0.500000
2019-03-16 20:10:09,817 2019-03-16 20:10:09: step 273/50000, loss = 0.242079 (2.756 sec/batch), lr: 0.500000
2019-03-16 20:10:12,925 2019-03-16 20:10:12: step 274/50000, loss = 0.196630 (3.090 sec/batch), lr: 0.500000
2019-03-16 20:10:16,035 2019-03-16 20:10:16: step 275/50000, loss = 0.240571 (3.095 sec/batch), lr: 0.500000
2019-03-16 20:10:19,251 2019-03-16 20:10:19: step 276/50000, loss = 0.197017 (3.200 sec/batch), lr: 0.500000
2019-03-16 20:10:22,887 2019-03-16 20:10:22: step 277/50000, loss = 0.232963 (3.617 sec/batch), lr: 0.500000
2019-03-16 20:10:26,503 2019-03-16 20:10:26: step 278/50000, loss = 0.196718 (3.596 sec/batch), lr: 0.500000
2019-03-16 20:10:30,495 2019-03-16 20:10:30: step 279/50000, loss = 0.248007 (3.983 sec/batch), lr: 0.500000
2019-03-16 20:10:34,660 2019-03-16 20:10:34: step 280/50000, loss = 0.201120 (4.141 sec/batch), lr: 0.500000
2019-03-16 20:10:38,880 2019-03-16 20:10:38: step 281/50000, loss = 0.250794 (4.196 sec/batch), lr: 0.500000
2019-03-16 20:10:43,535 2019-03-16 20:10:43: step 282/50000, loss = 0.209440 (4.630 sec/batch), lr: 0.500000
2019-03-16 20:10:48,477 2019-03-16 20:10:48: step 283/50000, loss = 0.249606 (4.933 sec/batch), lr: 0.500000
2019-03-16 20:10:53,720 2019-03-16 20:10:53: step 284/50000, loss = 0.199803 (5.234 sec/batch), lr: 0.500000
2019-03-16 20:10:59,260 2019-03-16 20:10:59: step 285/50000, loss = 0.241776 (5.519 sec/batch), lr: 0.500000
2019-03-16 20:11:04,943 2019-03-16 20:11:04: step 286/50000, loss = 0.212602 (5.673 sec/batch), lr: 0.500000
2019-03-16 20:11:10,978 2019-03-16 20:11:10: step 287/50000, loss = 0.244775 (6.005 sec/batch), lr: 0.500000
2019-03-16 20:11:17,616 2019-03-16 20:11:17: step 288/50000, loss = 0.201761 (6.630 sec/batch), lr: 0.500000
2019-03-16 20:11:24,765 2019-03-16 20:11:24: step 289/50000, loss = 0.245524 (7.139 sec/batch), lr: 0.500000
2019-03-16 20:11:32,477 2019-03-16 20:11:32: step 290/50000, loss = 0.206935 (7.671 sec/batch), lr: 0.500000
2019-03-16 20:11:40,568 2019-03-16 20:11:40: step 291/50000, loss = 0.255470 (8.044 sec/batch), lr: 0.500000
2019-03-16 20:11:49,990 2019-03-16 20:11:49: step 292/50000, loss = 0.210816 (9.410 sec/batch), lr: 0.500000
2019-03-16 20:12:00,022 2019-03-16 20:12:00: step 293/50000, loss = 0.255763 (9.972 sec/batch), lr: 0.500000
2019-03-16 20:12:11,102 2019-03-16 20:12:11: step 294/50000, loss = 0.211898 (11.018 sec/batch), lr: 0.500000
2019-03-16 20:12:23,089 2019-03-16 20:12:23: step 295/50000, loss = 0.255925 (11.913 sec/batch), lr: 0.500000
2019-03-16 20:12:37,274 2019-03-16 20:12:37: step 296/50000, loss = 0.216417 (14.104 sec/batch), lr: 0.500000
2019-03-16 20:12:54,062 2019-03-16 20:12:54: step 297/50000, loss = 0.263653 (16.690 sec/batch), lr: 0.500000
2019-03-16 20:13:14,040 2019-03-16 20:13:14: step 298/50000, loss = 0.208740 (19.865 sec/batch), lr: 0.500000
2019-03-16 20:13:41,681 2019-03-16 20:13:41: step 299/50000, loss = 0.237430 (27.623 sec/batch), lr: 0.500000
2019-03-16 20:14:15,248 2019-03-16 20:14:15: step 300/50000, loss = 0.190607 (33.385 sec/batch), lr: 0.500000
2019-03-16 20:14:43,315 step 300: Full loss = 0.139503, Edge acc. = 0.3106
2019-03-16 20:14:43,315 step 300: Dev acc. = 0.391913
2019-03-16 20:15:32,198 2019-03-16 20:15:32: step 301/50000, loss = 0.196280 (48.643 sec/batch), lr: 0.500000
2019-03-16 20:15:55,598 2019-03-16 20:15:55: step 302/50000, loss = 0.238850 (23.383 sec/batch), lr: 0.500000
2019-03-16 20:16:13,713 2019-03-16 20:16:13: step 303/50000, loss = 0.243993 (18.100 sec/batch), lr: 0.500000
2019-03-16 20:16:29,353 2019-03-16 20:16:29: step 304/50000, loss = 0.254948 (15.626 sec/batch), lr: 0.500000
2019-03-16 20:16:42,170 2019-03-16 20:16:42: step 305/50000, loss = 0.246557 (12.804 sec/batch), lr: 0.500000
2019-03-16 20:16:53,657 2019-03-16 20:16:53: step 306/50000, loss = 0.252346 (11.475 sec/batch), lr: 0.500000
2019-03-16 20:17:03,973 2019-03-16 20:17:03: step 307/50000, loss = 0.250182 (10.306 sec/batch), lr: 0.500000
2019-03-16 20:17:13,563 2019-03-16 20:17:13: step 308/50000, loss = 0.246768 (9.535 sec/batch), lr: 0.500000
2019-03-16 20:17:22,332 2019-03-16 20:17:22: step 309/50000, loss = 0.235692 (8.718 sec/batch), lr: 0.500000
2019-03-16 20:17:30,317 2019-03-16 20:17:30: step 310/50000, loss = 0.222896 (7.945 sec/batch), lr: 0.500000
2019-03-16 20:17:37,269 2019-03-16 20:17:37: step 311/50000, loss = 0.240585 (6.944 sec/batch), lr: 0.500000
2019-03-16 20:17:43,943 2019-03-16 20:17:43: step 312/50000, loss = 0.235734 (6.665 sec/batch), lr: 0.500000
2019-03-16 20:17:50,179 2019-03-16 20:17:50: step 313/50000, loss = 0.242309 (6.229 sec/batch), lr: 0.500000
2019-03-16 20:17:56,057 2019-03-16 20:17:56: step 314/50000, loss = 0.222709 (5.850 sec/batch), lr: 0.500000
2019-03-16 20:18:01,571 2019-03-16 20:18:01: step 315/50000, loss = 0.241888 (5.489 sec/batch), lr: 0.500000
2019-03-16 20:18:06,735 2019-03-16 20:18:06: step 316/50000, loss = 0.227397 (5.138 sec/batch), lr: 0.500000
2019-03-16 20:18:11,635 2019-03-16 20:18:11: step 317/50000, loss = 0.244130 (4.877 sec/batch), lr: 0.500000
2019-03-16 20:18:16,357 2019-03-16 20:18:16: step 318/50000, loss = 0.212698 (4.698 sec/batch), lr: 0.500000
2019-03-16 20:18:20,949 2019-03-16 20:18:20: step 319/50000, loss = 0.234120 (4.567 sec/batch), lr: 0.500000
2019-03-16 20:18:25,123 2019-03-16 20:18:25: step 320/50000, loss = 0.220609 (4.154 sec/batch), lr: 0.500000
2019-03-16 20:18:29,207 2019-03-16 20:18:29: step 321/50000, loss = 0.231570 (4.078 sec/batch), lr: 0.500000
2019-03-16 20:18:33,193 2019-03-16 20:18:33: step 322/50000, loss = 0.212451 (3.956 sec/batch), lr: 0.500000
2019-03-16 20:18:36,821 2019-03-16 20:18:36: step 323/50000, loss = 0.229914 (3.620 sec/batch), lr: 0.500000
2019-03-16 20:18:40,137 2019-03-16 20:18:40: step 324/50000, loss = 0.201131 (3.307 sec/batch), lr: 0.500000
2019-03-16 20:18:43,260 2019-03-16 20:18:43: step 325/50000, loss = 0.224883 (3.115 sec/batch), lr: 0.500000
2019-03-16 20:18:46,165 2019-03-16 20:18:46: step 326/50000, loss = 0.205341 (2.896 sec/batch), lr: 0.500000
2019-03-16 20:18:49,043 2019-03-16 20:18:49: step 327/50000, loss = 0.228751 (2.864 sec/batch), lr: 0.500000
2019-03-16 20:18:51,628 2019-03-16 20:18:51: step 328/50000, loss = 0.215981 (2.573 sec/batch), lr: 0.500000
2019-03-16 20:18:54,033 2019-03-16 20:18:54: step 329/50000, loss = 0.226974 (2.394 sec/batch), lr: 0.500000
2019-03-16 20:18:56,311 2019-03-16 20:18:56: step 330/50000, loss = 0.198011 (2.266 sec/batch), lr: 0.500000
2019-03-16 20:18:58,351 2019-03-16 20:18:58: step 331/50000, loss = 0.222755 (2.029 sec/batch), lr: 0.500000
2019-03-16 20:19:00,454 2019-03-16 20:19:00: step 332/50000, loss = 0.214606 (2.091 sec/batch), lr: 0.500000
2019-03-16 20:19:02,536 2019-03-16 20:19:02: step 333/50000, loss = 0.224982 (2.071 sec/batch), lr: 0.500000
2019-03-16 20:19:04,391 2019-03-16 20:19:04: step 334/50000, loss = 0.207937 (1.844 sec/batch), lr: 0.500000
2019-03-16 20:19:06,216 2019-03-16 20:19:06: step 335/50000, loss = 0.213528 (1.814 sec/batch), lr: 0.500000
2019-03-16 20:19:07,898 2019-03-16 20:19:07: step 336/50000, loss = 0.201731 (1.673 sec/batch), lr: 0.500000
2019-03-16 20:19:09,204 2019-03-16 20:19:09: step 337/50000, loss = 0.212667 (1.299 sec/batch), lr: 0.500000
2019-03-16 20:19:10,455 2019-03-16 20:19:10: step 338/50000, loss = 0.204043 (1.244 sec/batch), lr: 0.500000
2019-03-16 20:19:11,667 2019-03-16 20:19:11: step 339/50000, loss = 0.199845 (1.204 sec/batch), lr: 0.500000
2019-03-16 20:19:12,798 2019-03-16 20:19:12: step 340/50000, loss = 0.205871 (1.122 sec/batch), lr: 0.500000
2019-03-16 20:19:13,787 2019-03-16 20:19:13: step 341/50000, loss = 0.220529 (0.982 sec/batch), lr: 0.500000
2019-03-16 20:19:14,727 2019-03-16 20:19:14: step 342/50000, loss = 0.212385 (0.931 sec/batch), lr: 0.500000
2019-03-16 20:19:15,546 2019-03-16 20:19:15: step 343/50000, loss = 0.215778 (0.811 sec/batch), lr: 0.500000
2019-03-16 20:19:16,210 2019-03-16 20:19:16: step 344/50000, loss = 0.234772 (0.657 sec/batch), lr: 0.500000
2019-03-16 20:19:16,770 2019-03-16 20:19:16: step 345/50000, loss = 0.222319 (0.554 sec/batch), lr: 0.500000
2019-03-16 20:19:17,287 2019-03-16 20:19:17: step 346/50000, loss = 0.218061 (0.511 sec/batch), lr: 0.500000
2019-03-16 20:19:17,704 2019-03-16 20:19:17: step 347/50000, loss = 0.206176 (0.411 sec/batch), lr: 0.500000
2019-03-16 20:19:18,047 2019-03-16 20:19:18: step 348/50000, loss = 0.180153 (0.338 sec/batch), lr: 0.500000
2019-03-16 20:19:18,256 2019-03-16 20:19:18: step 349/50000, loss = 0.221189 (0.204 sec/batch), lr: 0.500000
2019-03-16 20:19:18,394 2019-03-16 20:19:18: step 350/50000, loss = 0.342187 (0.136 sec/batch), lr: 0.500000
2019-03-16 20:20:07,771 2019-03-16 20:20:07: step 351/50000, loss = 0.354777 (49.126 sec/batch), lr: 0.500000
2019-03-16 20:20:31,082 2019-03-16 20:20:31: step 352/50000, loss = 0.445652 (23.294 sec/batch), lr: 0.500000
2019-03-16 20:20:49,416 2019-03-16 20:20:49: step 353/50000, loss = 0.429760 (18.305 sec/batch), lr: 0.500000
2019-03-16 20:21:05,174 2019-03-16 20:21:05: step 354/50000, loss = 0.304930 (15.667 sec/batch), lr: 0.500000
2019-03-16 20:21:17,969 2019-03-16 20:21:17: step 355/50000, loss = 0.296517 (12.722 sec/batch), lr: 0.500000
2019-03-16 20:21:29,511 2019-03-16 20:21:29: step 356/50000, loss = 0.210413 (11.473 sec/batch), lr: 0.500000
2019-03-16 20:21:39,968 2019-03-16 20:21:39: step 357/50000, loss = 0.292561 (10.446 sec/batch), lr: 0.500000
2019-03-16 20:21:49,598 2019-03-16 20:21:49: step 358/50000, loss = 0.296475 (9.619 sec/batch), lr: 0.500000
2019-03-16 20:21:58,267 2019-03-16 20:21:58: step 359/50000, loss = 0.302435 (8.622 sec/batch), lr: 0.500000
2019-03-16 20:22:06,071 2019-03-16 20:22:06: step 360/50000, loss = 0.284686 (7.759 sec/batch), lr: 0.500000
2019-03-16 20:22:13,409 2019-03-16 20:22:13: step 361/50000, loss = 0.334965 (7.328 sec/batch), lr: 0.500000
2019-03-16 20:22:20,158 2019-03-16 20:22:20: step 362/50000, loss = 0.284604 (6.712 sec/batch), lr: 0.500000
2019-03-16 20:22:26,624 2019-03-16 20:22:26: step 363/50000, loss = 0.334352 (6.431 sec/batch), lr: 0.500000
2019-03-16 20:22:32,572 2019-03-16 20:22:32: step 364/50000, loss = 0.285903 (5.938 sec/batch), lr: 0.500000
2019-03-16 20:22:38,075 2019-03-16 20:22:38: step 365/50000, loss = 0.359111 (5.476 sec/batch), lr: 0.500000
2019-03-16 20:22:43,267 2019-03-16 20:22:43: step 366/50000, loss = 0.304135 (5.166 sec/batch), lr: 0.500000
2019-03-16 20:22:48,168 2019-03-16 20:22:48: step 367/50000, loss = 0.363462 (4.876 sec/batch), lr: 0.500000
2019-03-16 20:22:53,069 2019-03-16 20:22:53: step 368/50000, loss = 0.308767 (4.875 sec/batch), lr: 0.500000
2019-03-16 20:22:57,403 2019-03-16 20:22:57: step 369/50000, loss = 0.356208 (4.313 sec/batch), lr: 0.500000
2019-03-16 20:23:01,398 2019-03-16 20:23:01: step 370/50000, loss = 0.330479 (3.974 sec/batch), lr: 0.500000
2019-03-16 20:23:05,443 2019-03-16 20:23:05: step 371/50000, loss = 0.376467 (4.024 sec/batch), lr: 0.500000
2019-03-16 20:23:09,204 2019-03-16 20:23:09: step 372/50000, loss = 0.323589 (3.753 sec/batch), lr: 0.500000
2019-03-16 20:23:12,808 2019-03-16 20:23:12: step 373/50000, loss = 0.401001 (3.585 sec/batch), lr: 0.500000
2019-03-16 20:23:16,166 2019-03-16 20:23:16: step 374/50000, loss = 0.354994 (3.350 sec/batch), lr: 0.500000
2019-03-16 20:23:19,421 2019-03-16 20:23:19: step 375/50000, loss = 0.383194 (3.240 sec/batch), lr: 0.500000
2019-03-16 20:23:22,434 2019-03-16 20:23:22: step 376/50000, loss = 0.342724 (2.995 sec/batch), lr: 0.500000
2019-03-16 20:23:25,483 2019-03-16 20:23:25: step 377/50000, loss = 0.412415 (3.033 sec/batch), lr: 0.500000
2019-03-16 20:23:28,310 2019-03-16 20:23:28: step 378/50000, loss = 0.347657 (2.812 sec/batch), lr: 0.500000
2019-03-16 20:23:30,815 2019-03-16 20:23:30: step 379/50000, loss = 0.440571 (2.498 sec/batch), lr: 0.500000
2019-03-16 20:23:33,139 2019-03-16 20:23:33: step 380/50000, loss = 0.362636 (2.313 sec/batch), lr: 0.500000
2019-03-16 20:23:35,272 2019-03-16 20:23:35: step 381/50000, loss = 0.418440 (2.123 sec/batch), lr: 0.500000
2019-03-16 20:23:37,269 2019-03-16 20:23:37: step 382/50000, loss = 0.384057 (1.989 sec/batch), lr: 0.500000
2019-03-16 20:23:39,361 2019-03-16 20:23:39: step 383/50000, loss = 0.394228 (2.081 sec/batch), lr: 0.500000
2019-03-16 20:23:41,202 2019-03-16 20:23:41: step 384/50000, loss = 0.346201 (1.834 sec/batch), lr: 0.500000
2019-03-16 20:23:42,998 2019-03-16 20:23:42: step 385/50000, loss = 0.396895 (1.787 sec/batch), lr: 0.500000
2019-03-16 20:23:44,519 2019-03-16 20:23:44: step 386/50000, loss = 0.341835 (1.513 sec/batch), lr: 0.500000
2019-03-16 20:23:45,889 2019-03-16 20:23:45: step 387/50000, loss = 0.434491 (1.359 sec/batch), lr: 0.500000
2019-03-16 20:23:47,193 2019-03-16 20:23:47: step 388/50000, loss = 0.343735 (1.293 sec/batch), lr: 0.500000
2019-03-16 20:23:48,382 2019-03-16 20:23:48: step 389/50000, loss = 0.413536 (1.180 sec/batch), lr: 0.500000
2019-03-16 20:23:49,432 2019-03-16 20:23:49: step 390/50000, loss = 0.366595 (1.043 sec/batch), lr: 0.500000
2019-03-16 20:23:50,277 2019-03-16 20:23:50: step 391/50000, loss = 0.436898 (0.839 sec/batch), lr: 0.500000
2019-03-16 20:23:51,209 2019-03-16 20:23:51: step 392/50000, loss = 0.336211 (0.923 sec/batch), lr: 0.500000
2019-03-16 20:23:52,015 2019-03-16 20:23:52: step 393/50000, loss = 0.445782 (0.798 sec/batch), lr: 0.500000
2019-03-16 20:23:52,653 2019-03-16 20:23:52: step 394/50000, loss = 0.367167 (0.631 sec/batch), lr: 0.500000
2019-03-16 20:23:53,187 2019-03-16 20:23:53: step 395/50000, loss = 0.486293 (0.528 sec/batch), lr: 0.500000
2019-03-16 20:23:53,635 2019-03-16 20:23:53: step 396/50000, loss = 0.342681 (0.441 sec/batch), lr: 0.500000
2019-03-16 20:23:53,990 2019-03-16 20:23:53: step 397/50000, loss = 0.408145 (0.349 sec/batch), lr: 0.500000
2019-03-16 20:23:54,311 2019-03-16 20:23:54: step 398/50000, loss = 0.278406 (0.316 sec/batch), lr: 0.500000
2019-03-16 20:23:54,463 2019-03-16 20:23:54: step 399/50000, loss = 0.763758 (0.149 sec/batch), lr: 0.500000
2019-03-16 20:23:54,548 2019-03-16 20:23:54: step 400/50000, loss = 0.725778 (0.083 sec/batch), lr: 0.500000
2019-03-16 20:24:22,977 step 400: Full loss = 0.166873, Edge acc. = 0.2989
2019-03-16 20:24:22,978 step 400: Dev acc. = 0.384056
2019-03-16 20:24:23,129 2019-03-16 20:24:23: step 401/50000, loss = 0.066740 (0.146 sec/batch), lr: 0.250000
2019-03-16 20:24:23,368 2019-03-16 20:24:23: step 402/50000, loss = 0.134727 (0.236 sec/batch), lr: 0.250000
2019-03-16 20:24:23,707 2019-03-16 20:24:23: step 403/50000, loss = 0.184052 (0.335 sec/batch), lr: 0.250000
2019-03-16 20:24:24,143 2019-03-16 20:24:24: step 404/50000, loss = 0.178879 (0.430 sec/batch), lr: 0.250000
2019-03-16 20:24:24,663 2019-03-16 20:24:24: step 405/50000, loss = 0.186107 (0.514 sec/batch), lr: 0.250000
2019-03-16 20:24:25,257 2019-03-16 20:24:25: step 406/50000, loss = 0.177332 (0.588 sec/batch), lr: 0.250000
2019-03-16 20:24:25,978 2019-03-16 20:24:25: step 407/50000, loss = 0.187907 (0.717 sec/batch), lr: 0.250000
2019-03-16 20:24:26,697 2019-03-16 20:24:26: step 408/50000, loss = 0.196892 (0.714 sec/batch), lr: 0.250000
2019-03-16 20:24:27,667 2019-03-16 20:24:27: step 409/50000, loss = 0.207799 (0.962 sec/batch), lr: 0.250000
2019-03-16 20:24:28,615 2019-03-16 20:24:28: step 410/50000, loss = 0.182335 (0.940 sec/batch), lr: 0.250000
2019-03-16 20:24:29,606 2019-03-16 20:24:29: step 411/50000, loss = 0.194715 (0.984 sec/batch), lr: 0.250000
2019-03-16 20:24:30,714 2019-03-16 20:24:30: step 412/50000, loss = 0.186406 (1.101 sec/batch), lr: 0.250000
2019-03-16 20:24:31,922 2019-03-16 20:24:31: step 413/50000, loss = 0.194297 (1.199 sec/batch), lr: 0.250000
2019-03-16 20:24:33,415 2019-03-16 20:24:33: step 414/50000, loss = 0.177057 (1.484 sec/batch), lr: 0.250000
2019-03-16 20:24:34,946 2019-03-16 20:24:34: step 415/50000, loss = 0.198718 (1.522 sec/batch), lr: 0.250000
2019-03-16 20:24:36,755 2019-03-16 20:24:36: step 416/50000, loss = 0.187093 (1.800 sec/batch), lr: 0.250000
2019-03-16 20:24:38,625 2019-03-16 20:24:38: step 417/50000, loss = 0.189702 (1.861 sec/batch), lr: 0.250000
2019-03-16 20:24:40,630 2019-03-16 20:24:40: step 418/50000, loss = 0.190090 (1.996 sec/batch), lr: 0.250000
2019-03-16 20:24:42,761 2019-03-16 20:24:42: step 419/50000, loss = 0.193738 (2.120 sec/batch), lr: 0.250000
2019-03-16 20:24:45,011 2019-03-16 20:24:45: step 420/50000, loss = 0.188688 (2.237 sec/batch), lr: 0.250000
2019-03-16 20:24:47,605 2019-03-16 20:24:47: step 421/50000, loss = 0.205067 (2.579 sec/batch), lr: 0.250000
2019-03-16 20:24:50,379 2019-03-16 20:24:50: step 422/50000, loss = 0.176629 (2.759 sec/batch), lr: 0.250000
2019-03-16 20:24:53,198 2019-03-16 20:24:53: step 423/50000, loss = 0.212557 (2.804 sec/batch), lr: 0.250000
2019-03-16 20:24:56,347 2019-03-16 20:24:56: step 424/50000, loss = 0.183567 (3.132 sec/batch), lr: 0.250000
2019-03-16 20:24:59,420 2019-03-16 20:24:59: step 425/50000, loss = 0.209901 (3.058 sec/batch), lr: 0.250000
2019-03-16 20:25:02,667 2019-03-16 20:25:02: step 426/50000, loss = 0.192110 (3.229 sec/batch), lr: 0.250000
2019-03-16 20:25:06,176 2019-03-16 20:25:06: step 427/50000, loss = 0.202528 (3.483 sec/batch), lr: 0.250000
2019-03-16 20:25:09,838 2019-03-16 20:25:09: step 428/50000, loss = 0.186034 (3.647 sec/batch), lr: 0.250000
2019-03-16 20:25:13,704 2019-03-16 20:25:13: step 429/50000, loss = 0.218401 (3.847 sec/batch), lr: 0.250000
2019-03-16 20:25:17,801 2019-03-16 20:25:17: step 430/50000, loss = 0.192873 (4.077 sec/batch), lr: 0.250000
2019-03-16 20:25:21,951 2019-03-16 20:25:21: step 431/50000, loss = 0.219963 (4.130 sec/batch), lr: 0.250000
2019-03-16 20:25:26,574 2019-03-16 20:25:26: step 432/50000, loss = 0.199005 (4.599 sec/batch), lr: 0.250000
2019-03-16 20:25:31,356 2019-03-16 20:25:31: step 433/50000, loss = 0.217780 (4.759 sec/batch), lr: 0.250000
2019-03-16 20:25:36,377 2019-03-16 20:25:36: step 434/50000, loss = 0.197191 (4.996 sec/batch), lr: 0.250000
2019-03-16 20:25:41,782 2019-03-16 20:25:41: step 435/50000, loss = 0.213825 (5.398 sec/batch), lr: 0.250000
2019-03-16 20:25:47,422 2019-03-16 20:25:47: step 436/50000, loss = 0.203195 (5.611 sec/batch), lr: 0.250000
2019-03-16 20:25:53,568 2019-03-16 20:25:53: step 437/50000, loss = 0.213645 (6.111 sec/batch), lr: 0.250000
2019-03-16 20:26:00,308 2019-03-16 20:26:00: step 438/50000, loss = 0.194921 (6.731 sec/batch), lr: 0.250000
2019-03-16 20:26:07,384 2019-03-16 20:26:07: step 439/50000, loss = 0.215859 (7.069 sec/batch), lr: 0.250000
2019-03-16 20:26:15,034 2019-03-16 20:26:15: step 440/50000, loss = 0.197979 (7.639 sec/batch), lr: 0.250000
2019-03-16 20:26:23,064 2019-03-16 20:26:23: step 441/50000, loss = 0.225833 (7.977 sec/batch), lr: 0.250000
2019-03-16 20:26:32,157 2019-03-16 20:26:32: step 442/50000, loss = 0.205387 (9.040 sec/batch), lr: 0.250000
2019-03-16 20:26:42,230 2019-03-16 20:26:42: step 443/50000, loss = 0.228690 (10.018 sec/batch), lr: 0.250000
2019-03-16 20:26:53,187 2019-03-16 20:26:53: step 444/50000, loss = 0.205272 (10.900 sec/batch), lr: 0.250000
2019-03-16 20:27:05,187 2019-03-16 20:27:05: step 445/50000, loss = 0.208581 (11.935 sec/batch), lr: 0.250000
2019-03-16 20:27:19,290 2019-03-16 20:27:19: step 446/50000, loss = 0.264552 (14.026 sec/batch), lr: 0.250000
2019-03-16 20:27:36,069 2019-03-16 20:27:36: step 447/50000, loss = 0.224597 (16.683 sec/batch), lr: 0.250000
2019-03-16 20:27:56,059 2019-03-16 20:27:56: step 448/50000, loss = 0.230087 (19.877 sec/batch), lr: 0.250000
2019-03-16 20:28:23,994 2019-03-16 20:28:23: step 449/50000, loss = 0.229767 (27.780 sec/batch), lr: 0.250000
2019-03-16 20:28:57,810 2019-03-16 20:28:57: step 450/50000, loss = 0.175343 (33.646 sec/batch), lr: 0.250000
2019-03-16 20:29:47,047 2019-03-16 20:29:47: step 451/50000, loss = 0.186797 (48.994 sec/batch), lr: 0.250000
2019-03-16 20:30:10,376 2019-03-16 20:30:10: step 452/50000, loss = 0.213443 (23.197 sec/batch), lr: 0.250000
2019-03-16 20:30:28,990 2019-03-16 20:30:28: step 453/50000, loss = 0.228183 (18.599 sec/batch), lr: 0.250000
2019-03-16 20:30:44,549 2019-03-16 20:30:44: step 454/50000, loss = 0.233816 (15.548 sec/batch), lr: 0.250000
2019-03-16 20:30:57,386 2019-03-16 20:30:57: step 455/50000, loss = 0.224051 (12.825 sec/batch), lr: 0.250000
2019-03-16 20:31:09,038 2019-03-16 20:31:09: step 456/50000, loss = 0.230091 (11.640 sec/batch), lr: 0.250000
2019-03-16 20:31:20,108 2019-03-16 20:31:20: step 457/50000, loss = 0.225038 (11.006 sec/batch), lr: 0.250000
2019-03-16 20:31:29,721 2019-03-16 20:31:29: step 458/50000, loss = 0.230659 (9.601 sec/batch), lr: 0.250000
2019-03-16 20:31:38,714 2019-03-16 20:31:38: step 459/50000, loss = 0.206635 (8.941 sec/batch), lr: 0.250000
2019-03-16 20:31:46,985 2019-03-16 20:31:46: step 460/50000, loss = 0.222414 (8.224 sec/batch), lr: 0.250000
2019-03-16 20:31:54,298 2019-03-16 20:31:54: step 461/50000, loss = 0.212636 (7.304 sec/batch), lr: 0.250000
2019-03-16 20:32:01,084 2019-03-16 20:32:01: step 462/50000, loss = 0.228432 (6.751 sec/batch), lr: 0.250000
2019-03-16 20:32:07,401 2019-03-16 20:32:07: step 463/50000, loss = 0.214438 (6.309 sec/batch), lr: 0.250000
2019-03-16 20:32:13,454 2019-03-16 20:32:13: step 464/50000, loss = 0.218440 (6.012 sec/batch), lr: 0.250000
2019-03-16 20:32:19,112 2019-03-16 20:32:19: step 465/50000, loss = 0.211750 (5.627 sec/batch), lr: 0.250000
2019-03-16 20:32:24,388 2019-03-16 20:32:24: step 466/50000, loss = 0.226694 (5.249 sec/batch), lr: 0.250000
2019-03-16 20:32:29,261 2019-03-16 20:32:29: step 467/50000, loss = 0.216995 (4.847 sec/batch), lr: 0.250000
2019-03-16 20:32:33,995 2019-03-16 20:32:33: step 468/50000, loss = 0.211765 (4.709 sec/batch), lr: 0.250000
2019-03-16 20:32:38,407 2019-03-16 20:32:38: step 469/50000, loss = 0.208504 (4.404 sec/batch), lr: 0.250000
2019-03-16 20:32:42,766 2019-03-16 20:32:42: step 470/50000, loss = 0.216656 (4.337 sec/batch), lr: 0.250000
2019-03-16 20:32:46,816 2019-03-16 20:32:46: step 471/50000, loss = 0.205905 (4.031 sec/batch), lr: 0.250000
2019-03-16 20:32:50,595 2019-03-16 20:32:50: step 472/50000, loss = 0.210843 (3.762 sec/batch), lr: 0.250000
2019-03-16 20:32:54,092 2019-03-16 20:32:54: step 473/50000, loss = 0.204911 (3.478 sec/batch), lr: 0.250000
2019-03-16 20:32:57,443 2019-03-16 20:32:57: step 474/50000, loss = 0.199909 (3.333 sec/batch), lr: 0.250000
2019-03-16 20:33:00,737 2019-03-16 20:33:00: step 475/50000, loss = 0.203440 (3.285 sec/batch), lr: 0.250000
2019-03-16 20:33:03,874 2019-03-16 20:33:03: step 476/50000, loss = 0.198701 (3.128 sec/batch), lr: 0.250000
2019-03-16 20:33:06,865 2019-03-16 20:33:06: step 477/50000, loss = 0.204124 (2.974 sec/batch), lr: 0.250000
2019-03-16 20:33:09,575 2019-03-16 20:33:09: step 478/50000, loss = 0.201698 (2.703 sec/batch), lr: 0.250000
2019-03-16 20:33:12,122 2019-03-16 20:33:12: step 479/50000, loss = 0.206314 (2.533 sec/batch), lr: 0.250000
2019-03-16 20:33:14,706 2019-03-16 20:33:14: step 480/50000, loss = 0.185733 (2.571 sec/batch), lr: 0.250000
2019-03-16 20:33:16,916 2019-03-16 20:33:16: step 481/50000, loss = 0.199110 (2.197 sec/batch), lr: 0.250000
2019-03-16 20:33:18,999 2019-03-16 20:33:18: step 482/50000, loss = 0.200603 (2.074 sec/batch), lr: 0.250000
2019-03-16 20:33:21,072 2019-03-16 20:33:21: step 483/50000, loss = 0.198784 (2.062 sec/batch), lr: 0.250000
2019-03-16 20:33:22,977 2019-03-16 20:33:22: step 484/50000, loss = 0.198375 (1.893 sec/batch), lr: 0.250000
2019-03-16 20:33:24,651 2019-03-16 20:33:24: step 485/50000, loss = 0.195959 (1.664 sec/batch), lr: 0.250000
2019-03-16 20:33:26,277 2019-03-16 20:33:26: step 486/50000, loss = 0.187038 (1.616 sec/batch), lr: 0.250000
2019-03-16 20:33:27,800 2019-03-16 20:33:27: step 487/50000, loss = 0.189803 (1.512 sec/batch), lr: 0.250000
2019-03-16 20:33:29,230 2019-03-16 20:33:29: step 488/50000, loss = 0.180228 (1.421 sec/batch), lr: 0.250000
2019-03-16 20:33:30,460 2019-03-16 20:33:30: step 489/50000, loss = 0.177385 (1.223 sec/batch), lr: 0.250000
2019-03-16 20:33:31,556 2019-03-16 20:33:31: step 490/50000, loss = 0.182707 (1.088 sec/batch), lr: 0.250000
2019-03-16 20:33:32,509 2019-03-16 20:33:32: step 491/50000, loss = 0.198403 (0.946 sec/batch), lr: 0.250000
2019-03-16 20:33:33,471 2019-03-16 20:33:33: step 492/50000, loss = 0.187107 (0.954 sec/batch), lr: 0.250000
2019-03-16 20:33:34,296 2019-03-16 20:33:34: step 493/50000, loss = 0.187226 (0.818 sec/batch), lr: 0.250000
2019-03-16 20:33:34,969 2019-03-16 20:33:34: step 494/50000, loss = 0.188100 (0.665 sec/batch), lr: 0.250000
2019-03-16 20:33:35,530 2019-03-16 20:33:35: step 495/50000, loss = 0.190674 (0.555 sec/batch), lr: 0.250000
2019-03-16 20:33:36,053 2019-03-16 20:33:36: step 496/50000, loss = 0.170793 (0.517 sec/batch), lr: 0.250000
2019-03-16 20:33:36,473 2019-03-16 20:33:36: step 497/50000, loss = 0.174037 (0.414 sec/batch), lr: 0.250000
2019-03-16 20:33:36,806 2019-03-16 20:33:36: step 498/50000, loss = 0.152356 (0.328 sec/batch), lr: 0.250000
2019-03-16 20:33:37,010 2019-03-16 20:33:37: step 499/50000, loss = 0.125506 (0.201 sec/batch), lr: 0.250000
2019-03-16 20:33:37,149 2019-03-16 20:33:37: step 500/50000, loss = 0.224099 (0.136 sec/batch), lr: 0.250000
2019-03-16 20:34:05,642 step 500: Full loss = 0.190199, Edge acc. = 0.3304
2019-03-16 20:34:05,643 step 500: Dev acc. = 0.389035
2019-03-16 20:34:05,787 2019-03-16 20:34:05: step 501/50000, loss = 0.175296 (0.140 sec/batch), lr: 0.250000
2019-03-16 20:34:05,993 2019-03-16 20:34:05: step 502/50000, loss = 0.094449 (0.202 sec/batch), lr: 0.250000
2019-03-16 20:34:06,296 2019-03-16 20:34:06: step 503/50000, loss = 0.247885 (0.299 sec/batch), lr: 0.250000
2019-03-16 20:34:06,693 2019-03-16 20:34:06: step 504/50000, loss = 0.211476 (0.393 sec/batch), lr: 0.250000
2019-03-16 20:34:07,208 2019-03-16 20:34:07: step 505/50000, loss = 0.216800 (0.510 sec/batch), lr: 0.250000
2019-03-16 20:34:07,747 2019-03-16 20:34:07: step 506/50000, loss = 0.219394 (0.534 sec/batch), lr: 0.250000
2019-03-16 20:34:08,453 2019-03-16 20:34:08: step 507/50000, loss = 0.222496 (0.700 sec/batch), lr: 0.250000
2019-03-16 20:34:09,248 2019-03-16 20:34:09: step 508/50000, loss = 0.243038 (0.787 sec/batch), lr: 0.250000
2019-03-16 20:34:10,227 2019-03-16 20:34:10: step 509/50000, loss = 0.226176 (0.971 sec/batch), lr: 0.250000
2019-03-16 20:34:11,316 2019-03-16 20:34:11: step 510/50000, loss = 0.232995 (1.080 sec/batch), lr: 0.250000
2019-03-16 20:34:12,463 2019-03-16 20:34:12: step 511/50000, loss = 0.210433 (1.137 sec/batch), lr: 0.250000
2019-03-16 20:34:13,695 2019-03-16 20:34:13: step 512/50000, loss = 0.232395 (1.224 sec/batch), lr: 0.250000
2019-03-16 20:34:15,088 2019-03-16 20:34:15: step 513/50000, loss = 0.212220 (1.383 sec/batch), lr: 0.250000
2019-03-16 20:34:16,692 2019-03-16 20:34:16: step 514/50000, loss = 0.231011 (1.593 sec/batch), lr: 0.250000
2019-03-16 20:34:18,378 2019-03-16 20:34:18: step 515/50000, loss = 0.223230 (1.675 sec/batch), lr: 0.250000
2019-03-16 20:34:20,107 2019-03-16 20:34:20: step 516/50000, loss = 0.259889 (1.722 sec/batch), lr: 0.250000
2019-03-16 20:34:22,012 2019-03-16 20:34:22: step 517/50000, loss = 0.214267 (1.898 sec/batch), lr: 0.250000
2019-03-16 20:34:24,139 2019-03-16 20:34:24: step 518/50000, loss = 0.242135 (2.119 sec/batch), lr: 0.250000
2019-03-16 20:34:26,387 2019-03-16 20:34:26: step 519/50000, loss = 0.200578 (2.235 sec/batch), lr: 0.250000
2019-03-16 20:34:28,719 2019-03-16 20:34:28: step 520/50000, loss = 0.230217 (2.319 sec/batch), lr: 0.250000
2019-03-16 20:34:31,232 2019-03-16 20:34:31: step 521/50000, loss = 0.215861 (2.498 sec/batch), lr: 0.250000
2019-03-16 20:34:33,931 2019-03-16 20:34:33: step 522/50000, loss = 0.227464 (2.687 sec/batch), lr: 0.250000
2019-03-16 20:34:36,516 2019-03-16 20:34:36: step 523/50000, loss = 0.208267 (2.572 sec/batch), lr: 0.250000
2019-03-16 20:34:39,357 2019-03-16 20:34:39: step 524/50000, loss = 0.226269 (2.825 sec/batch), lr: 0.250000
2019-03-16 20:34:42,489 2019-03-16 20:34:42: step 525/50000, loss = 0.215626 (3.116 sec/batch), lr: 0.250000
2019-03-16 20:34:46,012 2019-03-16 20:34:46: step 526/50000, loss = 0.232350 (3.504 sec/batch), lr: 0.250000
2019-03-16 20:34:49,659 2019-03-16 20:34:49: step 527/50000, loss = 0.195751 (3.628 sec/batch), lr: 0.250000
2019-03-16 20:34:53,325 2019-03-16 20:34:53: step 528/50000, loss = 0.229430 (3.648 sec/batch), lr: 0.250000
2019-03-16 20:34:57,320 2019-03-16 20:34:57: step 529/50000, loss = 0.209915 (3.975 sec/batch), lr: 0.250000
2019-03-16 20:35:01,560 2019-03-16 20:35:01: step 530/50000, loss = 0.233903 (4.217 sec/batch), lr: 0.250000
2019-03-16 20:35:05,899 2019-03-16 20:35:05: step 531/50000, loss = 0.211661 (4.315 sec/batch), lr: 0.250000
2019-03-16 20:35:10,612 2019-03-16 20:35:10: step 532/50000, loss = 0.234035 (4.687 sec/batch), lr: 0.250000
2019-03-16 20:35:15,497 2019-03-16 20:35:15: step 533/50000, loss = 0.221159 (4.858 sec/batch), lr: 0.250000
2019-03-16 20:35:20,487 2019-03-16 20:35:20: step 534/50000, loss = 0.239217 (4.963 sec/batch), lr: 0.250000
2019-03-16 20:35:26,037 2019-03-16 20:35:26: step 535/50000, loss = 0.202699 (5.540 sec/batch), lr: 0.250000
2019-03-16 20:35:31,700 2019-03-16 20:35:31: step 536/50000, loss = 0.240730 (5.632 sec/batch), lr: 0.250000
2019-03-16 20:35:37,707 2019-03-16 20:35:37: step 537/50000, loss = 0.204925 (5.972 sec/batch), lr: 0.250000
2019-03-16 20:35:44,317 2019-03-16 20:35:44: step 538/50000, loss = 0.229386 (6.574 sec/batch), lr: 0.250000
2019-03-16 20:35:51,491 2019-03-16 20:35:51: step 539/50000, loss = 0.208686 (7.128 sec/batch), lr: 0.250000
2019-03-16 20:35:59,064 2019-03-16 20:35:59: step 540/50000, loss = 0.239335 (7.565 sec/batch), lr: 0.250000
2019-03-16 20:36:07,316 2019-03-16 20:36:07: step 541/50000, loss = 0.205921 (8.205 sec/batch), lr: 0.250000
2019-03-16 20:36:16,442 2019-03-16 20:36:16: step 542/50000, loss = 0.237284 (9.115 sec/batch), lr: 0.250000
2019-03-16 20:36:26,365 2019-03-16 20:36:26: step 543/50000, loss = 0.211491 (9.866 sec/batch), lr: 0.250000
2019-03-16 20:36:37,499 2019-03-16 20:36:37: step 544/50000, loss = 0.240630 (11.070 sec/batch), lr: 0.250000
2019-03-16 20:36:49,541 2019-03-16 20:36:49: step 545/50000, loss = 0.212693 (11.975 sec/batch), lr: 0.250000
2019-03-16 20:37:03,754 2019-03-16 20:37:03: step 546/50000, loss = 0.243787 (14.136 sec/batch), lr: 0.250000
2019-03-16 20:37:20,524 2019-03-16 20:37:20: step 547/50000, loss = 0.211112 (16.677 sec/batch), lr: 0.250000
2019-03-16 20:37:40,498 2019-03-16 20:37:40: step 548/50000, loss = 0.241077 (19.863 sec/batch), lr: 0.250000
2019-03-16 20:38:08,310 2019-03-16 20:38:08: step 549/50000, loss = 0.206084 (27.650 sec/batch), lr: 0.250000
2019-03-16 20:38:42,038 2019-03-16 20:38:42: step 550/50000, loss = 0.209081 (33.555 sec/batch), lr: 0.250000
2019-03-16 20:39:30,999 2019-03-16 20:39:30: step 551/50000, loss = 0.164728 (48.732 sec/batch), lr: 0.250000
2019-03-16 20:39:54,417 2019-03-16 20:39:54: step 552/50000, loss = 0.201109 (23.401 sec/batch), lr: 0.250000
2019-03-16 20:40:12,652 2019-03-16 20:40:12: step 553/50000, loss = 0.264561 (18.223 sec/batch), lr: 0.250000
2019-03-16 20:40:28,245 2019-03-16 20:40:28: step 554/50000, loss = 0.233009 (15.579 sec/batch), lr: 0.250000
2019-03-16 20:40:40,967 2019-03-16 20:40:40: step 555/50000, loss = 0.258131 (12.712 sec/batch), lr: 0.250000
2019-03-16 20:40:52,609 2019-03-16 20:40:52: step 556/50000, loss = 0.227242 (11.630 sec/batch), lr: 0.250000
2019-03-16 20:41:03,208 2019-03-16 20:41:03: step 557/50000, loss = 0.249988 (10.539 sec/batch), lr: 0.250000
2019-03-16 20:41:12,739 2019-03-16 20:41:12: step 558/50000, loss = 0.226609 (9.476 sec/batch), lr: 0.250000
2019-03-16 20:41:21,659 2019-03-16 20:41:21: step 559/50000, loss = 0.252738 (8.909 sec/batch), lr: 0.250000
2019-03-16 20:41:29,777 2019-03-16 20:41:29: step 560/50000, loss = 0.238564 (8.107 sec/batch), lr: 0.250000
2019-03-16 20:41:37,027 2019-03-16 20:41:37: step 561/50000, loss = 0.243633 (7.241 sec/batch), lr: 0.250000
2019-03-16 20:41:43,935 2019-03-16 20:41:43: step 562/50000, loss = 0.236002 (6.874 sec/batch), lr: 0.250000
2019-03-16 20:41:50,272 2019-03-16 20:41:50: step 563/50000, loss = 0.224340 (6.301 sec/batch), lr: 0.250000
2019-03-16 20:41:56,317 2019-03-16 20:41:56: step 564/50000, loss = 0.238477 (6.013 sec/batch), lr: 0.250000
2019-03-16 20:42:01,880 2019-03-16 20:42:01: step 565/50000, loss = 0.223946 (5.538 sec/batch), lr: 0.250000
2019-03-16 20:42:07,086 2019-03-16 20:42:07: step 566/50000, loss = 0.239148 (5.179 sec/batch), lr: 0.250000
2019-03-16 20:42:12,139 2019-03-16 20:42:12: step 567/50000, loss = 0.224891 (5.043 sec/batch), lr: 0.250000
2019-03-16 20:42:16,825 2019-03-16 20:42:16: step 568/50000, loss = 0.234493 (4.663 sec/batch), lr: 0.250000
2019-03-16 20:42:21,306 2019-03-16 20:42:21: step 569/50000, loss = 0.215147 (4.457 sec/batch), lr: 0.250000
2019-03-16 20:42:25,687 2019-03-16 20:42:25: step 570/50000, loss = 0.242810 (4.358 sec/batch), lr: 0.250000
2019-03-16 20:42:29,822 2019-03-16 20:42:29: step 571/50000, loss = 0.219010 (4.113 sec/batch), lr: 0.250000
2019-03-16 20:42:33,787 2019-03-16 20:42:33: step 572/50000, loss = 0.227053 (3.957 sec/batch), lr: 0.250000
2019-03-16 20:42:37,349 2019-03-16 20:42:37: step 573/50000, loss = 0.210962 (3.545 sec/batch), lr: 0.250000
2019-03-16 20:42:40,754 2019-03-16 20:42:40: step 574/50000, loss = 0.230939 (3.396 sec/batch), lr: 0.250000
2019-03-16 20:42:44,044 2019-03-16 20:42:44: step 575/50000, loss = 0.200394 (3.273 sec/batch), lr: 0.250000
2019-03-16 20:42:47,130 2019-03-16 20:42:47: step 576/50000, loss = 0.227024 (3.070 sec/batch), lr: 0.250000
2019-03-16 20:42:50,102 2019-03-16 20:42:50: step 577/50000, loss = 0.203911 (2.956 sec/batch), lr: 0.250000
2019-03-16 20:42:52,983 2019-03-16 20:42:52: step 578/50000, loss = 0.221590 (2.863 sec/batch), lr: 0.250000
2019-03-16 20:42:55,535 2019-03-16 20:42:55: step 579/50000, loss = 0.214704 (2.537 sec/batch), lr: 0.250000
2019-03-16 20:42:57,934 2019-03-16 20:42:57: step 580/50000, loss = 0.212956 (2.389 sec/batch), lr: 0.250000
2019-03-16 20:43:00,095 2019-03-16 20:43:00: step 581/50000, loss = 0.198338 (2.151 sec/batch), lr: 0.250000
2019-03-16 20:43:02,046 2019-03-16 20:43:02: step 582/50000, loss = 0.212291 (1.939 sec/batch), lr: 0.250000
2019-03-16 20:43:03,980 2019-03-16 20:43:03: step 583/50000, loss = 0.211743 (1.924 sec/batch), lr: 0.250000
2019-03-16 20:43:05,748 2019-03-16 20:43:05: step 584/50000, loss = 0.221548 (1.761 sec/batch), lr: 0.250000
2019-03-16 20:43:07,459 2019-03-16 20:43:07: step 585/50000, loss = 0.205723 (1.702 sec/batch), lr: 0.250000
2019-03-16 20:43:08,942 2019-03-16 20:43:08: step 586/50000, loss = 0.205209 (1.478 sec/batch), lr: 0.250000
2019-03-16 20:43:10,279 2019-03-16 20:43:10: step 587/50000, loss = 0.212783 (1.329 sec/batch), lr: 0.250000
2019-03-16 20:43:11,548 2019-03-16 20:43:11: step 588/50000, loss = 0.207797 (1.264 sec/batch), lr: 0.250000
2019-03-16 20:43:12,684 2019-03-16 20:43:12: step 589/50000, loss = 0.210640 (1.128 sec/batch), lr: 0.250000
2019-03-16 20:43:13,656 2019-03-16 20:43:13: step 590/50000, loss = 0.227887 (0.966 sec/batch), lr: 0.250000
2019-03-16 20:43:14,507 2019-03-16 20:43:14: step 591/50000, loss = 0.242892 (0.845 sec/batch), lr: 0.250000
2019-03-16 20:43:15,338 2019-03-16 20:43:15: step 592/50000, loss = 0.226494 (0.824 sec/batch), lr: 0.250000
2019-03-16 20:43:16,057 2019-03-16 20:43:16: step 593/50000, loss = 0.248928 (0.712 sec/batch), lr: 0.250000
2019-03-16 20:43:16,648 2019-03-16 20:43:16: step 594/50000, loss = 0.281907 (0.586 sec/batch), lr: 0.250000
2019-03-16 20:43:17,155 2019-03-16 20:43:17: step 595/50000, loss = 0.289665 (0.501 sec/batch), lr: 0.250000
2019-03-16 20:43:17,590 2019-03-16 20:43:17: step 596/50000, loss = 0.245287 (0.430 sec/batch), lr: 0.250000
2019-03-16 20:43:17,983 2019-03-16 20:43:17: step 597/50000, loss = 0.239268 (0.389 sec/batch), lr: 0.250000
2019-03-16 20:43:18,294 2019-03-16 20:43:18: step 598/50000, loss = 0.199514 (0.307 sec/batch), lr: 0.250000
2019-03-16 20:43:18,478 2019-03-16 20:43:18: step 599/50000, loss = 0.161665 (0.181 sec/batch), lr: 0.250000
2019-03-16 20:43:18,597 2019-03-16 20:43:18: step 600/50000, loss = 0.377249 (0.117 sec/batch), lr: 0.250000
2019-03-16 20:43:46,939 step 600: Full loss = 0.127187, Edge acc. = 0.2956
2019-03-16 20:43:46,999 step 600: Dev acc. = 0.262218
2019-03-16 20:43:47,150 2019-03-16 20:43:47: step 601/50000, loss = 0.185273 (0.146 sec/batch), lr: 0.125000
2019-03-16 20:43:47,374 2019-03-16 20:43:47: step 602/50000, loss = 0.104320 (0.220 sec/batch), lr: 0.125000
2019-03-16 20:43:47,677 2019-03-16 20:43:47: step 603/50000, loss = 0.196540 (0.299 sec/batch), lr: 0.125000
2019-03-16 20:43:48,106 2019-03-16 20:43:48: step 604/50000, loss = 0.175149 (0.424 sec/batch), lr: 0.125000
2019-03-16 20:43:48,647 2019-03-16 20:43:48: step 605/50000, loss = 0.166900 (0.535 sec/batch), lr: 0.125000
2019-03-16 20:43:49,298 2019-03-16 20:43:49: step 606/50000, loss = 0.169894 (0.646 sec/batch), lr: 0.125000
2019-03-16 20:43:50,072 2019-03-16 20:43:50: step 607/50000, loss = 0.167860 (0.768 sec/batch), lr: 0.125000
2019-03-16 20:43:50,837 2019-03-16 20:43:50: step 608/50000, loss = 0.183178 (0.762 sec/batch), lr: 0.125000
2019-03-16 20:43:51,708 2019-03-16 20:43:51: step 609/50000, loss = 0.181030 (0.864 sec/batch), lr: 0.125000
2019-03-16 20:43:52,791 2019-03-16 20:43:52: step 610/50000, loss = 0.176133 (1.075 sec/batch), lr: 0.125000
2019-03-16 20:43:53,957 2019-03-16 20:43:53: step 611/50000, loss = 0.176016 (1.156 sec/batch), lr: 0.125000
2019-03-16 20:43:55,230 2019-03-16 20:43:55: step 612/50000, loss = 0.183652 (1.264 sec/batch), lr: 0.125000
2019-03-16 20:43:56,562 2019-03-16 20:43:56: step 613/50000, loss = 0.170181 (1.323 sec/batch), lr: 0.125000
2019-03-16 20:43:58,007 2019-03-16 20:43:58: step 614/50000, loss = 0.174662 (1.436 sec/batch), lr: 0.125000
2019-03-16 20:43:59,491 2019-03-16 20:43:59: step 615/50000, loss = 0.183057 (1.480 sec/batch), lr: 0.125000
2019-03-16 20:44:01,252 2019-03-16 20:44:01: step 616/50000, loss = 0.196802 (1.754 sec/batch), lr: 0.125000
2019-03-16 20:44:03,109 2019-03-16 20:44:03: step 617/50000, loss = 0.179322 (1.846 sec/batch), lr: 0.125000
2019-03-16 20:44:05,088 2019-03-16 20:44:05: step 618/50000, loss = 0.197304 (1.967 sec/batch), lr: 0.125000
2019-03-16 20:44:07,230 2019-03-16 20:44:07: step 619/50000, loss = 0.176195 (2.134 sec/batch), lr: 0.125000
2019-03-16 20:44:09,430 2019-03-16 20:44:09: step 620/50000, loss = 0.195823 (2.187 sec/batch), lr: 0.125000
2019-03-16 20:44:11,722 2019-03-16 20:44:11: step 621/50000, loss = 0.185617 (2.281 sec/batch), lr: 0.125000
2019-03-16 20:44:14,367 2019-03-16 20:44:14: step 622/50000, loss = 0.185839 (2.632 sec/batch), lr: 0.125000
2019-03-16 20:44:17,220 2019-03-16 20:44:17: step 623/50000, loss = 0.189565 (2.838 sec/batch), lr: 0.125000
2019-03-16 20:44:20,343 2019-03-16 20:44:20: step 624/50000, loss = 0.190758 (3.107 sec/batch), lr: 0.125000
2019-03-16 20:44:23,406 2019-03-16 20:44:23: step 625/50000, loss = 0.198525 (3.045 sec/batch), lr: 0.125000
2019-03-16 20:44:26,670 2019-03-16 20:44:26: step 626/50000, loss = 0.194986 (3.246 sec/batch), lr: 0.125000
2019-03-16 20:44:30,092 2019-03-16 20:44:30: step 627/50000, loss = 0.189463 (3.404 sec/batch), lr: 0.125000
2019-03-16 20:44:33,583 2019-03-16 20:44:33: step 628/50000, loss = 0.197786 (3.471 sec/batch), lr: 0.125000
2019-03-16 20:44:37,418 2019-03-16 20:44:37: step 629/50000, loss = 0.203942 (3.813 sec/batch), lr: 0.125000
2019-03-16 20:44:41,725 2019-03-16 20:44:41: step 630/50000, loss = 0.202876 (4.284 sec/batch), lr: 0.125000
2019-03-16 20:44:46,073 2019-03-16 20:44:46: step 631/50000, loss = 0.204119 (4.324 sec/batch), lr: 0.125000
2019-03-16 20:44:50,721 2019-03-16 20:44:50: step 632/50000, loss = 0.208083 (4.622 sec/batch), lr: 0.125000
2019-03-16 20:44:55,742 2019-03-16 20:44:55: step 633/50000, loss = 0.201897 (4.993 sec/batch), lr: 0.125000
2019-03-16 20:45:01,012 2019-03-16 20:45:01: step 634/50000, loss = 0.203616 (5.241 sec/batch), lr: 0.125000
2019-03-16 20:45:06,588 2019-03-16 20:45:06: step 635/50000, loss = 0.198715 (5.547 sec/batch), lr: 0.125000
2019-03-16 20:45:12,285 2019-03-16 20:45:12: step 636/50000, loss = 0.214324 (5.662 sec/batch), lr: 0.125000
2019-03-16 20:45:18,325 2019-03-16 20:45:18: step 637/50000, loss = 0.195620 (6.006 sec/batch), lr: 0.125000
2019-03-16 20:45:25,081 2019-03-16 20:45:25: step 638/50000, loss = 0.202845 (6.745 sec/batch), lr: 0.125000
2019-03-16 20:45:32,265 2019-03-16 20:45:32: step 639/50000, loss = 0.196818 (7.148 sec/batch), lr: 0.125000
2019-03-16 20:45:39,801 2019-03-16 20:45:39: step 640/50000, loss = 0.210050 (7.493 sec/batch), lr: 0.125000
2019-03-16 20:45:47,952 2019-03-16 20:45:47: step 641/50000, loss = 0.201049 (8.104 sec/batch), lr: 0.125000
2019-03-16 20:45:57,078 2019-03-16 20:45:57: step 642/50000, loss = 0.214813 (9.073 sec/batch), lr: 0.125000
2019-03-16 20:46:07,793 2019-03-16 20:46:07: step 643/50000, loss = 0.205087 (10.655 sec/batch), lr: 0.125000
2019-03-16 20:46:18,845 2019-03-16 20:46:18: step 644/50000, loss = 0.219664 (10.990 sec/batch), lr: 0.125000
2019-03-16 20:46:30,974 2019-03-16 20:46:30: step 645/50000, loss = 0.204345 (12.056 sec/batch), lr: 0.125000
2019-03-16 20:46:45,226 2019-03-16 20:46:45: step 646/50000, loss = 0.224353 (14.166 sec/batch), lr: 0.125000
2019-03-16 20:47:02,184 2019-03-16 20:47:02: step 647/50000, loss = 0.211183 (16.853 sec/batch), lr: 0.125000
2019-03-16 20:47:21,991 2019-03-16 20:47:21: step 648/50000, loss = 0.211441 (19.684 sec/batch), lr: 0.125000
2019-03-16 20:47:50,305 2019-03-16 20:47:50: step 649/50000, loss = 0.215237 (28.148 sec/batch), lr: 0.125000
2019-03-16 20:48:23,997 2019-03-16 20:48:23: step 650/50000, loss = 0.185231 (33.678 sec/batch), lr: 0.125000
2019-03-16 20:49:12,890 2019-03-16 20:49:12: step 651/50000, loss = 0.168690 (48.648 sec/batch), lr: 0.125000
2019-03-16 20:49:36,443 2019-03-16 20:49:36: step 652/50000, loss = 0.208054 (23.536 sec/batch), lr: 0.125000
2019-03-16 20:49:54,552 2019-03-16 20:49:54: step 653/50000, loss = 0.236138 (18.093 sec/batch), lr: 0.125000
2019-03-16 20:50:10,223 2019-03-16 20:50:10: step 654/50000, loss = 0.217425 (15.576 sec/batch), lr: 0.125000
2019-03-16 20:50:23,042 2019-03-16 20:50:23: step 655/50000, loss = 0.235420 (12.741 sec/batch), lr: 0.125000
2019-03-16 20:50:34,512 2019-03-16 20:50:34: step 656/50000, loss = 0.205563 (11.458 sec/batch), lr: 0.125000
2019-03-16 20:50:44,821 2019-03-16 20:50:44: step 657/50000, loss = 0.240777 (10.254 sec/batch), lr: 0.125000
2019-03-16 20:50:54,332 2019-03-16 20:50:54: step 658/50000, loss = 0.204716 (9.461 sec/batch), lr: 0.125000
2019-03-16 20:51:03,264 2019-03-16 20:51:03: step 659/50000, loss = 0.222980 (8.882 sec/batch), lr: 0.125000
2019-03-16 20:51:11,403 2019-03-16 20:51:11: step 660/50000, loss = 0.207353 (8.093 sec/batch), lr: 0.125000
2019-03-16 20:51:18,738 2019-03-16 20:51:18: step 661/50000, loss = 0.229126 (7.294 sec/batch), lr: 0.125000
2019-03-16 20:51:25,605 2019-03-16 20:51:25: step 662/50000, loss = 0.200760 (6.829 sec/batch), lr: 0.125000
2019-03-16 20:51:31,962 2019-03-16 20:51:31: step 663/50000, loss = 0.215588 (6.323 sec/batch), lr: 0.125000
2019-03-16 20:51:37,880 2019-03-16 20:51:37: step 664/50000, loss = 0.201473 (5.910 sec/batch), lr: 0.125000
2019-03-16 20:51:43,461 2019-03-16 20:51:43: step 665/50000, loss = 0.210888 (5.550 sec/batch), lr: 0.125000
2019-03-16 20:51:48,818 2019-03-16 20:51:48: step 666/50000, loss = 0.207946 (5.327 sec/batch), lr: 0.125000
2019-03-16 20:51:53,576 2019-03-16 20:51:53: step 667/50000, loss = 0.222521 (4.735 sec/batch), lr: 0.125000
2019-03-16 20:51:58,392 2019-03-16 20:51:58: step 668/50000, loss = 0.202857 (4.791 sec/batch), lr: 0.125000
2019-03-16 20:52:02,973 2019-03-16 20:52:02: step 669/50000, loss = 0.218381 (4.572 sec/batch), lr: 0.125000
2019-03-16 20:52:07,106 2019-03-16 20:52:07: step 670/50000, loss = 0.208255 (4.112 sec/batch), lr: 0.125000
2019-03-16 20:52:11,247 2019-03-16 20:52:11: step 671/50000, loss = 0.215249 (4.119 sec/batch), lr: 0.125000
2019-03-16 20:52:15,190 2019-03-16 20:52:15: step 672/50000, loss = 0.194000 (3.921 sec/batch), lr: 0.125000
2019-03-16 20:52:18,831 2019-03-16 20:52:18: step 673/50000, loss = 0.206005 (3.622 sec/batch), lr: 0.125000
2019-03-16 20:52:22,245 2019-03-16 20:52:22: step 674/50000, loss = 0.197266 (3.405 sec/batch), lr: 0.125000
2019-03-16 20:52:25,531 2019-03-16 20:52:25: step 675/50000, loss = 0.204397 (3.269 sec/batch), lr: 0.125000
2019-03-16 20:52:28,585 2019-03-16 20:52:28: step 676/50000, loss = 0.198789 (3.037 sec/batch), lr: 0.125000
2019-03-16 20:52:31,630 2019-03-16 20:52:31: step 677/50000, loss = 0.207996 (3.030 sec/batch), lr: 0.125000
2019-03-16 20:52:34,368 2019-03-16 20:52:34: step 678/50000, loss = 0.199155 (2.725 sec/batch), lr: 0.125000
2019-03-16 20:52:36,946 2019-03-16 20:52:36: step 679/50000, loss = 0.216220 (2.564 sec/batch), lr: 0.125000
2019-03-16 20:52:39,497 2019-03-16 20:52:39: step 680/50000, loss = 0.191425 (2.538 sec/batch), lr: 0.125000
2019-03-16 20:52:41,731 2019-03-16 20:52:41: step 681/50000, loss = 0.197013 (2.221 sec/batch), lr: 0.125000
2019-03-16 20:52:43,836 2019-03-16 20:52:43: step 682/50000, loss = 0.191689 (2.098 sec/batch), lr: 0.125000
2019-03-16 20:52:45,930 2019-03-16 20:52:45: step 683/50000, loss = 0.194097 (2.082 sec/batch), lr: 0.125000
2019-03-16 20:52:47,816 2019-03-16 20:52:47: step 684/50000, loss = 0.193491 (1.874 sec/batch), lr: 0.125000
2019-03-16 20:52:49,681 2019-03-16 20:52:49: step 685/50000, loss = 0.186657 (1.855 sec/batch), lr: 0.125000
2019-03-16 20:52:51,195 2019-03-16 20:52:51: step 686/50000, loss = 0.180076 (1.509 sec/batch), lr: 0.125000
2019-03-16 20:52:52,646 2019-03-16 20:52:52: step 687/50000, loss = 0.192849 (1.442 sec/batch), lr: 0.125000
2019-03-16 20:52:54,017 2019-03-16 20:52:54: step 688/50000, loss = 0.172243 (1.361 sec/batch), lr: 0.125000
2019-03-16 20:52:55,133 2019-03-16 20:52:55: step 689/50000, loss = 0.176193 (1.109 sec/batch), lr: 0.125000
2019-03-16 20:52:56,142 2019-03-16 20:52:56: step 690/50000, loss = 0.177029 (1.003 sec/batch), lr: 0.125000
2019-03-16 20:52:57,130 2019-03-16 20:52:57: step 691/50000, loss = 0.191077 (0.979 sec/batch), lr: 0.125000
2019-03-16 20:52:58,078 2019-03-16 20:52:58: step 692/50000, loss = 0.177370 (0.940 sec/batch), lr: 0.125000
2019-03-16 20:52:58,899 2019-03-16 20:52:58: step 693/50000, loss = 0.199791 (0.813 sec/batch), lr: 0.125000
2019-03-16 20:52:59,576 2019-03-16 20:52:59: step 694/50000, loss = 0.179671 (0.669 sec/batch), lr: 0.125000
2019-03-16 20:53:00,133 2019-03-16 20:53:00: step 695/50000, loss = 0.189529 (0.552 sec/batch), lr: 0.125000
2019-03-16 20:53:00,657 2019-03-16 20:53:00: step 696/50000, loss = 0.162712 (0.517 sec/batch), lr: 0.125000
2019-03-16 20:53:01,085 2019-03-16 20:53:01: step 697/50000, loss = 0.156577 (0.422 sec/batch), lr: 0.125000
2019-03-16 20:53:01,408 2019-03-16 20:53:01: step 698/50000, loss = 0.157569 (0.318 sec/batch), lr: 0.125000
2019-03-16 20:53:01,603 2019-03-16 20:53:01: step 699/50000, loss = 0.063877 (0.192 sec/batch), lr: 0.125000
2019-03-16 20:53:01,739 2019-03-16 20:53:01: step 700/50000, loss = 0.071454 (0.133 sec/batch), lr: 0.125000
2019-03-16 20:53:30,140 step 700: Full loss = 0.254513, Edge acc. = 0.2899
2019-03-16 20:53:30,200 step 700: Dev acc. = 0.169759
2019-03-16 20:53:30,342 2019-03-16 20:53:30: step 701/50000, loss = 0.311873 (0.137 sec/batch), lr: 0.125000
2019-03-16 20:53:30,553 2019-03-16 20:53:30: step 702/50000, loss = 0.166096 (0.208 sec/batch), lr: 0.125000
2019-03-16 20:53:30,862 2019-03-16 20:53:30: step 703/50000, loss = 0.270173 (0.305 sec/batch), lr: 0.125000
2019-03-16 20:53:31,303 2019-03-16 20:53:31: step 704/50000, loss = 0.210104 (0.436 sec/batch), lr: 0.125000
2019-03-16 20:53:31,852 2019-03-16 20:53:31: step 705/50000, loss = 0.273920 (0.543 sec/batch), lr: 0.125000
2019-03-16 20:53:32,499 2019-03-16 20:53:32: step 706/50000, loss = 0.281913 (0.640 sec/batch), lr: 0.125000
2019-03-16 20:53:33,284 2019-03-16 20:53:33: step 707/50000, loss = 0.342433 (0.780 sec/batch), lr: 0.125000
2019-03-16 20:53:34,110 2019-03-16 20:53:34: step 708/50000, loss = 0.313642 (0.818 sec/batch), lr: 0.125000
2019-03-16 20:53:35,087 2019-03-16 20:53:35: step 709/50000, loss = 0.433232 (0.969 sec/batch), lr: 0.125000
2019-03-16 20:53:36,177 2019-03-16 20:53:36: step 710/50000, loss = 0.325942 (1.082 sec/batch), lr: 0.125000
2019-03-16 20:53:37,350 2019-03-16 20:53:37: step 711/50000, loss = 0.277992 (1.164 sec/batch), lr: 0.125000
2019-03-16 20:53:38,650 2019-03-16 20:53:38: step 712/50000, loss = 0.338433 (1.291 sec/batch), lr: 0.125000
2019-03-16 20:53:40,098 2019-03-16 20:53:40: step 713/50000, loss = 0.302570 (1.441 sec/batch), lr: 0.125000
2019-03-16 20:53:41,542 2019-03-16 20:53:41: step 714/50000, loss = 0.314033 (1.436 sec/batch), lr: 0.125000
2019-03-16 20:53:43,090 2019-03-16 20:53:43: step 715/50000, loss = 0.350922 (1.541 sec/batch), lr: 0.125000
2019-03-16 20:53:44,964 2019-03-16 20:53:44: step 716/50000, loss = 0.288600 (1.865 sec/batch), lr: 0.125000
2019-03-16 20:53:47,001 2019-03-16 20:53:47: step 717/50000, loss = 0.338689 (2.025 sec/batch), lr: 0.125000
2019-03-16 20:53:49,129 2019-03-16 20:53:49: step 718/50000, loss = 0.282691 (2.115 sec/batch), lr: 0.125000
2019-03-16 20:53:51,385 2019-03-16 20:53:51: step 719/50000, loss = 0.272236 (2.244 sec/batch), lr: 0.125000
2019-03-16 20:53:53,603 2019-03-16 20:53:53: step 720/50000, loss = 0.236992 (2.207 sec/batch), lr: 0.125000
2019-03-16 20:53:56,142 2019-03-16 20:53:56: step 721/50000, loss = 0.218053 (2.526 sec/batch), lr: 0.125000
2019-03-16 20:53:58,862 2019-03-16 20:53:58: step 722/50000, loss = 0.214882 (2.707 sec/batch), lr: 0.125000
2019-03-16 20:54:01,525 2019-03-16 20:54:01: step 723/50000, loss = 0.224370 (2.649 sec/batch), lr: 0.125000
2019-03-16 20:54:04,562 2019-03-16 20:54:04: step 724/50000, loss = 0.236126 (3.019 sec/batch), lr: 0.125000
2019-03-16 20:54:07,525 2019-03-16 20:54:07: step 725/50000, loss = 0.220137 (2.946 sec/batch), lr: 0.125000
2019-03-16 20:54:10,920 2019-03-16 20:54:10: step 726/50000, loss = 0.230869 (3.377 sec/batch), lr: 0.125000
2019-03-16 20:54:14,420 2019-03-16 20:54:14: step 727/50000, loss = 0.213782 (3.482 sec/batch), lr: 0.125000
2019-03-16 20:54:18,132 2019-03-16 20:54:18: step 728/50000, loss = 0.234283 (3.693 sec/batch), lr: 0.125000
2019-03-16 20:54:22,107 2019-03-16 20:54:22: step 729/50000, loss = 0.235110 (3.954 sec/batch), lr: 0.125000
2019-03-16 20:54:26,198 2019-03-16 20:54:26: step 730/50000, loss = 0.243796 (4.070 sec/batch), lr: 0.125000
2019-03-16 20:54:30,439 2019-03-16 20:54:30: step 731/50000, loss = 0.235173 (4.218 sec/batch), lr: 0.125000
2019-03-16 20:54:35,025 2019-03-16 20:54:35: step 732/50000, loss = 0.245143 (4.561 sec/batch), lr: 0.125000
2019-03-16 20:54:39,997 2019-03-16 20:54:39: step 733/50000, loss = 0.234471 (4.963 sec/batch), lr: 0.125000
2019-03-16 20:54:45,166 2019-03-16 20:54:45: step 734/50000, loss = 0.231941 (5.141 sec/batch), lr: 0.125000
2019-03-16 20:54:50,734 2019-03-16 20:54:50: step 735/50000, loss = 0.227153 (5.536 sec/batch), lr: 0.125000
2019-03-16 20:54:56,402 2019-03-16 20:54:56: step 736/50000, loss = 0.252507 (5.658 sec/batch), lr: 0.125000
2019-03-16 20:55:02,385 2019-03-16 20:55:02: step 737/50000, loss = 0.226691 (5.975 sec/batch), lr: 0.125000
2019-03-16 20:55:09,133 2019-03-16 20:55:09: step 738/50000, loss = 0.252091 (6.711 sec/batch), lr: 0.125000
2019-03-16 20:55:16,306 2019-03-16 20:55:16: step 739/50000, loss = 0.228293 (7.134 sec/batch), lr: 0.125000
2019-03-16 20:55:24,047 2019-03-16 20:55:24: step 740/50000, loss = 0.259126 (7.731 sec/batch), lr: 0.125000
2019-03-16 20:55:32,266 2019-03-16 20:55:32: step 741/50000, loss = 0.235771 (8.172 sec/batch), lr: 0.125000
2019-03-16 20:55:41,425 2019-03-16 20:55:41: step 742/50000, loss = 0.259939 (9.105 sec/batch), lr: 0.125000
2019-03-16 20:55:51,601 2019-03-16 20:55:51: step 743/50000, loss = 0.236245 (10.116 sec/batch), lr: 0.125000
2019-03-16 20:56:02,631 2019-03-16 20:56:02: step 744/50000, loss = 0.257703 (10.969 sec/batch), lr: 0.125000
2019-03-16 20:56:14,636 2019-03-16 20:56:14: step 745/50000, loss = 0.233453 (11.941 sec/batch), lr: 0.125000
2019-03-16 20:56:28,677 2019-03-16 20:56:28: step 746/50000, loss = 0.280990 (13.962 sec/batch), lr: 0.125000
2019-03-16 20:56:45,688 2019-03-16 20:56:45: step 747/50000, loss = 0.243769 (16.907 sec/batch), lr: 0.125000
2019-03-16 20:57:05,683 2019-03-16 20:57:05: step 748/50000, loss = 0.275136 (19.874 sec/batch), lr: 0.125000
2019-03-16 20:57:33,540 2019-03-16 20:57:33: step 749/50000, loss = 0.238235 (27.701 sec/batch), lr: 0.125000
2019-03-16 20:58:07,393 2019-03-16 20:58:07: step 750/50000, loss = 0.220624 (33.674 sec/batch), lr: 0.125000
2019-03-16 20:58:07,544 2019-03-16 20:58:07: step 751/50000, loss = 0.907656 (0.146 sec/batch), lr: 0.125000
2019-03-16 20:58:07,766 2019-03-16 20:58:07: step 752/50000, loss = 0.166195 (0.219 sec/batch), lr: 0.125000
2019-03-16 20:58:08,062 2019-03-16 20:58:08: step 753/50000, loss = 0.620310 (0.293 sec/batch), lr: 0.125000
2019-03-16 20:58:08,492 2019-03-16 20:58:08: step 754/50000, loss = 0.189577 (0.425 sec/batch), lr: 0.125000
2019-03-16 20:58:09,017 2019-03-16 20:58:09: step 755/50000, loss = 0.320356 (0.520 sec/batch), lr: 0.125000
2019-03-16 20:58:09,646 2019-03-16 20:58:09: step 756/50000, loss = 0.418471 (0.624 sec/batch), lr: 0.125000
2019-03-16 20:58:10,425 2019-03-16 20:58:10: step 757/50000, loss = 0.198081 (0.775 sec/batch), lr: 0.125000
2019-03-16 20:58:11,233 2019-03-16 20:58:11: step 758/50000, loss = 0.246690 (0.802 sec/batch), lr: 0.125000
2019-03-16 20:58:12,144 2019-03-16 20:58:12: step 759/50000, loss = 0.224745 (0.903 sec/batch), lr: 0.125000
2019-03-16 20:58:13,057 2019-03-16 20:58:13: step 760/50000, loss = 0.209475 (0.909 sec/batch), lr: 0.125000
2019-03-16 20:58:14,074 2019-03-16 20:58:14: step 761/50000, loss = 0.198422 (1.011 sec/batch), lr: 0.125000
2019-03-16 20:58:15,239 2019-03-16 20:58:15: step 762/50000, loss = 0.203658 (1.156 sec/batch), lr: 0.125000
2019-03-16 20:58:16,575 2019-03-16 20:58:16: step 763/50000, loss = 0.194358 (1.328 sec/batch), lr: 0.125000
2019-03-16 20:58:18,175 2019-03-16 20:58:18: step 764/50000, loss = 0.187250 (1.590 sec/batch), lr: 0.125000
2019-03-16 20:58:19,851 2019-03-16 20:58:19: step 765/50000, loss = 0.193661 (1.666 sec/batch), lr: 0.125000
2019-03-16 20:58:21,557 2019-03-16 20:58:21: step 766/50000, loss = 0.211959 (1.702 sec/batch), lr: 0.125000
2019-03-16 20:58:23,415 2019-03-16 20:58:23: step 767/50000, loss = 0.191830 (1.848 sec/batch), lr: 0.125000
2019-03-16 20:58:25,490 2019-03-16 20:58:25: step 768/50000, loss = 0.213182 (2.064 sec/batch), lr: 0.125000
2019-03-16 20:58:27,612 2019-03-16 20:58:27: step 769/50000, loss = 0.193048 (2.114 sec/batch), lr: 0.125000
2019-03-16 20:58:29,815 2019-03-16 20:58:29: step 770/50000, loss = 0.210800 (2.194 sec/batch), lr: 0.125000
2019-03-16 20:58:32,192 2019-03-16 20:58:32: step 771/50000, loss = 0.204686 (2.365 sec/batch), lr: 0.125000
2019-03-16 20:58:34,952 2019-03-16 20:58:34: step 772/50000, loss = 0.202532 (2.746 sec/batch), lr: 0.125000
2019-03-16 20:58:37,766 2019-03-16 20:58:37: step 773/50000, loss = 0.205639 (2.799 sec/batch), lr: 0.125000
2019-03-16 20:58:40,859 2019-03-16 20:58:40: step 774/50000, loss = 0.213410 (3.077 sec/batch), lr: 0.125000
2019-03-16 20:58:43,846 2019-03-16 20:58:43: step 775/50000, loss = 0.204200 (2.972 sec/batch), lr: 0.125000
2019-03-16 21:00:58,300 2019-03-16 21:00:58: step 1/50000, loss = 0.344588 (49.153 sec/batch), lr: 1.000000
2019-03-16 21:01:21,443 2019-03-16 21:01:21: step 2/50000, loss = 0.452280 (23.130 sec/batch), lr: 1.000000
2019-03-16 21:01:39,266 2019-03-16 21:01:39: step 3/50000, loss = 0.468313 (17.811 sec/batch), lr: 1.000000
2019-03-16 21:01:54,729 2019-03-16 21:01:54: step 4/50000, loss = 0.470339 (15.374 sec/batch), lr: 1.000000
2019-03-16 21:02:07,256 2019-03-16 21:02:07: step 5/50000, loss = 0.477272 (12.455 sec/batch), lr: 1.000000
2019-03-16 21:02:18,577 2019-03-16 21:02:18: step 6/50000, loss = 0.471270 (11.258 sec/batch), lr: 1.000000
2019-03-16 21:02:29,139 2019-03-16 21:02:29: step 7/50000, loss = 0.475387 (10.538 sec/batch), lr: 1.000000
2019-03-16 21:02:38,725 2019-03-16 21:02:38: step 8/50000, loss = 0.475531 (9.530 sec/batch), lr: 1.000000
2019-03-16 21:02:47,595 2019-03-16 21:02:47: step 9/50000, loss = 0.460888 (8.819 sec/batch), lr: 1.000000
2019-03-16 21:02:55,852 2019-03-16 21:02:55: step 10/50000, loss = 0.467227 (8.216 sec/batch), lr: 1.000000
2019-03-16 21:03:02,948 2019-03-16 21:03:02: step 11/50000, loss = 0.468147 (7.056 sec/batch), lr: 1.000000
2019-03-16 21:03:09,805 2019-03-16 21:03:09: step 12/50000, loss = 0.460318 (6.820 sec/batch), lr: 1.000000
2019-03-16 21:03:16,169 2019-03-16 21:03:16: step 13/50000, loss = 0.449785 (6.332 sec/batch), lr: 1.000000
2019-03-16 21:03:22,027 2019-03-16 21:03:22: step 14/50000, loss = 0.420556 (5.828 sec/batch), lr: 1.000000
2019-03-16 21:03:27,678 2019-03-16 21:03:27: step 15/50000, loss = 0.209454 (5.619 sec/batch), lr: 1.000000
2019-03-16 21:03:32,956 2019-03-16 21:03:32: step 16/50000, loss = 0.408472 (5.269 sec/batch), lr: 1.000000
2019-03-16 21:03:37,896 2019-03-16 21:03:37: step 17/50000, loss = 0.251090 (4.930 sec/batch), lr: 1.000000
2019-03-16 21:03:42,776 2019-03-16 21:03:42: step 18/50000, loss = 0.418405 (4.854 sec/batch), lr: 1.000000
2019-03-16 21:03:47,339 2019-03-16 21:03:47: step 19/50000, loss = 0.225388 (4.538 sec/batch), lr: 1.000000
2019-03-16 21:03:51,630 2019-03-16 21:03:51: step 20/50000, loss = 0.376027 (4.269 sec/batch), lr: 1.000000
2019-03-16 21:03:55,744 2019-03-16 21:03:55: step 21/50000, loss = 0.209697 (4.092 sec/batch), lr: 1.000000
2019-03-16 21:03:59,624 2019-03-16 21:03:59: step 22/50000, loss = 0.383500 (3.859 sec/batch), lr: 1.000000
2019-03-16 21:04:03,269 2019-03-16 21:04:03: step 23/50000, loss = 0.201209 (3.624 sec/batch), lr: 1.000000
2019-03-16 21:04:06,659 2019-03-16 21:04:06: step 24/50000, loss = 0.317051 (3.371 sec/batch), lr: 1.000000
2019-03-16 21:04:09,908 2019-03-16 21:04:09: step 25/50000, loss = 0.195797 (3.231 sec/batch), lr: 1.000000
2019-03-16 21:04:12,833 2019-03-16 21:04:12: step 26/50000, loss = 0.363682 (2.910 sec/batch), lr: 1.000000
2019-03-16 21:04:15,803 2019-03-16 21:04:15: step 27/50000, loss = 0.198261 (2.955 sec/batch), lr: 1.000000
2019-03-16 21:04:18,642 2019-03-16 21:04:18: step 28/50000, loss = 0.426730 (2.823 sec/batch), lr: 1.000000
2019-03-16 21:04:21,232 2019-03-16 21:04:21: step 29/50000, loss = 0.387278 (2.576 sec/batch), lr: 1.000000
2019-03-16 21:04:23,742 2019-03-16 21:04:23: step 30/50000, loss = 0.340344 (2.497 sec/batch), lr: 1.000000
2019-03-16 21:04:25,975 2019-03-16 21:04:25: step 31/50000, loss = 0.261006 (2.226 sec/batch), lr: 1.000000
2019-03-16 21:04:28,015 2019-03-16 21:04:28: step 32/50000, loss = 0.295406 (2.029 sec/batch), lr: 1.000000
2019-03-16 21:04:30,077 2019-03-16 21:04:30: step 33/50000, loss = 0.377895 (2.050 sec/batch), lr: 1.000000
2019-03-16 21:04:31,970 2019-03-16 21:04:31: step 34/50000, loss = 0.280365 (1.881 sec/batch), lr: 1.000000
2019-03-16 21:04:33,734 2019-03-16 21:04:33: step 35/50000, loss = 0.360417 (1.751 sec/batch), lr: 1.000000
2019-03-16 21:04:35,367 2019-03-16 21:04:35: step 36/50000, loss = 0.259809 (1.623 sec/batch), lr: 1.000000
2019-03-16 21:04:36,811 2019-03-16 21:04:36: step 37/50000, loss = 0.360806 (1.435 sec/batch), lr: 1.000000
2019-03-16 21:04:38,198 2019-03-16 21:04:38: step 38/50000, loss = 0.235809 (1.381 sec/batch), lr: 1.000000
2019-03-16 21:04:39,436 2019-03-16 21:04:39: step 39/50000, loss = 0.326833 (1.229 sec/batch), lr: 1.000000
2019-03-16 21:04:40,537 2019-03-16 21:04:40: step 40/50000, loss = 0.237919 (1.093 sec/batch), lr: 1.000000
2019-03-16 21:04:41,503 2019-03-16 21:04:41: step 41/50000, loss = 0.345234 (0.959 sec/batch), lr: 1.000000
2019-03-16 21:04:42,441 2019-03-16 21:04:42: step 42/50000, loss = 0.240500 (0.931 sec/batch), lr: 1.000000
2019-03-16 21:04:43,256 2019-03-16 21:04:43: step 43/50000, loss = 0.328986 (0.807 sec/batch), lr: 1.000000
2019-03-16 21:04:43,923 2019-03-16 21:04:43: step 44/50000, loss = 0.257743 (0.660 sec/batch), lr: 1.000000
2019-03-16 21:04:44,469 2019-03-16 21:04:44: step 45/50000, loss = 0.321794 (0.540 sec/batch), lr: 1.000000
2019-03-16 21:04:44,976 2019-03-16 21:04:44: step 46/50000, loss = 0.258289 (0.502 sec/batch), lr: 1.000000
2019-03-16 21:04:45,384 2019-03-16 21:04:45: step 47/50000, loss = 0.282544 (0.402 sec/batch), lr: 1.000000
2019-03-16 21:04:45,708 2019-03-16 21:04:45: step 48/50000, loss = 0.278708 (0.320 sec/batch), lr: 1.000000
2019-03-16 21:04:45,904 2019-03-16 21:04:45: step 49/50000, loss = 0.351066 (0.191 sec/batch), lr: 1.000000
2019-03-16 21:04:46,030 2019-03-16 21:04:46: step 50/50000, loss = 0.530983 (0.124 sec/batch), lr: 1.000000
2019-03-16 21:04:46,214 2019-03-16 21:04:46: step 51/50000, loss = 0.789055 (0.177 sec/batch), lr: 1.000000
2019-03-16 21:04:46,467 2019-03-16 21:04:46: step 52/50000, loss = 0.546026 (0.249 sec/batch), lr: 1.000000
2019-03-16 21:04:46,806 2019-03-16 21:04:46: step 53/50000, loss = 0.514020 (0.333 sec/batch), lr: 1.000000
2019-03-16 21:04:47,228 2019-03-16 21:04:47: step 54/50000, loss = 0.488586 (0.417 sec/batch), lr: 1.000000
2019-03-16 21:04:47,749 2019-03-16 21:04:47: step 55/50000, loss = 0.486197 (0.514 sec/batch), lr: 1.000000
2019-03-16 21:04:48,378 2019-03-16 21:04:48: step 56/50000, loss = 0.469379 (0.623 sec/batch), lr: 1.000000
2019-03-16 21:04:49,162 2019-03-16 21:04:49: step 57/50000, loss = 0.480068 (0.776 sec/batch), lr: 1.000000
2019-03-16 21:04:49,973 2019-03-16 21:04:49: step 58/50000, loss = 0.510063 (0.803 sec/batch), lr: 1.000000
2019-03-16 21:04:50,923 2019-03-16 21:04:50: step 59/50000, loss = 0.505295 (0.942 sec/batch), lr: 1.000000
2019-03-16 21:04:51,906 2019-03-16 21:04:51: step 60/50000, loss = 0.465305 (0.978 sec/batch), lr: 1.000000
2019-03-16 21:04:52,877 2019-03-16 21:04:52: step 61/50000, loss = 0.505705 (0.965 sec/batch), lr: 1.000000
2019-03-16 21:04:54,018 2019-03-16 21:04:54: step 62/50000, loss = 0.492161 (1.137 sec/batch), lr: 1.000000
2019-03-16 21:04:55,451 2019-03-16 21:04:55: step 63/50000, loss = 0.484772 (1.423 sec/batch), lr: 1.000000
2019-03-16 21:04:57,032 2019-03-16 21:04:57: step 64/50000, loss = 0.471212 (1.572 sec/batch), lr: 1.000000
2019-03-16 21:04:58,711 2019-03-16 21:04:58: step 65/50000, loss = 0.503000 (1.665 sec/batch), lr: 1.000000
2019-03-16 21:05:00,507 2019-03-16 21:05:00: step 66/50000, loss = 0.502460 (1.785 sec/batch), lr: 1.000000
2019-03-16 21:05:02,503 2019-03-16 21:05:02: step 67/50000, loss = 0.472296 (1.983 sec/batch), lr: 1.000000
2019-03-16 21:05:04,596 2019-03-16 21:05:04: step 68/50000, loss = 0.501744 (2.080 sec/batch), lr: 1.000000
2019-03-16 21:05:06,879 2019-03-16 21:05:06: step 69/50000, loss = 0.476337 (2.269 sec/batch), lr: 1.000000
2019-03-16 21:05:09,600 2019-03-16 21:05:09: step 70/50000, loss = 0.501134 (2.707 sec/batch), lr: 1.000000
2019-03-16 21:05:12,706 2019-03-16 21:05:12: step 71/50000, loss = 0.495295 (3.083 sec/batch), lr: 1.000000
2019-03-16 21:05:15,927 2019-03-16 21:05:15: step 72/50000, loss = 0.482156 (3.200 sec/batch), lr: 1.000000
2019-03-16 21:05:18,837 2019-03-16 21:05:18: step 73/50000, loss = 0.500341 (2.894 sec/batch), lr: 1.000000
2019-03-16 21:05:22,005 2019-03-16 21:05:22: step 74/50000, loss = 0.496387 (3.151 sec/batch), lr: 1.000000
2019-03-16 21:05:25,127 2019-03-16 21:05:25: step 75/50000, loss = 0.499924 (3.105 sec/batch), lr: 1.000000
2019-03-16 21:05:28,582 2019-03-16 21:05:28: step 76/50000, loss = 0.497341 (3.436 sec/batch), lr: 1.000000
2019-03-16 21:05:32,231 2019-03-16 21:05:32: step 77/50000, loss = 0.484758 (3.629 sec/batch), lr: 1.000000
2019-03-16 21:05:35,983 2019-03-16 21:05:35: step 78/50000, loss = 0.499325 (3.731 sec/batch), lr: 1.000000
2019-03-16 21:05:40,043 2019-03-16 21:05:40: step 79/50000, loss = 0.499180 (4.037 sec/batch), lr: 1.000000
2019-03-16 21:05:44,281 2019-03-16 21:05:44: step 80/50000, loss = 0.489625 (4.215 sec/batch), lr: 1.000000
2019-03-16 21:05:48,671 2019-03-16 21:05:48: step 81/50000, loss = 0.498865 (4.366 sec/batch), lr: 1.000000
2019-03-16 21:05:53,423 2019-03-16 21:05:53: step 82/50000, loss = 0.497696 (4.725 sec/batch), lr: 1.000000
2019-03-16 21:05:58,402 2019-03-16 21:05:58: step 83/50000, loss = 0.493757 (4.952 sec/batch), lr: 1.000000
2019-03-16 21:06:03,701 2019-03-16 21:06:03: step 84/50000, loss = 0.485513 (5.271 sec/batch), lr: 1.000000
2019-03-16 21:06:09,347 2019-03-16 21:06:09: step 85/50000, loss = 0.482285 (5.615 sec/batch), lr: 1.000000
2019-03-16 21:06:15,103 2019-03-16 21:06:15: step 86/50000, loss = 0.498158 (5.723 sec/batch), lr: 1.000000
2019-03-16 21:06:21,162 2019-03-16 21:06:21: step 87/50000, loss = 0.494561 (6.025 sec/batch), lr: 1.000000
2019-03-16 21:06:28,028 2019-03-16 21:06:28: step 88/50000, loss = 0.481813 (6.828 sec/batch), lr: 1.000000
2019-03-16 21:06:35,282 2019-03-16 21:06:35: step 89/50000, loss = 0.484554 (7.213 sec/batch), lr: 1.000000
2019-03-16 21:06:43,111 2019-03-16 21:06:43: step 90/50000, loss = 0.489366 (7.787 sec/batch), lr: 1.000000
2019-03-16 21:06:51,411 2019-03-16 21:06:51: step 91/50000, loss = 0.493929 (8.252 sec/batch), lr: 1.000000
2019-03-16 21:07:00,731 2019-03-16 21:07:00: step 92/50000, loss = 0.490567 (9.266 sec/batch), lr: 1.000000
2019-03-16 21:07:10,899 2019-03-16 21:07:10: step 93/50000, loss = 0.487585 (10.110 sec/batch), lr: 1.000000
2019-03-16 21:07:22,040 2019-03-16 21:07:22: step 94/50000, loss = 0.484278 (11.079 sec/batch), lr: 1.000000
2019-03-16 21:07:34,281 2019-03-16 21:07:34: step 95/50000, loss = 0.483586 (12.168 sec/batch), lr: 1.000000
2019-03-16 21:07:48,639 2019-03-16 21:07:48: step 96/50000, loss = 0.471766 (14.344 sec/batch), lr: 1.000000
2019-03-16 21:08:05,685 2019-03-16 21:08:05: step 97/50000, loss = 0.477312 (16.950 sec/batch), lr: 1.000000
2019-03-16 21:08:26,235 2019-03-16 21:08:26: step 98/50000, loss = 0.465934 (20.430 sec/batch), lr: 1.000000
2019-03-16 21:08:54,561 2019-03-16 21:08:54: step 99/50000, loss = 0.447538 (28.155 sec/batch), lr: 1.000000
2019-03-16 21:09:28,784 2019-03-16 21:09:28: step 100/50000, loss = 0.377893 (34.041 sec/batch), lr: 1.000000
2019-03-16 21:09:56,827 step 100: Full loss = 0.266068, Edge acc. = 0.3370
2019-03-16 21:09:56,888 step 100: Dev acc. = 0.332879
2019-03-16 21:10:46,889 2019-03-16 21:10:46: step 101/50000, loss = 0.353820 (49.760 sec/batch), lr: 1.000000
2019-03-16 21:11:10,487 2019-03-16 21:11:10: step 102/50000, loss = 0.457840 (23.458 sec/batch), lr: 1.000000
2019-03-16 21:11:28,725 2019-03-16 21:11:28: step 103/50000, loss = 0.474910 (18.223 sec/batch), lr: 1.000000
2019-03-16 21:11:44,586 2019-03-16 21:11:44: step 104/50000, loss = 0.477514 (15.765 sec/batch), lr: 1.000000
2019-03-16 21:11:57,461 2019-03-16 21:11:57: step 105/50000, loss = 0.485794 (12.797 sec/batch), lr: 1.000000
2019-03-16 21:12:09,104 2019-03-16 21:12:09: step 106/50000, loss = 0.480659 (11.572 sec/batch), lr: 1.000000
2019-03-16 21:12:19,604 2019-03-16 21:12:19: step 107/50000, loss = 0.485442 (10.486 sec/batch), lr: 1.000000
2019-03-16 21:12:29,125 2019-03-16 21:12:29: step 108/50000, loss = 0.487602 (9.465 sec/batch), lr: 1.000000
2019-03-16 21:12:37,969 2019-03-16 21:12:37: step 109/50000, loss = 0.474544 (8.832 sec/batch), lr: 1.000000
2019-03-16 21:12:46,170 2019-03-16 21:12:46: step 110/50000, loss = 0.483053 (8.156 sec/batch), lr: 1.000000
2019-03-16 21:12:53,626 2019-03-16 21:12:53: step 111/50000, loss = 0.487764 (7.413 sec/batch), lr: 1.000000
2019-03-16 21:13:00,510 2019-03-16 21:13:00: step 112/50000, loss = 0.485106 (6.874 sec/batch), lr: 1.000000
2019-03-16 21:13:06,954 2019-03-16 21:13:06: step 113/50000, loss = 0.482444 (6.409 sec/batch), lr: 1.000000
2019-03-16 21:13:12,913 2019-03-16 21:13:12: step 114/50000, loss = 0.478519 (5.950 sec/batch), lr: 1.000000
2019-03-16 21:13:18,646 2019-03-16 21:13:18: step 115/50000, loss = 0.482266 (5.700 sec/batch), lr: 1.000000
2019-03-16 21:13:24,006 2019-03-16 21:13:24: step 116/50000, loss = 0.484059 (5.332 sec/batch), lr: 1.000000
2019-03-16 21:13:29,038 2019-03-16 21:13:29: step 117/50000, loss = 0.484944 (5.024 sec/batch), lr: 1.000000
2019-03-16 21:13:33,852 2019-03-16 21:13:33: step 118/50000, loss = 0.469713 (4.787 sec/batch), lr: 1.000000
2019-03-16 21:13:38,464 2019-03-16 21:13:38: step 119/50000, loss = 0.468576 (4.604 sec/batch), lr: 1.000000
2019-03-16 21:13:42,792 2019-03-16 21:13:42: step 120/50000, loss = 0.474597 (4.304 sec/batch), lr: 1.000000
2019-03-16 21:13:47,063 2019-03-16 21:13:47: step 121/50000, loss = 0.448939 (4.248 sec/batch), lr: 1.000000
2019-03-16 21:13:51,005 2019-03-16 21:13:51: step 122/50000, loss = 0.442807 (3.933 sec/batch), lr: 1.000000
2019-03-16 21:13:54,602 2019-03-16 21:13:54: step 123/50000, loss = 0.409709 (3.576 sec/batch), lr: 1.000000
2019-03-16 21:13:57,919 2019-03-16 21:13:57: step 124/50000, loss = 0.275776 (3.299 sec/batch), lr: 1.000000
2019-03-16 21:14:01,535 2019-03-16 21:14:01: step 125/50000, loss = 0.398420 (3.598 sec/batch), lr: 1.000000
2019-03-16 21:14:04,673 2019-03-16 21:14:04: step 126/50000, loss = 0.411034 (3.121 sec/batch), lr: 1.000000
2019-03-16 21:14:07,787 2019-03-16 21:14:07: step 127/50000, loss = 0.197582 (3.097 sec/batch), lr: 1.000000
2019-03-16 21:14:10,634 2019-03-16 21:14:10: step 128/50000, loss = 0.315871 (2.838 sec/batch), lr: 1.000000
2019-03-16 21:14:13,288 2019-03-16 21:14:13: step 129/50000, loss = 0.558333 (2.646 sec/batch), lr: 1.000000
2019-03-16 21:14:15,834 2019-03-16 21:14:15: step 130/50000, loss = 0.457237 (2.532 sec/batch), lr: 1.000000
2019-03-16 21:14:18,198 2019-03-16 21:14:18: step 131/50000, loss = 0.299309 (2.351 sec/batch), lr: 1.000000
2019-03-16 21:14:20,330 2019-03-16 21:14:20: step 132/50000, loss = 0.200045 (2.119 sec/batch), lr: 1.000000
2019-03-16 21:14:22,443 2019-03-16 21:14:22: step 133/50000, loss = 0.251699 (2.099 sec/batch), lr: 1.000000
2019-03-16 21:14:24,354 2019-03-16 21:14:24: step 134/50000, loss = 0.360282 (1.903 sec/batch), lr: 1.000000
2019-03-16 21:14:26,186 2019-03-16 21:14:26: step 135/50000, loss = 0.233330 (1.822 sec/batch), lr: 1.000000
2019-03-16 21:14:27,831 2019-03-16 21:14:27: step 136/50000, loss = 0.349454 (1.638 sec/batch), lr: 1.000000
2019-03-16 21:14:29,291 2019-03-16 21:14:29: step 137/50000, loss = 0.247129 (1.454 sec/batch), lr: 1.000000
2019-03-16 21:14:30,687 2019-03-16 21:14:30: step 138/50000, loss = 0.348771 (1.389 sec/batch), lr: 1.000000
2019-03-16 21:14:31,922 2019-03-16 21:14:31: step 139/50000, loss = 0.202544 (1.226 sec/batch), lr: 1.000000
2019-03-16 21:14:33,066 2019-03-16 21:14:33: step 140/50000, loss = 0.353716 (1.134 sec/batch), lr: 1.000000
2019-03-16 21:14:34,047 2019-03-16 21:14:34: step 141/50000, loss = 0.242617 (0.973 sec/batch), lr: 1.000000
2019-03-16 21:14:34,987 2019-03-16 21:14:34: step 142/50000, loss = 0.367893 (0.932 sec/batch), lr: 1.000000
2019-03-16 21:14:35,810 2019-03-16 21:14:35: step 143/50000, loss = 0.236213 (0.815 sec/batch), lr: 1.000000
2019-03-16 21:14:36,488 2019-03-16 21:14:36: step 144/50000, loss = 0.408055 (0.670 sec/batch), lr: 1.000000
2019-03-16 21:14:37,042 2019-03-16 21:14:37: step 145/50000, loss = 0.224360 (0.548 sec/batch), lr: 1.000000
2019-03-16 21:14:37,556 2019-03-16 21:14:37: step 146/50000, loss = 0.389246 (0.508 sec/batch), lr: 1.000000
2019-03-16 21:14:37,948 2019-03-16 21:14:37: step 147/50000, loss = 0.181204 (0.386 sec/batch), lr: 1.000000
2019-03-16 21:14:38,252 2019-03-16 21:14:38: step 148/50000, loss = 0.391002 (0.299 sec/batch), lr: 1.000000
2019-03-16 21:14:38,454 2019-03-16 21:14:38: step 149/50000, loss = 0.087554 (0.198 sec/batch), lr: 1.000000
2019-03-16 21:14:38,583 2019-03-16 21:14:38: step 150/50000, loss = 0.035090 (0.127 sec/batch), lr: 1.000000
2019-03-16 21:15:28,399 2019-03-16 21:15:28: step 151/50000, loss = 0.196081 (49.566 sec/batch), lr: 1.000000
2019-03-16 21:15:52,048 2019-03-16 21:15:52: step 152/50000, loss = 0.253897 (23.632 sec/batch), lr: 1.000000
2019-03-16 21:16:10,432 2019-03-16 21:16:10: step 153/50000, loss = 0.244283 (18.278 sec/batch), lr: 1.000000
2019-03-16 21:16:26,132 2019-03-16 21:16:26: step 154/50000, loss = 0.343448 (15.686 sec/batch), lr: 1.000000
2019-03-16 21:16:39,083 2019-03-16 21:16:39: step 155/50000, loss = 0.264754 (12.939 sec/batch), lr: 1.000000
2019-03-16 21:16:50,783 2019-03-16 21:16:50: step 156/50000, loss = 0.336099 (11.687 sec/batch), lr: 1.000000
2019-03-16 21:17:01,452 2019-03-16 21:17:01: step 157/50000, loss = 0.249941 (10.606 sec/batch), lr: 1.000000
2019-03-16 21:17:11,136 2019-03-16 21:17:11: step 158/50000, loss = 0.338899 (9.631 sec/batch), lr: 1.000000
2019-03-16 21:17:20,158 2019-03-16 21:17:20: step 159/50000, loss = 0.240491 (8.971 sec/batch), lr: 1.000000
2019-03-16 21:17:28,362 2019-03-16 21:17:28: step 160/50000, loss = 0.338135 (8.158 sec/batch), lr: 1.000000
2019-03-16 21:17:35,773 2019-03-16 21:17:35: step 161/50000, loss = 0.241904 (7.370 sec/batch), lr: 1.000000
2019-03-16 21:17:42,658 2019-03-16 21:17:42: step 162/50000, loss = 0.335468 (6.839 sec/batch), lr: 1.000000
2019-03-16 21:17:49,094 2019-03-16 21:17:49: step 163/50000, loss = 0.232467 (6.427 sec/batch), lr: 1.000000
2019-03-16 21:17:55,146 2019-03-16 21:17:55: step 164/50000, loss = 0.334554 (6.022 sec/batch), lr: 1.000000
2019-03-16 21:18:00,749 2019-03-16 21:18:00: step 165/50000, loss = 0.231648 (5.572 sec/batch), lr: 1.000000
2019-03-16 21:18:06,118 2019-03-16 21:18:06: step 166/50000, loss = 0.335792 (5.339 sec/batch), lr: 1.000000
2019-03-16 21:18:11,260 2019-03-16 21:18:11: step 167/50000, loss = 0.228148 (5.133 sec/batch), lr: 1.000000
2019-03-16 21:18:16,338 2019-03-16 21:18:16: step 168/50000, loss = 0.328660 (5.051 sec/batch), lr: 1.000000
2019-03-16 21:18:20,845 2019-03-16 21:18:20: step 169/50000, loss = 0.230238 (4.483 sec/batch), lr: 1.000000
2019-03-16 21:18:25,125 2019-03-16 21:18:25: step 170/50000, loss = 0.339888 (4.256 sec/batch), lr: 1.000000
2019-03-16 21:18:29,249 2019-03-16 21:18:29: step 171/50000, loss = 0.226910 (4.100 sec/batch), lr: 1.000000
2019-03-16 21:18:33,259 2019-03-16 21:18:33: step 172/50000, loss = 0.319958 (3.980 sec/batch), lr: 1.000000
2019-03-16 21:18:36,974 2019-03-16 21:18:36: step 173/50000, loss = 0.236919 (3.696 sec/batch), lr: 1.000000
2019-03-16 21:18:40,400 2019-03-16 21:18:40: step 174/50000, loss = 0.342846 (3.408 sec/batch), lr: 1.000000
2019-03-16 21:18:43,796 2019-03-16 21:18:43: step 175/50000, loss = 0.216808 (3.378 sec/batch), lr: 1.000000
2019-03-16 21:18:46,938 2019-03-16 21:18:46: step 176/50000, loss = 0.333003 (3.125 sec/batch), lr: 1.000000
2019-03-16 21:18:49,957 2019-03-16 21:18:49: step 177/50000, loss = 0.215615 (3.003 sec/batch), lr: 1.000000
2019-03-16 21:18:52,781 2019-03-16 21:18:52: step 178/50000, loss = 0.311178 (2.810 sec/batch), lr: 1.000000
2019-03-16 21:18:55,396 2019-03-16 21:18:55: step 179/50000, loss = 0.245706 (2.606 sec/batch), lr: 1.000000
2019-03-16 21:18:57,889 2019-03-16 21:18:57: step 180/50000, loss = 0.325515 (2.480 sec/batch), lr: 1.000000
2019-03-16 21:19:00,227 2019-03-16 21:19:00: step 181/50000, loss = 0.212495 (2.326 sec/batch), lr: 1.000000
2019-03-16 21:19:02,294 2019-03-16 21:19:02: step 182/50000, loss = 0.316791 (2.060 sec/batch), lr: 1.000000
2019-03-16 21:19:04,250 2019-03-16 21:19:04: step 183/50000, loss = 0.243421 (1.944 sec/batch), lr: 1.000000
2019-03-16 21:19:06,024 2019-03-16 21:19:06: step 184/50000, loss = 0.337642 (1.765 sec/batch), lr: 1.000000
2019-03-16 21:19:07,853 2019-03-16 21:19:07: step 185/50000, loss = 0.232107 (1.818 sec/batch), lr: 1.000000
2019-03-16 21:19:09,483 2019-03-16 21:19:09: step 186/50000, loss = 0.341491 (1.624 sec/batch), lr: 1.000000
2019-03-16 21:19:10,861 2019-03-16 21:19:10: step 187/50000, loss = 0.256656 (1.373 sec/batch), lr: 1.000000
2019-03-16 21:19:12,247 2019-03-16 21:19:12: step 188/50000, loss = 0.372806 (1.378 sec/batch), lr: 1.000000
2019-03-16 21:19:13,342 2019-03-16 21:19:13: step 189/50000, loss = 0.211258 (1.089 sec/batch), lr: 1.000000
2019-03-16 21:19:14,452 2019-03-16 21:19:14: step 190/50000, loss = 0.391506 (1.102 sec/batch), lr: 1.000000
2019-03-16 21:19:15,411 2019-03-16 21:19:15: step 191/50000, loss = 0.274080 (0.952 sec/batch), lr: 1.000000
2019-03-16 21:19:16,257 2019-03-16 21:19:16: step 192/50000, loss = 0.444282 (0.837 sec/batch), lr: 1.000000
2019-03-16 21:19:17,058 2019-03-16 21:19:17: step 193/50000, loss = 0.201688 (0.794 sec/batch), lr: 1.000000
2019-03-16 21:19:17,718 2019-03-16 21:19:17: step 194/50000, loss = 0.287805 (0.653 sec/batch), lr: 1.000000
2019-03-16 21:19:18,273 2019-03-16 21:19:18: step 195/50000, loss = 0.333221 (0.548 sec/batch), lr: 1.000000
2019-03-16 21:19:18,783 2019-03-16 21:19:18: step 196/50000, loss = 0.393580 (0.504 sec/batch), lr: 1.000000
2019-03-16 21:19:19,192 2019-03-16 21:19:19: step 197/50000, loss = 0.182732 (0.404 sec/batch), lr: 1.000000
2019-03-16 21:19:19,483 2019-03-16 21:19:19: step 198/50000, loss = 0.289059 (0.285 sec/batch), lr: 1.000000
2019-03-16 21:19:19,656 2019-03-16 21:19:19: step 199/50000, loss = 0.380952 (0.170 sec/batch), lr: 1.000000
2019-03-16 21:19:19,785 2019-03-16 21:19:19: step 200/50000, loss = 0.762322 (0.127 sec/batch), lr: 1.000000
2019-03-16 21:19:47,789 step 200: Full loss = 0.217422, Edge acc. = 0.2807
2019-03-16 21:19:47,847 step 200: Dev acc. = 0.312708
2019-03-16 21:19:47,990 2019-03-16 21:19:47: step 201/50000, loss = 0.185691 (0.138 sec/batch), lr: 0.500000
2019-03-16 21:19:48,207 2019-03-16 21:19:48: step 202/50000, loss = 0.152824 (0.214 sec/batch), lr: 0.500000
2019-03-16 21:19:48,483 2019-03-16 21:19:48: step 203/50000, loss = 0.183909 (0.272 sec/batch), lr: 0.500000
2019-03-16 21:19:48,900 2019-03-16 21:19:48: step 204/50000, loss = 0.190777 (0.413 sec/batch), lr: 0.500000
2019-03-16 21:19:49,434 2019-03-16 21:19:49: step 205/50000, loss = 0.179963 (0.527 sec/batch), lr: 0.500000
2019-03-16 21:19:50,073 2019-03-16 21:19:50: step 206/50000, loss = 0.179205 (0.632 sec/batch), lr: 0.500000
2019-03-16 21:19:50,864 2019-03-16 21:19:50: step 207/50000, loss = 0.181772 (0.785 sec/batch), lr: 0.500000
2019-03-16 21:19:51,675 2019-03-16 21:19:51: step 208/50000, loss = 0.203371 (0.803 sec/batch), lr: 0.500000
2019-03-16 21:19:52,605 2019-03-16 21:19:52: step 209/50000, loss = 0.213333 (0.922 sec/batch), lr: 0.500000
2019-03-16 21:19:53,693 2019-03-16 21:19:53: step 210/50000, loss = 0.184647 (1.079 sec/batch), lr: 0.500000
2019-03-16 21:19:54,833 2019-03-16 21:19:54: step 211/50000, loss = 0.183433 (1.132 sec/batch), lr: 0.500000
2019-03-16 21:19:56,140 2019-03-16 21:19:56: step 212/50000, loss = 0.197015 (1.297 sec/batch), lr: 0.500000
2019-03-16 21:19:57,560 2019-03-16 21:19:57: step 213/50000, loss = 0.194136 (1.410 sec/batch), lr: 0.500000
2019-03-16 21:19:59,117 2019-03-16 21:19:59: step 214/50000, loss = 0.182635 (1.548 sec/batch), lr: 0.500000
2019-03-16 21:20:00,843 2019-03-16 21:20:00: step 215/50000, loss = 0.209928 (1.715 sec/batch), lr: 0.500000
2019-03-16 21:20:02,619 2019-03-16 21:20:02: step 216/50000, loss = 0.186864 (1.763 sec/batch), lr: 0.500000
2019-03-16 21:20:04,535 2019-03-16 21:20:04: step 217/50000, loss = 0.188765 (1.904 sec/batch), lr: 0.500000
2019-03-16 21:20:06,530 2019-03-16 21:20:06: step 218/50000, loss = 0.198288 (1.988 sec/batch), lr: 0.500000
2019-03-16 21:20:08,823 2019-03-16 21:20:08: step 219/50000, loss = 0.199129 (2.279 sec/batch), lr: 0.500000
2019-03-16 21:20:11,184 2019-03-16 21:20:11: step 220/50000, loss = 0.191453 (2.347 sec/batch), lr: 0.500000
2019-03-16 21:20:13,787 2019-03-16 21:20:13: step 221/50000, loss = 0.209583 (2.589 sec/batch), lr: 0.500000
2019-03-16 21:20:16,543 2019-03-16 21:20:16: step 222/50000, loss = 0.180448 (2.740 sec/batch), lr: 0.500000
2019-03-16 21:20:19,390 2019-03-16 21:20:19: step 223/50000, loss = 0.213502 (2.831 sec/batch), lr: 0.500000
2019-03-16 21:20:22,489 2019-03-16 21:20:22: step 224/50000, loss = 0.188963 (3.083 sec/batch), lr: 0.500000
2019-03-16 21:20:25,433 2019-03-16 21:20:25: step 225/50000, loss = 0.213032 (2.927 sec/batch), lr: 0.500000
2019-03-16 21:20:28,617 2019-03-16 21:20:28: step 226/50000, loss = 0.190053 (3.167 sec/batch), lr: 0.500000
2019-03-16 21:20:32,249 2019-03-16 21:20:32: step 227/50000, loss = 0.208695 (3.611 sec/batch), lr: 0.500000
2019-03-16 21:20:35,941 2019-03-16 21:20:35: step 228/50000, loss = 0.194040 (3.673 sec/batch), lr: 0.500000
2019-03-16 21:20:39,797 2019-03-16 21:20:39: step 229/50000, loss = 0.224523 (3.847 sec/batch), lr: 0.500000
2019-03-16 21:20:44,023 2019-03-16 21:20:44: step 230/50000, loss = 0.195881 (4.217 sec/batch), lr: 0.500000
2019-03-16 21:20:48,235 2019-03-16 21:20:48: step 231/50000, loss = 0.223635 (4.202 sec/batch), lr: 0.500000
2019-03-16 21:20:52,940 2019-03-16 21:20:52: step 232/50000, loss = 0.199714 (4.678 sec/batch), lr: 0.500000
2019-03-16 21:20:57,937 2019-03-16 21:20:57: step 233/50000, loss = 0.220386 (4.987 sec/batch), lr: 0.500000
2019-03-16 21:21:03,019 2019-03-16 21:21:03: step 234/50000, loss = 0.193154 (5.054 sec/batch), lr: 0.500000
2019-03-16 21:21:08,594 2019-03-16 21:21:08: step 235/50000, loss = 0.216161 (5.566 sec/batch), lr: 0.500000
2019-03-16 21:21:14,390 2019-03-16 21:21:14: step 236/50000, loss = 0.204134 (5.787 sec/batch), lr: 0.500000
2019-03-16 21:21:20,525 2019-03-16 21:21:20: step 237/50000, loss = 0.216067 (6.099 sec/batch), lr: 0.500000
2019-03-16 21:21:27,392 2019-03-16 21:21:27: step 238/50000, loss = 0.195892 (6.857 sec/batch), lr: 0.500000
2019-03-16 21:21:34,672 2019-03-16 21:21:34: step 239/50000, loss = 0.222824 (7.241 sec/batch), lr: 0.500000
2019-03-16 21:21:42,470 2019-03-16 21:21:42: step 240/50000, loss = 0.198367 (7.755 sec/batch), lr: 0.500000
2019-03-16 21:21:50,820 2019-03-16 21:21:50: step 241/50000, loss = 0.228257 (8.303 sec/batch), lr: 0.500000
2019-03-16 21:22:00,259 2019-03-16 21:22:00: step 242/50000, loss = 0.201988 (9.385 sec/batch), lr: 0.500000
2019-03-16 21:22:10,369 2019-03-16 21:22:10: step 243/50000, loss = 0.233860 (10.052 sec/batch), lr: 0.500000
2019-03-16 21:22:21,539 2019-03-16 21:22:21: step 244/50000, loss = 0.198100 (11.108 sec/batch), lr: 0.500000
2019-03-16 21:22:33,668 2019-03-16 21:22:33: step 245/50000, loss = 0.219798 (12.060 sec/batch), lr: 0.500000
2019-03-16 21:22:47,950 2019-03-16 21:22:47: step 246/50000, loss = 0.216453 (14.201 sec/batch), lr: 0.500000
2019-03-16 21:23:05,027 2019-03-16 21:23:05: step 247/50000, loss = 0.234654 (16.981 sec/batch), lr: 0.500000
2019-03-16 21:23:24,960 2019-03-16 21:23:24: step 248/50000, loss = 0.206151 (19.822 sec/batch), lr: 0.500000
2019-03-16 21:23:52,842 2019-03-16 21:23:52: step 249/50000, loss = 0.235363 (27.728 sec/batch), lr: 0.500000
2019-03-16 21:24:26,745 2019-03-16 21:24:26: step 250/50000, loss = 0.167638 (33.709 sec/batch), lr: 0.500000
2019-03-16 21:24:26,907 2019-03-16 21:24:26: step 251/50000, loss = 0.700391 (0.157 sec/batch), lr: 0.500000
2019-03-16 21:24:27,164 2019-03-16 21:24:27: step 252/50000, loss = 0.135738 (0.253 sec/batch), lr: 0.500000
2019-03-16 21:24:27,508 2019-03-16 21:24:27: step 253/50000, loss = 0.208392 (0.340 sec/batch), lr: 0.500000
2019-03-16 21:24:27,938 2019-03-16 21:24:27: step 254/50000, loss = 0.180291 (0.425 sec/batch), lr: 0.500000
2019-03-16 21:24:28,476 2019-03-16 21:24:28: step 255/50000, loss = 0.212264 (0.532 sec/batch), lr: 0.500000
2019-03-16 21:24:29,128 2019-03-16 21:24:29: step 256/50000, loss = 0.178701 (0.646 sec/batch), lr: 0.500000
2019-03-16 21:24:29,916 2019-03-16 21:24:29: step 257/50000, loss = 0.213715 (0.779 sec/batch), lr: 0.500000
2019-03-16 21:24:30,742 2019-03-16 21:24:30: step 258/50000, loss = 0.210364 (0.819 sec/batch), lr: 0.500000
2019-03-16 21:24:31,719 2019-03-16 21:24:31: step 259/50000, loss = 0.224935 (0.968 sec/batch), lr: 0.500000
2019-03-16 21:24:32,809 2019-03-16 21:24:32: step 260/50000, loss = 0.182580 (1.081 sec/batch), lr: 0.500000
2019-03-16 21:24:33,961 2019-03-16 21:24:33: step 261/50000, loss = 0.204153 (1.142 sec/batch), lr: 0.500000
2019-03-16 21:24:35,251 2019-03-16 21:24:35: step 262/50000, loss = 0.186202 (1.283 sec/batch), lr: 0.500000
2019-03-16 21:24:36,680 2019-03-16 21:24:36: step 263/50000, loss = 0.203538 (1.422 sec/batch), lr: 0.500000
2019-03-16 21:24:38,316 2019-03-16 21:24:38: step 264/50000, loss = 0.171875 (1.624 sec/batch), lr: 0.500000
2019-03-16 21:24:40,004 2019-03-16 21:24:40: step 265/50000, loss = 0.206486 (1.681 sec/batch), lr: 0.500000
2019-03-16 21:24:41,882 2019-03-16 21:24:41: step 266/50000, loss = 0.180133 (1.871 sec/batch), lr: 0.500000
2019-03-16 21:24:43,938 2019-03-16 21:24:43: step 267/50000, loss = 0.198476 (2.044 sec/batch), lr: 0.500000
2019-03-16 21:24:46,036 2019-03-16 21:24:46: step 268/50000, loss = 0.178096 (2.086 sec/batch), lr: 0.500000
2019-03-16 21:24:48,343 2019-03-16 21:24:48: step 269/50000, loss = 0.200856 (2.293 sec/batch), lr: 0.500000
2019-03-16 21:24:50,662 2019-03-16 21:24:50: step 270/50000, loss = 0.175080 (2.306 sec/batch), lr: 0.500000
2019-03-16 21:24:53,256 2019-03-16 21:24:53: step 271/50000, loss = 0.207142 (2.579 sec/batch), lr: 0.500000
2019-03-16 21:24:55,934 2019-03-16 21:24:55: step 272/50000, loss = 0.167757 (2.662 sec/batch), lr: 0.500000
2019-03-16 21:24:58,721 2019-03-16 21:24:58: step 273/50000, loss = 0.209601 (2.772 sec/batch), lr: 0.500000
2019-03-16 21:25:01,842 2019-03-16 21:25:01: step 274/50000, loss = 0.175736 (3.104 sec/batch), lr: 0.500000
2019-03-16 21:25:04,965 2019-03-16 21:25:04: step 275/50000, loss = 0.207662 (3.106 sec/batch), lr: 0.500000
2019-03-16 21:25:08,345 2019-03-16 21:25:08: step 276/50000, loss = 0.179771 (3.361 sec/batch), lr: 0.500000
2019-03-16 21:25:11,962 2019-03-16 21:25:11: step 277/50000, loss = 0.202767 (3.599 sec/batch), lr: 0.500000
2019-03-16 21:25:15,650 2019-03-16 21:25:15: step 278/50000, loss = 0.182904 (3.668 sec/batch), lr: 0.500000
2019-03-16 21:25:19,674 2019-03-16 21:25:19: step 279/50000, loss = 0.219162 (4.016 sec/batch), lr: 0.500000
2019-03-16 21:25:23,851 2019-03-16 21:25:23: step 280/50000, loss = 0.183218 (4.153 sec/batch), lr: 0.500000
2019-03-16 21:25:28,079 2019-03-16 21:25:28: step 281/50000, loss = 0.215543 (4.204 sec/batch), lr: 0.500000
2019-03-16 21:25:32,545 2019-03-16 21:25:32: step 282/50000, loss = 0.187416 (4.456 sec/batch), lr: 0.500000
2019-03-16 21:25:37,352 2019-03-16 21:25:37: step 283/50000, loss = 0.211240 (4.780 sec/batch), lr: 0.500000
2019-03-16 21:25:42,597 2019-03-16 21:25:42: step 284/50000, loss = 0.179594 (5.214 sec/batch), lr: 0.500000
2019-03-16 21:25:48,150 2019-03-16 21:25:48: step 285/50000, loss = 0.211876 (5.543 sec/batch), lr: 0.500000
2019-03-16 21:25:53,924 2019-03-16 21:25:53: step 286/50000, loss = 0.190466 (5.764 sec/batch), lr: 0.500000
2019-03-16 21:26:00,063 2019-03-16 21:26:00: step 287/50000, loss = 0.210541 (6.116 sec/batch), lr: 0.500000
2019-03-16 21:26:06,713 2019-03-16 21:26:06: step 288/50000, loss = 0.185952 (6.615 sec/batch), lr: 0.500000
2019-03-16 21:26:13,991 2019-03-16 21:26:13: step 289/50000, loss = 0.216883 (7.268 sec/batch), lr: 0.500000
2019-03-16 21:26:21,717 2019-03-16 21:26:21: step 290/50000, loss = 0.186974 (7.715 sec/batch), lr: 0.500000
2019-03-16 21:26:30,028 2019-03-16 21:26:30: step 291/50000, loss = 0.222198 (8.264 sec/batch), lr: 0.500000
2019-03-16 21:26:39,109 2019-03-16 21:26:39: step 292/50000, loss = 0.192301 (9.027 sec/batch), lr: 0.500000
2019-03-16 21:26:49,318 2019-03-16 21:26:49: step 293/50000, loss = 0.227887 (10.150 sec/batch), lr: 0.500000
2019-03-16 21:27:00,486 2019-03-16 21:27:00: step 294/50000, loss = 0.189648 (11.100 sec/batch), lr: 0.500000
2019-03-16 21:27:12,763 2019-03-16 21:27:12: step 295/50000, loss = 0.225820 (12.207 sec/batch), lr: 0.500000
2019-03-16 21:27:27,038 2019-03-16 21:27:27: step 296/50000, loss = 0.200650 (14.195 sec/batch), lr: 0.500000
2019-03-16 21:27:44,194 2019-03-16 21:27:44: step 297/50000, loss = 0.237535 (17.059 sec/batch), lr: 0.500000
2019-03-16 21:28:04,067 2019-03-16 21:28:04: step 298/50000, loss = 0.195941 (19.760 sec/batch), lr: 0.500000
2019-03-16 21:28:32,187 2019-03-16 21:28:32: step 299/50000, loss = 0.222888 (27.965 sec/batch), lr: 0.500000
2019-03-16 21:29:06,051 2019-03-16 21:29:06: step 300/50000, loss = 0.162870 (33.691 sec/batch), lr: 0.500000
2019-03-16 21:29:33,790 step 300: Full loss = 0.127461, Edge acc. = 0.3649
2019-03-16 21:29:33,850 step 300: Dev acc. = 0.385079
2019-03-16 21:30:23,114 2019-03-16 21:30:23: step 301/50000, loss = 0.180125 (49.026 sec/batch), lr: 0.500000
2019-03-16 21:30:46,665 2019-03-16 21:30:46: step 302/50000, loss = 0.202294 (23.535 sec/batch), lr: 0.500000
2019-03-16 21:31:04,867 2019-03-16 21:31:04: step 303/50000, loss = 0.216280 (18.187 sec/batch), lr: 0.500000
2019-03-16 21:31:20,541 2019-03-16 21:31:20: step 304/50000, loss = 0.220142 (15.660 sec/batch), lr: 0.500000
2019-03-16 21:31:33,241 2019-03-16 21:31:33: step 305/50000, loss = 0.210764 (12.687 sec/batch), lr: 0.500000
2019-03-16 21:31:44,854 2019-03-16 21:31:44: step 306/50000, loss = 0.224270 (11.601 sec/batch), lr: 0.500000
2019-03-16 21:31:55,517 2019-03-16 21:31:55: step 307/50000, loss = 0.213287 (10.599 sec/batch), lr: 0.500000
2019-03-16 21:32:05,195 2019-03-16 21:32:05: step 308/50000, loss = 0.217917 (9.623 sec/batch), lr: 0.500000
2019-03-16 21:32:14,196 2019-03-16 21:32:14: step 309/50000, loss = 0.196294 (8.951 sec/batch), lr: 0.500000
2019-03-16 21:32:22,421 2019-03-16 21:32:22: step 310/50000, loss = 0.198426 (8.178 sec/batch), lr: 0.500000
2019-03-16 21:32:29,780 2019-03-16 21:32:29: step 311/50000, loss = 0.202470 (7.350 sec/batch), lr: 0.500000
2019-03-16 21:32:36,511 2019-03-16 21:32:36: step 312/50000, loss = 0.213134 (6.692 sec/batch), lr: 0.500000
2019-03-16 21:32:42,945 2019-03-16 21:32:42: step 313/50000, loss = 0.203144 (6.424 sec/batch), lr: 0.500000
2019-03-16 21:32:49,004 2019-03-16 21:32:49: step 314/50000, loss = 0.196347 (6.026 sec/batch), lr: 0.500000
2019-03-16 21:32:54,717 2019-03-16 21:32:54: step 315/50000, loss = 0.202455 (5.682 sec/batch), lr: 0.500000
2019-03-16 21:33:00,118 2019-03-16 21:33:00: step 316/50000, loss = 0.203072 (5.371 sec/batch), lr: 0.500000
2019-03-16 21:33:05,120 2019-03-16 21:33:05: step 317/50000, loss = 0.201287 (4.975 sec/batch), lr: 0.500000
2019-03-16 21:33:10,059 2019-03-16 21:33:10: step 318/50000, loss = 0.181775 (4.912 sec/batch), lr: 0.500000
2019-03-16 21:33:14,662 2019-03-16 21:33:14: step 319/50000, loss = 0.191336 (4.577 sec/batch), lr: 0.500000
2019-03-16 21:33:19,067 2019-03-16 21:33:19: step 320/50000, loss = 0.194808 (4.381 sec/batch), lr: 0.500000
2019-03-16 21:33:23,364 2019-03-16 21:33:23: step 321/50000, loss = 0.199481 (4.276 sec/batch), lr: 0.500000
2019-03-16 21:33:27,305 2019-03-16 21:33:27: step 322/50000, loss = 0.192171 (3.920 sec/batch), lr: 0.500000
2019-03-16 21:33:30,824 2019-03-16 21:33:30: step 323/50000, loss = 0.198021 (3.499 sec/batch), lr: 0.500000
2019-03-16 21:33:34,214 2019-03-16 21:33:34: step 324/50000, loss = 0.185865 (3.372 sec/batch), lr: 0.500000
2019-03-16 21:33:37,413 2019-03-16 21:33:37: step 325/50000, loss = 0.196168 (3.181 sec/batch), lr: 0.500000
2019-03-16 21:33:40,540 2019-03-16 21:33:40: step 326/50000, loss = 0.188472 (3.110 sec/batch), lr: 0.500000
2019-03-16 21:33:43,598 2019-03-16 21:33:43: step 327/50000, loss = 0.200168 (3.042 sec/batch), lr: 0.500000
2019-03-16 21:33:46,262 2019-03-16 21:33:46: step 328/50000, loss = 0.188454 (2.649 sec/batch), lr: 0.500000
2019-03-16 21:33:48,700 2019-03-16 21:33:48: step 329/50000, loss = 0.203051 (2.424 sec/batch), lr: 0.500000
2019-03-16 21:33:51,202 2019-03-16 21:33:51: step 330/50000, loss = 0.175566 (2.489 sec/batch), lr: 0.500000
2019-03-16 21:33:53,404 2019-03-16 21:33:53: step 331/50000, loss = 0.201514 (2.189 sec/batch), lr: 0.500000
2019-03-16 21:33:55,349 2019-03-16 21:33:55: step 332/50000, loss = 0.197703 (1.934 sec/batch), lr: 0.500000
2019-03-16 21:33:57,328 2019-03-16 21:33:57: step 333/50000, loss = 0.206397 (1.967 sec/batch), lr: 0.500000
2019-03-16 21:33:59,094 2019-03-16 21:33:59: step 334/50000, loss = 0.184638 (1.755 sec/batch), lr: 0.500000
2019-03-16 21:34:00,821 2019-03-16 21:34:00: step 335/50000, loss = 0.198386 (1.717 sec/batch), lr: 0.500000
2019-03-16 21:34:02,446 2019-03-16 21:34:02: step 336/50000, loss = 0.181988 (1.615 sec/batch), lr: 0.500000
2019-03-16 21:34:03,974 2019-03-16 21:34:03: step 337/50000, loss = 0.200405 (1.519 sec/batch), lr: 0.500000
2019-03-16 21:34:05,401 2019-03-16 21:34:05: step 338/50000, loss = 0.180543 (1.417 sec/batch), lr: 0.500000
2019-03-16 21:34:06,658 2019-03-16 21:34:06: step 339/50000, loss = 0.189201 (1.247 sec/batch), lr: 0.500000
2019-03-16 21:34:07,788 2019-03-16 21:34:07: step 340/50000, loss = 0.195568 (1.120 sec/batch), lr: 0.500000
2019-03-16 21:34:08,747 2019-03-16 21:34:08: step 341/50000, loss = 0.219311 (0.952 sec/batch), lr: 0.500000
2019-03-16 21:34:09,694 2019-03-16 21:34:09: step 342/50000, loss = 0.200863 (0.939 sec/batch), lr: 0.500000
2019-03-16 21:34:10,524 2019-03-16 21:34:10: step 343/50000, loss = 0.204697 (0.824 sec/batch), lr: 0.500000
2019-03-16 21:34:11,202 2019-03-16 21:34:11: step 344/50000, loss = 0.211060 (0.670 sec/batch), lr: 0.500000
2019-03-16 21:34:11,750 2019-03-16 21:34:11: step 345/50000, loss = 0.210266 (0.542 sec/batch), lr: 0.500000
2019-03-16 21:34:12,260 2019-03-16 21:34:12: step 346/50000, loss = 0.175421 (0.504 sec/batch), lr: 0.500000
2019-03-16 21:34:12,674 2019-03-16 21:34:12: step 347/50000, loss = 0.194357 (0.408 sec/batch), lr: 0.500000
2019-03-16 21:34:12,999 2019-03-16 21:34:12: step 348/50000, loss = 0.146455 (0.320 sec/batch), lr: 0.500000
2019-03-16 21:34:13,199 2019-03-16 21:34:13: step 349/50000, loss = 0.170307 (0.196 sec/batch), lr: 0.500000
2019-03-16 21:34:13,325 2019-03-16 21:34:13: step 350/50000, loss = 0.323624 (0.124 sec/batch), lr: 0.500000
2019-03-16 21:35:03,198 2019-03-16 21:35:03: step 351/50000, loss = 0.329147 (49.616 sec/batch), lr: 0.500000
2019-03-16 21:35:27,055 2019-03-16 21:35:27: step 352/50000, loss = 0.385486 (23.726 sec/batch), lr: 0.500000
2019-03-16 21:35:45,456 2019-03-16 21:35:45: step 353/50000, loss = 0.266190 (18.387 sec/batch), lr: 0.500000
2019-03-16 21:36:01,338 2019-03-16 21:36:01: step 354/50000, loss = 0.361990 (15.794 sec/batch), lr: 0.500000
2019-03-16 21:36:14,105 2019-03-16 21:36:14: step 355/50000, loss = 0.309726 (12.754 sec/batch), lr: 0.500000
2019-03-16 21:36:25,859 2019-03-16 21:36:25: step 356/50000, loss = 0.325627 (11.742 sec/batch), lr: 0.500000
2019-03-16 21:36:36,612 2019-03-16 21:36:36: step 357/50000, loss = 0.317960 (10.689 sec/batch), lr: 0.500000
2019-03-16 21:36:46,471 2019-03-16 21:36:46: step 358/50000, loss = 0.340729 (9.803 sec/batch), lr: 0.500000
2019-03-16 21:36:55,379 2019-03-16 21:36:55: step 359/50000, loss = 0.307205 (8.860 sec/batch), lr: 0.500000
2019-03-16 21:37:03,651 2019-03-16 21:37:03: step 360/50000, loss = 0.332519 (8.226 sec/batch), lr: 0.500000
2019-03-16 21:37:11,123 2019-03-16 21:37:11: step 361/50000, loss = 0.313725 (7.431 sec/batch), lr: 0.500000
2019-03-16 21:37:18,080 2019-03-16 21:37:18: step 362/50000, loss = 0.282787 (6.919 sec/batch), lr: 0.500000
2019-03-16 21:37:24,597 2019-03-16 21:37:24: step 363/50000, loss = 0.253445 (6.482 sec/batch), lr: 0.500000
2019-03-16 21:37:30,701 2019-03-16 21:37:30: step 364/50000, loss = 0.238746 (6.095 sec/batch), lr: 0.500000
2019-03-16 21:37:36,533 2019-03-16 21:37:36: step 365/50000, loss = 0.239317 (5.800 sec/batch), lr: 0.500000
2019-03-16 21:37:41,941 2019-03-16 21:37:41: step 366/50000, loss = 0.247081 (5.381 sec/batch), lr: 0.500000
2019-03-16 21:37:47,018 2019-03-16 21:37:47: step 367/50000, loss = 0.236708 (5.069 sec/batch), lr: 0.500000
2019-03-16 21:37:51,933 2019-03-16 21:37:51: step 368/50000, loss = 0.229382 (4.886 sec/batch), lr: 0.500000
2019-03-16 21:37:56,608 2019-03-16 21:37:56: step 369/50000, loss = 0.231707 (4.649 sec/batch), lr: 0.500000
2019-03-16 21:38:00,994 2019-03-16 21:38:00: step 370/50000, loss = 0.225703 (4.362 sec/batch), lr: 0.500000
2019-03-16 21:38:05,244 2019-03-16 21:38:05: step 371/50000, loss = 0.232362 (4.225 sec/batch), lr: 0.500000
2019-03-16 21:38:09,269 2019-03-16 21:38:09: step 372/50000, loss = 0.227953 (4.016 sec/batch), lr: 0.500000
2019-03-16 21:38:12,979 2019-03-16 21:38:12: step 373/50000, loss = 0.240435 (3.690 sec/batch), lr: 0.500000
2019-03-16 21:38:16,402 2019-03-16 21:38:16: step 374/50000, loss = 0.216763 (3.404 sec/batch), lr: 0.500000
2019-03-16 21:38:19,776 2019-03-16 21:38:19: step 375/50000, loss = 0.239838 (3.356 sec/batch), lr: 0.500000
2019-03-16 21:38:22,928 2019-03-16 21:38:22: step 376/50000, loss = 0.216876 (3.144 sec/batch), lr: 0.500000
2019-03-16 21:38:26,009 2019-03-16 21:38:26: step 377/50000, loss = 0.242565 (3.064 sec/batch), lr: 0.500000
2019-03-16 21:38:28,848 2019-03-16 21:38:28: step 378/50000, loss = 0.227888 (2.824 sec/batch), lr: 0.500000
2019-03-16 21:38:31,433 2019-03-16 21:38:31: step 379/50000, loss = 0.247335 (2.578 sec/batch), lr: 0.500000
2019-03-16 21:38:33,968 2019-03-16 21:38:33: step 380/50000, loss = 0.217153 (2.520 sec/batch), lr: 0.500000
2019-03-16 21:38:36,328 2019-03-16 21:38:36: step 381/50000, loss = 0.256393 (2.348 sec/batch), lr: 0.500000
2019-03-16 21:38:38,465 2019-03-16 21:38:38: step 382/50000, loss = 0.231853 (2.129 sec/batch), lr: 0.500000
2019-03-16 21:38:40,548 2019-03-16 21:38:40: step 383/50000, loss = 0.269987 (2.069 sec/batch), lr: 0.500000
2019-03-16 21:38:42,495 2019-03-16 21:38:42: step 384/50000, loss = 0.233675 (1.935 sec/batch), lr: 0.500000
2019-03-16 21:38:44,398 2019-03-16 21:38:44: step 385/50000, loss = 0.265483 (1.890 sec/batch), lr: 0.500000
2019-03-16 21:38:46,088 2019-03-16 21:38:46: step 386/50000, loss = 0.248830 (1.679 sec/batch), lr: 0.500000
2019-03-16 21:38:47,623 2019-03-16 21:38:47: step 387/50000, loss = 0.296688 (1.525 sec/batch), lr: 0.500000
2019-03-16 21:38:49,071 2019-03-16 21:38:49: step 388/50000, loss = 0.255751 (1.437 sec/batch), lr: 0.500000
2019-03-16 21:38:50,364 2019-03-16 21:38:50: step 389/50000, loss = 0.279833 (1.283 sec/batch), lr: 0.500000
2019-03-16 21:38:51,464 2019-03-16 21:38:51: step 390/50000, loss = 0.299073 (1.093 sec/batch), lr: 0.500000
2019-03-16 21:38:52,440 2019-03-16 21:38:52: step 391/50000, loss = 0.410842 (0.968 sec/batch), lr: 0.500000
2019-03-16 21:38:53,351 2019-03-16 21:38:53: step 392/50000, loss = 0.294850 (0.902 sec/batch), lr: 0.500000
2019-03-16 21:38:54,081 2019-03-16 21:38:54: step 393/50000, loss = 0.408096 (0.722 sec/batch), lr: 0.500000
2019-03-16 21:38:54,744 2019-03-16 21:38:54: step 394/50000, loss = 0.395899 (0.656 sec/batch), lr: 0.500000
2019-03-16 21:38:55,266 2019-03-16 21:38:55: step 395/50000, loss = 0.529927 (0.516 sec/batch), lr: 0.500000
2019-03-16 21:38:55,768 2019-03-16 21:38:55: step 396/50000, loss = 0.154829 (0.496 sec/batch), lr: 0.500000
2019-03-16 21:38:56,185 2019-03-16 21:38:56: step 397/50000, loss = 0.171925 (0.411 sec/batch), lr: 0.500000
2019-03-16 21:38:56,513 2019-03-16 21:38:56: step 398/50000, loss = 0.176932 (0.323 sec/batch), lr: 0.500000
2019-03-16 21:38:56,717 2019-03-16 21:38:56: step 399/50000, loss = 0.165673 (0.200 sec/batch), lr: 0.500000
2019-03-16 21:38:56,846 2019-03-16 21:38:56: step 400/50000, loss = 0.698726 (0.127 sec/batch), lr: 0.500000
2019-03-16 21:39:24,829 step 400: Full loss = 0.286620, Edge acc. = 0.1119
2019-03-16 21:39:24,888 step 400: Dev acc. = 0.097243
2019-03-16 21:39:25,032 2019-03-16 21:39:25: step 401/50000, loss = 0.404929 (0.139 sec/batch), lr: 0.250000
2019-03-16 21:39:25,255 2019-03-16 21:39:25: step 402/50000, loss = 0.366561 (0.219 sec/batch), lr: 0.250000
2019-03-16 21:39:25,552 2019-03-16 21:39:25: step 403/50000, loss = 0.276170 (0.293 sec/batch), lr: 0.250000
2019-03-16 21:39:25,973 2019-03-16 21:39:25: step 404/50000, loss = 0.166572 (0.416 sec/batch), lr: 0.250000
2019-03-16 21:39:26,511 2019-03-16 21:39:26: step 405/50000, loss = 0.163558 (0.531 sec/batch), lr: 0.250000
2019-03-16 21:39:27,162 2019-03-16 21:39:27: step 406/50000, loss = 0.165204 (0.645 sec/batch), lr: 0.250000
2019-03-16 21:39:27,952 2019-03-16 21:39:27: step 407/50000, loss = 0.163761 (0.784 sec/batch), lr: 0.250000
2019-03-16 21:39:28,799 2019-03-16 21:39:28: step 408/50000, loss = 0.176519 (0.839 sec/batch), lr: 0.250000
2019-03-16 21:39:29,763 2019-03-16 21:39:29: step 409/50000, loss = 0.186557 (0.954 sec/batch), lr: 0.250000
2019-03-16 21:39:30,867 2019-03-16 21:39:30: step 410/50000, loss = 0.168873 (1.094 sec/batch), lr: 0.250000
2019-03-16 21:39:32,030 2019-03-16 21:39:32: step 411/50000, loss = 0.176210 (1.153 sec/batch), lr: 0.250000
2019-03-16 21:39:33,349 2019-03-16 21:39:33: step 412/50000, loss = 0.167564 (1.309 sec/batch), lr: 0.250000
2019-03-16 21:39:34,809 2019-03-16 21:39:34: step 413/50000, loss = 0.173864 (1.453 sec/batch), lr: 0.250000
2019-03-16 21:39:36,444 2019-03-16 21:39:36: step 414/50000, loss = 0.164253 (1.625 sec/batch), lr: 0.250000
2019-03-16 21:39:38,148 2019-03-16 21:39:38: step 415/50000, loss = 0.184438 (1.693 sec/batch), lr: 0.250000
2019-03-16 21:39:40,051 2019-03-16 21:39:40: step 416/50000, loss = 0.174165 (1.895 sec/batch), lr: 0.250000
2019-03-16 21:39:42,073 2019-03-16 21:39:42: step 417/50000, loss = 0.181906 (2.015 sec/batch), lr: 0.250000
2019-03-16 21:39:44,070 2019-03-16 21:39:44: step 418/50000, loss = 0.176348 (1.984 sec/batch), lr: 0.250000
2019-03-16 21:39:46,230 2019-03-16 21:39:46: step 419/50000, loss = 0.182275 (2.147 sec/batch), lr: 0.250000
2019-03-16 21:39:48,559 2019-03-16 21:39:48: step 420/50000, loss = 0.174131 (2.315 sec/batch), lr: 0.250000
2019-03-16 21:39:50,999 2019-03-16 21:39:50: step 421/50000, loss = 0.191863 (2.427 sec/batch), lr: 0.250000
2019-03-16 21:39:53,733 2019-03-16 21:39:53: step 422/50000, loss = 0.166559 (2.718 sec/batch), lr: 0.250000
2019-03-16 21:39:56,471 2019-03-16 21:39:56: step 423/50000, loss = 0.196264 (2.723 sec/batch), lr: 0.250000
2019-03-16 21:39:59,597 2019-03-16 21:39:59: step 424/50000, loss = 0.171499 (3.110 sec/batch), lr: 0.250000
2019-03-16 21:40:02,737 2019-03-16 21:40:02: step 425/50000, loss = 0.194862 (3.123 sec/batch), lr: 0.250000
2019-03-16 21:40:06,202 2019-03-16 21:40:06: step 426/50000, loss = 0.175163 (3.446 sec/batch), lr: 0.250000
2019-03-16 21:40:09,832 2019-03-16 21:40:09: step 427/50000, loss = 0.190385 (3.621 sec/batch), lr: 0.250000
2019-03-16 21:40:13,579 2019-03-16 21:40:13: step 428/50000, loss = 0.178978 (3.727 sec/batch), lr: 0.250000
2019-03-16 21:40:17,646 2019-03-16 21:40:17: step 429/50000, loss = 0.208688 (4.045 sec/batch), lr: 0.250000
2019-03-16 21:40:21,950 2019-03-16 21:40:21: step 430/50000, loss = 0.182554 (4.282 sec/batch), lr: 0.250000
2019-03-16 21:40:26,154 2019-03-16 21:40:26: step 431/50000, loss = 0.204294 (4.180 sec/batch), lr: 0.250000
2019-03-16 21:40:30,779 2019-03-16 21:40:30: step 432/50000, loss = 0.184052 (4.600 sec/batch), lr: 0.250000
2019-03-16 21:40:35,729 2019-03-16 21:40:35: step 433/50000, loss = 0.199889 (4.924 sec/batch), lr: 0.250000
2019-03-16 21:40:40,992 2019-03-16 21:40:40: step 434/50000, loss = 0.178984 (5.237 sec/batch), lr: 0.250000
2019-03-16 21:40:46,636 2019-03-16 21:40:46: step 435/50000, loss = 0.203378 (5.613 sec/batch), lr: 0.250000
2019-03-16 21:40:52,364 2019-03-16 21:40:52: step 436/50000, loss = 0.188914 (5.696 sec/batch), lr: 0.250000
2019-03-16 21:40:58,553 2019-03-16 21:40:58: step 437/50000, loss = 0.203537 (6.155 sec/batch), lr: 0.250000
2019-03-16 21:41:05,399 2019-03-16 21:41:05: step 438/50000, loss = 0.185651 (6.807 sec/batch), lr: 0.250000
2019-03-16 21:41:12,577 2019-03-16 21:41:12: step 439/50000, loss = 0.208892 (7.139 sec/batch), lr: 0.250000
2019-03-16 21:41:20,413 2019-03-16 21:41:20: step 440/50000, loss = 0.188120 (7.794 sec/batch), lr: 0.250000
2019-03-16 21:41:28,763 2019-03-16 21:41:28: step 441/50000, loss = 0.213361 (8.303 sec/batch), lr: 0.250000
2019-03-16 21:41:38,125 2019-03-16 21:41:38: step 442/50000, loss = 0.193951 (9.351 sec/batch), lr: 0.250000
2019-03-16 21:41:48,485 2019-03-16 21:41:48: step 443/50000, loss = 0.218679 (10.302 sec/batch), lr: 0.250000
2019-03-16 21:41:59,732 2019-03-16 21:41:59: step 444/50000, loss = 0.192305 (11.184 sec/batch), lr: 0.250000
2019-03-16 21:42:12,080 2019-03-16 21:42:12: step 445/50000, loss = 0.217785 (12.275 sec/batch), lr: 0.250000
2019-03-16 21:42:26,499 2019-03-16 21:42:26: step 446/50000, loss = 0.202669 (14.338 sec/batch), lr: 0.250000
2019-03-16 21:42:43,551 2019-03-16 21:42:43: step 447/50000, loss = 0.216116 (16.955 sec/batch), lr: 0.250000
2019-03-16 21:43:03,660 2019-03-16 21:43:03: step 448/50000, loss = 0.213731 (19.995 sec/batch), lr: 0.250000
2019-03-16 21:43:31,921 2019-03-16 21:43:31: step 449/50000, loss = 0.223062 (28.098 sec/batch), lr: 0.250000
2019-03-16 21:44:06,174 2019-03-16 21:44:06: step 450/50000, loss = 0.165791 (34.068 sec/batch), lr: 0.250000
2019-03-16 21:44:55,604 2019-03-16 21:44:55: step 451/50000, loss = 0.179287 (49.191 sec/batch), lr: 0.250000
2019-03-16 21:45:19,350 2019-03-16 21:45:19: step 452/50000, loss = 0.197348 (23.612 sec/batch), lr: 0.250000
2019-03-16 21:45:37,728 2019-03-16 21:45:37: step 453/50000, loss = 0.215138 (18.363 sec/batch), lr: 0.250000
2019-03-16 21:45:53,615 2019-03-16 21:45:53: step 454/50000, loss = 0.220617 (15.874 sec/batch), lr: 0.250000
2019-03-16 21:46:06,579 2019-03-16 21:46:06: step 455/50000, loss = 0.209613 (12.950 sec/batch), lr: 0.250000
2019-03-16 21:46:18,300 2019-03-16 21:46:18: step 456/50000, loss = 0.216755 (11.653 sec/batch), lr: 0.250000
2019-03-16 21:46:29,185 2019-03-16 21:46:29: step 457/50000, loss = 0.206690 (10.873 sec/batch), lr: 0.250000
2019-03-16 21:46:39,050 2019-03-16 21:46:39: step 458/50000, loss = 0.218091 (9.808 sec/batch), lr: 0.250000
2019-03-16 21:46:48,221 2019-03-16 21:46:48: step 459/50000, loss = 0.191728 (9.114 sec/batch), lr: 0.250000
2019-03-16 21:46:56,469 2019-03-16 21:46:56: step 460/50000, loss = 0.198463 (8.204 sec/batch), lr: 0.250000
2019-03-16 21:47:03,946 2019-03-16 21:47:03: step 461/50000, loss = 0.194507 (7.435 sec/batch), lr: 0.250000
2019-03-16 21:47:10,925 2019-03-16 21:47:10: step 462/50000, loss = 0.215517 (6.940 sec/batch), lr: 0.250000
2019-03-16 21:47:17,520 2019-03-16 21:47:17: step 463/50000, loss = 0.194369 (6.558 sec/batch), lr: 0.250000
2019-03-16 21:47:23,674 2019-03-16 21:47:23: step 464/50000, loss = 0.198502 (6.145 sec/batch), lr: 0.250000
2019-03-16 21:47:29,417 2019-03-16 21:47:29: step 465/50000, loss = 0.192506 (5.703 sec/batch), lr: 0.250000
2019-03-16 21:47:34,725 2019-03-16 21:47:34: step 466/50000, loss = 0.202838 (5.278 sec/batch), lr: 0.250000
2019-03-16 21:47:39,696 2019-03-16 21:47:39: step 467/50000, loss = 0.187981 (4.943 sec/batch), lr: 0.250000
2019-03-16 21:47:44,691 2019-03-16 21:47:44: step 468/50000, loss = 0.182198 (4.967 sec/batch), lr: 0.250000
2019-03-16 21:47:49,307 2019-03-16 21:47:49: step 469/50000, loss = 0.184476 (4.593 sec/batch), lr: 0.250000
2019-03-16 21:47:53,574 2019-03-16 21:47:53: step 470/50000, loss = 0.200429 (4.243 sec/batch), lr: 0.250000
2019-03-16 21:47:57,741 2019-03-16 21:47:57: step 471/50000, loss = 0.191135 (4.147 sec/batch), lr: 0.250000
2019-03-16 21:48:01,677 2019-03-16 21:48:01: step 472/50000, loss = 0.189585 (3.918 sec/batch), lr: 0.250000
2019-03-16 21:48:05,452 2019-03-16 21:48:05: step 473/50000, loss = 0.185699 (3.755 sec/batch), lr: 0.250000
2019-03-16 21:48:08,931 2019-03-16 21:48:08: step 474/50000, loss = 0.184360 (3.460 sec/batch), lr: 0.250000
2019-03-16 21:48:12,053 2019-03-16 21:48:12: step 475/50000, loss = 0.180673 (3.103 sec/batch), lr: 0.250000
2019-03-16 21:48:15,142 2019-03-16 21:48:15: step 476/50000, loss = 0.185045 (3.073 sec/batch), lr: 0.250000
2019-03-16 21:48:18,266 2019-03-16 21:48:18: step 477/50000, loss = 0.184416 (3.108 sec/batch), lr: 0.250000
2019-03-16 21:48:21,132 2019-03-16 21:48:21: step 478/50000, loss = 0.187163 (2.850 sec/batch), lr: 0.250000
2019-03-16 21:48:23,749 2019-03-16 21:48:23: step 479/50000, loss = 0.184786 (2.599 sec/batch), lr: 0.250000
2019-03-16 21:48:26,273 2019-03-16 21:48:26: step 480/50000, loss = 0.171362 (2.511 sec/batch), lr: 0.250000
2019-03-16 21:48:28,605 2019-03-16 21:48:28: step 481/50000, loss = 0.182573 (2.320 sec/batch), lr: 0.250000
2019-03-16 21:48:30,526 2019-03-16 21:48:30: step 482/50000, loss = 0.184468 (1.907 sec/batch), lr: 0.250000
2019-03-16 21:48:32,348 2019-03-16 21:48:32: step 483/50000, loss = 0.186697 (1.811 sec/batch), lr: 0.250000
2019-03-16 21:48:34,142 2019-03-16 21:48:34: step 484/50000, loss = 0.182003 (1.782 sec/batch), lr: 0.250000
2019-03-16 21:48:36,033 2019-03-16 21:48:36: step 485/50000, loss = 0.180355 (1.879 sec/batch), lr: 0.250000
2019-03-16 21:48:37,745 2019-03-16 21:48:37: step 486/50000, loss = 0.168888 (1.702 sec/batch), lr: 0.250000
2019-03-16 21:48:39,258 2019-03-16 21:48:39: step 487/50000, loss = 0.176374 (1.502 sec/batch), lr: 0.250000
2019-03-16 21:48:40,678 2019-03-16 21:48:40: step 488/50000, loss = 0.164740 (1.410 sec/batch), lr: 0.250000
2019-03-16 21:48:41,979 2019-03-16 21:48:41: step 489/50000, loss = 0.160877 (1.293 sec/batch), lr: 0.250000
2019-03-16 21:48:43,121 2019-03-16 21:48:43: step 490/50000, loss = 0.166516 (1.133 sec/batch), lr: 0.250000
2019-03-16 21:48:44,124 2019-03-16 21:48:44: step 491/50000, loss = 0.185098 (0.995 sec/batch), lr: 0.250000
2019-03-16 21:48:45,074 2019-03-16 21:48:45: step 492/50000, loss = 0.173602 (0.941 sec/batch), lr: 0.250000
2019-03-16 21:48:45,890 2019-03-16 21:48:45: step 493/50000, loss = 0.170333 (0.809 sec/batch), lr: 0.250000
2019-03-16 21:48:46,568 2019-03-16 21:48:46: step 494/50000, loss = 0.166785 (0.670 sec/batch), lr: 0.250000
2019-03-16 21:48:47,134 2019-03-16 21:48:47: step 495/50000, loss = 0.174914 (0.560 sec/batch), lr: 0.250000
2019-03-16 21:48:47,648 2019-03-16 21:48:47: step 496/50000, loss = 0.146486 (0.508 sec/batch), lr: 0.250000
2019-03-16 21:48:48,063 2019-03-16 21:48:48: step 497/50000, loss = 0.154837 (0.409 sec/batch), lr: 0.250000
2019-03-16 21:48:48,389 2019-03-16 21:48:48: step 498/50000, loss = 0.140893 (0.321 sec/batch), lr: 0.250000
2019-03-16 21:48:48,590 2019-03-16 21:48:48: step 499/50000, loss = 0.100430 (0.196 sec/batch), lr: 0.250000
2019-03-16 21:48:48,703 2019-03-16 21:48:48: step 500/50000, loss = 0.253692 (0.111 sec/batch), lr: 0.250000
2019-03-16 21:49:16,649 step 500: Full loss = 0.210866, Edge acc. = 0.3490
2019-03-16 21:49:16,708 step 500: Dev acc. = 0.374198
2019-03-16 21:49:16,852 2019-03-16 21:49:16: step 501/50000, loss = 0.208707 (0.140 sec/batch), lr: 0.250000
2019-03-16 21:49:17,085 2019-03-16 21:49:17: step 502/50000, loss = 0.118866 (0.229 sec/batch), lr: 0.250000
2019-03-16 21:49:17,409 2019-03-16 21:49:17: step 503/50000, loss = 0.202327 (0.319 sec/batch), lr: 0.250000
2019-03-16 21:49:17,849 2019-03-16 21:49:17: step 504/50000, loss = 0.174114 (0.434 sec/batch), lr: 0.250000
2019-03-16 21:49:18,392 2019-03-16 21:49:18: step 505/50000, loss = 0.162024 (0.537 sec/batch), lr: 0.250000
2019-03-16 21:49:19,038 2019-03-16 21:49:19: step 506/50000, loss = 0.176630 (0.639 sec/batch), lr: 0.250000
2019-03-16 21:49:19,831 2019-03-16 21:49:19: step 507/50000, loss = 0.181037 (0.785 sec/batch), lr: 0.250000
2019-03-16 21:49:20,659 2019-03-16 21:49:20: step 508/50000, loss = 0.206973 (0.820 sec/batch), lr: 0.250000
2019-03-16 21:49:21,644 2019-03-16 21:49:21: step 509/50000, loss = 0.198320 (0.976 sec/batch), lr: 0.250000
2019-03-16 21:49:22,755 2019-03-16 21:49:22: step 510/50000, loss = 0.203262 (1.102 sec/batch), lr: 0.250000
2019-03-16 21:49:23,916 2019-03-16 21:49:23: step 511/50000, loss = 0.190317 (1.151 sec/batch), lr: 0.250000
2019-03-16 21:49:25,214 2019-03-16 21:49:25: step 512/50000, loss = 0.217234 (1.289 sec/batch), lr: 0.250000
2019-03-16 21:49:26,683 2019-03-16 21:49:26: step 513/50000, loss = 0.199882 (1.461 sec/batch), lr: 0.250000
2019-03-16 21:49:28,319 2019-03-16 21:49:28: step 514/50000, loss = 0.215339 (1.625 sec/batch), lr: 0.250000
2019-03-16 21:49:30,006 2019-03-16 21:49:30: step 515/50000, loss = 0.175514 (1.676 sec/batch), lr: 0.250000
2019-03-16 21:49:31,814 2019-03-16 21:49:31: step 516/50000, loss = 0.211112 (1.798 sec/batch), lr: 0.250000
2019-03-16 21:49:33,875 2019-03-16 21:49:33: step 517/50000, loss = 0.185583 (2.049 sec/batch), lr: 0.250000
2019-03-16 21:49:35,998 2019-03-16 21:49:35: step 518/50000, loss = 0.210119 (2.116 sec/batch), lr: 0.250000
2019-03-16 21:49:38,151 2019-03-16 21:49:38: step 519/50000, loss = 0.172186 (2.138 sec/batch), lr: 0.250000
2019-03-16 21:49:40,305 2019-03-16 21:49:40: step 520/50000, loss = 0.200366 (2.141 sec/batch), lr: 0.250000
2019-03-16 21:49:42,839 2019-03-16 21:49:42: step 521/50000, loss = 0.184315 (2.519 sec/batch), lr: 0.250000
2019-03-16 21:49:45,559 2019-03-16 21:49:45: step 522/50000, loss = 0.191137 (2.705 sec/batch), lr: 0.250000
2019-03-16 21:49:48,394 2019-03-16 21:49:48: step 523/50000, loss = 0.180344 (2.821 sec/batch), lr: 0.250000
2019-03-16 21:49:51,307 2019-03-16 21:49:51: step 524/50000, loss = 0.193607 (2.900 sec/batch), lr: 0.250000
2019-03-16 21:49:54,382 2019-03-16 21:49:54: step 525/50000, loss = 0.188696 (3.059 sec/batch), lr: 0.250000
2019-03-16 21:49:57,791 2019-03-16 21:49:57: step 526/50000, loss = 0.196841 (3.391 sec/batch), lr: 0.250000
2019-03-16 21:50:01,495 2019-03-16 21:50:01: step 527/50000, loss = 0.176097 (3.684 sec/batch), lr: 0.250000
2019-03-16 21:50:05,233 2019-03-16 21:50:05: step 528/50000, loss = 0.196821 (3.718 sec/batch), lr: 0.250000
2019-03-16 21:50:09,203 2019-03-16 21:50:09: step 529/50000, loss = 0.196531 (3.962 sec/batch), lr: 0.250000
2019-03-16 21:50:13,366 2019-03-16 21:50:13: step 530/50000, loss = 0.202095 (4.142 sec/batch), lr: 0.250000
2019-03-16 21:50:17,747 2019-03-16 21:50:17: step 531/50000, loss = 0.190528 (4.356 sec/batch), lr: 0.250000
2019-03-16 21:50:22,455 2019-03-16 21:50:22: step 532/50000, loss = 0.205675 (4.684 sec/batch), lr: 0.250000
2019-03-16 21:50:27,276 2019-03-16 21:50:27: step 533/50000, loss = 0.189687 (4.812 sec/batch), lr: 0.250000
2019-03-16 21:50:32,628 2019-03-16 21:50:32: step 534/50000, loss = 0.203841 (5.321 sec/batch), lr: 0.250000
2019-03-16 21:50:38,440 2019-03-16 21:50:38: step 535/50000, loss = 0.186608 (5.781 sec/batch), lr: 0.250000
2019-03-16 21:50:44,256 2019-03-16 21:50:44: step 536/50000, loss = 0.208836 (5.783 sec/batch), lr: 0.250000
2019-03-16 21:50:50,439 2019-03-16 21:50:50: step 537/50000, loss = 0.187754 (6.174 sec/batch), lr: 0.250000
2019-03-16 21:50:57,153 2019-03-16 21:50:57: step 538/50000, loss = 0.201986 (6.678 sec/batch), lr: 0.250000
2019-03-16 21:51:04,448 2019-03-16 21:51:04: step 539/50000, loss = 0.189528 (7.258 sec/batch), lr: 0.250000
2019-03-16 21:51:12,148 2019-03-16 21:51:12: step 540/50000, loss = 0.211422 (7.659 sec/batch), lr: 0.250000
2019-03-16 21:51:20,518 2019-03-16 21:51:20: step 541/50000, loss = 0.193569 (8.324 sec/batch), lr: 0.250000
2019-03-16 21:51:29,819 2019-03-16 21:51:29: step 542/50000, loss = 0.214636 (9.290 sec/batch), lr: 0.250000
2019-03-16 21:51:40,071 2019-03-16 21:51:40: step 543/50000, loss = 0.197726 (10.192 sec/batch), lr: 0.250000
2019-03-16 21:51:51,319 2019-03-16 21:51:51: step 544/50000, loss = 0.217866 (11.186 sec/batch), lr: 0.250000
2019-03-16 21:52:03,752 2019-03-16 21:52:03: step 545/50000, loss = 0.194596 (12.366 sec/batch), lr: 0.250000
2019-03-16 21:52:18,175 2019-03-16 21:52:18: step 546/50000, loss = 0.224358 (14.343 sec/batch), lr: 0.250000
2019-03-16 21:52:35,339 2019-03-16 21:52:35: step 547/50000, loss = 0.199258 (17.061 sec/batch), lr: 0.250000
2019-03-16 21:52:55,670 2019-03-16 21:52:55: step 548/50000, loss = 0.223363 (20.209 sec/batch), lr: 0.250000
