2019-03-16 19:12:07,997 2019-03-16 19:12:07: step 1/50000, loss = 0.358880 (30.832 sec/batch), lr: 1.000000
2019-03-16 19:12:25,151 2019-03-16 19:12:25: step 2/50000, loss = 0.450220 (17.050 sec/batch), lr: 1.000000
2019-03-16 19:12:39,783 2019-03-16 19:12:39: step 3/50000, loss = 0.451454 (14.622 sec/batch), lr: 1.000000
2019-03-16 19:12:51,915 2019-03-16 19:12:51: step 4/50000, loss = 0.449583 (12.123 sec/batch), lr: 1.000000
2019-03-16 19:13:02,745 2019-03-16 19:13:02: step 5/50000, loss = 0.445848 (10.767 sec/batch), lr: 1.000000
2019-03-16 19:13:12,941 2019-03-16 19:13:12: step 6/50000, loss = 0.439902 (10.137 sec/batch), lr: 1.000000
2019-03-16 19:13:22,319 2019-03-16 19:13:22: step 7/50000, loss = 0.418149 (9.324 sec/batch), lr: 1.000000
2019-03-16 19:13:31,044 2019-03-16 19:13:31: step 8/50000, loss = 0.232231 (8.717 sec/batch), lr: 1.000000
2019-03-16 19:13:38,772 2019-03-16 19:13:38: step 9/50000, loss = 0.388474 (7.687 sec/batch), lr: 1.000000
2019-03-16 19:13:46,099 2019-03-16 19:13:46: step 10/50000, loss = 0.247081 (7.287 sec/batch), lr: 1.000000
2019-03-16 19:13:53,066 2019-03-16 19:13:53: step 11/50000, loss = 0.392674 (6.930 sec/batch), lr: 1.000000
2019-03-16 19:13:59,622 2019-03-16 19:13:59: step 12/50000, loss = 0.220874 (6.524 sec/batch), lr: 1.000000
2019-03-16 19:14:05,885 2019-03-16 19:14:05: step 13/50000, loss = 0.391958 (6.229 sec/batch), lr: 1.000000
2019-03-16 19:14:11,929 2019-03-16 19:14:11: step 14/50000, loss = 0.226244 (6.012 sec/batch), lr: 1.000000
2019-03-16 19:14:17,988 2019-03-16 19:14:17: step 15/50000, loss = 0.335051 (6.029 sec/batch), lr: 1.000000
2019-03-16 19:14:23,326 2019-03-16 19:14:23: step 16/50000, loss = 0.226147 (5.299 sec/batch), lr: 1.000000
2019-03-16 19:14:28,788 2019-03-16 19:14:28: step 17/50000, loss = 0.359756 (5.433 sec/batch), lr: 1.000000
2019-03-16 19:14:33,713 2019-03-16 19:14:33: step 18/50000, loss = 0.224932 (4.900 sec/batch), lr: 1.000000
2019-03-16 19:14:38,516 2019-03-16 19:14:38: step 19/50000, loss = 0.357195 (4.779 sec/batch), lr: 1.000000
2019-03-16 19:14:43,246 2019-03-16 19:14:43: step 20/50000, loss = 0.225946 (4.706 sec/batch), lr: 1.000000
2019-03-16 19:14:47,548 2019-03-16 19:14:47: step 21/50000, loss = 0.612347 (4.296 sec/batch), lr: 1.000000
2019-03-16 19:14:51,799 2019-03-16 19:14:51: step 22/50000, loss = 0.409537 (4.244 sec/batch), lr: 1.000000
2019-03-16 19:14:55,862 2019-03-16 19:14:55: step 23/50000, loss = 0.253447 (4.057 sec/batch), lr: 1.000000
2019-03-16 19:15:00,002 2019-03-16 19:15:00: step 24/50000, loss = 0.417081 (4.119 sec/batch), lr: 1.000000
2019-03-16 19:15:03,961 2019-03-16 19:15:03: step 25/50000, loss = 0.218869 (3.940 sec/batch), lr: 1.000000
2019-03-16 19:15:07,612 2019-03-16 19:15:07: step 26/50000, loss = 0.228641 (3.633 sec/batch), lr: 1.000000
2019-03-16 19:15:11,242 2019-03-16 19:15:11: step 27/50000, loss = 0.330441 (3.624 sec/batch), lr: 1.000000
2019-03-16 19:15:14,704 2019-03-16 19:15:14: step 28/50000, loss = 0.228561 (3.446 sec/batch), lr: 1.000000
2019-03-16 19:15:18,145 2019-03-16 19:15:18: step 29/50000, loss = 0.369663 (3.423 sec/batch), lr: 1.000000
2019-03-16 19:15:21,639 2019-03-16 19:15:21: step 30/50000, loss = 0.214170 (3.479 sec/batch), lr: 1.000000
2019-03-16 19:15:24,947 2019-03-16 19:15:24: step 31/50000, loss = 0.357791 (3.292 sec/batch), lr: 1.000000
2019-03-16 19:15:28,053 2019-03-16 19:15:28: step 32/50000, loss = 0.217392 (3.090 sec/batch), lr: 1.000000
2019-03-16 19:15:31,144 2019-03-16 19:15:31: step 33/50000, loss = 0.349471 (3.077 sec/batch), lr: 1.000000
2019-03-16 19:15:34,206 2019-03-16 19:15:34: step 34/50000, loss = 0.218092 (3.047 sec/batch), lr: 1.000000
2019-03-16 19:15:37,133 2019-03-16 19:15:37: step 35/50000, loss = 0.333245 (2.912 sec/batch), lr: 1.000000
2019-03-16 19:15:39,837 2019-03-16 19:15:39: step 36/50000, loss = 0.221650 (2.691 sec/batch), lr: 1.000000
2019-03-16 19:15:42,715 2019-03-16 19:15:42: step 37/50000, loss = 0.323047 (2.865 sec/batch), lr: 1.000000
2019-03-16 19:15:45,401 2019-03-16 19:15:45: step 38/50000, loss = 0.220462 (2.680 sec/batch), lr: 1.000000
2019-03-16 19:15:47,920 2019-03-16 19:15:47: step 39/50000, loss = 0.322980 (2.515 sec/batch), lr: 1.000000
2019-03-16 19:15:50,611 2019-03-16 19:15:50: step 40/50000, loss = 0.226801 (2.686 sec/batch), lr: 1.000000
2019-03-16 19:15:53,229 2019-03-16 19:15:53: step 41/50000, loss = 0.301846 (2.605 sec/batch), lr: 1.000000
2019-03-16 19:15:55,733 2019-03-16 19:15:55: step 42/50000, loss = 0.221162 (2.493 sec/batch), lr: 1.000000
2019-03-16 19:15:58,200 2019-03-16 19:15:58: step 43/50000, loss = 0.303582 (2.455 sec/batch), lr: 1.000000
2019-03-16 19:16:00,598 2019-03-16 19:16:00: step 44/50000, loss = 0.203082 (2.385 sec/batch), lr: 1.000000
2019-03-16 19:16:02,936 2019-03-16 19:16:02: step 45/50000, loss = 0.292004 (2.327 sec/batch), lr: 1.000000
2019-03-16 19:16:05,213 2019-03-16 19:16:05: step 46/50000, loss = 0.205974 (2.266 sec/batch), lr: 1.000000
2019-03-16 19:16:07,150 2019-03-16 19:16:07: step 47/50000, loss = 0.287341 (1.927 sec/batch), lr: 1.000000
2019-03-16 19:16:09,145 2019-03-16 19:16:09: step 48/50000, loss = 0.208671 (1.986 sec/batch), lr: 1.000000
2019-03-16 19:16:11,259 2019-03-16 19:16:11: step 49/50000, loss = 0.284327 (2.104 sec/batch), lr: 1.000000
2019-03-16 19:16:13,090 2019-03-16 19:16:13: step 50/50000, loss = 0.213675 (1.822 sec/batch), lr: 1.000000
2019-03-16 19:16:15,055 2019-03-16 19:16:15: step 51/50000, loss = 0.277926 (1.960 sec/batch), lr: 1.000000
2019-03-16 19:16:17,033 2019-03-16 19:16:17: step 52/50000, loss = 0.216406 (1.969 sec/batch), lr: 1.000000
2019-03-16 19:16:18,844 2019-03-16 19:16:18: step 53/50000, loss = 0.273115 (1.801 sec/batch), lr: 1.000000
2019-03-16 19:16:20,522 2019-03-16 19:16:20: step 54/50000, loss = 0.217773 (1.669 sec/batch), lr: 1.000000
2019-03-16 19:16:22,307 2019-03-16 19:16:22: step 55/50000, loss = 0.269574 (1.776 sec/batch), lr: 1.000000
2019-03-16 19:16:24,092 2019-03-16 19:16:24: step 56/50000, loss = 0.205983 (1.776 sec/batch), lr: 1.000000
2019-03-16 19:16:25,711 2019-03-16 19:16:25: step 57/50000, loss = 0.269657 (1.610 sec/batch), lr: 1.000000
2019-03-16 19:16:27,358 2019-03-16 19:16:27: step 58/50000, loss = 0.203581 (1.640 sec/batch), lr: 1.000000
2019-03-16 19:16:28,966 2019-03-16 19:16:28: step 59/50000, loss = 0.250828 (1.599 sec/batch), lr: 1.000000
2019-03-16 19:16:30,455 2019-03-16 19:16:30: step 60/50000, loss = 0.208756 (1.484 sec/batch), lr: 1.000000
2019-03-16 19:16:31,936 2019-03-16 19:16:31: step 61/50000, loss = 0.257753 (1.477 sec/batch), lr: 1.000000
2019-03-16 19:16:33,388 2019-03-16 19:16:33: step 62/50000, loss = 0.197235 (1.444 sec/batch), lr: 1.000000
2019-03-16 19:16:34,871 2019-03-16 19:16:34: step 63/50000, loss = 0.244394 (1.474 sec/batch), lr: 1.000000
2019-03-16 19:16:36,272 2019-03-16 19:16:36: step 64/50000, loss = 0.200187 (1.394 sec/batch), lr: 1.000000
2019-03-16 19:16:37,727 2019-03-16 19:16:37: step 65/50000, loss = 0.247503 (1.447 sec/batch), lr: 1.000000
2019-03-16 19:16:39,084 2019-03-16 19:16:39: step 66/50000, loss = 0.197308 (1.350 sec/batch), lr: 1.000000
2019-03-16 19:16:40,357 2019-03-16 19:16:40: step 67/50000, loss = 0.234141 (1.262 sec/batch), lr: 1.000000
2019-03-16 19:16:41,840 2019-03-16 19:16:41: step 68/50000, loss = 0.211310 (1.476 sec/batch), lr: 1.000000
2019-03-16 19:16:42,989 2019-03-16 19:16:42: step 69/50000, loss = 0.238600 (1.143 sec/batch), lr: 1.000000
2019-03-16 19:16:43,999 2019-03-16 19:16:43: step 70/50000, loss = 0.194052 (1.005 sec/batch), lr: 1.000000
2019-03-16 19:16:44,934 2019-03-16 19:16:44: step 71/50000, loss = 0.229315 (0.929 sec/batch), lr: 1.000000
2019-03-16 19:16:45,850 2019-03-16 19:16:45: step 72/50000, loss = 0.184296 (0.911 sec/batch), lr: 1.000000
2019-03-16 19:16:46,674 2019-03-16 19:16:46: step 73/50000, loss = 0.220333 (0.820 sec/batch), lr: 1.000000
2019-03-16 19:16:47,522 2019-03-16 19:16:47: step 74/50000, loss = 0.197678 (0.846 sec/batch), lr: 1.000000
2019-03-16 19:16:48,333 2019-03-16 19:16:48: step 75/50000, loss = 0.196413 (0.808 sec/batch), lr: 1.000000
2019-03-16 19:16:49,097 2019-03-16 19:16:49: step 76/50000, loss = 0.203008 (0.761 sec/batch), lr: 1.000000
2019-03-16 19:16:49,914 2019-03-16 19:16:49: step 77/50000, loss = 0.198581 (0.811 sec/batch), lr: 1.000000
2019-03-16 19:16:50,628 2019-03-16 19:16:50: step 78/50000, loss = 0.206175 (0.710 sec/batch), lr: 1.000000
2019-03-16 19:16:51,357 2019-03-16 19:16:51: step 79/50000, loss = 0.202596 (0.724 sec/batch), lr: 1.000000
2019-03-16 19:16:52,069 2019-03-16 19:16:52: step 80/50000, loss = 0.198210 (0.707 sec/batch), lr: 1.000000
2019-03-16 19:16:52,654 2019-03-16 19:16:52: step 81/50000, loss = 0.205227 (0.581 sec/batch), lr: 1.000000
2019-03-16 19:16:53,261 2019-03-16 19:16:53: step 82/50000, loss = 0.201607 (0.602 sec/batch), lr: 1.000000
2019-03-16 19:16:53,890 2019-03-16 19:16:53: step 83/50000, loss = 0.209047 (0.626 sec/batch), lr: 1.000000
2019-03-16 19:16:54,427 2019-03-16 19:16:54: step 84/50000, loss = 0.196870 (0.533 sec/batch), lr: 1.000000
2019-03-16 19:16:54,961 2019-03-16 19:16:54: step 85/50000, loss = 0.197478 (0.530 sec/batch), lr: 1.000000
2019-03-16 19:16:55,496 2019-03-16 19:16:55: step 86/50000, loss = 0.186906 (0.531 sec/batch), lr: 1.000000
2019-03-16 19:16:55,949 2019-03-16 19:16:55: step 87/50000, loss = 0.190666 (0.450 sec/batch), lr: 1.000000
2019-03-16 19:16:56,401 2019-03-16 19:16:56: step 88/50000, loss = 0.189202 (0.448 sec/batch), lr: 1.000000
2019-03-16 19:16:56,761 2019-03-16 19:16:56: step 89/50000, loss = 0.180124 (0.356 sec/batch), lr: 1.000000
2019-03-16 19:16:57,138 2019-03-16 19:16:57: step 90/50000, loss = 0.186125 (0.373 sec/batch), lr: 1.000000
2019-03-16 19:16:57,497 2019-03-16 19:16:57: step 91/50000, loss = 0.149336 (0.355 sec/batch), lr: 1.000000
2019-03-16 19:16:57,813 2019-03-16 19:16:57: step 92/50000, loss = 0.180833 (0.313 sec/batch), lr: 1.000000
2019-03-16 19:16:58,119 2019-03-16 19:16:58: step 93/50000, loss = 0.159464 (0.303 sec/batch), lr: 1.000000
2019-03-16 19:16:58,381 2019-03-16 19:16:58: step 94/50000, loss = 0.167422 (0.259 sec/batch), lr: 1.000000
2019-03-16 19:16:58,634 2019-03-16 19:16:58: step 95/50000, loss = 0.143067 (0.250 sec/batch), lr: 1.000000
2019-03-16 19:16:58,842 2019-03-16 19:16:58: step 96/50000, loss = 0.170385 (0.206 sec/batch), lr: 1.000000
2019-03-16 19:16:58,995 2019-03-16 19:16:58: step 97/50000, loss = 0.107000 (0.151 sec/batch), lr: 1.000000
2019-03-16 19:16:59,121 2019-03-16 19:16:59: step 98/50000, loss = 0.096483 (0.123 sec/batch), lr: 1.000000
2019-03-16 19:16:59,218 2019-03-16 19:16:59: step 99/50000, loss = 0.079346 (0.096 sec/batch), lr: 1.000000
2019-03-16 19:16:59,289 2019-03-16 19:16:59: step 100/50000, loss = 0.049876 (0.071 sec/batch), lr: 1.000000
2019-03-16 19:17:25,047 step 100: Full loss = 0.186479, Edge acc. = 0.2268
2019-03-16 19:17:25,193 2019-03-16 19:17:25: step 101/50000, loss = 0.124666 (0.087 sec/batch), lr: 1.000000
2019-03-16 19:17:25,306 2019-03-16 19:17:25: step 102/50000, loss = 0.062719 (0.111 sec/batch), lr: 1.000000
2019-03-16 19:17:25,434 2019-03-16 19:17:25: step 103/50000, loss = 0.095820 (0.126 sec/batch), lr: 1.000000
2019-03-16 19:17:25,623 2019-03-16 19:17:25: step 104/50000, loss = 0.148733 (0.187 sec/batch), lr: 1.000000
2019-03-16 19:17:25,868 2019-03-16 19:17:25: step 105/50000, loss = 0.141038 (0.242 sec/batch), lr: 1.000000
2019-03-16 19:17:26,124 2019-03-16 19:17:26: step 106/50000, loss = 0.184070 (0.254 sec/batch), lr: 1.000000
2019-03-16 19:17:26,425 2019-03-16 19:17:26: step 107/50000, loss = 0.144522 (0.297 sec/batch), lr: 1.000000
2019-03-16 19:17:26,728 2019-03-16 19:17:26: step 108/50000, loss = 0.179935 (0.301 sec/batch), lr: 1.000000
2019-03-16 19:17:27,078 2019-03-16 19:17:27: step 109/50000, loss = 0.145876 (0.346 sec/batch), lr: 1.000000
2019-03-16 19:17:27,461 2019-03-16 19:17:27: step 110/50000, loss = 0.195000 (0.380 sec/batch), lr: 1.000000
2019-03-16 19:17:27,833 2019-03-16 19:17:27: step 111/50000, loss = 0.189170 (0.368 sec/batch), lr: 1.000000
2019-03-16 19:17:28,283 2019-03-16 19:17:28: step 112/50000, loss = 0.173561 (0.446 sec/batch), lr: 1.000000
2019-03-16 19:17:28,733 2019-03-16 19:17:28: step 113/50000, loss = 0.189910 (0.446 sec/batch), lr: 1.000000
2019-03-16 19:17:29,266 2019-03-16 19:17:29: step 114/50000, loss = 0.183258 (0.529 sec/batch), lr: 1.000000
2019-03-16 19:17:29,797 2019-03-16 19:17:29: step 115/50000, loss = 0.190391 (0.526 sec/batch), lr: 1.000000
2019-03-16 19:17:30,325 2019-03-16 19:17:30: step 116/50000, loss = 0.171963 (0.523 sec/batch), lr: 1.000000
2019-03-16 19:17:30,933 2019-03-16 19:17:30: step 117/50000, loss = 0.185032 (0.604 sec/batch), lr: 1.000000
2019-03-16 19:17:31,561 2019-03-16 19:17:31: step 118/50000, loss = 0.205632 (0.623 sec/batch), lr: 1.000000
2019-03-16 19:17:32,195 2019-03-16 19:17:32: step 119/50000, loss = 0.205087 (0.629 sec/batch), lr: 1.000000
2019-03-16 19:17:32,903 2019-03-16 19:17:32: step 120/50000, loss = 0.179957 (0.702 sec/batch), lr: 1.000000
2019-03-16 19:17:33,636 2019-03-16 19:17:33: step 121/50000, loss = 0.210963 (0.728 sec/batch), lr: 1.000000
2019-03-16 19:17:34,357 2019-03-16 19:17:34: step 122/50000, loss = 0.185026 (0.716 sec/batch), lr: 1.000000
2019-03-16 19:17:35,182 2019-03-16 19:17:35: step 123/50000, loss = 0.205227 (0.819 sec/batch), lr: 1.000000
2019-03-16 19:17:35,981 2019-03-16 19:17:35: step 124/50000, loss = 0.197350 (0.792 sec/batch), lr: 1.000000
2019-03-16 19:17:36,820 2019-03-16 19:17:36: step 125/50000, loss = 0.216058 (0.834 sec/batch), lr: 1.000000
2019-03-16 19:17:37,776 2019-03-16 19:17:37: step 126/50000, loss = 0.189051 (0.950 sec/batch), lr: 1.000000
2019-03-16 19:17:38,752 2019-03-16 19:17:38: step 127/50000, loss = 0.219750 (0.969 sec/batch), lr: 1.000000
2019-03-16 19:17:39,792 2019-03-16 19:17:39: step 128/50000, loss = 0.200347 (1.034 sec/batch), lr: 1.000000
2019-03-16 19:17:40,883 2019-03-16 19:17:40: step 129/50000, loss = 0.199965 (1.084 sec/batch), lr: 1.000000
2019-03-16 19:17:41,987 2019-03-16 19:17:41: step 130/50000, loss = 0.214675 (1.097 sec/batch), lr: 1.000000
2019-03-16 19:17:43,159 2019-03-16 19:17:43: step 131/50000, loss = 0.191578 (1.164 sec/batch), lr: 1.000000
2019-03-16 19:17:44,311 2019-03-16 19:17:44: step 132/50000, loss = 0.201979 (1.149 sec/batch), lr: 1.000000
2019-03-16 19:17:45,541 2019-03-16 19:17:45: step 133/50000, loss = 0.279419 (1.223 sec/batch), lr: 1.000000
2019-03-16 19:17:46,863 2019-03-16 19:17:46: step 134/50000, loss = 0.219659 (1.315 sec/batch), lr: 1.000000
2019-03-16 19:17:48,205 2019-03-16 19:17:48: step 135/50000, loss = 0.227019 (1.335 sec/batch), lr: 1.000000
2019-03-16 19:17:49,564 2019-03-16 19:17:49: step 136/50000, loss = 0.224730 (1.352 sec/batch), lr: 1.000000
2019-03-16 19:17:50,893 2019-03-16 19:17:50: step 137/50000, loss = 0.216799 (1.321 sec/batch), lr: 1.000000
2019-03-16 19:17:52,354 2019-03-16 19:17:52: step 138/50000, loss = 0.230966 (1.453 sec/batch), lr: 1.000000
2019-03-16 19:17:53,842 2019-03-16 19:17:53: step 139/50000, loss = 0.197436 (1.484 sec/batch), lr: 1.000000
2019-03-16 19:17:55,339 2019-03-16 19:17:55: step 140/50000, loss = 0.243840 (1.489 sec/batch), lr: 1.000000
2019-03-16 19:17:56,971 2019-03-16 19:17:56: step 141/50000, loss = 0.193714 (1.623 sec/batch), lr: 1.000000
2019-03-16 19:17:58,613 2019-03-16 19:17:58: step 142/50000, loss = 0.240130 (1.634 sec/batch), lr: 1.000000
2019-03-16 19:18:00,127 2019-03-16 19:18:00: step 143/50000, loss = 0.200061 (1.507 sec/batch), lr: 1.000000
2019-03-16 19:18:01,850 2019-03-16 19:18:01: step 144/50000, loss = 0.232404 (1.714 sec/batch), lr: 1.000000
2019-03-16 19:18:03,597 2019-03-16 19:18:03: step 145/50000, loss = 0.205461 (1.742 sec/batch), lr: 1.000000
2019-03-16 19:18:05,373 2019-03-16 19:18:05: step 146/50000, loss = 0.237089 (1.771 sec/batch), lr: 1.000000
2019-03-16 19:18:07,131 2019-03-16 19:18:07: step 147/50000, loss = 0.206519 (1.751 sec/batch), lr: 1.000000
2019-03-16 19:18:08,943 2019-03-16 19:18:08: step 148/50000, loss = 0.238588 (1.805 sec/batch), lr: 1.000000
2019-03-16 19:18:10,654 2019-03-16 19:18:10: step 149/50000, loss = 0.205329 (1.701 sec/batch), lr: 1.000000
2019-03-16 19:18:12,342 2019-03-16 19:18:12: step 150/50000, loss = 0.235488 (1.684 sec/batch), lr: 1.000000
2019-03-16 19:18:14,243 2019-03-16 19:18:14: step 151/50000, loss = 0.192972 (1.896 sec/batch), lr: 1.000000
2019-03-16 19:18:16,225 2019-03-16 19:18:16: step 152/50000, loss = 0.240839 (1.977 sec/batch), lr: 1.000000
2019-03-16 19:18:18,367 2019-03-16 19:18:18: step 153/50000, loss = 0.203747 (2.131 sec/batch), lr: 1.000000
2019-03-16 19:18:20,553 2019-03-16 19:18:20: step 154/50000, loss = 0.227943 (2.176 sec/batch), lr: 1.000000
2019-03-16 19:18:22,814 2019-03-16 19:18:22: step 155/50000, loss = 0.198094 (2.250 sec/batch), lr: 1.000000
2019-03-16 19:18:24,973 2019-03-16 19:18:24: step 156/50000, loss = 0.231243 (2.148 sec/batch), lr: 1.000000
2019-03-16 19:18:27,462 2019-03-16 19:18:27: step 157/50000, loss = 0.211749 (2.478 sec/batch), lr: 1.000000
2019-03-16 19:18:29,883 2019-03-16 19:18:29: step 158/50000, loss = 0.243249 (2.410 sec/batch), lr: 1.000000
2019-03-16 19:18:32,307 2019-03-16 19:18:32: step 159/50000, loss = 0.196360 (2.411 sec/batch), lr: 1.000000
2019-03-16 19:18:34,912 2019-03-16 19:18:34: step 160/50000, loss = 0.243047 (2.592 sec/batch), lr: 1.000000
2019-03-16 19:18:37,587 2019-03-16 19:18:37: step 161/50000, loss = 0.210208 (2.664 sec/batch), lr: 1.000000
2019-03-16 19:18:40,268 2019-03-16 19:18:40: step 162/50000, loss = 0.237557 (2.668 sec/batch), lr: 1.000000
2019-03-16 19:18:43,087 2019-03-16 19:18:43: step 163/50000, loss = 0.210357 (2.807 sec/batch), lr: 1.000000
2019-03-16 19:18:45,850 2019-03-16 19:18:45: step 164/50000, loss = 0.235420 (2.750 sec/batch), lr: 1.000000
2019-03-16 19:18:48,871 2019-03-16 19:18:48: step 165/50000, loss = 0.211411 (3.006 sec/batch), lr: 1.000000
2019-03-16 19:18:51,982 2019-03-16 19:18:51: step 166/50000, loss = 0.239783 (3.106 sec/batch), lr: 1.000000
2019-03-16 19:18:55,010 2019-03-16 19:18:55: step 167/50000, loss = 0.207752 (3.014 sec/batch), lr: 1.000000
2019-03-16 19:18:58,223 2019-03-16 19:18:58: step 168/50000, loss = 0.232487 (3.198 sec/batch), lr: 1.000000
2019-03-16 19:19:01,457 2019-03-16 19:19:01: step 169/50000, loss = 0.210993 (3.219 sec/batch), lr: 1.000000
2019-03-16 19:19:04,861 2019-03-16 19:19:04: step 170/50000, loss = 0.224188 (3.388 sec/batch), lr: 1.000000
2019-03-16 19:19:08,343 2019-03-16 19:19:08: step 171/50000, loss = 0.211967 (3.464 sec/batch), lr: 1.000000
2019-03-16 19:19:11,749 2019-03-16 19:19:11: step 172/50000, loss = 0.234914 (3.389 sec/batch), lr: 1.000000
2019-03-16 19:19:15,469 2019-03-16 19:19:15: step 173/50000, loss = 0.209848 (3.701 sec/batch), lr: 1.000000
2019-03-16 19:19:19,207 2019-03-16 19:19:19: step 174/50000, loss = 0.230362 (3.719 sec/batch), lr: 1.000000
2019-03-16 19:19:23,215 2019-03-16 19:19:23: step 175/50000, loss = 0.208979 (3.987 sec/batch), lr: 1.000000
2019-03-16 19:19:27,347 2019-03-16 19:19:27: step 176/50000, loss = 0.229285 (4.112 sec/batch), lr: 1.000000
2019-03-16 19:19:31,574 2019-03-16 19:19:31: step 177/50000, loss = 0.206600 (4.206 sec/batch), lr: 1.000000
2019-03-16 19:19:35,732 2019-03-16 19:19:35: step 178/50000, loss = 0.223485 (4.137 sec/batch), lr: 1.000000
2019-03-16 19:19:40,126 2019-03-16 19:19:40: step 179/50000, loss = 0.212789 (4.372 sec/batch), lr: 1.000000
2019-03-16 19:19:44,835 2019-03-16 19:19:44: step 180/50000, loss = 0.234562 (4.684 sec/batch), lr: 1.000000
2019-03-16 19:19:49,782 2019-03-16 19:19:49: step 181/50000, loss = 0.209069 (4.920 sec/batch), lr: 1.000000
2019-03-16 19:19:54,726 2019-03-16 19:19:54: step 182/50000, loss = 0.232596 (4.921 sec/batch), lr: 1.000000
2019-03-16 19:19:59,945 2019-03-16 19:19:59: step 183/50000, loss = 0.212923 (5.195 sec/batch), lr: 1.000000
2019-03-16 19:20:05,325 2019-03-16 19:20:05: step 184/50000, loss = 0.231308 (5.375 sec/batch), lr: 1.000000
2019-03-16 19:20:10,958 2019-03-16 19:20:10: step 185/50000, loss = 0.216237 (5.605 sec/batch), lr: 1.000000
2019-03-16 19:20:17,015 2019-03-16 19:20:17: step 186/50000, loss = 0.242984 (6.024 sec/batch), lr: 1.000000
2019-03-16 19:20:23,359 2019-03-16 19:20:23: step 187/50000, loss = 0.208565 (6.337 sec/batch), lr: 1.000000
2019-03-16 19:20:29,882 2019-03-16 19:20:29: step 188/50000, loss = 0.240659 (6.486 sec/batch), lr: 1.000000
2019-03-16 19:20:36,824 2019-03-16 19:20:36: step 189/50000, loss = 0.211498 (6.904 sec/batch), lr: 1.000000
2019-03-16 19:20:44,164 2019-03-16 19:20:44: step 190/50000, loss = 0.236506 (7.293 sec/batch), lr: 1.000000
2019-03-16 19:20:51,865 2019-03-16 19:20:51: step 191/50000, loss = 0.225975 (7.657 sec/batch), lr: 1.000000
2019-03-16 19:21:00,457 2019-03-16 19:21:00: step 192/50000, loss = 0.239911 (8.543 sec/batch), lr: 1.000000
2019-03-16 19:21:09,877 2019-03-16 19:21:09: step 193/50000, loss = 0.210310 (9.365 sec/batch), lr: 1.000000
2019-03-16 19:21:20,046 2019-03-16 19:21:20: step 194/50000, loss = 0.253347 (10.108 sec/batch), lr: 1.000000
2019-03-16 19:21:30,618 2019-03-16 19:21:30: step 195/50000, loss = 0.218555 (10.507 sec/batch), lr: 1.000000
2019-03-16 19:21:42,891 2019-03-16 19:21:42: step 196/50000, loss = 0.218778 (12.201 sec/batch), lr: 1.000000
2019-03-16 19:21:57,115 2019-03-16 19:21:57: step 197/50000, loss = 0.269504 (14.140 sec/batch), lr: 1.000000
2019-03-16 19:22:13,993 2019-03-16 19:22:13: step 198/50000, loss = 0.238333 (16.781 sec/batch), lr: 1.000000
2019-03-16 19:22:35,925 2019-03-16 19:22:35: step 199/50000, loss = 0.228495 (21.800 sec/batch), lr: 1.000000
2019-03-16 19:22:49,967 2019-03-16 19:22:49: step 200/50000, loss = 0.270388 (13.945 sec/batch), lr: 1.000000
2019-03-16 19:23:15,415 step 200: Full loss = 0.234095, Edge acc. = 0.2544
2019-03-16 19:23:46,059 2019-03-16 19:23:46: step 201/50000, loss = 0.177528 (30.481 sec/batch), lr: 0.500000
2019-03-16 19:24:03,594 2019-03-16 19:24:03: step 202/50000, loss = 0.220092 (17.434 sec/batch), lr: 0.500000
2019-03-16 19:24:17,655 2019-03-16 19:24:17: step 203/50000, loss = 0.224105 (13.981 sec/batch), lr: 0.500000
2019-03-16 19:24:29,670 2019-03-16 19:24:29: step 204/50000, loss = 0.217135 (11.943 sec/batch), lr: 0.500000
2019-03-16 19:24:40,465 2019-03-16 19:24:40: step 205/50000, loss = 0.230141 (10.730 sec/batch), lr: 0.500000
2019-03-16 19:24:50,605 2019-03-16 19:24:50: step 206/50000, loss = 0.214284 (10.081 sec/batch), lr: 0.500000
2019-03-16 19:24:59,981 2019-03-16 19:24:59: step 207/50000, loss = 0.239480 (9.321 sec/batch), lr: 0.500000
2019-03-16 19:25:08,550 2019-03-16 19:25:08: step 208/50000, loss = 0.210779 (8.561 sec/batch), lr: 0.500000
2019-03-16 19:25:16,013 2019-03-16 19:25:16: step 209/50000, loss = 0.224479 (7.422 sec/batch), lr: 0.500000
2019-03-16 19:25:23,282 2019-03-16 19:25:23: step 210/50000, loss = 0.216891 (7.263 sec/batch), lr: 0.500000
2019-03-16 19:25:30,228 2019-03-16 19:25:30: step 211/50000, loss = 0.227901 (6.908 sec/batch), lr: 0.500000
2019-03-16 19:25:36,861 2019-03-16 19:25:36: step 212/50000, loss = 0.208542 (6.597 sec/batch), lr: 0.500000
2019-03-16 19:25:43,206 2019-03-16 19:25:43: step 213/50000, loss = 0.224683 (6.310 sec/batch), lr: 0.500000
2019-03-16 19:25:49,222 2019-03-16 19:25:49: step 214/50000, loss = 0.214630 (6.009 sec/batch), lr: 0.500000
2019-03-16 19:25:54,985 2019-03-16 19:25:54: step 215/50000, loss = 0.222217 (5.733 sec/batch), lr: 0.500000
2019-03-16 19:26:00,382 2019-03-16 19:26:00: step 216/50000, loss = 0.206523 (5.368 sec/batch), lr: 0.500000
2019-03-16 19:26:05,773 2019-03-16 19:26:05: step 217/50000, loss = 0.216320 (5.364 sec/batch), lr: 0.500000
2019-03-16 19:26:11,068 2019-03-16 19:26:11: step 218/50000, loss = 0.203863 (5.272 sec/batch), lr: 0.500000
2019-03-16 19:26:15,895 2019-03-16 19:26:15: step 219/50000, loss = 0.208985 (4.802 sec/batch), lr: 0.500000
2019-03-16 19:26:20,460 2019-03-16 19:26:20: step 220/50000, loss = 0.205918 (4.534 sec/batch), lr: 0.500000
2019-03-16 19:26:24,683 2019-03-16 19:26:24: step 221/50000, loss = 0.224502 (4.202 sec/batch), lr: 0.500000
2019-03-16 19:26:28,973 2019-03-16 19:26:28: step 222/50000, loss = 0.203911 (4.269 sec/batch), lr: 0.500000
2019-03-16 19:26:33,055 2019-03-16 19:26:33: step 223/50000, loss = 0.208508 (4.063 sec/batch), lr: 0.500000
2019-03-16 19:26:36,967 2019-03-16 19:26:36: step 224/50000, loss = 0.196000 (3.892 sec/batch), lr: 0.500000
2019-03-16 19:26:40,833 2019-03-16 19:26:40: step 225/50000, loss = 0.193591 (3.848 sec/batch), lr: 0.500000
2019-03-16 19:26:44,443 2019-03-16 19:26:44: step 226/50000, loss = 0.209790 (3.592 sec/batch), lr: 0.500000
2019-03-16 19:26:48,087 2019-03-16 19:26:48: step 227/50000, loss = 0.205431 (3.638 sec/batch), lr: 0.500000
2019-03-16 19:26:51,539 2019-03-16 19:26:51: step 228/50000, loss = 0.211281 (3.435 sec/batch), lr: 0.500000
2019-03-16 19:26:54,945 2019-03-16 19:26:54: step 229/50000, loss = 0.205434 (3.390 sec/batch), lr: 0.500000
2019-03-16 19:26:58,308 2019-03-16 19:26:58: step 230/50000, loss = 0.199532 (3.348 sec/batch), lr: 0.500000
2019-03-16 19:27:01,495 2019-03-16 19:27:01: step 231/50000, loss = 0.206874 (3.172 sec/batch), lr: 0.500000
2019-03-16 19:27:04,533 2019-03-16 19:27:04: step 232/50000, loss = 0.205285 (3.024 sec/batch), lr: 0.500000
2019-03-16 19:27:07,336 2019-03-16 19:27:07: step 233/50000, loss = 0.202006 (2.792 sec/batch), lr: 0.500000
2019-03-16 19:27:10,079 2019-03-16 19:27:10: step 234/50000, loss = 0.191361 (2.731 sec/batch), lr: 0.500000
2019-03-16 19:27:13,065 2019-03-16 19:27:13: step 235/50000, loss = 0.204767 (2.972 sec/batch), lr: 0.500000
2019-03-16 19:27:15,832 2019-03-16 19:27:15: step 236/50000, loss = 0.200448 (2.755 sec/batch), lr: 0.500000
2019-03-16 19:27:18,660 2019-03-16 19:27:18: step 237/50000, loss = 0.200064 (2.815 sec/batch), lr: 0.500000
2019-03-16 19:27:21,263 2019-03-16 19:27:21: step 238/50000, loss = 0.205735 (2.594 sec/batch), lr: 0.500000
2019-03-16 19:27:23,733 2019-03-16 19:27:23: step 239/50000, loss = 0.203086 (2.459 sec/batch), lr: 0.500000
2019-03-16 19:27:26,241 2019-03-16 19:27:26: step 240/50000, loss = 0.199219 (2.496 sec/batch), lr: 0.500000
2019-03-16 19:27:28,872 2019-03-16 19:27:28: step 241/50000, loss = 0.205367 (2.620 sec/batch), lr: 0.500000
2019-03-16 19:27:31,239 2019-03-16 19:27:31: step 242/50000, loss = 0.201634 (2.356 sec/batch), lr: 0.500000
2019-03-16 19:27:33,531 2019-03-16 19:27:33: step 243/50000, loss = 0.199002 (2.283 sec/batch), lr: 0.500000
2019-03-16 19:27:35,872 2019-03-16 19:27:35: step 244/50000, loss = 0.177656 (2.337 sec/batch), lr: 0.500000
2019-03-16 19:27:37,945 2019-03-16 19:27:37: step 245/50000, loss = 0.190712 (2.064 sec/batch), lr: 0.500000
2019-03-16 19:27:40,036 2019-03-16 19:27:40: step 246/50000, loss = 0.190648 (2.082 sec/batch), lr: 0.500000
2019-03-16 19:27:42,167 2019-03-16 19:27:42: step 247/50000, loss = 0.192226 (2.121 sec/batch), lr: 0.500000
2019-03-16 19:27:44,336 2019-03-16 19:27:44: step 248/50000, loss = 0.187137 (2.158 sec/batch), lr: 0.500000
2019-03-16 19:27:46,418 2019-03-16 19:27:46: step 249/50000, loss = 0.195864 (2.072 sec/batch), lr: 0.500000
2019-03-16 19:27:48,344 2019-03-16 19:27:48: step 250/50000, loss = 0.188439 (1.916 sec/batch), lr: 0.500000
2019-03-16 19:27:50,294 2019-03-16 19:27:50: step 251/50000, loss = 0.190344 (1.940 sec/batch), lr: 0.500000
2019-03-16 19:27:52,206 2019-03-16 19:27:52: step 252/50000, loss = 0.185033 (1.905 sec/batch), lr: 0.500000
2019-03-16 19:27:54,133 2019-03-16 19:27:54: step 253/50000, loss = 0.192223 (1.919 sec/batch), lr: 0.500000
2019-03-16 19:27:55,750 2019-03-16 19:27:55: step 254/50000, loss = 0.194154 (1.610 sec/batch), lr: 0.500000
2019-03-16 19:27:57,488 2019-03-16 19:27:57: step 255/50000, loss = 0.195777 (1.730 sec/batch), lr: 0.500000
2019-03-16 19:27:59,224 2019-03-16 19:27:59: step 256/50000, loss = 0.189466 (1.727 sec/batch), lr: 0.500000
2019-03-16 19:28:00,780 2019-03-16 19:28:00: step 257/50000, loss = 0.194870 (1.550 sec/batch), lr: 0.500000
2019-03-16 19:28:02,211 2019-03-16 19:28:02: step 258/50000, loss = 0.184884 (1.426 sec/batch), lr: 0.500000
2019-03-16 19:28:03,675 2019-03-16 19:28:03: step 259/50000, loss = 0.179252 (1.459 sec/batch), lr: 0.500000
2019-03-16 19:28:04,899 2019-03-16 19:28:04: step 260/50000, loss = 0.191665 (1.221 sec/batch), lr: 0.500000
2019-03-16 19:28:06,178 2019-03-16 19:28:06: step 261/50000, loss = 0.191802 (1.273 sec/batch), lr: 0.500000
2019-03-16 19:28:07,598 2019-03-16 19:28:07: step 262/50000, loss = 0.175359 (1.413 sec/batch), lr: 0.500000
2019-03-16 19:28:08,912 2019-03-16 19:28:08: step 263/50000, loss = 0.187561 (1.307 sec/batch), lr: 0.500000
2019-03-16 19:28:10,101 2019-03-16 19:28:10: step 264/50000, loss = 0.176119 (1.184 sec/batch), lr: 0.500000
2019-03-16 19:28:11,386 2019-03-16 19:28:11: step 265/50000, loss = 0.194858 (1.281 sec/batch), lr: 0.500000
2019-03-16 19:28:12,532 2019-03-16 19:28:12: step 266/50000, loss = 0.177559 (1.140 sec/batch), lr: 0.500000
2019-03-16 19:28:13,757 2019-03-16 19:28:13: step 267/50000, loss = 0.178802 (1.218 sec/batch), lr: 0.500000
2019-03-16 19:28:14,954 2019-03-16 19:28:14: step 268/50000, loss = 0.188116 (1.191 sec/batch), lr: 0.500000
2019-03-16 19:28:16,022 2019-03-16 19:28:16: step 269/50000, loss = 0.183396 (1.064 sec/batch), lr: 0.500000
2019-03-16 19:28:16,994 2019-03-16 19:28:16: step 270/50000, loss = 0.176759 (0.968 sec/batch), lr: 0.500000
2019-03-16 19:28:17,888 2019-03-16 19:28:17: step 271/50000, loss = 0.183659 (0.890 sec/batch), lr: 0.500000
2019-03-16 19:28:18,815 2019-03-16 19:28:18: step 272/50000, loss = 0.167098 (0.922 sec/batch), lr: 0.500000
2019-03-16 19:28:19,752 2019-03-16 19:28:19: step 273/50000, loss = 0.179148 (0.931 sec/batch), lr: 0.500000
2019-03-16 19:28:20,674 2019-03-16 19:28:20: step 274/50000, loss = 0.178209 (0.916 sec/batch), lr: 0.500000
2019-03-16 19:28:21,490 2019-03-16 19:28:21: step 275/50000, loss = 0.170131 (0.812 sec/batch), lr: 0.500000
2019-03-16 19:28:22,307 2019-03-16 19:28:22: step 276/50000, loss = 0.183138 (0.812 sec/batch), lr: 0.500000
2019-03-16 19:28:23,044 2019-03-16 19:28:23: step 277/50000, loss = 0.165259 (0.731 sec/batch), lr: 0.500000
2019-03-16 19:28:23,697 2019-03-16 19:28:23: step 278/50000, loss = 0.179943 (0.650 sec/batch), lr: 0.500000
2019-03-16 19:28:24,318 2019-03-16 19:28:24: step 279/50000, loss = 0.182206 (0.617 sec/batch), lr: 0.500000
2019-03-16 19:28:24,944 2019-03-16 19:28:24: step 280/50000, loss = 0.170915 (0.621 sec/batch), lr: 0.500000
2019-03-16 19:28:25,452 2019-03-16 19:28:25: step 281/50000, loss = 0.183616 (0.506 sec/batch), lr: 0.500000
2019-03-16 19:28:26,032 2019-03-16 19:28:26: step 282/50000, loss = 0.179556 (0.577 sec/batch), lr: 0.500000
2019-03-16 19:28:26,641 2019-03-16 19:28:26: step 283/50000, loss = 0.179204 (0.604 sec/batch), lr: 0.500000
2019-03-16 19:28:27,179 2019-03-16 19:28:27: step 284/50000, loss = 0.178406 (0.534 sec/batch), lr: 0.500000
2019-03-16 19:28:27,708 2019-03-16 19:28:27: step 285/50000, loss = 0.178056 (0.524 sec/batch), lr: 0.500000
2019-03-16 19:28:28,238 2019-03-16 19:28:28: step 286/50000, loss = 0.166056 (0.525 sec/batch), lr: 0.500000
2019-03-16 19:28:28,694 2019-03-16 19:28:28: step 287/50000, loss = 0.174344 (0.453 sec/batch), lr: 0.500000
2019-03-16 19:28:29,119 2019-03-16 19:28:29: step 288/50000, loss = 0.165210 (0.421 sec/batch), lr: 0.500000
2019-03-16 19:28:29,479 2019-03-16 19:28:29: step 289/50000, loss = 0.168317 (0.357 sec/batch), lr: 0.500000
2019-03-16 19:28:29,855 2019-03-16 19:28:29: step 290/50000, loss = 0.172845 (0.372 sec/batch), lr: 0.500000
2019-03-16 19:28:30,204 2019-03-16 19:28:30: step 291/50000, loss = 0.155487 (0.347 sec/batch), lr: 0.500000
2019-03-16 19:28:30,521 2019-03-16 19:28:30: step 292/50000, loss = 0.160640 (0.313 sec/batch), lr: 0.500000
2019-03-16 19:28:30,821 2019-03-16 19:28:30: step 293/50000, loss = 0.140789 (0.297 sec/batch), lr: 0.500000
2019-03-16 19:28:31,081 2019-03-16 19:28:31: step 294/50000, loss = 0.166426 (0.258 sec/batch), lr: 0.500000
2019-03-16 19:28:31,316 2019-03-16 19:28:31: step 295/50000, loss = 0.146708 (0.233 sec/batch), lr: 0.500000
2019-03-16 19:28:31,526 2019-03-16 19:28:31: step 296/50000, loss = 0.153197 (0.208 sec/batch), lr: 0.500000
2019-03-16 19:28:31,677 2019-03-16 19:28:31: step 297/50000, loss = 0.093033 (0.148 sec/batch), lr: 0.500000
2019-03-16 19:28:31,821 2019-03-16 19:28:31: step 298/50000, loss = 0.068823 (0.143 sec/batch), lr: 0.500000
2019-03-16 19:28:31,956 2019-03-16 19:28:31: step 299/50000, loss = 0.060083 (0.132 sec/batch), lr: 0.500000
2019-03-16 19:28:32,038 2019-03-16 19:28:32: step 300/50000, loss = 0.057160 (0.082 sec/batch), lr: 0.500000
2019-03-16 19:28:57,219 step 300: Full loss = 0.189050, Edge acc. = 0.3496
2019-03-16 19:29:27,574 2019-03-16 19:29:27: step 301/50000, loss = 0.294414 (30.132 sec/batch), lr: 0.500000
2019-03-16 19:29:44,315 2019-03-16 19:29:44: step 302/50000, loss = 0.345618 (16.733 sec/batch), lr: 0.500000
2019-03-16 19:29:58,341 2019-03-16 19:29:58: step 303/50000, loss = 0.321689 (14.017 sec/batch), lr: 0.500000
2019-03-16 19:30:10,247 2019-03-16 19:30:10: step 304/50000, loss = 0.295797 (11.897 sec/batch), lr: 0.500000
2019-03-16 19:30:20,860 2019-03-16 19:30:20: step 305/50000, loss = 0.263980 (10.606 sec/batch), lr: 0.500000
2019-03-16 19:30:30,874 2019-03-16 19:30:30: step 306/50000, loss = 0.232656 (9.955 sec/batch), lr: 0.500000
2019-03-16 19:30:40,067 2019-03-16 19:30:40: step 307/50000, loss = 0.222072 (9.143 sec/batch), lr: 0.500000
2019-03-16 19:30:48,631 2019-03-16 19:30:48: step 308/50000, loss = 0.210867 (8.514 sec/batch), lr: 0.500000
2019-03-16 19:30:56,273 2019-03-16 19:30:56: step 309/50000, loss = 0.230117 (7.600 sec/batch), lr: 0.500000
2019-03-16 19:31:03,416 2019-03-16 19:31:03: step 310/50000, loss = 0.219287 (7.105 sec/batch), lr: 0.500000
2019-03-16 19:31:10,245 2019-03-16 19:31:10: step 311/50000, loss = 0.226791 (6.824 sec/batch), lr: 0.500000
2019-03-16 19:31:16,842 2019-03-16 19:31:16: step 312/50000, loss = 0.205107 (6.562 sec/batch), lr: 0.500000
2019-03-16 19:31:23,288 2019-03-16 19:31:23: step 313/50000, loss = 0.228858 (6.439 sec/batch), lr: 0.500000
2019-03-16 19:31:29,236 2019-03-16 19:31:29: step 314/50000, loss = 0.210411 (5.916 sec/batch), lr: 0.500000
2019-03-16 19:31:34,974 2019-03-16 19:31:34: step 315/50000, loss = 0.217346 (5.733 sec/batch), lr: 0.500000
2019-03-16 19:31:40,427 2019-03-16 19:31:40: step 316/50000, loss = 0.206665 (5.424 sec/batch), lr: 0.500000
2019-03-16 19:31:45,854 2019-03-16 19:31:45: step 317/50000, loss = 0.212913 (5.398 sec/batch), lr: 0.500000
2019-03-16 19:31:50,721 2019-03-16 19:31:50: step 318/50000, loss = 0.204469 (4.862 sec/batch), lr: 0.500000
2019-03-16 19:31:55,578 2019-03-16 19:31:55: step 319/50000, loss = 0.208365 (4.832 sec/batch), lr: 0.500000
2019-03-16 19:32:00,187 2019-03-16 19:32:00: step 320/50000, loss = 0.202069 (4.586 sec/batch), lr: 0.500000
2019-03-16 19:32:04,519 2019-03-16 19:32:04: step 321/50000, loss = 0.218783 (4.312 sec/batch), lr: 0.500000
2019-03-16 19:32:08,567 2019-03-16 19:32:08: step 322/50000, loss = 0.201943 (4.027 sec/batch), lr: 0.500000
2019-03-16 19:32:12,716 2019-03-16 19:32:12: step 323/50000, loss = 0.214849 (4.128 sec/batch), lr: 0.500000
2019-03-16 19:32:16,681 2019-03-16 19:32:16: step 324/50000, loss = 0.187377 (3.947 sec/batch), lr: 0.500000
2019-03-16 19:32:20,651 2019-03-16 19:32:20: step 325/50000, loss = 0.199131 (3.965 sec/batch), lr: 0.500000
2019-03-16 19:32:24,293 2019-03-16 19:32:24: step 326/50000, loss = 0.203645 (3.625 sec/batch), lr: 0.500000
2019-03-16 19:32:27,996 2019-03-16 19:32:27: step 327/50000, loss = 0.208547 (3.684 sec/batch), lr: 0.500000
2019-03-16 19:32:31,460 2019-03-16 19:32:31: step 328/50000, loss = 0.201693 (3.449 sec/batch), lr: 0.500000
2019-03-16 19:32:34,846 2019-03-16 19:32:34: step 329/50000, loss = 0.204366 (3.371 sec/batch), lr: 0.500000
2019-03-16 19:32:38,197 2019-03-16 19:32:38: step 330/50000, loss = 0.192444 (3.345 sec/batch), lr: 0.500000
2019-03-16 19:32:41,439 2019-03-16 19:32:41: step 331/50000, loss = 0.203831 (3.236 sec/batch), lr: 0.500000
2019-03-16 19:32:44,578 2019-03-16 19:32:44: step 332/50000, loss = 0.201079 (3.119 sec/batch), lr: 0.500000
2019-03-16 19:32:47,668 2019-03-16 19:32:47: step 333/50000, loss = 0.209622 (3.084 sec/batch), lr: 0.500000
2019-03-16 19:32:50,675 2019-03-16 19:32:50: step 334/50000, loss = 0.193867 (2.995 sec/batch), lr: 0.500000
2019-03-16 19:32:53,583 2019-03-16 19:32:53: step 335/50000, loss = 0.193494 (2.895 sec/batch), lr: 0.500000
2019-03-16 19:32:56,419 2019-03-16 19:32:56: step 336/50000, loss = 0.196347 (2.831 sec/batch), lr: 0.500000
2019-03-16 19:32:59,273 2019-03-16 19:32:59: step 337/50000, loss = 0.201975 (2.840 sec/batch), lr: 0.500000
2019-03-16 19:33:01,946 2019-03-16 19:33:01: step 338/50000, loss = 0.201911 (2.668 sec/batch), lr: 0.500000
2019-03-16 19:33:04,563 2019-03-16 19:33:04: step 339/50000, loss = 0.194109 (2.606 sec/batch), lr: 0.500000
2019-03-16 19:33:07,200 2019-03-16 19:33:07: step 340/50000, loss = 0.196734 (2.632 sec/batch), lr: 0.500000
2019-03-16 19:33:09,722 2019-03-16 19:33:09: step 341/50000, loss = 0.204595 (2.511 sec/batch), lr: 0.500000
2019-03-16 19:33:12,121 2019-03-16 19:33:12: step 342/50000, loss = 0.199064 (2.389 sec/batch), lr: 0.500000
2019-03-16 19:33:14,380 2019-03-16 19:33:14: step 343/50000, loss = 0.198335 (2.249 sec/batch), lr: 0.500000
2019-03-16 19:33:16,598 2019-03-16 19:33:16: step 344/50000, loss = 0.176556 (2.208 sec/batch), lr: 0.500000
2019-03-16 19:33:18,833 2019-03-16 19:33:18: step 345/50000, loss = 0.188111 (2.230 sec/batch), lr: 0.500000
2019-03-16 19:33:21,137 2019-03-16 19:33:21: step 346/50000, loss = 0.181678 (2.294 sec/batch), lr: 0.500000
2019-03-16 19:33:23,135 2019-03-16 19:33:23: step 347/50000, loss = 0.190410 (1.991 sec/batch), lr: 0.500000
2019-03-16 19:33:25,076 2019-03-16 19:33:25: step 348/50000, loss = 0.182868 (1.932 sec/batch), lr: 0.500000
2019-03-16 19:33:27,185 2019-03-16 19:33:27: step 349/50000, loss = 0.187592 (2.099 sec/batch), lr: 0.500000
2019-03-16 19:33:29,098 2019-03-16 19:33:29: step 350/50000, loss = 0.181903 (1.904 sec/batch), lr: 0.500000
2019-03-16 19:33:30,724 2019-03-16 19:33:30: step 351/50000, loss = 0.187844 (1.617 sec/batch), lr: 0.500000
2019-03-16 19:33:32,466 2019-03-16 19:33:32: step 352/50000, loss = 0.181651 (1.738 sec/batch), lr: 0.500000
2019-03-16 19:33:34,095 2019-03-16 19:33:34: step 353/50000, loss = 0.188267 (1.621 sec/batch), lr: 0.500000
2019-03-16 19:33:35,753 2019-03-16 19:33:35: step 354/50000, loss = 0.189682 (1.650 sec/batch), lr: 0.500000
2019-03-16 19:33:37,405 2019-03-16 19:33:37: step 355/50000, loss = 0.187286 (1.644 sec/batch), lr: 0.500000
2019-03-16 19:33:38,997 2019-03-16 19:33:38: step 356/50000, loss = 0.185432 (1.584 sec/batch), lr: 0.500000
2019-03-16 19:33:40,481 2019-03-16 19:33:40: step 357/50000, loss = 0.189387 (1.477 sec/batch), lr: 0.500000
2019-03-16 19:33:42,086 2019-03-16 19:33:42: step 358/50000, loss = 0.181107 (1.598 sec/batch), lr: 0.500000
2019-03-16 19:33:43,632 2019-03-16 19:33:43: step 359/50000, loss = 0.172411 (1.538 sec/batch), lr: 0.500000
2019-03-16 19:33:45,067 2019-03-16 19:33:45: step 360/50000, loss = 0.175592 (1.431 sec/batch), lr: 0.500000
2019-03-16 19:33:46,536 2019-03-16 19:33:46: step 361/50000, loss = 0.193016 (1.464 sec/batch), lr: 0.500000
2019-03-16 19:33:47,825 2019-03-16 19:33:47: step 362/50000, loss = 0.180386 (1.284 sec/batch), lr: 0.500000
2019-03-16 19:33:48,982 2019-03-16 19:33:48: step 363/50000, loss = 0.193188 (1.153 sec/batch), lr: 0.500000
2019-03-16 19:33:50,077 2019-03-16 19:33:50: step 364/50000, loss = 0.178417 (1.090 sec/batch), lr: 0.500000
2019-03-16 19:33:51,170 2019-03-16 19:33:51: step 365/50000, loss = 0.186311 (1.086 sec/batch), lr: 0.500000
2019-03-16 19:33:52,225 2019-03-16 19:33:52: step 366/50000, loss = 0.172185 (1.052 sec/batch), lr: 0.500000
2019-03-16 19:33:53,158 2019-03-16 19:33:53: step 367/50000, loss = 0.185231 (0.931 sec/batch), lr: 0.500000
2019-03-16 19:33:54,139 2019-03-16 19:33:54: step 368/50000, loss = 0.187500 (0.977 sec/batch), lr: 0.500000
2019-03-16 19:33:55,114 2019-03-16 19:33:55: step 369/50000, loss = 0.186476 (0.970 sec/batch), lr: 0.500000
2019-03-16 19:33:56,058 2019-03-16 19:33:56: step 370/50000, loss = 0.179967 (0.939 sec/batch), lr: 0.500000
2019-03-16 19:33:56,897 2019-03-16 19:33:56: step 371/50000, loss = 0.177248 (0.835 sec/batch), lr: 0.500000
2019-03-16 19:33:57,811 2019-03-16 19:33:57: step 372/50000, loss = 0.159763 (0.908 sec/batch), lr: 0.500000
2019-03-16 19:33:58,757 2019-03-16 19:33:58: step 373/50000, loss = 0.169354 (0.942 sec/batch), lr: 0.500000
2019-03-16 19:33:59,681 2019-03-16 19:33:59: step 374/50000, loss = 0.180947 (0.919 sec/batch), lr: 0.500000
2019-03-16 19:34:00,520 2019-03-16 19:34:00: step 375/50000, loss = 0.165333 (0.834 sec/batch), lr: 0.500000
2019-03-16 19:34:01,350 2019-03-16 19:34:01: step 376/50000, loss = 0.180661 (0.825 sec/batch), lr: 0.500000
2019-03-16 19:34:02,089 2019-03-16 19:34:02: step 377/50000, loss = 0.164350 (0.733 sec/batch), lr: 0.500000
2019-03-16 19:34:02,753 2019-03-16 19:34:02: step 378/50000, loss = 0.186538 (0.659 sec/batch), lr: 0.500000
2019-03-16 19:34:03,374 2019-03-16 19:34:03: step 379/50000, loss = 0.171694 (0.618 sec/batch), lr: 0.500000
2019-03-16 19:34:03,918 2019-03-16 19:34:03: step 380/50000, loss = 0.161563 (0.543 sec/batch), lr: 0.500000
2019-03-16 19:34:04,440 2019-03-16 19:34:04: step 381/50000, loss = 0.184735 (0.518 sec/batch), lr: 0.500000
2019-03-16 19:34:04,952 2019-03-16 19:34:04: step 382/50000, loss = 0.183503 (0.509 sec/batch), lr: 0.500000
2019-03-16 19:34:05,548 2019-03-16 19:34:05: step 383/50000, loss = 0.182154 (0.592 sec/batch), lr: 0.500000
2019-03-16 19:34:05,992 2019-03-16 19:34:05: step 384/50000, loss = 0.174537 (0.440 sec/batch), lr: 0.500000
2019-03-16 19:34:06,466 2019-03-16 19:34:06: step 385/50000, loss = 0.181612 (0.471 sec/batch), lr: 0.500000
2019-03-16 19:34:06,954 2019-03-16 19:34:06: step 386/50000, loss = 0.178164 (0.485 sec/batch), lr: 0.500000
2019-03-16 19:34:07,324 2019-03-16 19:34:07: step 387/50000, loss = 0.162791 (0.368 sec/batch), lr: 0.500000
2019-03-16 19:34:07,694 2019-03-16 19:34:07: step 388/50000, loss = 0.163781 (0.367 sec/batch), lr: 0.500000
2019-03-16 19:34:07,991 2019-03-16 19:34:07: step 389/50000, loss = 0.164169 (0.296 sec/batch), lr: 0.500000
2019-03-16 19:34:08,293 2019-03-16 19:34:08: step 390/50000, loss = 0.164680 (0.300 sec/batch), lr: 0.500000
2019-03-16 19:34:08,602 2019-03-16 19:34:08: step 391/50000, loss = 0.146929 (0.306 sec/batch), lr: 0.500000
2019-03-16 19:34:08,893 2019-03-16 19:34:08: step 392/50000, loss = 0.164100 (0.288 sec/batch), lr: 0.500000
2019-03-16 19:34:09,156 2019-03-16 19:34:09: step 393/50000, loss = 0.146988 (0.261 sec/batch), lr: 0.500000
2019-03-16 19:34:09,378 2019-03-16 19:34:09: step 394/50000, loss = 0.164888 (0.220 sec/batch), lr: 0.500000
2019-03-16 19:34:09,588 2019-03-16 19:34:09: step 395/50000, loss = 0.139494 (0.208 sec/batch), lr: 0.500000
2019-03-16 19:34:09,763 2019-03-16 19:34:09: step 396/50000, loss = 0.152528 (0.173 sec/batch), lr: 0.500000
2019-03-16 19:34:09,892 2019-03-16 19:34:09: step 397/50000, loss = 0.105865 (0.127 sec/batch), lr: 0.500000
2019-03-16 19:34:10,012 2019-03-16 19:34:10: step 398/50000, loss = 0.049791 (0.119 sec/batch), lr: 0.500000
2019-03-16 19:34:10,111 2019-03-16 19:34:10: step 399/50000, loss = 0.055353 (0.097 sec/batch), lr: 0.500000
2019-03-16 19:34:10,181 2019-03-16 19:34:10: step 400/50000, loss = 0.022888 (0.070 sec/batch), lr: 0.500000
2019-03-16 19:34:35,292 step 400: Full loss = 0.173642, Edge acc. = 0.3045
2019-03-16 19:34:35,440 2019-03-16 19:34:35: step 401/50000, loss = 0.061556 (0.091 sec/batch), lr: 0.250000
2019-03-16 19:34:35,538 2019-03-16 19:34:35: step 402/50000, loss = 0.040949 (0.096 sec/batch), lr: 0.250000
2019-03-16 19:34:35,635 2019-03-16 19:34:35: step 403/50000, loss = 0.096498 (0.096 sec/batch), lr: 0.250000
2019-03-16 19:34:35,791 2019-03-16 19:34:35: step 404/50000, loss = 0.130617 (0.155 sec/batch), lr: 0.250000
2019-03-16 19:34:35,999 2019-03-16 19:34:35: step 405/50000, loss = 0.133901 (0.205 sec/batch), lr: 0.250000
2019-03-16 19:34:36,226 2019-03-16 19:34:36: step 406/50000, loss = 0.171185 (0.225 sec/batch), lr: 0.250000
2019-03-16 19:34:36,493 2019-03-16 19:34:36: step 407/50000, loss = 0.135769 (0.263 sec/batch), lr: 0.250000
2019-03-16 19:34:36,785 2019-03-16 19:34:36: step 408/50000, loss = 0.180562 (0.290 sec/batch), lr: 0.250000
2019-03-16 19:34:37,136 2019-03-16 19:34:37: step 409/50000, loss = 0.131529 (0.348 sec/batch), lr: 0.250000
2019-03-16 19:34:37,484 2019-03-16 19:34:37: step 410/50000, loss = 0.168950 (0.344 sec/batch), lr: 0.250000
2019-03-16 19:34:37,841 2019-03-16 19:34:37: step 411/50000, loss = 0.165168 (0.354 sec/batch), lr: 0.250000
2019-03-16 19:34:38,262 2019-03-16 19:34:38: step 412/50000, loss = 0.163555 (0.417 sec/batch), lr: 0.250000
2019-03-16 19:34:38,691 2019-03-16 19:34:38: step 413/50000, loss = 0.152858 (0.425 sec/batch), lr: 0.250000
2019-03-16 19:34:39,220 2019-03-16 19:34:39: step 414/50000, loss = 0.166545 (0.524 sec/batch), lr: 0.250000
2019-03-16 19:34:39,737 2019-03-16 19:34:39: step 415/50000, loss = 0.173313 (0.513 sec/batch), lr: 0.250000
2019-03-16 19:34:40,255 2019-03-16 19:34:40: step 416/50000, loss = 0.166648 (0.514 sec/batch), lr: 0.250000
2019-03-16 19:34:40,874 2019-03-16 19:34:40: step 417/50000, loss = 0.170388 (0.614 sec/batch), lr: 0.250000
2019-03-16 19:34:41,495 2019-03-16 19:34:41: step 418/50000, loss = 0.185203 (0.616 sec/batch), lr: 0.250000
2019-03-16 19:34:42,117 2019-03-16 19:34:42: step 419/50000, loss = 0.183372 (0.616 sec/batch), lr: 0.250000
2019-03-16 19:34:42,799 2019-03-16 19:34:42: step 420/50000, loss = 0.168107 (0.678 sec/batch), lr: 0.250000
2019-03-16 19:34:43,504 2019-03-16 19:34:43: step 421/50000, loss = 0.174026 (0.700 sec/batch), lr: 0.250000
2019-03-16 19:34:44,225 2019-03-16 19:34:44: step 422/50000, loss = 0.176911 (0.716 sec/batch), lr: 0.250000
2019-03-16 19:34:45,009 2019-03-16 19:34:45: step 423/50000, loss = 0.176372 (0.779 sec/batch), lr: 0.250000
2019-03-16 19:34:45,737 2019-03-16 19:34:45: step 424/50000, loss = 0.173356 (0.725 sec/batch), lr: 0.250000
2019-03-16 19:34:46,433 2019-03-16 19:34:46: step 425/50000, loss = 0.174679 (0.693 sec/batch), lr: 0.250000
2019-03-16 19:34:47,256 2019-03-16 19:34:47: step 426/50000, loss = 0.157377 (0.819 sec/batch), lr: 0.250000
2019-03-16 19:34:48,168 2019-03-16 19:34:48: step 427/50000, loss = 0.178884 (0.907 sec/batch), lr: 0.250000
2019-03-16 19:34:49,080 2019-03-16 19:34:49: step 428/50000, loss = 0.166707 (0.908 sec/batch), lr: 0.250000
2019-03-16 19:34:50,009 2019-03-16 19:34:50: step 429/50000, loss = 0.175630 (0.925 sec/batch), lr: 0.250000
2019-03-16 19:34:50,926 2019-03-16 19:34:50: step 430/50000, loss = 0.174637 (0.914 sec/batch), lr: 0.250000
2019-03-16 19:34:51,980 2019-03-16 19:34:51: step 431/50000, loss = 0.182467 (1.049 sec/batch), lr: 0.250000
2019-03-16 19:34:53,169 2019-03-16 19:34:53: step 432/50000, loss = 0.174770 (1.184 sec/batch), lr: 0.250000
2019-03-16 19:34:54,331 2019-03-16 19:34:54: step 433/50000, loss = 0.180756 (1.156 sec/batch), lr: 0.250000
2019-03-16 19:34:55,439 2019-03-16 19:34:55: step 434/50000, loss = 0.167937 (1.104 sec/batch), lr: 0.250000
2019-03-16 19:34:56,608 2019-03-16 19:34:56: step 435/50000, loss = 0.183023 (1.165 sec/batch), lr: 0.250000
2019-03-16 19:34:57,777 2019-03-16 19:34:57: step 436/50000, loss = 0.187571 (1.163 sec/batch), lr: 0.250000
2019-03-16 19:34:58,960 2019-03-16 19:34:58: step 437/50000, loss = 0.191097 (1.178 sec/batch), lr: 0.250000
2019-03-16 19:35:00,243 2019-03-16 19:35:00: step 438/50000, loss = 0.173982 (1.277 sec/batch), lr: 0.250000
2019-03-16 19:35:01,683 2019-03-16 19:35:01: step 439/50000, loss = 0.172724 (1.432 sec/batch), lr: 0.250000
2019-03-16 19:35:03,058 2019-03-16 19:35:03: step 440/50000, loss = 0.179245 (1.369 sec/batch), lr: 0.250000
2019-03-16 19:35:04,498 2019-03-16 19:35:04: step 441/50000, loss = 0.173100 (1.437 sec/batch), lr: 0.250000
2019-03-16 19:35:05,976 2019-03-16 19:35:05: step 442/50000, loss = 0.191394 (1.470 sec/batch), lr: 0.250000
2019-03-16 19:35:07,573 2019-03-16 19:35:07: step 443/50000, loss = 0.169391 (1.589 sec/batch), lr: 0.250000
2019-03-16 19:35:09,236 2019-03-16 19:35:09: step 444/50000, loss = 0.171189 (1.656 sec/batch), lr: 0.250000
2019-03-16 19:35:10,687 2019-03-16 19:35:10: step 445/50000, loss = 0.170669 (1.446 sec/batch), lr: 0.250000
2019-03-16 19:35:12,138 2019-03-16 19:35:12: step 446/50000, loss = 0.191390 (1.444 sec/batch), lr: 0.250000
2019-03-16 19:35:13,901 2019-03-16 19:35:13: step 447/50000, loss = 0.170821 (1.755 sec/batch), lr: 0.250000
2019-03-16 19:35:15,704 2019-03-16 19:35:15: step 448/50000, loss = 0.180458 (1.793 sec/batch), lr: 0.250000
2019-03-16 19:35:17,461 2019-03-16 19:35:17: step 449/50000, loss = 0.184662 (1.748 sec/batch), lr: 0.250000
2019-03-16 19:35:19,239 2019-03-16 19:35:19: step 450/50000, loss = 0.180739 (1.771 sec/batch), lr: 0.250000
2019-03-16 19:35:21,036 2019-03-16 19:35:21: step 451/50000, loss = 0.178193 (1.790 sec/batch), lr: 0.250000
2019-03-16 19:35:22,862 2019-03-16 19:35:22: step 452/50000, loss = 0.183674 (1.815 sec/batch), lr: 0.250000
2019-03-16 19:35:24,748 2019-03-16 19:35:24: step 453/50000, loss = 0.187176 (1.876 sec/batch), lr: 0.250000
2019-03-16 19:35:26,815 2019-03-16 19:35:26: step 454/50000, loss = 0.178493 (2.059 sec/batch), lr: 0.250000
2019-03-16 19:35:28,833 2019-03-16 19:35:28: step 455/50000, loss = 0.177031 (2.011 sec/batch), lr: 0.250000
2019-03-16 19:35:30,722 2019-03-16 19:35:30: step 456/50000, loss = 0.183216 (1.886 sec/batch), lr: 0.250000
2019-03-16 19:35:32,921 2019-03-16 19:35:32: step 457/50000, loss = 0.196889 (2.196 sec/batch), lr: 0.250000
2019-03-16 19:35:35,219 2019-03-16 19:35:35: step 458/50000, loss = 0.188949 (2.290 sec/batch), lr: 0.250000
2019-03-16 19:35:37,601 2019-03-16 19:35:37: step 459/50000, loss = 0.183917 (2.379 sec/batch), lr: 0.250000
2019-03-16 19:35:40,066 2019-03-16 19:35:40: step 460/50000, loss = 0.189408 (2.456 sec/batch), lr: 0.250000
2019-03-16 19:35:42,542 2019-03-16 19:35:42: step 461/50000, loss = 0.185802 (2.467 sec/batch), lr: 0.250000
2019-03-16 19:35:45,049 2019-03-16 19:35:45: step 462/50000, loss = 0.192367 (2.496 sec/batch), lr: 0.250000
2019-03-16 19:35:47,823 2019-03-16 19:35:47: step 463/50000, loss = 0.194015 (2.761 sec/batch), lr: 0.250000
2019-03-16 19:35:50,392 2019-03-16 19:35:50: step 464/50000, loss = 0.193603 (2.559 sec/batch), lr: 0.250000
2019-03-16 19:35:53,015 2019-03-16 19:35:53: step 465/50000, loss = 0.181441 (2.619 sec/batch), lr: 0.250000
2019-03-16 19:35:55,756 2019-03-16 19:35:55: step 466/50000, loss = 0.193942 (2.736 sec/batch), lr: 0.250000
2019-03-16 19:35:58,508 2019-03-16 19:35:58: step 467/50000, loss = 0.182275 (2.738 sec/batch), lr: 0.250000
2019-03-16 19:36:01,647 2019-03-16 19:36:01: step 468/50000, loss = 0.192644 (3.125 sec/batch), lr: 0.250000
2019-03-16 19:36:04,863 2019-03-16 19:36:04: step 469/50000, loss = 0.192951 (3.201 sec/batch), lr: 0.250000
2019-03-16 19:36:08,246 2019-03-16 19:36:08: step 470/50000, loss = 0.194181 (3.366 sec/batch), lr: 0.250000
2019-03-16 19:36:11,462 2019-03-16 19:36:11: step 471/50000, loss = 0.187763 (3.203 sec/batch), lr: 0.250000
2019-03-16 19:36:14,747 2019-03-16 19:36:14: step 472/50000, loss = 0.192782 (3.263 sec/batch), lr: 0.250000
2019-03-16 19:36:18,421 2019-03-16 19:36:18: step 473/50000, loss = 0.199285 (3.656 sec/batch), lr: 0.250000
2019-03-16 19:36:22,062 2019-03-16 19:36:22: step 474/50000, loss = 0.185084 (3.622 sec/batch), lr: 0.250000
2019-03-16 19:36:25,917 2019-03-16 19:36:25: step 475/50000, loss = 0.192641 (3.850 sec/batch), lr: 0.250000
2019-03-16 19:36:29,802 2019-03-16 19:36:29: step 476/50000, loss = 0.188056 (3.867 sec/batch), lr: 0.250000
2019-03-16 19:36:33,865 2019-03-16 19:36:33: step 477/50000, loss = 0.194860 (4.044 sec/batch), lr: 0.250000
2019-03-16 19:36:38,220 2019-03-16 19:36:38: step 478/50000, loss = 0.193409 (4.349 sec/batch), lr: 0.250000
2019-03-16 19:36:42,346 2019-03-16 19:36:42: step 479/50000, loss = 0.190435 (4.121 sec/batch), lr: 0.250000
2019-03-16 19:36:46,988 2019-03-16 19:36:46: step 480/50000, loss = 0.200544 (4.620 sec/batch), lr: 0.250000
2019-03-16 19:36:51,846 2019-03-16 19:36:51: step 481/50000, loss = 0.188665 (4.836 sec/batch), lr: 0.250000
2019-03-16 19:36:56,635 2019-03-16 19:36:56: step 482/50000, loss = 0.193592 (4.766 sec/batch), lr: 0.250000
2019-03-16 19:37:01,844 2019-03-16 19:37:01: step 483/50000, loss = 0.202245 (5.183 sec/batch), lr: 0.250000
2019-03-16 19:37:07,244 2019-03-16 19:37:07: step 484/50000, loss = 0.194684 (5.374 sec/batch), lr: 0.250000
2019-03-16 19:37:12,829 2019-03-16 19:37:12: step 485/50000, loss = 0.198911 (5.558 sec/batch), lr: 0.250000
2019-03-16 19:37:18,717 2019-03-16 19:37:18: step 486/50000, loss = 0.204416 (5.861 sec/batch), lr: 0.250000
2019-03-16 19:37:24,921 2019-03-16 19:37:24: step 487/50000, loss = 0.194029 (6.172 sec/batch), lr: 0.250000
2019-03-16 19:37:31,439 2019-03-16 19:37:31: step 488/50000, loss = 0.211773 (6.485 sec/batch), lr: 0.250000
2019-03-16 19:37:38,128 2019-03-16 19:37:38: step 489/50000, loss = 0.202458 (6.657 sec/batch), lr: 0.250000
2019-03-16 19:37:45,229 2019-03-16 19:37:45: step 490/50000, loss = 0.201366 (7.065 sec/batch), lr: 0.250000
2019-03-16 19:37:52,688 2019-03-16 19:37:52: step 491/50000, loss = 0.216349 (7.453 sec/batch), lr: 0.250000
2019-03-16 19:38:01,138 2019-03-16 19:38:01: step 492/50000, loss = 0.206587 (8.404 sec/batch), lr: 0.250000
2019-03-16 19:38:10,408 2019-03-16 19:38:10: step 493/50000, loss = 0.203385 (9.216 sec/batch), lr: 0.250000
2019-03-16 19:38:20,222 2019-03-16 19:38:20: step 494/50000, loss = 0.213474 (9.756 sec/batch), lr: 0.250000
2019-03-16 19:38:30,617 2019-03-16 19:38:30: step 495/50000, loss = 0.222650 (10.338 sec/batch), lr: 0.250000
2019-03-16 19:38:42,364 2019-03-16 19:38:42: step 496/50000, loss = 0.202458 (11.677 sec/batch), lr: 0.250000
2019-03-16 19:38:56,332 2019-03-16 19:38:56: step 497/50000, loss = 0.209394 (13.959 sec/batch), lr: 0.250000
2019-03-16 19:39:12,927 2019-03-16 19:39:12: step 498/50000, loss = 0.219090 (16.505 sec/batch), lr: 0.250000
2019-03-16 19:39:34,580 2019-03-16 19:39:34: step 499/50000, loss = 0.201078 (21.515 sec/batch), lr: 0.250000
2019-03-16 19:39:48,579 2019-03-16 19:39:48: step 500/50000, loss = 0.243099 (13.904 sec/batch), lr: 0.250000
2019-03-16 19:40:13,697 step 500: Full loss = 0.182578, Edge acc. = 0.2832
2019-03-16 19:40:13,837 2019-03-16 19:40:13: step 501/50000, loss = 0.379468 (0.083 sec/batch), lr: 0.250000
2019-03-16 19:40:13,949 2019-03-16 19:40:13: step 502/50000, loss = 0.157196 (0.110 sec/batch), lr: 0.250000
2019-03-16 19:40:14,071 2019-03-16 19:40:14: step 503/50000, loss = 0.134457 (0.120 sec/batch), lr: 0.250000
2019-03-16 19:40:14,219 2019-03-16 19:40:14: step 504/50000, loss = 0.132549 (0.147 sec/batch), lr: 0.250000
2019-03-16 19:40:14,409 2019-03-16 19:40:14: step 505/50000, loss = 0.140119 (0.188 sec/batch), lr: 0.250000
2019-03-16 19:40:14,617 2019-03-16 19:40:14: step 506/50000, loss = 0.164829 (0.206 sec/batch), lr: 0.250000
2019-03-16 19:40:14,875 2019-03-16 19:40:14: step 507/50000, loss = 0.147195 (0.256 sec/batch), lr: 0.250000
2019-03-16 19:40:15,177 2019-03-16 19:40:15: step 508/50000, loss = 0.170963 (0.299 sec/batch), lr: 0.250000
2019-03-16 19:40:15,504 2019-03-16 19:40:15: step 509/50000, loss = 0.145859 (0.324 sec/batch), lr: 0.250000
2019-03-16 19:40:15,836 2019-03-16 19:40:15: step 510/50000, loss = 0.178931 (0.329 sec/batch), lr: 0.250000
2019-03-16 19:40:16,207 2019-03-16 19:40:16: step 511/50000, loss = 0.164901 (0.367 sec/batch), lr: 0.250000
2019-03-16 19:40:16,649 2019-03-16 19:40:16: step 512/50000, loss = 0.162393 (0.438 sec/batch), lr: 0.250000
2019-03-16 19:40:17,098 2019-03-16 19:40:17: step 513/50000, loss = 0.160058 (0.446 sec/batch), lr: 0.250000
2019-03-16 19:40:17,624 2019-03-16 19:40:17: step 514/50000, loss = 0.167119 (0.522 sec/batch), lr: 0.250000
2019-03-16 19:40:18,142 2019-03-16 19:40:18: step 515/50000, loss = 0.183333 (0.514 sec/batch), lr: 0.250000
2019-03-16 19:40:18,631 2019-03-16 19:40:18: step 516/50000, loss = 0.173085 (0.486 sec/batch), lr: 0.250000
2019-03-16 19:40:19,212 2019-03-16 19:40:19: step 517/50000, loss = 0.167196 (0.577 sec/batch), lr: 0.250000
2019-03-16 19:40:19,805 2019-03-16 19:40:19: step 518/50000, loss = 0.187717 (0.589 sec/batch), lr: 0.250000
2019-03-16 19:40:20,410 2019-03-16 19:40:20: step 519/50000, loss = 0.175364 (0.601 sec/batch), lr: 0.250000
2019-03-16 19:40:21,100 2019-03-16 19:40:21: step 520/50000, loss = 0.167278 (0.685 sec/batch), lr: 0.250000
2019-03-16 19:40:21,798 2019-03-16 19:40:21: step 521/50000, loss = 0.159879 (0.695 sec/batch), lr: 0.250000
2019-03-16 19:40:22,482 2019-03-16 19:40:22: step 522/50000, loss = 0.176554 (0.679 sec/batch), lr: 0.250000
2019-03-16 19:40:23,183 2019-03-16 19:40:23: step 523/50000, loss = 0.166345 (0.697 sec/batch), lr: 0.250000
2019-03-16 19:40:24,004 2019-03-16 19:40:24: step 524/50000, loss = 0.164743 (0.816 sec/batch), lr: 0.250000
2019-03-16 19:40:24,848 2019-03-16 19:40:24: step 525/50000, loss = 0.171253 (0.838 sec/batch), lr: 0.250000
2019-03-16 19:40:25,721 2019-03-16 19:40:25: step 526/50000, loss = 0.159489 (0.867 sec/batch), lr: 0.250000
2019-03-16 19:40:26,559 2019-03-16 19:40:26: step 527/50000, loss = 0.177077 (0.832 sec/batch), lr: 0.250000
2019-03-16 19:40:27,524 2019-03-16 19:40:27: step 528/50000, loss = 0.165747 (0.961 sec/batch), lr: 0.250000
2019-03-16 19:40:28,597 2019-03-16 19:40:28: step 529/50000, loss = 0.167470 (1.066 sec/batch), lr: 0.250000
2019-03-16 19:40:29,679 2019-03-16 19:40:29: step 530/50000, loss = 0.176665 (1.075 sec/batch), lr: 0.250000
2019-03-16 19:40:30,892 2019-03-16 19:40:30: step 531/50000, loss = 0.169160 (1.209 sec/batch), lr: 0.250000
2019-03-16 19:40:31,943 2019-03-16 19:40:31: step 532/50000, loss = 0.174794 (1.045 sec/batch), lr: 0.250000
2019-03-16 19:40:33,011 2019-03-16 19:40:33: step 533/50000, loss = 0.179300 (1.062 sec/batch), lr: 0.250000
2019-03-16 19:40:34,235 2019-03-16 19:40:34: step 534/50000, loss = 0.165488 (1.218 sec/batch), lr: 0.250000
2019-03-16 19:40:35,546 2019-03-16 19:40:35: step 535/50000, loss = 0.188955 (1.304 sec/batch), lr: 0.250000
2019-03-16 19:40:36,817 2019-03-16 19:40:36: step 536/50000, loss = 0.165716 (1.264 sec/batch), lr: 0.250000
2019-03-16 19:40:38,017 2019-03-16 19:40:38: step 537/50000, loss = 0.185412 (1.194 sec/batch), lr: 0.250000
2019-03-16 19:40:39,407 2019-03-16 19:40:39: step 538/50000, loss = 0.161634 (1.383 sec/batch), lr: 0.250000
2019-03-16 19:40:40,878 2019-03-16 19:40:40: step 539/50000, loss = 0.176565 (1.463 sec/batch), lr: 0.250000
2019-03-16 19:40:42,250 2019-03-16 19:40:42: step 540/50000, loss = 0.178462 (1.368 sec/batch), lr: 0.250000
2019-03-16 19:40:43,689 2019-03-16 19:40:43: step 541/50000, loss = 0.172964 (1.433 sec/batch), lr: 0.250000
2019-03-16 19:40:45,243 2019-03-16 19:40:45: step 542/50000, loss = 0.183811 (1.547 sec/batch), lr: 0.250000
2019-03-16 19:46:25,930 2019-03-16 19:46:25: step 1/50000, loss = 0.334436 (49.664 sec/batch), lr: 1.000000
2019-03-16 19:46:49,426 2019-03-16 19:46:49: step 2/50000, loss = 0.441510 (23.360 sec/batch), lr: 1.000000
2019-03-16 19:47:07,784 2019-03-16 19:47:07: step 3/50000, loss = 0.454779 (18.342 sec/batch), lr: 1.000000
2019-03-16 19:47:23,302 2019-03-16 19:47:23: step 4/50000, loss = 0.454172 (15.435 sec/batch), lr: 1.000000
2019-03-16 19:47:35,968 2019-03-16 19:47:35: step 5/50000, loss = 0.457554 (12.656 sec/batch), lr: 1.000000
2019-03-16 19:47:47,384 2019-03-16 19:47:47: step 6/50000, loss = 0.446155 (11.349 sec/batch), lr: 1.000000
2019-03-16 19:47:57,897 2019-03-16 19:47:57: step 7/50000, loss = 0.440297 (10.502 sec/batch), lr: 1.000000
2019-03-16 19:48:07,394 2019-03-16 19:48:07: step 8/50000, loss = 0.398086 (9.443 sec/batch), lr: 1.000000
2019-03-16 19:48:16,335 2019-03-16 19:48:16: step 9/50000, loss = 0.281469 (8.890 sec/batch), lr: 1.000000
2019-03-16 19:48:24,462 2019-03-16 19:48:24: step 10/50000, loss = 0.433304 (8.083 sec/batch), lr: 1.000000
2019-03-16 19:48:31,663 2019-03-16 19:48:31: step 11/50000, loss = 0.256254 (7.162 sec/batch), lr: 1.000000
2019-03-16 19:48:38,561 2019-03-16 19:48:38: step 12/50000, loss = 0.431002 (6.860 sec/batch), lr: 1.000000
2019-03-16 19:48:45,021 2019-03-16 19:48:45: step 13/50000, loss = 0.233283 (6.424 sec/batch), lr: 1.000000
2019-03-16 19:48:50,852 2019-03-16 19:48:50: step 14/50000, loss = 0.418979 (5.822 sec/batch), lr: 1.000000
2019-03-16 19:48:56,509 2019-03-16 19:48:56: step 15/50000, loss = 0.226450 (5.650 sec/batch), lr: 1.000000
2019-03-16 19:49:01,850 2019-03-16 19:49:01: step 16/50000, loss = 0.423358 (5.312 sec/batch), lr: 1.000000
2019-03-16 19:49:06,876 2019-03-16 19:49:06: step 17/50000, loss = 0.221973 (4.999 sec/batch), lr: 1.000000
2019-03-16 19:49:11,822 2019-03-16 19:49:11: step 18/50000, loss = 0.402533 (4.920 sec/batch), lr: 1.000000
2019-03-16 19:49:16,109 2019-03-16 19:49:16: step 19/50000, loss = 0.224212 (4.263 sec/batch), lr: 1.000000
2019-03-16 19:49:20,113 2019-03-16 19:49:20: step 20/50000, loss = 0.416662 (3.995 sec/batch), lr: 1.000000
2019-03-16 19:49:24,204 2019-03-16 19:49:24: step 21/50000, loss = 0.208435 (4.069 sec/batch), lr: 1.000000
2019-03-16 19:49:28,168 2019-03-16 19:49:28: step 22/50000, loss = 0.398992 (3.943 sec/batch), lr: 1.000000
2019-03-16 19:49:31,873 2019-03-16 19:49:31: step 23/50000, loss = 0.202782 (3.696 sec/batch), lr: 1.000000
2019-03-16 19:49:35,277 2019-03-16 19:49:35: step 24/50000, loss = 0.395909 (3.385 sec/batch), lr: 1.000000
2019-03-16 19:49:38,557 2019-03-16 19:49:38: step 25/50000, loss = 0.209353 (3.263 sec/batch), lr: 1.000000
2019-03-16 19:49:41,713 2019-03-16 19:49:41: step 26/50000, loss = 0.393705 (3.138 sec/batch), lr: 1.000000
2019-03-16 19:49:44,464 2019-03-16 19:49:44: step 27/50000, loss = 0.210832 (2.735 sec/batch), lr: 1.000000
2019-03-16 19:49:47,182 2019-03-16 19:49:47: step 28/50000, loss = 0.383252 (2.702 sec/batch), lr: 1.000000
2019-03-16 19:49:49,618 2019-03-16 19:49:49: step 29/50000, loss = 0.209505 (2.423 sec/batch), lr: 1.000000
2019-03-16 19:49:51,945 2019-03-16 19:49:51: step 30/50000, loss = 0.364408 (2.316 sec/batch), lr: 1.000000
2019-03-16 19:49:54,250 2019-03-16 19:49:54: step 31/50000, loss = 0.202994 (2.297 sec/batch), lr: 1.000000
2019-03-16 19:49:56,406 2019-03-16 19:49:56: step 32/50000, loss = 0.361012 (2.144 sec/batch), lr: 1.000000
2019-03-16 19:49:58,480 2019-03-16 19:49:58: step 33/50000, loss = 0.215515 (2.062 sec/batch), lr: 1.000000
2019-03-16 19:50:00,176 2019-03-16 19:50:00: step 34/50000, loss = 0.356140 (1.689 sec/batch), lr: 1.000000
2019-03-16 19:50:01,896 2019-03-16 19:50:01: step 35/50000, loss = 0.200577 (1.711 sec/batch), lr: 1.000000
2019-03-16 19:50:03,432 2019-03-16 19:50:03: step 36/50000, loss = 0.338139 (1.529 sec/batch), lr: 1.000000
2019-03-16 19:50:04,943 2019-03-16 19:50:04: step 37/50000, loss = 0.202800 (1.505 sec/batch), lr: 1.000000
2019-03-16 19:50:06,323 2019-03-16 19:50:06: step 38/50000, loss = 0.310444 (1.369 sec/batch), lr: 1.000000
2019-03-16 19:50:07,520 2019-03-16 19:50:07: step 39/50000, loss = 0.189529 (1.191 sec/batch), lr: 1.000000
2019-03-16 19:50:08,485 2019-03-16 19:50:08: step 40/50000, loss = 0.311186 (0.956 sec/batch), lr: 1.000000
2019-03-16 19:50:09,322 2019-03-16 19:50:09: step 41/50000, loss = 0.209785 (0.829 sec/batch), lr: 1.000000
2019-03-16 19:50:10,233 2019-03-16 19:50:10: step 42/50000, loss = 0.296366 (0.903 sec/batch), lr: 1.000000
2019-03-16 19:50:11,037 2019-03-16 19:50:11: step 43/50000, loss = 0.214526 (0.797 sec/batch), lr: 1.000000
2019-03-16 19:50:11,715 2019-03-16 19:50:11: step 44/50000, loss = 0.290485 (0.671 sec/batch), lr: 1.000000
2019-03-16 19:50:12,219 2019-03-16 19:50:12: step 45/50000, loss = 0.239106 (0.497 sec/batch), lr: 1.000000
2019-03-16 19:50:12,666 2019-03-16 19:50:12: step 46/50000, loss = 0.244582 (0.444 sec/batch), lr: 1.000000
2019-03-16 19:50:13,032 2019-03-16 19:50:13: step 47/50000, loss = 0.236469 (0.361 sec/batch), lr: 1.000000
2019-03-16 19:50:13,308 2019-03-16 19:50:13: step 48/50000, loss = 0.208102 (0.272 sec/batch), lr: 1.000000
2019-03-16 19:50:13,514 2019-03-16 19:50:13: step 49/50000, loss = 0.305363 (0.202 sec/batch), lr: 1.000000
2019-03-16 19:50:13,611 2019-03-16 19:50:13: step 50/50000, loss = 0.235603 (0.095 sec/batch), lr: 1.000000
2019-03-16 19:50:13,747 2019-03-16 19:50:13: step 51/50000, loss = 0.232334 (0.131 sec/batch), lr: 1.000000
2019-03-16 19:50:13,964 2019-03-16 19:50:13: step 52/50000, loss = 0.299227 (0.214 sec/batch), lr: 1.000000
2019-03-16 19:50:14,245 2019-03-16 19:50:14: step 53/50000, loss = 0.183647 (0.278 sec/batch), lr: 1.000000
2019-03-16 19:50:14,601 2019-03-16 19:50:14: step 54/50000, loss = 1.589275 (0.354 sec/batch), lr: 1.000000
2019-03-16 19:50:15,062 2019-03-16 19:50:15: step 55/50000, loss = 0.777315 (0.456 sec/batch), lr: 1.000000
2019-03-16 19:50:15,621 2019-03-16 19:50:15: step 56/50000, loss = 0.546938 (0.554 sec/batch), lr: 1.000000
2019-03-16 19:50:16,206 2019-03-16 19:50:16: step 57/50000, loss = 0.509852 (0.581 sec/batch), lr: 1.000000
2019-03-16 19:50:16,907 2019-03-16 19:50:16: step 58/50000, loss = 0.528245 (0.694 sec/batch), lr: 1.000000
2019-03-16 19:50:17,783 2019-03-16 19:50:17: step 59/50000, loss = 0.517118 (0.869 sec/batch), lr: 1.000000
2019-03-16 19:50:18,792 2019-03-16 19:50:18: step 60/50000, loss = 0.473929 (1.001 sec/batch), lr: 1.000000
2019-03-16 19:50:19,861 2019-03-16 19:50:19: step 61/50000, loss = 0.513414 (1.061 sec/batch), lr: 1.000000
2019-03-16 19:50:20,975 2019-03-16 19:50:20: step 62/50000, loss = 0.498474 (1.105 sec/batch), lr: 1.000000
2019-03-16 19:50:22,247 2019-03-16 19:50:22: step 63/50000, loss = 0.489663 (1.264 sec/batch), lr: 1.000000
2019-03-16 19:50:23,766 2019-03-16 19:50:23: step 64/50000, loss = 0.475318 (1.509 sec/batch), lr: 1.000000
2019-03-16 19:50:25,310 2019-03-16 19:50:25: step 65/50000, loss = 0.506935 (1.536 sec/batch), lr: 1.000000
2019-03-16 19:50:27,108 2019-03-16 19:50:27: step 66/50000, loss = 0.505655 (1.786 sec/batch), lr: 1.000000
2019-03-16 19:50:29,121 2019-03-16 19:50:29: step 67/50000, loss = 0.474914 (2.000 sec/batch), lr: 1.000000
2019-03-16 19:50:31,182 2019-03-16 19:50:31: step 68/50000, loss = 0.504115 (2.049 sec/batch), lr: 1.000000
2019-03-16 19:50:33,297 2019-03-16 19:50:33: step 69/50000, loss = 0.478254 (2.099 sec/batch), lr: 1.000000
2019-03-16 19:50:35,967 2019-03-16 19:50:35: step 70/50000, loss = 0.502792 (2.658 sec/batch), lr: 1.000000
2019-03-16 19:50:38,952 2019-03-16 19:50:38: step 71/50000, loss = 0.496659 (2.972 sec/batch), lr: 1.000000
2019-03-16 19:50:42,165 2019-03-16 19:50:42: step 72/50000, loss = 0.483216 (3.196 sec/batch), lr: 1.000000
2019-03-16 19:50:45,065 2019-03-16 19:50:45: step 73/50000, loss = 0.501194 (2.883 sec/batch), lr: 1.000000
2019-03-16 19:50:48,206 2019-03-16 19:50:48: step 74/50000, loss = 0.496975 (3.125 sec/batch), lr: 1.000000
2019-03-16 19:50:51,227 2019-03-16 19:50:51: step 75/50000, loss = 0.500269 (3.003 sec/batch), lr: 1.000000
2019-03-16 19:50:54,461 2019-03-16 19:50:54: step 76/50000, loss = 0.497456 (3.213 sec/batch), lr: 1.000000
2019-03-16 19:50:57,997 2019-03-16 19:50:57: step 77/50000, loss = 0.484657 (3.516 sec/batch), lr: 1.000000
2019-03-16 19:51:01,679 2019-03-16 19:51:01: step 78/50000, loss = 0.499011 (3.662 sec/batch), lr: 1.000000
2019-03-16 19:51:05,996 2019-03-16 19:51:05: step 79/50000, loss = 0.498643 (4.295 sec/batch), lr: 1.000000
2019-03-16 19:51:10,127 2019-03-16 19:51:10: step 80/50000, loss = 0.488899 (4.107 sec/batch), lr: 1.000000
2019-03-16 19:51:14,311 2019-03-16 19:51:14: step 81/50000, loss = 0.497906 (4.160 sec/batch), lr: 1.000000
2019-03-16 19:51:18,998 2019-03-16 19:51:18: step 82/50000, loss = 0.496539 (4.662 sec/batch), lr: 1.000000
2019-03-16 19:51:24,006 2019-03-16 19:51:24: step 83/50000, loss = 0.492421 (4.981 sec/batch), lr: 1.000000
2019-03-16 19:51:29,284 2019-03-16 19:51:29: step 84/50000, loss = 0.483953 (5.248 sec/batch), lr: 1.000000
2019-03-16 19:51:34,857 2019-03-16 19:51:34: step 85/50000, loss = 0.480545 (5.544 sec/batch), lr: 1.000000
2019-03-16 19:51:40,662 2019-03-16 19:51:40: step 86/50000, loss = 0.496197 (5.773 sec/batch), lr: 1.000000
2019-03-16 19:51:46,833 2019-03-16 19:51:46: step 87/50000, loss = 0.492348 (6.136 sec/batch), lr: 1.000000
2019-03-16 19:51:53,667 2019-03-16 19:51:53: step 88/50000, loss = 0.479423 (6.785 sec/batch), lr: 1.000000
2019-03-16 19:52:00,884 2019-03-16 19:52:00: step 89/50000, loss = 0.481952 (7.179 sec/batch), lr: 1.000000
2019-03-16 19:52:08,603 2019-03-16 19:52:08: step 90/50000, loss = 0.486519 (7.676 sec/batch), lr: 1.000000
2019-03-16 19:52:16,870 2019-03-16 19:52:16: step 91/50000, loss = 0.490857 (8.220 sec/batch), lr: 1.000000
2019-03-16 19:52:25,991 2019-03-16 19:52:25: step 92/50000, loss = 0.487266 (9.068 sec/batch), lr: 1.000000
2019-03-16 19:52:36,057 2019-03-16 19:52:36: step 93/50000, loss = 0.484093 (10.007 sec/batch), lr: 1.000000
2019-03-16 19:52:47,112 2019-03-16 19:52:47: step 94/50000, loss = 0.480591 (10.995 sec/batch), lr: 1.000000
2019-03-16 19:52:59,171 2019-03-16 19:52:59: step 95/50000, loss = 0.479636 (11.989 sec/batch), lr: 1.000000
2019-03-16 19:53:13,475 2019-03-16 19:53:13: step 96/50000, loss = 0.467735 (14.220 sec/batch), lr: 1.000000
2019-03-16 19:53:30,444 2019-03-16 19:53:30: step 97/50000, loss = 0.473005 (16.866 sec/batch), lr: 1.000000
2019-03-16 19:53:50,323 2019-03-16 19:53:50: step 98/50000, loss = 0.461504 (19.758 sec/batch), lr: 1.000000
2019-03-16 19:54:18,276 2019-03-16 19:54:18: step 99/50000, loss = 0.443213 (27.790 sec/batch), lr: 1.000000
2019-03-16 19:54:52,018 2019-03-16 19:54:52: step 100/50000, loss = 0.374144 (33.563 sec/batch), lr: 1.000000
2019-03-16 19:55:19,986 step 100: Full loss = 0.261761, Edge acc. = 0.2564
2019-03-16 19:55:20,045 step 100: Dev acc. = 0.403435
2019-03-16 19:56:09,360 2019-03-16 19:56:09: step 101/50000, loss = 0.350054 (49.077 sec/batch), lr: 1.000000
2019-03-16 19:56:32,692 2019-03-16 19:56:32: step 102/50000, loss = 0.452165 (23.170 sec/batch), lr: 1.000000
2019-03-16 19:56:51,388 2019-03-16 19:56:51: step 103/50000, loss = 0.468195 (18.585 sec/batch), lr: 1.000000
2019-03-16 19:57:07,243 2019-03-16 19:57:07: step 104/50000, loss = 0.469867 (15.759 sec/batch), lr: 1.000000
2019-03-16 19:57:19,761 2019-03-16 19:57:19: step 105/50000, loss = 0.476830 (12.443 sec/batch), lr: 1.000000
2019-03-16 19:57:31,073 2019-03-16 19:57:31: step 106/50000, loss = 0.470124 (11.303 sec/batch), lr: 1.000000
2019-03-16 19:57:41,650 2019-03-16 19:57:41: step 107/50000, loss = 0.473205 (10.566 sec/batch), lr: 1.000000
2019-03-16 19:57:51,247 2019-03-16 19:57:51: step 108/50000, loss = 0.472082 (9.540 sec/batch), lr: 1.000000
2019-03-16 19:58:00,216 2019-03-16 19:58:00: step 109/50000, loss = 0.455543 (8.917 sec/batch), lr: 1.000000
2019-03-16 19:58:08,370 2019-03-16 19:58:08: step 110/50000, loss = 0.457280 (8.108 sec/batch), lr: 1.000000
2019-03-16 19:58:15,667 2019-03-16 19:58:15: step 111/50000, loss = 0.445696 (7.287 sec/batch), lr: 1.000000
2019-03-16 19:58:22,545 2019-03-16 19:58:22: step 112/50000, loss = 0.370659 (6.839 sec/batch), lr: 1.000000
2019-03-16 19:58:29,021 2019-03-16 19:58:29: step 113/50000, loss = 0.502483 (6.441 sec/batch), lr: 1.000000
2019-03-16 19:58:35,016 2019-03-16 19:58:35: step 114/50000, loss = 0.476011 (5.961 sec/batch), lr: 1.000000
2019-03-16 19:58:40,535 2019-03-16 19:58:40: step 115/50000, loss = 0.439214 (5.491 sec/batch), lr: 1.000000
2019-03-16 19:58:45,594 2019-03-16 19:58:45: step 116/50000, loss = 0.296417 (5.052 sec/batch), lr: 1.000000
2019-03-16 19:58:50,622 2019-03-16 19:58:50: step 117/50000, loss = 0.320449 (5.001 sec/batch), lr: 1.000000
2019-03-16 19:58:55,527 2019-03-16 19:58:55: step 118/50000, loss = 0.209009 (4.879 sec/batch), lr: 1.000000
2019-03-16 19:59:00,085 2019-03-16 19:59:00: step 119/50000, loss = 0.323555 (4.532 sec/batch), lr: 1.000000
2019-03-16 19:59:04,281 2019-03-16 19:59:04: step 120/50000, loss = 0.679725 (4.173 sec/batch), lr: 1.000000
2019-03-16 19:59:08,319 2019-03-16 19:59:08: step 121/50000, loss = 0.457411 (4.015 sec/batch), lr: 1.000000
2019-03-16 19:59:12,253 2019-03-16 19:59:12: step 122/50000, loss = 0.346217 (3.913 sec/batch), lr: 1.000000
2019-03-16 19:59:15,807 2019-03-16 19:59:15: step 123/50000, loss = 0.289197 (3.533 sec/batch), lr: 1.000000
2019-03-16 19:59:19,137 2019-03-16 19:59:19: step 124/50000, loss = 0.209255 (3.315 sec/batch), lr: 1.000000
2019-03-16 19:59:22,346 2019-03-16 19:59:22: step 125/50000, loss = 0.341569 (3.193 sec/batch), lr: 1.000000
2019-03-16 19:59:25,469 2019-03-16 19:59:25: step 126/50000, loss = 0.216208 (3.106 sec/batch), lr: 1.000000
2019-03-16 19:59:28,524 2019-03-16 19:59:28: step 127/50000, loss = 0.329940 (3.047 sec/batch), lr: 1.000000
2019-03-16 19:59:31,244 2019-03-16 19:59:31: step 128/50000, loss = 0.219378 (2.712 sec/batch), lr: 1.000000
2019-03-16 19:59:33,663 2019-03-16 19:59:33: step 129/50000, loss = 0.325782 (2.406 sec/batch), lr: 1.000000
2019-03-16 19:59:36,096 2019-03-16 19:59:36: step 130/50000, loss = 0.214240 (2.422 sec/batch), lr: 1.000000
2019-03-16 19:59:38,331 2019-03-16 19:59:38: step 131/50000, loss = 0.319086 (2.221 sec/batch), lr: 1.000000
2019-03-16 19:59:40,499 2019-03-16 19:59:40: step 132/50000, loss = 0.227439 (2.160 sec/batch), lr: 1.000000
2019-03-16 19:59:42,612 2019-03-16 19:59:42: step 133/50000, loss = 0.313843 (2.099 sec/batch), lr: 1.000000
2019-03-16 19:59:44,517 2019-03-16 19:59:44: step 134/50000, loss = 0.223351 (1.893 sec/batch), lr: 1.000000
2019-03-16 19:59:46,374 2019-03-16 19:59:46: step 135/50000, loss = 0.300654 (1.850 sec/batch), lr: 1.000000
2019-03-16 19:59:48,038 2019-03-16 19:59:48: step 136/50000, loss = 0.214232 (1.654 sec/batch), lr: 1.000000
2019-03-16 19:59:49,366 2019-03-16 19:59:49: step 137/50000, loss = 0.297049 (1.320 sec/batch), lr: 1.000000
2019-03-16 19:59:50,627 2019-03-16 19:59:50: step 138/50000, loss = 0.207531 (1.255 sec/batch), lr: 1.000000
2019-03-16 19:59:51,709 2019-03-16 19:59:51: step 139/50000, loss = 0.270362 (1.079 sec/batch), lr: 1.000000
2019-03-16 19:59:52,661 2019-03-16 19:59:52: step 140/50000, loss = 0.223649 (0.945 sec/batch), lr: 1.000000
2019-03-16 19:59:53,494 2019-03-16 19:59:53: step 141/50000, loss = 0.281901 (0.827 sec/batch), lr: 1.000000
2019-03-16 19:59:54,309 2019-03-16 19:59:54: step 142/50000, loss = 0.231158 (0.809 sec/batch), lr: 1.000000
2019-03-16 19:59:55,065 2019-03-16 19:59:55: step 143/50000, loss = 0.276201 (0.749 sec/batch), lr: 1.000000
2019-03-16 19:59:55,671 2019-03-16 19:59:55: step 144/50000, loss = 0.252816 (0.601 sec/batch), lr: 1.000000
2019-03-16 19:59:56,205 2019-03-16 19:59:56: step 145/50000, loss = 0.274607 (0.528 sec/batch), lr: 1.000000
2019-03-16 19:59:56,710 2019-03-16 19:59:56: step 146/50000, loss = 0.255707 (0.499 sec/batch), lr: 1.000000
2019-03-16 19:59:57,127 2019-03-16 19:59:57: step 147/50000, loss = 0.233338 (0.412 sec/batch), lr: 1.000000
2019-03-16 19:59:57,454 2019-03-16 19:59:57: step 148/50000, loss = 0.282119 (0.323 sec/batch), lr: 1.000000
2019-03-16 19:59:57,665 2019-03-16 19:59:57: step 149/50000, loss = 0.298075 (0.207 sec/batch), lr: 1.000000
2019-03-16 19:59:57,801 2019-03-16 19:59:57: step 150/50000, loss = 0.569975 (0.133 sec/batch), lr: 1.000000
2019-03-16 20:00:47,441 2019-03-16 20:00:47: step 151/50000, loss = 0.396507 (49.395 sec/batch), lr: 1.000000
2019-03-16 20:01:10,828 2019-03-16 20:01:10: step 152/50000, loss = 0.501317 (23.374 sec/batch), lr: 1.000000
2019-03-16 20:01:29,100 2019-03-16 20:01:29: step 153/50000, loss = 0.511629 (18.168 sec/batch), lr: 1.000000
2019-03-16 20:01:44,737 2019-03-16 20:01:44: step 154/50000, loss = 0.508307 (15.548 sec/batch), lr: 1.000000
2019-03-16 20:01:57,569 2019-03-16 20:01:57: step 155/50000, loss = 0.514085 (12.755 sec/batch), lr: 1.000000
2019-03-16 20:02:09,159 2019-03-16 20:02:09: step 156/50000, loss = 0.505508 (11.578 sec/batch), lr: 1.000000
2019-03-16 20:02:19,661 2019-03-16 20:02:19: step 157/50000, loss = 0.506498 (10.491 sec/batch), lr: 1.000000
2019-03-16 20:02:29,210 2019-03-16 20:02:29: step 158/50000, loss = 0.506659 (9.496 sec/batch), lr: 1.000000
2019-03-16 20:02:37,980 2019-03-16 20:02:37: step 159/50000, loss = 0.490337 (8.721 sec/batch), lr: 1.000000
2019-03-16 20:02:46,076 2019-03-16 20:02:46: step 160/50000, loss = 0.496414 (8.052 sec/batch), lr: 1.000000
2019-03-16 20:02:53,252 2019-03-16 20:02:53: step 161/50000, loss = 0.499164 (7.168 sec/batch), lr: 1.000000
2019-03-16 20:03:00,081 2019-03-16 20:03:00: step 162/50000, loss = 0.493944 (6.794 sec/batch), lr: 1.000000
2019-03-16 20:03:06,359 2019-03-16 20:03:06: step 163/50000, loss = 0.488516 (6.243 sec/batch), lr: 1.000000
2019-03-16 20:03:12,358 2019-03-16 20:03:12: step 164/50000, loss = 0.482041 (5.989 sec/batch), lr: 1.000000
2019-03-16 20:03:18,015 2019-03-16 20:03:18: step 165/50000, loss = 0.482844 (5.627 sec/batch), lr: 1.000000
2019-03-16 20:03:23,137 2019-03-16 20:03:23: step 166/50000, loss = 0.481890 (5.093 sec/batch), lr: 1.000000
2019-03-16 20:03:27,959 2019-03-16 20:03:27: step 167/50000, loss = 0.479195 (4.795 sec/batch), lr: 1.000000
2019-03-16 20:03:32,714 2019-03-16 20:03:32: step 168/50000, loss = 0.460464 (4.729 sec/batch), lr: 1.000000
2019-03-16 20:03:37,278 2019-03-16 20:03:37: step 169/50000, loss = 0.455281 (4.554 sec/batch), lr: 1.000000
2019-03-16 20:03:41,450 2019-03-16 20:03:41: step 170/50000, loss = 0.456317 (4.150 sec/batch), lr: 1.000000
2019-03-16 20:03:45,505 2019-03-16 20:03:45: step 171/50000, loss = 0.423466 (4.032 sec/batch), lr: 1.000000
2019-03-16 20:03:49,213 2019-03-16 20:03:49: step 172/50000, loss = 0.403136 (3.687 sec/batch), lr: 1.000000
2019-03-16 20:03:52,879 2019-03-16 20:03:52: step 173/50000, loss = 0.344991 (3.648 sec/batch), lr: 1.000000
2019-03-16 20:03:56,246 2019-03-16 20:03:56: step 174/50000, loss = 0.224524 (3.349 sec/batch), lr: 1.000000
2019-03-16 20:03:59,519 2019-03-16 20:03:59: step 175/50000, loss = 0.468612 (3.256 sec/batch), lr: 1.000000
2019-03-16 20:04:02,629 2019-03-16 20:04:02: step 176/50000, loss = 0.432637 (3.093 sec/batch), lr: 1.000000
2019-03-16 20:04:05,655 2019-03-16 20:04:05: step 177/50000, loss = 0.200987 (3.018 sec/batch), lr: 1.000000
2019-03-16 20:04:08,487 2019-03-16 20:04:08: step 178/50000, loss = 0.373062 (2.816 sec/batch), lr: 1.000000
2019-03-16 20:04:11,093 2019-03-16 20:04:11: step 179/50000, loss = 0.406548 (2.591 sec/batch), lr: 1.000000
2019-03-16 20:04:13,327 2019-03-16 20:04:13: step 180/50000, loss = 0.549275 (2.220 sec/batch), lr: 1.000000
2019-03-16 20:04:15,481 2019-03-16 20:04:15: step 181/50000, loss = 0.491194 (2.140 sec/batch), lr: 1.000000
2019-03-16 20:04:17,540 2019-03-16 20:04:17: step 182/50000, loss = 0.481221 (2.047 sec/batch), lr: 1.000000
2019-03-16 20:04:19,509 2019-03-16 20:04:19: step 183/50000, loss = 0.439855 (1.956 sec/batch), lr: 1.000000
2019-03-16 20:04:21,269 2019-03-16 20:04:21: step 184/50000, loss = 0.313751 (1.754 sec/batch), lr: 1.000000
2019-03-16 20:04:22,984 2019-03-16 20:04:22: step 185/50000, loss = 0.553442 (1.704 sec/batch), lr: 1.000000
2019-03-16 20:04:24,604 2019-03-16 20:04:24: step 186/50000, loss = 0.619529 (1.610 sec/batch), lr: 1.000000
2019-03-16 20:04:26,106 2019-03-16 20:04:26: step 187/50000, loss = 0.488138 (1.494 sec/batch), lr: 1.000000
2019-03-16 20:04:27,537 2019-03-16 20:04:27: step 188/50000, loss = 0.384822 (1.420 sec/batch), lr: 1.000000
2019-03-16 20:04:28,787 2019-03-16 20:04:28: step 189/50000, loss = 0.224530 (1.241 sec/batch), lr: 1.000000
2019-03-16 20:04:29,868 2019-03-16 20:04:29: step 190/50000, loss = 1.061766 (1.075 sec/batch), lr: 1.000000
2019-03-16 20:04:30,828 2019-03-16 20:04:30: step 191/50000, loss = 0.834552 (0.953 sec/batch), lr: 1.000000
2019-03-16 20:04:31,775 2019-03-16 20:04:31: step 192/50000, loss = 0.485396 (0.939 sec/batch), lr: 1.000000
2019-03-16 20:04:32,594 2019-03-16 20:04:32: step 193/50000, loss = 0.392960 (0.811 sec/batch), lr: 1.000000
2019-03-16 20:04:33,262 2019-03-16 20:04:33: step 194/50000, loss = 0.202052 (0.660 sec/batch), lr: 1.000000
2019-03-16 20:04:33,817 2019-03-16 20:04:33: step 195/50000, loss = 0.649093 (0.549 sec/batch), lr: 1.000000
2019-03-16 20:04:34,331 2019-03-16 20:04:34: step 196/50000, loss = 0.933620 (0.509 sec/batch), lr: 1.000000
2019-03-16 20:04:34,750 2019-03-16 20:04:34: step 197/50000, loss = 0.512789 (0.413 sec/batch), lr: 1.000000
2019-03-16 20:04:35,079 2019-03-16 20:04:35: step 198/50000, loss = 0.354043 (0.324 sec/batch), lr: 1.000000
2019-03-16 20:04:35,289 2019-03-16 20:04:35: step 199/50000, loss = 0.148243 (0.206 sec/batch), lr: 1.000000
2019-03-16 20:04:35,428 2019-03-16 20:04:35: step 200/50000, loss = 0.826097 (0.137 sec/batch), lr: 1.000000
2019-03-16 20:05:03,577 step 200: Full loss = 0.303917, Edge acc. = 0.1131
2019-03-16 20:05:03,638 step 200: Dev acc. = 0.100113
2019-03-16 20:05:03,785 2019-03-16 20:05:03: step 201/50000, loss = 0.560154 (0.143 sec/batch), lr: 0.500000
2019-03-16 20:05:03,997 2019-03-16 20:05:03: step 202/50000, loss = 0.473682 (0.209 sec/batch), lr: 0.500000
2019-03-16 20:05:04,282 2019-03-16 20:05:04: step 203/50000, loss = 0.436327 (0.281 sec/batch), lr: 0.500000
2019-03-16 20:05:04,599 2019-03-16 20:05:04: step 204/50000, loss = 0.378166 (0.313 sec/batch), lr: 0.500000
2019-03-16 20:05:05,019 2019-03-16 20:05:05: step 205/50000, loss = 0.312924 (0.417 sec/batch), lr: 0.500000
2019-03-16 20:05:05,570 2019-03-16 20:05:05: step 206/50000, loss = 0.234792 (0.546 sec/batch), lr: 0.500000
2019-03-16 20:05:06,349 2019-03-16 20:05:06: step 207/50000, loss = 0.207955 (0.773 sec/batch), lr: 0.500000
2019-03-16 20:05:07,166 2019-03-16 20:05:07: step 208/50000, loss = 0.211708 (0.808 sec/batch), lr: 0.500000
2019-03-16 20:05:08,147 2019-03-16 20:05:08: step 209/50000, loss = 0.208846 (0.973 sec/batch), lr: 0.500000
2019-03-16 20:05:09,081 2019-03-16 20:05:09: step 210/50000, loss = 0.206518 (0.928 sec/batch), lr: 0.500000
2019-03-16 20:05:10,101 2019-03-16 20:05:10: step 211/50000, loss = 0.216839 (1.011 sec/batch), lr: 0.500000
2019-03-16 20:05:11,409 2019-03-16 20:05:11: step 212/50000, loss = 0.195933 (1.301 sec/batch), lr: 0.500000
2019-03-16 20:05:12,712 2019-03-16 20:05:12: step 213/50000, loss = 0.222396 (1.300 sec/batch), lr: 0.500000
2019-03-16 20:05:14,329 2019-03-16 20:05:14: step 214/50000, loss = 0.191765 (1.605 sec/batch), lr: 0.500000
2019-03-16 20:05:15,878 2019-03-16 20:05:15: step 215/50000, loss = 0.226626 (1.538 sec/batch), lr: 0.500000
2019-03-16 20:05:17,691 2019-03-16 20:05:17: step 216/50000, loss = 0.212348 (1.806 sec/batch), lr: 0.500000
2019-03-16 20:05:19,592 2019-03-16 20:05:19: step 217/50000, loss = 0.214092 (1.893 sec/batch), lr: 0.500000
2019-03-16 20:05:21,658 2019-03-16 20:05:21: step 218/50000, loss = 0.211630 (2.055 sec/batch), lr: 0.500000
2019-03-16 20:05:23,914 2019-03-16 20:05:23: step 219/50000, loss = 0.218100 (2.245 sec/batch), lr: 0.500000
2019-03-16 20:05:26,126 2019-03-16 20:05:26: step 220/50000, loss = 0.211845 (2.201 sec/batch), lr: 0.500000
2019-03-16 20:05:28,647 2019-03-16 20:05:28: step 221/50000, loss = 0.229769 (2.507 sec/batch), lr: 0.500000
2019-03-16 20:05:31,362 2019-03-16 20:05:31: step 222/50000, loss = 0.195753 (2.700 sec/batch), lr: 0.500000
2019-03-16 20:05:34,031 2019-03-16 20:05:34: step 223/50000, loss = 0.238250 (2.653 sec/batch), lr: 0.500000
2019-03-16 20:05:36,889 2019-03-16 20:05:36: step 224/50000, loss = 0.201067 (2.843 sec/batch), lr: 0.500000
2019-03-16 20:05:39,680 2019-03-16 20:05:39: step 225/50000, loss = 0.236948 (2.776 sec/batch), lr: 0.500000
2019-03-16 20:05:43,032 2019-03-16 20:05:43: step 226/50000, loss = 0.204912 (3.334 sec/batch), lr: 0.500000
2019-03-16 20:05:46,654 2019-03-16 20:05:46: step 227/50000, loss = 0.229596 (3.603 sec/batch), lr: 0.500000
2019-03-16 20:05:50,240 2019-03-16 20:05:50: step 228/50000, loss = 0.205142 (3.569 sec/batch), lr: 0.500000
2019-03-16 20:05:54,135 2019-03-16 20:05:54: step 229/50000, loss = 0.245423 (3.875 sec/batch), lr: 0.500000
2019-03-16 20:05:58,367 2019-03-16 20:05:58: step 230/50000, loss = 0.207442 (4.208 sec/batch), lr: 0.500000
2019-03-16 20:06:02,591 2019-03-16 20:06:02: step 231/50000, loss = 0.251769 (4.202 sec/batch), lr: 0.500000
2019-03-16 20:06:07,023 2019-03-16 20:06:07: step 232/50000, loss = 0.216888 (4.407 sec/batch), lr: 0.500000
2019-03-16 20:06:11,858 2019-03-16 20:06:11: step 233/50000, loss = 0.251007 (4.807 sec/batch), lr: 0.500000
2019-03-16 20:06:16,924 2019-03-16 20:06:16: step 234/50000, loss = 0.207652 (5.038 sec/batch), lr: 0.500000
2019-03-16 20:06:22,394 2019-03-16 20:06:22: step 235/50000, loss = 0.246011 (5.460 sec/batch), lr: 0.500000
2019-03-16 20:06:28,097 2019-03-16 20:06:28: step 236/50000, loss = 0.216308 (5.671 sec/batch), lr: 0.500000
2019-03-16 20:06:34,175 2019-03-16 20:06:34: step 237/50000, loss = 0.245559 (6.044 sec/batch), lr: 0.500000
2019-03-16 20:06:40,813 2019-03-16 20:06:40: step 238/50000, loss = 0.206499 (6.601 sec/batch), lr: 0.500000
2019-03-16 20:06:48,000 2019-03-16 20:06:48: step 239/50000, loss = 0.249997 (7.177 sec/batch), lr: 0.500000
2019-03-16 20:06:55,634 2019-03-16 20:06:55: step 240/50000, loss = 0.209823 (7.592 sec/batch), lr: 0.500000
2019-03-16 20:07:03,665 2019-03-16 20:07:03: step 241/50000, loss = 0.258121 (7.989 sec/batch), lr: 0.500000
2019-03-16 20:07:12,582 2019-03-16 20:07:12: step 242/50000, loss = 0.211351 (8.867 sec/batch), lr: 0.500000
2019-03-16 20:07:22,602 2019-03-16 20:07:22: step 243/50000, loss = 0.260276 (9.961 sec/batch), lr: 0.500000
2019-03-16 20:07:33,631 2019-03-16 20:07:33: step 244/50000, loss = 0.214022 (10.968 sec/batch), lr: 0.500000
2019-03-16 20:07:45,704 2019-03-16 20:07:45: step 245/50000, loss = 0.249142 (12.003 sec/batch), lr: 0.500000
2019-03-16 20:07:59,948 2019-03-16 20:07:59: step 246/50000, loss = 0.229050 (14.159 sec/batch), lr: 0.500000
2019-03-16 20:08:16,785 2019-03-16 20:08:16: step 247/50000, loss = 0.261411 (16.740 sec/batch), lr: 0.500000
2019-03-16 20:08:36,788 2019-03-16 20:08:36: step 248/50000, loss = 0.214975 (19.889 sec/batch), lr: 0.500000
2019-03-16 20:09:04,406 2019-03-16 20:09:04: step 249/50000, loss = 0.260139 (27.464 sec/batch), lr: 0.500000
2019-03-16 20:09:38,023 2019-03-16 20:09:38: step 250/50000, loss = 0.175723 (33.448 sec/batch), lr: 0.500000
2019-03-16 20:09:38,193 2019-03-16 20:09:38: step 251/50000, loss = 1.757442 (0.164 sec/batch), lr: 0.500000
2019-03-16 20:09:38,436 2019-03-16 20:09:38: step 252/50000, loss = 0.160770 (0.238 sec/batch), lr: 0.500000
2019-03-16 20:09:38,783 2019-03-16 20:09:38: step 253/50000, loss = 0.325745 (0.342 sec/batch), lr: 0.500000
2019-03-16 20:09:39,225 2019-03-16 20:09:39: step 254/50000, loss = 0.190130 (0.437 sec/batch), lr: 0.500000
2019-03-16 20:09:39,765 2019-03-16 20:09:39: step 255/50000, loss = 0.258281 (0.533 sec/batch), lr: 0.500000
2019-03-16 20:09:40,404 2019-03-16 20:09:40: step 256/50000, loss = 0.204196 (0.634 sec/batch), lr: 0.500000
2019-03-16 20:09:41,192 2019-03-16 20:09:41: step 257/50000, loss = 0.246303 (0.782 sec/batch), lr: 0.500000
2019-03-16 20:09:42,008 2019-03-16 20:09:42: step 258/50000, loss = 0.206671 (0.809 sec/batch), lr: 0.500000
2019-03-16 20:09:42,980 2019-03-16 20:09:42: step 259/50000, loss = 0.258745 (0.964 sec/batch), lr: 0.500000
2019-03-16 20:09:44,065 2019-03-16 20:09:44: step 260/50000, loss = 0.190678 (1.079 sec/batch), lr: 0.500000
2019-03-16 20:09:45,234 2019-03-16 20:09:45: step 261/50000, loss = 0.242160 (1.159 sec/batch), lr: 0.500000
2019-03-16 20:09:46,553 2019-03-16 20:09:46: step 262/50000, loss = 0.197028 (1.309 sec/batch), lr: 0.500000
2019-03-16 20:09:47,994 2019-03-16 20:09:47: step 263/50000, loss = 0.230452 (1.434 sec/batch), lr: 0.500000
2019-03-16 20:09:49,556 2019-03-16 20:09:49: step 264/50000, loss = 0.184636 (1.555 sec/batch), lr: 0.500000
2019-03-16 20:09:51,081 2019-03-16 20:09:51: step 265/50000, loss = 0.232692 (1.520 sec/batch), lr: 0.500000
2019-03-16 20:09:53,003 2019-03-16 20:09:53: step 266/50000, loss = 0.198318 (1.914 sec/batch), lr: 0.500000
2019-03-16 20:09:55,077 2019-03-16 20:09:55: step 267/50000, loss = 0.221267 (2.065 sec/batch), lr: 0.500000
2019-03-16 20:09:57,201 2019-03-16 20:09:57: step 268/50000, loss = 0.197700 (2.116 sec/batch), lr: 0.500000
2019-03-16 20:09:59,447 2019-03-16 20:09:59: step 269/50000, loss = 0.227397 (2.233 sec/batch), lr: 0.500000
2019-03-16 20:10:01,830 2019-03-16 20:10:01: step 270/50000, loss = 0.198182 (2.369 sec/batch), lr: 0.500000
2019-03-16 20:10:04,411 2019-03-16 20:10:04: step 271/50000, loss = 0.235156 (2.566 sec/batch), lr: 0.500000
2019-03-16 20:10:07,046 2019-03-16 20:10:07: step 272/50000, loss = 0.190012 (2.620 sec/batch), lr: 0.500000
2019-03-16 20:10:09,817 2019-03-16 20:10:09: step 273/50000, loss = 0.242079 (2.756 sec/batch), lr: 0.500000
2019-03-16 20:10:12,925 2019-03-16 20:10:12: step 274/50000, loss = 0.196630 (3.090 sec/batch), lr: 0.500000
2019-03-16 20:10:16,035 2019-03-16 20:10:16: step 275/50000, loss = 0.240571 (3.095 sec/batch), lr: 0.500000
2019-03-16 20:10:19,251 2019-03-16 20:10:19: step 276/50000, loss = 0.197017 (3.200 sec/batch), lr: 0.500000
2019-03-16 20:10:22,887 2019-03-16 20:10:22: step 277/50000, loss = 0.232963 (3.617 sec/batch), lr: 0.500000
2019-03-16 20:10:26,503 2019-03-16 20:10:26: step 278/50000, loss = 0.196718 (3.596 sec/batch), lr: 0.500000
2019-03-16 20:10:30,495 2019-03-16 20:10:30: step 279/50000, loss = 0.248007 (3.983 sec/batch), lr: 0.500000
2019-03-16 20:10:34,660 2019-03-16 20:10:34: step 280/50000, loss = 0.201120 (4.141 sec/batch), lr: 0.500000
2019-03-16 20:10:38,880 2019-03-16 20:10:38: step 281/50000, loss = 0.250794 (4.196 sec/batch), lr: 0.500000
2019-03-16 20:10:43,535 2019-03-16 20:10:43: step 282/50000, loss = 0.209440 (4.630 sec/batch), lr: 0.500000
2019-03-16 20:10:48,477 2019-03-16 20:10:48: step 283/50000, loss = 0.249606 (4.933 sec/batch), lr: 0.500000
2019-03-16 20:10:53,720 2019-03-16 20:10:53: step 284/50000, loss = 0.199803 (5.234 sec/batch), lr: 0.500000
2019-03-16 20:10:59,260 2019-03-16 20:10:59: step 285/50000, loss = 0.241776 (5.519 sec/batch), lr: 0.500000
2019-03-16 20:11:04,943 2019-03-16 20:11:04: step 286/50000, loss = 0.212602 (5.673 sec/batch), lr: 0.500000
2019-03-16 20:11:10,978 2019-03-16 20:11:10: step 287/50000, loss = 0.244775 (6.005 sec/batch), lr: 0.500000
2019-03-16 20:11:17,616 2019-03-16 20:11:17: step 288/50000, loss = 0.201761 (6.630 sec/batch), lr: 0.500000
2019-03-16 20:11:24,765 2019-03-16 20:11:24: step 289/50000, loss = 0.245524 (7.139 sec/batch), lr: 0.500000
2019-03-16 20:11:32,477 2019-03-16 20:11:32: step 290/50000, loss = 0.206935 (7.671 sec/batch), lr: 0.500000
2019-03-16 20:11:40,568 2019-03-16 20:11:40: step 291/50000, loss = 0.255470 (8.044 sec/batch), lr: 0.500000
2019-03-16 20:11:49,990 2019-03-16 20:11:49: step 292/50000, loss = 0.210816 (9.410 sec/batch), lr: 0.500000
2019-03-16 20:12:00,022 2019-03-16 20:12:00: step 293/50000, loss = 0.255763 (9.972 sec/batch), lr: 0.500000
2019-03-16 20:12:11,102 2019-03-16 20:12:11: step 294/50000, loss = 0.211898 (11.018 sec/batch), lr: 0.500000
2019-03-16 20:12:23,089 2019-03-16 20:12:23: step 295/50000, loss = 0.255925 (11.913 sec/batch), lr: 0.500000
2019-03-16 20:12:37,274 2019-03-16 20:12:37: step 296/50000, loss = 0.216417 (14.104 sec/batch), lr: 0.500000
2019-03-16 20:12:54,062 2019-03-16 20:12:54: step 297/50000, loss = 0.263653 (16.690 sec/batch), lr: 0.500000
2019-03-16 20:13:14,040 2019-03-16 20:13:14: step 298/50000, loss = 0.208740 (19.865 sec/batch), lr: 0.500000
2019-03-16 20:13:41,681 2019-03-16 20:13:41: step 299/50000, loss = 0.237430 (27.623 sec/batch), lr: 0.500000
2019-03-16 20:14:15,248 2019-03-16 20:14:15: step 300/50000, loss = 0.190607 (33.385 sec/batch), lr: 0.500000
2019-03-16 20:14:43,315 step 300: Full loss = 0.139503, Edge acc. = 0.3106
2019-03-16 20:14:43,315 step 300: Dev acc. = 0.391913
2019-03-16 20:15:32,198 2019-03-16 20:15:32: step 301/50000, loss = 0.196280 (48.643 sec/batch), lr: 0.500000
2019-03-16 20:15:55,598 2019-03-16 20:15:55: step 302/50000, loss = 0.238850 (23.383 sec/batch), lr: 0.500000
2019-03-16 20:16:13,713 2019-03-16 20:16:13: step 303/50000, loss = 0.243993 (18.100 sec/batch), lr: 0.500000
2019-03-16 20:16:29,353 2019-03-16 20:16:29: step 304/50000, loss = 0.254948 (15.626 sec/batch), lr: 0.500000
2019-03-16 20:16:42,170 2019-03-16 20:16:42: step 305/50000, loss = 0.246557 (12.804 sec/batch), lr: 0.500000
2019-03-16 20:16:53,657 2019-03-16 20:16:53: step 306/50000, loss = 0.252346 (11.475 sec/batch), lr: 0.500000
2019-03-16 20:17:03,973 2019-03-16 20:17:03: step 307/50000, loss = 0.250182 (10.306 sec/batch), lr: 0.500000
2019-03-16 20:17:13,563 2019-03-16 20:17:13: step 308/50000, loss = 0.246768 (9.535 sec/batch), lr: 0.500000
2019-03-16 20:17:22,332 2019-03-16 20:17:22: step 309/50000, loss = 0.235692 (8.718 sec/batch), lr: 0.500000
2019-03-16 20:17:30,317 2019-03-16 20:17:30: step 310/50000, loss = 0.222896 (7.945 sec/batch), lr: 0.500000
2019-03-16 20:17:37,269 2019-03-16 20:17:37: step 311/50000, loss = 0.240585 (6.944 sec/batch), lr: 0.500000
2019-03-16 20:17:43,943 2019-03-16 20:17:43: step 312/50000, loss = 0.235734 (6.665 sec/batch), lr: 0.500000
2019-03-16 20:17:50,179 2019-03-16 20:17:50: step 313/50000, loss = 0.242309 (6.229 sec/batch), lr: 0.500000
2019-03-16 20:17:56,057 2019-03-16 20:17:56: step 314/50000, loss = 0.222709 (5.850 sec/batch), lr: 0.500000
2019-03-16 20:18:01,571 2019-03-16 20:18:01: step 315/50000, loss = 0.241888 (5.489 sec/batch), lr: 0.500000
2019-03-16 20:18:06,735 2019-03-16 20:18:06: step 316/50000, loss = 0.227397 (5.138 sec/batch), lr: 0.500000
2019-03-16 20:18:11,635 2019-03-16 20:18:11: step 317/50000, loss = 0.244130 (4.877 sec/batch), lr: 0.500000
2019-03-16 20:18:16,357 2019-03-16 20:18:16: step 318/50000, loss = 0.212698 (4.698 sec/batch), lr: 0.500000
2019-03-16 20:18:20,949 2019-03-16 20:18:20: step 319/50000, loss = 0.234120 (4.567 sec/batch), lr: 0.500000
2019-03-16 20:18:25,123 2019-03-16 20:18:25: step 320/50000, loss = 0.220609 (4.154 sec/batch), lr: 0.500000
2019-03-16 20:18:29,207 2019-03-16 20:18:29: step 321/50000, loss = 0.231570 (4.078 sec/batch), lr: 0.500000
2019-03-16 20:18:33,193 2019-03-16 20:18:33: step 322/50000, loss = 0.212451 (3.956 sec/batch), lr: 0.500000
2019-03-16 20:18:36,821 2019-03-16 20:18:36: step 323/50000, loss = 0.229914 (3.620 sec/batch), lr: 0.500000
2019-03-16 20:18:40,137 2019-03-16 20:18:40: step 324/50000, loss = 0.201131 (3.307 sec/batch), lr: 0.500000
2019-03-16 20:18:43,260 2019-03-16 20:18:43: step 325/50000, loss = 0.224883 (3.115 sec/batch), lr: 0.500000
2019-03-16 20:18:46,165 2019-03-16 20:18:46: step 326/50000, loss = 0.205341 (2.896 sec/batch), lr: 0.500000
2019-03-16 20:18:49,043 2019-03-16 20:18:49: step 327/50000, loss = 0.228751 (2.864 sec/batch), lr: 0.500000
2019-03-16 20:18:51,628 2019-03-16 20:18:51: step 328/50000, loss = 0.215981 (2.573 sec/batch), lr: 0.500000
2019-03-16 20:18:54,033 2019-03-16 20:18:54: step 329/50000, loss = 0.226974 (2.394 sec/batch), lr: 0.500000
2019-03-16 20:18:56,311 2019-03-16 20:18:56: step 330/50000, loss = 0.198011 (2.266 sec/batch), lr: 0.500000
2019-03-16 20:18:58,351 2019-03-16 20:18:58: step 331/50000, loss = 0.222755 (2.029 sec/batch), lr: 0.500000
2019-03-16 20:19:00,454 2019-03-16 20:19:00: step 332/50000, loss = 0.214606 (2.091 sec/batch), lr: 0.500000
2019-03-16 20:19:02,536 2019-03-16 20:19:02: step 333/50000, loss = 0.224982 (2.071 sec/batch), lr: 0.500000
2019-03-16 20:19:04,391 2019-03-16 20:19:04: step 334/50000, loss = 0.207937 (1.844 sec/batch), lr: 0.500000
2019-03-16 20:19:06,216 2019-03-16 20:19:06: step 335/50000, loss = 0.213528 (1.814 sec/batch), lr: 0.500000
2019-03-16 20:19:07,898 2019-03-16 20:19:07: step 336/50000, loss = 0.201731 (1.673 sec/batch), lr: 0.500000
2019-03-16 20:19:09,204 2019-03-16 20:19:09: step 337/50000, loss = 0.212667 (1.299 sec/batch), lr: 0.500000
2019-03-16 20:19:10,455 2019-03-16 20:19:10: step 338/50000, loss = 0.204043 (1.244 sec/batch), lr: 0.500000
2019-03-16 20:19:11,667 2019-03-16 20:19:11: step 339/50000, loss = 0.199845 (1.204 sec/batch), lr: 0.500000
2019-03-16 20:19:12,798 2019-03-16 20:19:12: step 340/50000, loss = 0.205871 (1.122 sec/batch), lr: 0.500000
2019-03-16 20:19:13,787 2019-03-16 20:19:13: step 341/50000, loss = 0.220529 (0.982 sec/batch), lr: 0.500000
2019-03-16 20:19:14,727 2019-03-16 20:19:14: step 342/50000, loss = 0.212385 (0.931 sec/batch), lr: 0.500000
2019-03-16 20:19:15,546 2019-03-16 20:19:15: step 343/50000, loss = 0.215778 (0.811 sec/batch), lr: 0.500000
2019-03-16 20:19:16,210 2019-03-16 20:19:16: step 344/50000, loss = 0.234772 (0.657 sec/batch), lr: 0.500000
2019-03-16 20:19:16,770 2019-03-16 20:19:16: step 345/50000, loss = 0.222319 (0.554 sec/batch), lr: 0.500000
2019-03-16 20:19:17,287 2019-03-16 20:19:17: step 346/50000, loss = 0.218061 (0.511 sec/batch), lr: 0.500000
2019-03-16 20:19:17,704 2019-03-16 20:19:17: step 347/50000, loss = 0.206176 (0.411 sec/batch), lr: 0.500000
2019-03-16 20:19:18,047 2019-03-16 20:19:18: step 348/50000, loss = 0.180153 (0.338 sec/batch), lr: 0.500000
2019-03-16 20:19:18,256 2019-03-16 20:19:18: step 349/50000, loss = 0.221189 (0.204 sec/batch), lr: 0.500000
2019-03-16 20:19:18,394 2019-03-16 20:19:18: step 350/50000, loss = 0.342187 (0.136 sec/batch), lr: 0.500000
2019-03-16 20:20:07,771 2019-03-16 20:20:07: step 351/50000, loss = 0.354777 (49.126 sec/batch), lr: 0.500000
2019-03-16 20:20:31,082 2019-03-16 20:20:31: step 352/50000, loss = 0.445652 (23.294 sec/batch), lr: 0.500000
2019-03-16 20:20:49,416 2019-03-16 20:20:49: step 353/50000, loss = 0.429760 (18.305 sec/batch), lr: 0.500000
2019-03-16 20:21:05,174 2019-03-16 20:21:05: step 354/50000, loss = 0.304930 (15.667 sec/batch), lr: 0.500000
2019-03-16 20:21:17,969 2019-03-16 20:21:17: step 355/50000, loss = 0.296517 (12.722 sec/batch), lr: 0.500000
2019-03-16 20:21:29,511 2019-03-16 20:21:29: step 356/50000, loss = 0.210413 (11.473 sec/batch), lr: 0.500000
2019-03-16 20:21:39,968 2019-03-16 20:21:39: step 357/50000, loss = 0.292561 (10.446 sec/batch), lr: 0.500000
2019-03-16 20:21:49,598 2019-03-16 20:21:49: step 358/50000, loss = 0.296475 (9.619 sec/batch), lr: 0.500000
2019-03-16 20:21:58,267 2019-03-16 20:21:58: step 359/50000, loss = 0.302435 (8.622 sec/batch), lr: 0.500000
2019-03-16 20:22:06,071 2019-03-16 20:22:06: step 360/50000, loss = 0.284686 (7.759 sec/batch), lr: 0.500000
2019-03-16 20:22:13,409 2019-03-16 20:22:13: step 361/50000, loss = 0.334965 (7.328 sec/batch), lr: 0.500000
2019-03-16 20:22:20,158 2019-03-16 20:22:20: step 362/50000, loss = 0.284604 (6.712 sec/batch), lr: 0.500000
2019-03-16 20:22:26,624 2019-03-16 20:22:26: step 363/50000, loss = 0.334352 (6.431 sec/batch), lr: 0.500000
2019-03-16 20:22:32,572 2019-03-16 20:22:32: step 364/50000, loss = 0.285903 (5.938 sec/batch), lr: 0.500000
2019-03-16 20:22:38,075 2019-03-16 20:22:38: step 365/50000, loss = 0.359111 (5.476 sec/batch), lr: 0.500000
2019-03-16 20:22:43,267 2019-03-16 20:22:43: step 366/50000, loss = 0.304135 (5.166 sec/batch), lr: 0.500000
2019-03-16 20:22:48,168 2019-03-16 20:22:48: step 367/50000, loss = 0.363462 (4.876 sec/batch), lr: 0.500000
2019-03-16 20:22:53,069 2019-03-16 20:22:53: step 368/50000, loss = 0.308767 (4.875 sec/batch), lr: 0.500000
2019-03-16 20:22:57,403 2019-03-16 20:22:57: step 369/50000, loss = 0.356208 (4.313 sec/batch), lr: 0.500000
2019-03-16 20:23:01,398 2019-03-16 20:23:01: step 370/50000, loss = 0.330479 (3.974 sec/batch), lr: 0.500000
2019-03-16 20:23:05,443 2019-03-16 20:23:05: step 371/50000, loss = 0.376467 (4.024 sec/batch), lr: 0.500000
2019-03-16 20:23:09,204 2019-03-16 20:23:09: step 372/50000, loss = 0.323589 (3.753 sec/batch), lr: 0.500000
2019-03-16 20:23:12,808 2019-03-16 20:23:12: step 373/50000, loss = 0.401001 (3.585 sec/batch), lr: 0.500000
2019-03-16 20:23:16,166 2019-03-16 20:23:16: step 374/50000, loss = 0.354994 (3.350 sec/batch), lr: 0.500000
2019-03-16 20:23:19,421 2019-03-16 20:23:19: step 375/50000, loss = 0.383194 (3.240 sec/batch), lr: 0.500000
2019-03-16 20:23:22,434 2019-03-16 20:23:22: step 376/50000, loss = 0.342724 (2.995 sec/batch), lr: 0.500000
2019-03-16 20:23:25,483 2019-03-16 20:23:25: step 377/50000, loss = 0.412415 (3.033 sec/batch), lr: 0.500000
2019-03-16 20:23:28,310 2019-03-16 20:23:28: step 378/50000, loss = 0.347657 (2.812 sec/batch), lr: 0.500000
2019-03-16 20:23:30,815 2019-03-16 20:23:30: step 379/50000, loss = 0.440571 (2.498 sec/batch), lr: 0.500000
2019-03-16 20:23:33,139 2019-03-16 20:23:33: step 380/50000, loss = 0.362636 (2.313 sec/batch), lr: 0.500000
2019-03-16 20:23:35,272 2019-03-16 20:23:35: step 381/50000, loss = 0.418440 (2.123 sec/batch), lr: 0.500000
2019-03-16 20:23:37,269 2019-03-16 20:23:37: step 382/50000, loss = 0.384057 (1.989 sec/batch), lr: 0.500000
2019-03-16 20:23:39,361 2019-03-16 20:23:39: step 383/50000, loss = 0.394228 (2.081 sec/batch), lr: 0.500000
2019-03-16 20:23:41,202 2019-03-16 20:23:41: step 384/50000, loss = 0.346201 (1.834 sec/batch), lr: 0.500000
2019-03-16 20:23:42,998 2019-03-16 20:23:42: step 385/50000, loss = 0.396895 (1.787 sec/batch), lr: 0.500000
2019-03-16 20:23:44,519 2019-03-16 20:23:44: step 386/50000, loss = 0.341835 (1.513 sec/batch), lr: 0.500000
2019-03-16 20:23:45,889 2019-03-16 20:23:45: step 387/50000, loss = 0.434491 (1.359 sec/batch), lr: 0.500000
2019-03-16 20:23:47,193 2019-03-16 20:23:47: step 388/50000, loss = 0.343735 (1.293 sec/batch), lr: 0.500000
2019-03-16 20:23:48,382 2019-03-16 20:23:48: step 389/50000, loss = 0.413536 (1.180 sec/batch), lr: 0.500000
2019-03-16 20:23:49,432 2019-03-16 20:23:49: step 390/50000, loss = 0.366595 (1.043 sec/batch), lr: 0.500000
2019-03-16 20:23:50,277 2019-03-16 20:23:50: step 391/50000, loss = 0.436898 (0.839 sec/batch), lr: 0.500000
2019-03-16 20:23:51,209 2019-03-16 20:23:51: step 392/50000, loss = 0.336211 (0.923 sec/batch), lr: 0.500000
2019-03-16 20:23:52,015 2019-03-16 20:23:52: step 393/50000, loss = 0.445782 (0.798 sec/batch), lr: 0.500000
2019-03-16 20:23:52,653 2019-03-16 20:23:52: step 394/50000, loss = 0.367167 (0.631 sec/batch), lr: 0.500000
2019-03-16 20:23:53,187 2019-03-16 20:23:53: step 395/50000, loss = 0.486293 (0.528 sec/batch), lr: 0.500000
2019-03-16 20:23:53,635 2019-03-16 20:23:53: step 396/50000, loss = 0.342681 (0.441 sec/batch), lr: 0.500000
2019-03-16 20:23:53,990 2019-03-16 20:23:53: step 397/50000, loss = 0.408145 (0.349 sec/batch), lr: 0.500000
2019-03-16 20:23:54,311 2019-03-16 20:23:54: step 398/50000, loss = 0.278406 (0.316 sec/batch), lr: 0.500000
2019-03-16 20:23:54,463 2019-03-16 20:23:54: step 399/50000, loss = 0.763758 (0.149 sec/batch), lr: 0.500000
2019-03-16 20:23:54,548 2019-03-16 20:23:54: step 400/50000, loss = 0.725778 (0.083 sec/batch), lr: 0.500000
2019-03-16 20:24:22,977 step 400: Full loss = 0.166873, Edge acc. = 0.2989
2019-03-16 20:24:22,978 step 400: Dev acc. = 0.384056
2019-03-16 20:24:23,129 2019-03-16 20:24:23: step 401/50000, loss = 0.066740 (0.146 sec/batch), lr: 0.250000
2019-03-16 20:24:23,368 2019-03-16 20:24:23: step 402/50000, loss = 0.134727 (0.236 sec/batch), lr: 0.250000
2019-03-16 20:24:23,707 2019-03-16 20:24:23: step 403/50000, loss = 0.184052 (0.335 sec/batch), lr: 0.250000
2019-03-16 20:24:24,143 2019-03-16 20:24:24: step 404/50000, loss = 0.178879 (0.430 sec/batch), lr: 0.250000
2019-03-16 20:24:24,663 2019-03-16 20:24:24: step 405/50000, loss = 0.186107 (0.514 sec/batch), lr: 0.250000
2019-03-16 20:24:25,257 2019-03-16 20:24:25: step 406/50000, loss = 0.177332 (0.588 sec/batch), lr: 0.250000
2019-03-16 20:24:25,978 2019-03-16 20:24:25: step 407/50000, loss = 0.187907 (0.717 sec/batch), lr: 0.250000
2019-03-16 20:24:26,697 2019-03-16 20:24:26: step 408/50000, loss = 0.196892 (0.714 sec/batch), lr: 0.250000
2019-03-16 20:24:27,667 2019-03-16 20:24:27: step 409/50000, loss = 0.207799 (0.962 sec/batch), lr: 0.250000
2019-03-16 20:24:28,615 2019-03-16 20:24:28: step 410/50000, loss = 0.182335 (0.940 sec/batch), lr: 0.250000
2019-03-16 20:24:29,606 2019-03-16 20:24:29: step 411/50000, loss = 0.194715 (0.984 sec/batch), lr: 0.250000
2019-03-16 20:24:30,714 2019-03-16 20:24:30: step 412/50000, loss = 0.186406 (1.101 sec/batch), lr: 0.250000
2019-03-16 20:24:31,922 2019-03-16 20:24:31: step 413/50000, loss = 0.194297 (1.199 sec/batch), lr: 0.250000
2019-03-16 20:24:33,415 2019-03-16 20:24:33: step 414/50000, loss = 0.177057 (1.484 sec/batch), lr: 0.250000
2019-03-16 20:24:34,946 2019-03-16 20:24:34: step 415/50000, loss = 0.198718 (1.522 sec/batch), lr: 0.250000
2019-03-16 20:24:36,755 2019-03-16 20:24:36: step 416/50000, loss = 0.187093 (1.800 sec/batch), lr: 0.250000
2019-03-16 20:24:38,625 2019-03-16 20:24:38: step 417/50000, loss = 0.189702 (1.861 sec/batch), lr: 0.250000
2019-03-16 20:24:40,630 2019-03-16 20:24:40: step 418/50000, loss = 0.190090 (1.996 sec/batch), lr: 0.250000
2019-03-16 20:24:42,761 2019-03-16 20:24:42: step 419/50000, loss = 0.193738 (2.120 sec/batch), lr: 0.250000
2019-03-16 20:24:45,011 2019-03-16 20:24:45: step 420/50000, loss = 0.188688 (2.237 sec/batch), lr: 0.250000
2019-03-16 20:24:47,605 2019-03-16 20:24:47: step 421/50000, loss = 0.205067 (2.579 sec/batch), lr: 0.250000
2019-03-16 20:24:50,379 2019-03-16 20:24:50: step 422/50000, loss = 0.176629 (2.759 sec/batch), lr: 0.250000
2019-03-16 20:24:53,198 2019-03-16 20:24:53: step 423/50000, loss = 0.212557 (2.804 sec/batch), lr: 0.250000
2019-03-16 20:24:56,347 2019-03-16 20:24:56: step 424/50000, loss = 0.183567 (3.132 sec/batch), lr: 0.250000
2019-03-16 20:24:59,420 2019-03-16 20:24:59: step 425/50000, loss = 0.209901 (3.058 sec/batch), lr: 0.250000
2019-03-16 20:25:02,667 2019-03-16 20:25:02: step 426/50000, loss = 0.192110 (3.229 sec/batch), lr: 0.250000
2019-03-16 20:25:06,176 2019-03-16 20:25:06: step 427/50000, loss = 0.202528 (3.483 sec/batch), lr: 0.250000
2019-03-16 20:25:09,838 2019-03-16 20:25:09: step 428/50000, loss = 0.186034 (3.647 sec/batch), lr: 0.250000
2019-03-16 20:25:13,704 2019-03-16 20:25:13: step 429/50000, loss = 0.218401 (3.847 sec/batch), lr: 0.250000
2019-03-16 20:25:17,801 2019-03-16 20:25:17: step 430/50000, loss = 0.192873 (4.077 sec/batch), lr: 0.250000
2019-03-16 20:25:21,951 2019-03-16 20:25:21: step 431/50000, loss = 0.219963 (4.130 sec/batch), lr: 0.250000
2019-03-16 20:25:26,574 2019-03-16 20:25:26: step 432/50000, loss = 0.199005 (4.599 sec/batch), lr: 0.250000
2019-03-16 20:25:31,356 2019-03-16 20:25:31: step 433/50000, loss = 0.217780 (4.759 sec/batch), lr: 0.250000
2019-03-16 20:25:36,377 2019-03-16 20:25:36: step 434/50000, loss = 0.197191 (4.996 sec/batch), lr: 0.250000
2019-03-16 20:25:41,782 2019-03-16 20:25:41: step 435/50000, loss = 0.213825 (5.398 sec/batch), lr: 0.250000
2019-03-16 20:25:47,422 2019-03-16 20:25:47: step 436/50000, loss = 0.203195 (5.611 sec/batch), lr: 0.250000
2019-03-16 20:25:53,568 2019-03-16 20:25:53: step 437/50000, loss = 0.213645 (6.111 sec/batch), lr: 0.250000
2019-03-16 20:26:00,308 2019-03-16 20:26:00: step 438/50000, loss = 0.194921 (6.731 sec/batch), lr: 0.250000
2019-03-16 20:26:07,384 2019-03-16 20:26:07: step 439/50000, loss = 0.215859 (7.069 sec/batch), lr: 0.250000
2019-03-16 20:26:15,034 2019-03-16 20:26:15: step 440/50000, loss = 0.197979 (7.639 sec/batch), lr: 0.250000
2019-03-16 20:26:23,064 2019-03-16 20:26:23: step 441/50000, loss = 0.225833 (7.977 sec/batch), lr: 0.250000
2019-03-16 20:26:32,157 2019-03-16 20:26:32: step 442/50000, loss = 0.205387 (9.040 sec/batch), lr: 0.250000
2019-03-16 20:26:42,230 2019-03-16 20:26:42: step 443/50000, loss = 0.228690 (10.018 sec/batch), lr: 0.250000
2019-03-16 20:26:53,187 2019-03-16 20:26:53: step 444/50000, loss = 0.205272 (10.900 sec/batch), lr: 0.250000
2019-03-16 20:27:05,187 2019-03-16 20:27:05: step 445/50000, loss = 0.208581 (11.935 sec/batch), lr: 0.250000
2019-03-16 20:27:19,290 2019-03-16 20:27:19: step 446/50000, loss = 0.264552 (14.026 sec/batch), lr: 0.250000
2019-03-16 20:27:36,069 2019-03-16 20:27:36: step 447/50000, loss = 0.224597 (16.683 sec/batch), lr: 0.250000
2019-03-16 20:27:56,059 2019-03-16 20:27:56: step 448/50000, loss = 0.230087 (19.877 sec/batch), lr: 0.250000
2019-03-16 20:28:23,994 2019-03-16 20:28:23: step 449/50000, loss = 0.229767 (27.780 sec/batch), lr: 0.250000
2019-03-16 20:28:57,810 2019-03-16 20:28:57: step 450/50000, loss = 0.175343 (33.646 sec/batch), lr: 0.250000
2019-03-16 20:29:47,047 2019-03-16 20:29:47: step 451/50000, loss = 0.186797 (48.994 sec/batch), lr: 0.250000
2019-03-16 20:30:10,376 2019-03-16 20:30:10: step 452/50000, loss = 0.213443 (23.197 sec/batch), lr: 0.250000
2019-03-16 20:30:28,990 2019-03-16 20:30:28: step 453/50000, loss = 0.228183 (18.599 sec/batch), lr: 0.250000
2019-03-16 20:30:44,549 2019-03-16 20:30:44: step 454/50000, loss = 0.233816 (15.548 sec/batch), lr: 0.250000
2019-03-16 20:30:57,386 2019-03-16 20:30:57: step 455/50000, loss = 0.224051 (12.825 sec/batch), lr: 0.250000
2019-03-16 20:31:09,038 2019-03-16 20:31:09: step 456/50000, loss = 0.230091 (11.640 sec/batch), lr: 0.250000
2019-03-16 20:31:20,108 2019-03-16 20:31:20: step 457/50000, loss = 0.225038 (11.006 sec/batch), lr: 0.250000
2019-03-16 20:31:29,721 2019-03-16 20:31:29: step 458/50000, loss = 0.230659 (9.601 sec/batch), lr: 0.250000
2019-03-16 20:31:38,714 2019-03-16 20:31:38: step 459/50000, loss = 0.206635 (8.941 sec/batch), lr: 0.250000
2019-03-16 20:31:46,985 2019-03-16 20:31:46: step 460/50000, loss = 0.222414 (8.224 sec/batch), lr: 0.250000
2019-03-16 20:31:54,298 2019-03-16 20:31:54: step 461/50000, loss = 0.212636 (7.304 sec/batch), lr: 0.250000
2019-03-16 20:32:01,084 2019-03-16 20:32:01: step 462/50000, loss = 0.228432 (6.751 sec/batch), lr: 0.250000
2019-03-16 20:32:07,401 2019-03-16 20:32:07: step 463/50000, loss = 0.214438 (6.309 sec/batch), lr: 0.250000
2019-03-16 20:32:13,454 2019-03-16 20:32:13: step 464/50000, loss = 0.218440 (6.012 sec/batch), lr: 0.250000
2019-03-16 20:32:19,112 2019-03-16 20:32:19: step 465/50000, loss = 0.211750 (5.627 sec/batch), lr: 0.250000
2019-03-16 20:32:24,388 2019-03-16 20:32:24: step 466/50000, loss = 0.226694 (5.249 sec/batch), lr: 0.250000
2019-03-16 20:32:29,261 2019-03-16 20:32:29: step 467/50000, loss = 0.216995 (4.847 sec/batch), lr: 0.250000
2019-03-16 20:32:33,995 2019-03-16 20:32:33: step 468/50000, loss = 0.211765 (4.709 sec/batch), lr: 0.250000
2019-03-16 20:32:38,407 2019-03-16 20:32:38: step 469/50000, loss = 0.208504 (4.404 sec/batch), lr: 0.250000
2019-03-16 20:32:42,766 2019-03-16 20:32:42: step 470/50000, loss = 0.216656 (4.337 sec/batch), lr: 0.250000
2019-03-16 20:32:46,816 2019-03-16 20:32:46: step 471/50000, loss = 0.205905 (4.031 sec/batch), lr: 0.250000
2019-03-16 20:32:50,595 2019-03-16 20:32:50: step 472/50000, loss = 0.210843 (3.762 sec/batch), lr: 0.250000
2019-03-16 20:32:54,092 2019-03-16 20:32:54: step 473/50000, loss = 0.204911 (3.478 sec/batch), lr: 0.250000
2019-03-16 20:32:57,443 2019-03-16 20:32:57: step 474/50000, loss = 0.199909 (3.333 sec/batch), lr: 0.250000
2019-03-16 20:33:00,737 2019-03-16 20:33:00: step 475/50000, loss = 0.203440 (3.285 sec/batch), lr: 0.250000
2019-03-16 20:33:03,874 2019-03-16 20:33:03: step 476/50000, loss = 0.198701 (3.128 sec/batch), lr: 0.250000
2019-03-16 20:33:06,865 2019-03-16 20:33:06: step 477/50000, loss = 0.204124 (2.974 sec/batch), lr: 0.250000
2019-03-16 20:33:09,575 2019-03-16 20:33:09: step 478/50000, loss = 0.201698 (2.703 sec/batch), lr: 0.250000
2019-03-16 20:33:12,122 2019-03-16 20:33:12: step 479/50000, loss = 0.206314 (2.533 sec/batch), lr: 0.250000
2019-03-16 20:33:14,706 2019-03-16 20:33:14: step 480/50000, loss = 0.185733 (2.571 sec/batch), lr: 0.250000
2019-03-16 20:33:16,916 2019-03-16 20:33:16: step 481/50000, loss = 0.199110 (2.197 sec/batch), lr: 0.250000
2019-03-16 20:33:18,999 2019-03-16 20:33:18: step 482/50000, loss = 0.200603 (2.074 sec/batch), lr: 0.250000
2019-03-16 20:33:21,072 2019-03-16 20:33:21: step 483/50000, loss = 0.198784 (2.062 sec/batch), lr: 0.250000
2019-03-16 20:33:22,977 2019-03-16 20:33:22: step 484/50000, loss = 0.198375 (1.893 sec/batch), lr: 0.250000
2019-03-16 20:33:24,651 2019-03-16 20:33:24: step 485/50000, loss = 0.195959 (1.664 sec/batch), lr: 0.250000
2019-03-16 20:33:26,277 2019-03-16 20:33:26: step 486/50000, loss = 0.187038 (1.616 sec/batch), lr: 0.250000
2019-03-16 20:33:27,800 2019-03-16 20:33:27: step 487/50000, loss = 0.189803 (1.512 sec/batch), lr: 0.250000
2019-03-16 20:33:29,230 2019-03-16 20:33:29: step 488/50000, loss = 0.180228 (1.421 sec/batch), lr: 0.250000
2019-03-16 20:33:30,460 2019-03-16 20:33:30: step 489/50000, loss = 0.177385 (1.223 sec/batch), lr: 0.250000
2019-03-16 20:33:31,556 2019-03-16 20:33:31: step 490/50000, loss = 0.182707 (1.088 sec/batch), lr: 0.250000
2019-03-16 20:33:32,509 2019-03-16 20:33:32: step 491/50000, loss = 0.198403 (0.946 sec/batch), lr: 0.250000
2019-03-16 20:33:33,471 2019-03-16 20:33:33: step 492/50000, loss = 0.187107 (0.954 sec/batch), lr: 0.250000
2019-03-16 20:33:34,296 2019-03-16 20:33:34: step 493/50000, loss = 0.187226 (0.818 sec/batch), lr: 0.250000
2019-03-16 20:33:34,969 2019-03-16 20:33:34: step 494/50000, loss = 0.188100 (0.665 sec/batch), lr: 0.250000
2019-03-16 20:33:35,530 2019-03-16 20:33:35: step 495/50000, loss = 0.190674 (0.555 sec/batch), lr: 0.250000
2019-03-16 20:33:36,053 2019-03-16 20:33:36: step 496/50000, loss = 0.170793 (0.517 sec/batch), lr: 0.250000
2019-03-16 20:33:36,473 2019-03-16 20:33:36: step 497/50000, loss = 0.174037 (0.414 sec/batch), lr: 0.250000
2019-03-16 20:33:36,806 2019-03-16 20:33:36: step 498/50000, loss = 0.152356 (0.328 sec/batch), lr: 0.250000
2019-03-16 20:33:37,010 2019-03-16 20:33:37: step 499/50000, loss = 0.125506 (0.201 sec/batch), lr: 0.250000
2019-03-16 20:33:37,149 2019-03-16 20:33:37: step 500/50000, loss = 0.224099 (0.136 sec/batch), lr: 0.250000
2019-03-16 20:34:05,642 step 500: Full loss = 0.190199, Edge acc. = 0.3304
2019-03-16 20:34:05,643 step 500: Dev acc. = 0.389035
2019-03-16 20:34:05,787 2019-03-16 20:34:05: step 501/50000, loss = 0.175296 (0.140 sec/batch), lr: 0.250000
2019-03-16 20:34:05,993 2019-03-16 20:34:05: step 502/50000, loss = 0.094449 (0.202 sec/batch), lr: 0.250000
2019-03-16 20:34:06,296 2019-03-16 20:34:06: step 503/50000, loss = 0.247885 (0.299 sec/batch), lr: 0.250000
2019-03-16 20:34:06,693 2019-03-16 20:34:06: step 504/50000, loss = 0.211476 (0.393 sec/batch), lr: 0.250000
2019-03-16 20:34:07,208 2019-03-16 20:34:07: step 505/50000, loss = 0.216800 (0.510 sec/batch), lr: 0.250000
2019-03-16 20:34:07,747 2019-03-16 20:34:07: step 506/50000, loss = 0.219394 (0.534 sec/batch), lr: 0.250000
2019-03-16 20:34:08,453 2019-03-16 20:34:08: step 507/50000, loss = 0.222496 (0.700 sec/batch), lr: 0.250000
2019-03-16 20:34:09,248 2019-03-16 20:34:09: step 508/50000, loss = 0.243038 (0.787 sec/batch), lr: 0.250000
2019-03-16 20:34:10,227 2019-03-16 20:34:10: step 509/50000, loss = 0.226176 (0.971 sec/batch), lr: 0.250000
2019-03-16 20:34:11,316 2019-03-16 20:34:11: step 510/50000, loss = 0.232995 (1.080 sec/batch), lr: 0.250000
2019-03-16 20:34:12,463 2019-03-16 20:34:12: step 511/50000, loss = 0.210433 (1.137 sec/batch), lr: 0.250000
2019-03-16 20:34:13,695 2019-03-16 20:34:13: step 512/50000, loss = 0.232395 (1.224 sec/batch), lr: 0.250000
2019-03-16 20:34:15,088 2019-03-16 20:34:15: step 513/50000, loss = 0.212220 (1.383 sec/batch), lr: 0.250000
2019-03-16 20:34:16,692 2019-03-16 20:34:16: step 514/50000, loss = 0.231011 (1.593 sec/batch), lr: 0.250000
2019-03-16 20:34:18,378 2019-03-16 20:34:18: step 515/50000, loss = 0.223230 (1.675 sec/batch), lr: 0.250000
2019-03-16 20:34:20,107 2019-03-16 20:34:20: step 516/50000, loss = 0.259889 (1.722 sec/batch), lr: 0.250000
2019-03-16 20:34:22,012 2019-03-16 20:34:22: step 517/50000, loss = 0.214267 (1.898 sec/batch), lr: 0.250000
2019-03-16 20:34:24,139 2019-03-16 20:34:24: step 518/50000, loss = 0.242135 (2.119 sec/batch), lr: 0.250000
2019-03-16 20:34:26,387 2019-03-16 20:34:26: step 519/50000, loss = 0.200578 (2.235 sec/batch), lr: 0.250000
2019-03-16 20:34:28,719 2019-03-16 20:34:28: step 520/50000, loss = 0.230217 (2.319 sec/batch), lr: 0.250000
2019-03-16 20:34:31,232 2019-03-16 20:34:31: step 521/50000, loss = 0.215861 (2.498 sec/batch), lr: 0.250000
2019-03-16 20:34:33,931 2019-03-16 20:34:33: step 522/50000, loss = 0.227464 (2.687 sec/batch), lr: 0.250000
2019-03-16 20:34:36,516 2019-03-16 20:34:36: step 523/50000, loss = 0.208267 (2.572 sec/batch), lr: 0.250000
2019-03-16 20:34:39,357 2019-03-16 20:34:39: step 524/50000, loss = 0.226269 (2.825 sec/batch), lr: 0.250000
2019-03-16 20:34:42,489 2019-03-16 20:34:42: step 525/50000, loss = 0.215626 (3.116 sec/batch), lr: 0.250000
2019-03-16 20:34:46,012 2019-03-16 20:34:46: step 526/50000, loss = 0.232350 (3.504 sec/batch), lr: 0.250000
2019-03-16 20:34:49,659 2019-03-16 20:34:49: step 527/50000, loss = 0.195751 (3.628 sec/batch), lr: 0.250000
2019-03-16 20:34:53,325 2019-03-16 20:34:53: step 528/50000, loss = 0.229430 (3.648 sec/batch), lr: 0.250000
2019-03-16 20:34:57,320 2019-03-16 20:34:57: step 529/50000, loss = 0.209915 (3.975 sec/batch), lr: 0.250000
2019-03-16 20:35:01,560 2019-03-16 20:35:01: step 530/50000, loss = 0.233903 (4.217 sec/batch), lr: 0.250000
2019-03-16 20:35:05,899 2019-03-16 20:35:05: step 531/50000, loss = 0.211661 (4.315 sec/batch), lr: 0.250000
2019-03-16 20:35:10,612 2019-03-16 20:35:10: step 532/50000, loss = 0.234035 (4.687 sec/batch), lr: 0.250000
2019-03-16 20:35:15,497 2019-03-16 20:35:15: step 533/50000, loss = 0.221159 (4.858 sec/batch), lr: 0.250000
2019-03-16 20:35:20,487 2019-03-16 20:35:20: step 534/50000, loss = 0.239217 (4.963 sec/batch), lr: 0.250000
2019-03-16 20:35:26,037 2019-03-16 20:35:26: step 535/50000, loss = 0.202699 (5.540 sec/batch), lr: 0.250000
2019-03-16 20:35:31,700 2019-03-16 20:35:31: step 536/50000, loss = 0.240730 (5.632 sec/batch), lr: 0.250000
2019-03-16 20:35:37,707 2019-03-16 20:35:37: step 537/50000, loss = 0.204925 (5.972 sec/batch), lr: 0.250000
2019-03-16 20:35:44,317 2019-03-16 20:35:44: step 538/50000, loss = 0.229386 (6.574 sec/batch), lr: 0.250000
2019-03-16 20:35:51,491 2019-03-16 20:35:51: step 539/50000, loss = 0.208686 (7.128 sec/batch), lr: 0.250000
2019-03-16 20:35:59,064 2019-03-16 20:35:59: step 540/50000, loss = 0.239335 (7.565 sec/batch), lr: 0.250000
2019-03-16 20:36:07,316 2019-03-16 20:36:07: step 541/50000, loss = 0.205921 (8.205 sec/batch), lr: 0.250000
2019-03-16 20:36:16,442 2019-03-16 20:36:16: step 542/50000, loss = 0.237284 (9.115 sec/batch), lr: 0.250000
2019-03-16 20:36:26,365 2019-03-16 20:36:26: step 543/50000, loss = 0.211491 (9.866 sec/batch), lr: 0.250000
2019-03-16 20:36:37,499 2019-03-16 20:36:37: step 544/50000, loss = 0.240630 (11.070 sec/batch), lr: 0.250000
2019-03-16 20:36:49,541 2019-03-16 20:36:49: step 545/50000, loss = 0.212693 (11.975 sec/batch), lr: 0.250000
2019-03-16 20:37:03,754 2019-03-16 20:37:03: step 546/50000, loss = 0.243787 (14.136 sec/batch), lr: 0.250000
2019-03-16 20:37:20,524 2019-03-16 20:37:20: step 547/50000, loss = 0.211112 (16.677 sec/batch), lr: 0.250000
2019-03-16 20:37:40,498 2019-03-16 20:37:40: step 548/50000, loss = 0.241077 (19.863 sec/batch), lr: 0.250000
2019-03-16 20:38:08,310 2019-03-16 20:38:08: step 549/50000, loss = 0.206084 (27.650 sec/batch), lr: 0.250000
2019-03-16 20:38:42,038 2019-03-16 20:38:42: step 550/50000, loss = 0.209081 (33.555 sec/batch), lr: 0.250000
2019-03-16 20:39:30,999 2019-03-16 20:39:30: step 551/50000, loss = 0.164728 (48.732 sec/batch), lr: 0.250000
2019-03-16 20:39:54,417 2019-03-16 20:39:54: step 552/50000, loss = 0.201109 (23.401 sec/batch), lr: 0.250000
2019-03-16 20:40:12,652 2019-03-16 20:40:12: step 553/50000, loss = 0.264561 (18.223 sec/batch), lr: 0.250000
2019-03-16 20:40:28,245 2019-03-16 20:40:28: step 554/50000, loss = 0.233009 (15.579 sec/batch), lr: 0.250000
2019-03-16 20:40:40,967 2019-03-16 20:40:40: step 555/50000, loss = 0.258131 (12.712 sec/batch), lr: 0.250000
2019-03-16 20:40:52,609 2019-03-16 20:40:52: step 556/50000, loss = 0.227242 (11.630 sec/batch), lr: 0.250000
2019-03-16 20:41:03,208 2019-03-16 20:41:03: step 557/50000, loss = 0.249988 (10.539 sec/batch), lr: 0.250000
2019-03-16 20:41:12,739 2019-03-16 20:41:12: step 558/50000, loss = 0.226609 (9.476 sec/batch), lr: 0.250000
2019-03-16 20:41:21,659 2019-03-16 20:41:21: step 559/50000, loss = 0.252738 (8.909 sec/batch), lr: 0.250000
2019-03-16 20:41:29,777 2019-03-16 20:41:29: step 560/50000, loss = 0.238564 (8.107 sec/batch), lr: 0.250000
2019-03-16 20:41:37,027 2019-03-16 20:41:37: step 561/50000, loss = 0.243633 (7.241 sec/batch), lr: 0.250000
2019-03-16 20:41:43,935 2019-03-16 20:41:43: step 562/50000, loss = 0.236002 (6.874 sec/batch), lr: 0.250000
2019-03-16 20:41:50,272 2019-03-16 20:41:50: step 563/50000, loss = 0.224340 (6.301 sec/batch), lr: 0.250000
2019-03-16 20:41:56,317 2019-03-16 20:41:56: step 564/50000, loss = 0.238477 (6.013 sec/batch), lr: 0.250000
2019-03-16 20:42:01,880 2019-03-16 20:42:01: step 565/50000, loss = 0.223946 (5.538 sec/batch), lr: 0.250000
2019-03-16 20:42:07,086 2019-03-16 20:42:07: step 566/50000, loss = 0.239148 (5.179 sec/batch), lr: 0.250000
2019-03-16 20:42:12,139 2019-03-16 20:42:12: step 567/50000, loss = 0.224891 (5.043 sec/batch), lr: 0.250000
2019-03-16 20:42:16,825 2019-03-16 20:42:16: step 568/50000, loss = 0.234493 (4.663 sec/batch), lr: 0.250000
2019-03-16 20:42:21,306 2019-03-16 20:42:21: step 569/50000, loss = 0.215147 (4.457 sec/batch), lr: 0.250000
2019-03-16 20:42:25,687 2019-03-16 20:42:25: step 570/50000, loss = 0.242810 (4.358 sec/batch), lr: 0.250000
2019-03-16 20:42:29,822 2019-03-16 20:42:29: step 571/50000, loss = 0.219010 (4.113 sec/batch), lr: 0.250000
2019-03-16 20:42:33,787 2019-03-16 20:42:33: step 572/50000, loss = 0.227053 (3.957 sec/batch), lr: 0.250000
2019-03-16 20:42:37,349 2019-03-16 20:42:37: step 573/50000, loss = 0.210962 (3.545 sec/batch), lr: 0.250000
2019-03-16 20:42:40,754 2019-03-16 20:42:40: step 574/50000, loss = 0.230939 (3.396 sec/batch), lr: 0.250000
2019-03-16 20:42:44,044 2019-03-16 20:42:44: step 575/50000, loss = 0.200394 (3.273 sec/batch), lr: 0.250000
2019-03-16 20:42:47,130 2019-03-16 20:42:47: step 576/50000, loss = 0.227024 (3.070 sec/batch), lr: 0.250000
2019-03-16 20:42:50,102 2019-03-16 20:42:50: step 577/50000, loss = 0.203911 (2.956 sec/batch), lr: 0.250000
2019-03-16 20:42:52,983 2019-03-16 20:42:52: step 578/50000, loss = 0.221590 (2.863 sec/batch), lr: 0.250000
2019-03-16 20:42:55,535 2019-03-16 20:42:55: step 579/50000, loss = 0.214704 (2.537 sec/batch), lr: 0.250000
2019-03-16 20:42:57,934 2019-03-16 20:42:57: step 580/50000, loss = 0.212956 (2.389 sec/batch), lr: 0.250000
2019-03-16 20:43:00,095 2019-03-16 20:43:00: step 581/50000, loss = 0.198338 (2.151 sec/batch), lr: 0.250000
2019-03-16 20:43:02,046 2019-03-16 20:43:02: step 582/50000, loss = 0.212291 (1.939 sec/batch), lr: 0.250000
2019-03-16 20:43:03,980 2019-03-16 20:43:03: step 583/50000, loss = 0.211743 (1.924 sec/batch), lr: 0.250000
2019-03-16 20:43:05,748 2019-03-16 20:43:05: step 584/50000, loss = 0.221548 (1.761 sec/batch), lr: 0.250000
2019-03-16 20:43:07,459 2019-03-16 20:43:07: step 585/50000, loss = 0.205723 (1.702 sec/batch), lr: 0.250000
2019-03-16 20:43:08,942 2019-03-16 20:43:08: step 586/50000, loss = 0.205209 (1.478 sec/batch), lr: 0.250000
2019-03-16 20:43:10,279 2019-03-16 20:43:10: step 587/50000, loss = 0.212783 (1.329 sec/batch), lr: 0.250000
2019-03-16 20:43:11,548 2019-03-16 20:43:11: step 588/50000, loss = 0.207797 (1.264 sec/batch), lr: 0.250000
2019-03-16 20:43:12,684 2019-03-16 20:43:12: step 589/50000, loss = 0.210640 (1.128 sec/batch), lr: 0.250000
2019-03-16 20:43:13,656 2019-03-16 20:43:13: step 590/50000, loss = 0.227887 (0.966 sec/batch), lr: 0.250000
2019-03-16 20:43:14,507 2019-03-16 20:43:14: step 591/50000, loss = 0.242892 (0.845 sec/batch), lr: 0.250000
2019-03-16 20:43:15,338 2019-03-16 20:43:15: step 592/50000, loss = 0.226494 (0.824 sec/batch), lr: 0.250000
2019-03-16 20:43:16,057 2019-03-16 20:43:16: step 593/50000, loss = 0.248928 (0.712 sec/batch), lr: 0.250000
2019-03-16 20:43:16,648 2019-03-16 20:43:16: step 594/50000, loss = 0.281907 (0.586 sec/batch), lr: 0.250000
2019-03-16 20:43:17,155 2019-03-16 20:43:17: step 595/50000, loss = 0.289665 (0.501 sec/batch), lr: 0.250000
2019-03-16 20:43:17,590 2019-03-16 20:43:17: step 596/50000, loss = 0.245287 (0.430 sec/batch), lr: 0.250000
2019-03-16 20:43:17,983 2019-03-16 20:43:17: step 597/50000, loss = 0.239268 (0.389 sec/batch), lr: 0.250000
2019-03-16 20:43:18,294 2019-03-16 20:43:18: step 598/50000, loss = 0.199514 (0.307 sec/batch), lr: 0.250000
2019-03-16 20:43:18,478 2019-03-16 20:43:18: step 599/50000, loss = 0.161665 (0.181 sec/batch), lr: 0.250000
2019-03-16 20:43:18,597 2019-03-16 20:43:18: step 600/50000, loss = 0.377249 (0.117 sec/batch), lr: 0.250000
2019-03-16 20:43:46,939 step 600: Full loss = 0.127187, Edge acc. = 0.2956
2019-03-16 20:43:46,999 step 600: Dev acc. = 0.262218
2019-03-16 20:43:47,150 2019-03-16 20:43:47: step 601/50000, loss = 0.185273 (0.146 sec/batch), lr: 0.125000
2019-03-16 20:43:47,374 2019-03-16 20:43:47: step 602/50000, loss = 0.104320 (0.220 sec/batch), lr: 0.125000
2019-03-16 20:43:47,677 2019-03-16 20:43:47: step 603/50000, loss = 0.196540 (0.299 sec/batch), lr: 0.125000
2019-03-16 20:43:48,106 2019-03-16 20:43:48: step 604/50000, loss = 0.175149 (0.424 sec/batch), lr: 0.125000
2019-03-16 20:43:48,647 2019-03-16 20:43:48: step 605/50000, loss = 0.166900 (0.535 sec/batch), lr: 0.125000
2019-03-16 20:43:49,298 2019-03-16 20:43:49: step 606/50000, loss = 0.169894 (0.646 sec/batch), lr: 0.125000
2019-03-16 20:43:50,072 2019-03-16 20:43:50: step 607/50000, loss = 0.167860 (0.768 sec/batch), lr: 0.125000
2019-03-16 20:43:50,837 2019-03-16 20:43:50: step 608/50000, loss = 0.183178 (0.762 sec/batch), lr: 0.125000
2019-03-16 20:43:51,708 2019-03-16 20:43:51: step 609/50000, loss = 0.181030 (0.864 sec/batch), lr: 0.125000
2019-03-16 20:43:52,791 2019-03-16 20:43:52: step 610/50000, loss = 0.176133 (1.075 sec/batch), lr: 0.125000
2019-03-16 20:43:53,957 2019-03-16 20:43:53: step 611/50000, loss = 0.176016 (1.156 sec/batch), lr: 0.125000
2019-03-16 20:43:55,230 2019-03-16 20:43:55: step 612/50000, loss = 0.183652 (1.264 sec/batch), lr: 0.125000
2019-03-16 20:43:56,562 2019-03-16 20:43:56: step 613/50000, loss = 0.170181 (1.323 sec/batch), lr: 0.125000
2019-03-16 20:43:58,007 2019-03-16 20:43:58: step 614/50000, loss = 0.174662 (1.436 sec/batch), lr: 0.125000
2019-03-16 20:43:59,491 2019-03-16 20:43:59: step 615/50000, loss = 0.183057 (1.480 sec/batch), lr: 0.125000
2019-03-16 20:44:01,252 2019-03-16 20:44:01: step 616/50000, loss = 0.196802 (1.754 sec/batch), lr: 0.125000
2019-03-16 20:44:03,109 2019-03-16 20:44:03: step 617/50000, loss = 0.179322 (1.846 sec/batch), lr: 0.125000
2019-03-16 20:44:05,088 2019-03-16 20:44:05: step 618/50000, loss = 0.197304 (1.967 sec/batch), lr: 0.125000
2019-03-16 20:44:07,230 2019-03-16 20:44:07: step 619/50000, loss = 0.176195 (2.134 sec/batch), lr: 0.125000
2019-03-16 20:44:09,430 2019-03-16 20:44:09: step 620/50000, loss = 0.195823 (2.187 sec/batch), lr: 0.125000
2019-03-16 20:44:11,722 2019-03-16 20:44:11: step 621/50000, loss = 0.185617 (2.281 sec/batch), lr: 0.125000
2019-03-16 20:44:14,367 2019-03-16 20:44:14: step 622/50000, loss = 0.185839 (2.632 sec/batch), lr: 0.125000
2019-03-16 20:44:17,220 2019-03-16 20:44:17: step 623/50000, loss = 0.189565 (2.838 sec/batch), lr: 0.125000
2019-03-16 20:44:20,343 2019-03-16 20:44:20: step 624/50000, loss = 0.190758 (3.107 sec/batch), lr: 0.125000
2019-03-16 20:44:23,406 2019-03-16 20:44:23: step 625/50000, loss = 0.198525 (3.045 sec/batch), lr: 0.125000
2019-03-16 20:44:26,670 2019-03-16 20:44:26: step 626/50000, loss = 0.194986 (3.246 sec/batch), lr: 0.125000
2019-03-16 20:44:30,092 2019-03-16 20:44:30: step 627/50000, loss = 0.189463 (3.404 sec/batch), lr: 0.125000
2019-03-16 20:44:33,583 2019-03-16 20:44:33: step 628/50000, loss = 0.197786 (3.471 sec/batch), lr: 0.125000
2019-03-16 20:44:37,418 2019-03-16 20:44:37: step 629/50000, loss = 0.203942 (3.813 sec/batch), lr: 0.125000
2019-03-16 20:44:41,725 2019-03-16 20:44:41: step 630/50000, loss = 0.202876 (4.284 sec/batch), lr: 0.125000
2019-03-16 20:44:46,073 2019-03-16 20:44:46: step 631/50000, loss = 0.204119 (4.324 sec/batch), lr: 0.125000
2019-03-16 20:44:50,721 2019-03-16 20:44:50: step 632/50000, loss = 0.208083 (4.622 sec/batch), lr: 0.125000
2019-03-16 20:44:55,742 2019-03-16 20:44:55: step 633/50000, loss = 0.201897 (4.993 sec/batch), lr: 0.125000
2019-03-16 20:45:01,012 2019-03-16 20:45:01: step 634/50000, loss = 0.203616 (5.241 sec/batch), lr: 0.125000
2019-03-16 20:45:06,588 2019-03-16 20:45:06: step 635/50000, loss = 0.198715 (5.547 sec/batch), lr: 0.125000
2019-03-16 20:45:12,285 2019-03-16 20:45:12: step 636/50000, loss = 0.214324 (5.662 sec/batch), lr: 0.125000
2019-03-16 20:45:18,325 2019-03-16 20:45:18: step 637/50000, loss = 0.195620 (6.006 sec/batch), lr: 0.125000
2019-03-16 20:45:25,081 2019-03-16 20:45:25: step 638/50000, loss = 0.202845 (6.745 sec/batch), lr: 0.125000
2019-03-16 20:45:32,265 2019-03-16 20:45:32: step 639/50000, loss = 0.196818 (7.148 sec/batch), lr: 0.125000
2019-03-16 20:45:39,801 2019-03-16 20:45:39: step 640/50000, loss = 0.210050 (7.493 sec/batch), lr: 0.125000
2019-03-16 20:45:47,952 2019-03-16 20:45:47: step 641/50000, loss = 0.201049 (8.104 sec/batch), lr: 0.125000
2019-03-16 20:45:57,078 2019-03-16 20:45:57: step 642/50000, loss = 0.214813 (9.073 sec/batch), lr: 0.125000
2019-03-16 20:46:07,793 2019-03-16 20:46:07: step 643/50000, loss = 0.205087 (10.655 sec/batch), lr: 0.125000
2019-03-16 20:46:18,845 2019-03-16 20:46:18: step 644/50000, loss = 0.219664 (10.990 sec/batch), lr: 0.125000
2019-03-16 20:46:30,974 2019-03-16 20:46:30: step 645/50000, loss = 0.204345 (12.056 sec/batch), lr: 0.125000
2019-03-16 20:46:45,226 2019-03-16 20:46:45: step 646/50000, loss = 0.224353 (14.166 sec/batch), lr: 0.125000
2019-03-16 20:47:02,184 2019-03-16 20:47:02: step 647/50000, loss = 0.211183 (16.853 sec/batch), lr: 0.125000
2019-03-16 20:47:21,991 2019-03-16 20:47:21: step 648/50000, loss = 0.211441 (19.684 sec/batch), lr: 0.125000
2019-03-16 20:47:50,305 2019-03-16 20:47:50: step 649/50000, loss = 0.215237 (28.148 sec/batch), lr: 0.125000
2019-03-16 20:48:23,997 2019-03-16 20:48:23: step 650/50000, loss = 0.185231 (33.678 sec/batch), lr: 0.125000
2019-03-16 20:49:12,890 2019-03-16 20:49:12: step 651/50000, loss = 0.168690 (48.648 sec/batch), lr: 0.125000
2019-03-16 20:49:36,443 2019-03-16 20:49:36: step 652/50000, loss = 0.208054 (23.536 sec/batch), lr: 0.125000
2019-03-16 20:49:54,552 2019-03-16 20:49:54: step 653/50000, loss = 0.236138 (18.093 sec/batch), lr: 0.125000
2019-03-16 20:50:10,223 2019-03-16 20:50:10: step 654/50000, loss = 0.217425 (15.576 sec/batch), lr: 0.125000
2019-03-16 20:50:23,042 2019-03-16 20:50:23: step 655/50000, loss = 0.235420 (12.741 sec/batch), lr: 0.125000
2019-03-16 20:50:34,512 2019-03-16 20:50:34: step 656/50000, loss = 0.205563 (11.458 sec/batch), lr: 0.125000
2019-03-16 20:50:44,821 2019-03-16 20:50:44: step 657/50000, loss = 0.240777 (10.254 sec/batch), lr: 0.125000
2019-03-16 20:50:54,332 2019-03-16 20:50:54: step 658/50000, loss = 0.204716 (9.461 sec/batch), lr: 0.125000
2019-03-16 20:51:03,264 2019-03-16 20:51:03: step 659/50000, loss = 0.222980 (8.882 sec/batch), lr: 0.125000
2019-03-16 20:51:11,403 2019-03-16 20:51:11: step 660/50000, loss = 0.207353 (8.093 sec/batch), lr: 0.125000
2019-03-16 20:51:18,738 2019-03-16 20:51:18: step 661/50000, loss = 0.229126 (7.294 sec/batch), lr: 0.125000
2019-03-16 20:51:25,605 2019-03-16 20:51:25: step 662/50000, loss = 0.200760 (6.829 sec/batch), lr: 0.125000
2019-03-16 20:51:31,962 2019-03-16 20:51:31: step 663/50000, loss = 0.215588 (6.323 sec/batch), lr: 0.125000
2019-03-16 20:51:37,880 2019-03-16 20:51:37: step 664/50000, loss = 0.201473 (5.910 sec/batch), lr: 0.125000
2019-03-16 20:51:43,461 2019-03-16 20:51:43: step 665/50000, loss = 0.210888 (5.550 sec/batch), lr: 0.125000
2019-03-16 20:51:48,818 2019-03-16 20:51:48: step 666/50000, loss = 0.207946 (5.327 sec/batch), lr: 0.125000
2019-03-16 20:51:53,576 2019-03-16 20:51:53: step 667/50000, loss = 0.222521 (4.735 sec/batch), lr: 0.125000
2019-03-16 20:51:58,392 2019-03-16 20:51:58: step 668/50000, loss = 0.202857 (4.791 sec/batch), lr: 0.125000
2019-03-16 20:52:02,973 2019-03-16 20:52:02: step 669/50000, loss = 0.218381 (4.572 sec/batch), lr: 0.125000
2019-03-16 20:52:07,106 2019-03-16 20:52:07: step 670/50000, loss = 0.208255 (4.112 sec/batch), lr: 0.125000
2019-03-16 20:52:11,247 2019-03-16 20:52:11: step 671/50000, loss = 0.215249 (4.119 sec/batch), lr: 0.125000
2019-03-16 20:52:15,190 2019-03-16 20:52:15: step 672/50000, loss = 0.194000 (3.921 sec/batch), lr: 0.125000
2019-03-16 20:52:18,831 2019-03-16 20:52:18: step 673/50000, loss = 0.206005 (3.622 sec/batch), lr: 0.125000
2019-03-16 20:52:22,245 2019-03-16 20:52:22: step 674/50000, loss = 0.197266 (3.405 sec/batch), lr: 0.125000
2019-03-16 20:52:25,531 2019-03-16 20:52:25: step 675/50000, loss = 0.204397 (3.269 sec/batch), lr: 0.125000
2019-03-16 20:52:28,585 2019-03-16 20:52:28: step 676/50000, loss = 0.198789 (3.037 sec/batch), lr: 0.125000
2019-03-16 20:52:31,630 2019-03-16 20:52:31: step 677/50000, loss = 0.207996 (3.030 sec/batch), lr: 0.125000
2019-03-16 20:52:34,368 2019-03-16 20:52:34: step 678/50000, loss = 0.199155 (2.725 sec/batch), lr: 0.125000
2019-03-16 20:52:36,946 2019-03-16 20:52:36: step 679/50000, loss = 0.216220 (2.564 sec/batch), lr: 0.125000
2019-03-16 20:52:39,497 2019-03-16 20:52:39: step 680/50000, loss = 0.191425 (2.538 sec/batch), lr: 0.125000
2019-03-16 20:52:41,731 2019-03-16 20:52:41: step 681/50000, loss = 0.197013 (2.221 sec/batch), lr: 0.125000
2019-03-16 20:52:43,836 2019-03-16 20:52:43: step 682/50000, loss = 0.191689 (2.098 sec/batch), lr: 0.125000
2019-03-16 20:52:45,930 2019-03-16 20:52:45: step 683/50000, loss = 0.194097 (2.082 sec/batch), lr: 0.125000
2019-03-16 20:52:47,816 2019-03-16 20:52:47: step 684/50000, loss = 0.193491 (1.874 sec/batch), lr: 0.125000
2019-03-16 20:52:49,681 2019-03-16 20:52:49: step 685/50000, loss = 0.186657 (1.855 sec/batch), lr: 0.125000
2019-03-16 20:52:51,195 2019-03-16 20:52:51: step 686/50000, loss = 0.180076 (1.509 sec/batch), lr: 0.125000
2019-03-16 20:52:52,646 2019-03-16 20:52:52: step 687/50000, loss = 0.192849 (1.442 sec/batch), lr: 0.125000
2019-03-16 20:52:54,017 2019-03-16 20:52:54: step 688/50000, loss = 0.172243 (1.361 sec/batch), lr: 0.125000
2019-03-16 20:52:55,133 2019-03-16 20:52:55: step 689/50000, loss = 0.176193 (1.109 sec/batch), lr: 0.125000
2019-03-16 20:52:56,142 2019-03-16 20:52:56: step 690/50000, loss = 0.177029 (1.003 sec/batch), lr: 0.125000
2019-03-16 20:52:57,130 2019-03-16 20:52:57: step 691/50000, loss = 0.191077 (0.979 sec/batch), lr: 0.125000
2019-03-16 20:52:58,078 2019-03-16 20:52:58: step 692/50000, loss = 0.177370 (0.940 sec/batch), lr: 0.125000
2019-03-16 20:52:58,899 2019-03-16 20:52:58: step 693/50000, loss = 0.199791 (0.813 sec/batch), lr: 0.125000
2019-03-16 20:52:59,576 2019-03-16 20:52:59: step 694/50000, loss = 0.179671 (0.669 sec/batch), lr: 0.125000
2019-03-16 20:53:00,133 2019-03-16 20:53:00: step 695/50000, loss = 0.189529 (0.552 sec/batch), lr: 0.125000
2019-03-16 20:53:00,657 2019-03-16 20:53:00: step 696/50000, loss = 0.162712 (0.517 sec/batch), lr: 0.125000
2019-03-16 20:53:01,085 2019-03-16 20:53:01: step 697/50000, loss = 0.156577 (0.422 sec/batch), lr: 0.125000
2019-03-16 20:53:01,408 2019-03-16 20:53:01: step 698/50000, loss = 0.157569 (0.318 sec/batch), lr: 0.125000
2019-03-16 20:53:01,603 2019-03-16 20:53:01: step 699/50000, loss = 0.063877 (0.192 sec/batch), lr: 0.125000
2019-03-16 20:53:01,739 2019-03-16 20:53:01: step 700/50000, loss = 0.071454 (0.133 sec/batch), lr: 0.125000
2019-03-16 20:53:30,140 step 700: Full loss = 0.254513, Edge acc. = 0.2899
2019-03-16 20:53:30,200 step 700: Dev acc. = 0.169759
2019-03-16 20:53:30,342 2019-03-16 20:53:30: step 701/50000, loss = 0.311873 (0.137 sec/batch), lr: 0.125000
2019-03-16 20:53:30,553 2019-03-16 20:53:30: step 702/50000, loss = 0.166096 (0.208 sec/batch), lr: 0.125000
2019-03-16 20:53:30,862 2019-03-16 20:53:30: step 703/50000, loss = 0.270173 (0.305 sec/batch), lr: 0.125000
2019-03-16 20:53:31,303 2019-03-16 20:53:31: step 704/50000, loss = 0.210104 (0.436 sec/batch), lr: 0.125000
2019-03-16 20:53:31,852 2019-03-16 20:53:31: step 705/50000, loss = 0.273920 (0.543 sec/batch), lr: 0.125000
2019-03-16 20:53:32,499 2019-03-16 20:53:32: step 706/50000, loss = 0.281913 (0.640 sec/batch), lr: 0.125000
2019-03-16 20:53:33,284 2019-03-16 20:53:33: step 707/50000, loss = 0.342433 (0.780 sec/batch), lr: 0.125000
2019-03-16 20:53:34,110 2019-03-16 20:53:34: step 708/50000, loss = 0.313642 (0.818 sec/batch), lr: 0.125000
2019-03-16 20:53:35,087 2019-03-16 20:53:35: step 709/50000, loss = 0.433232 (0.969 sec/batch), lr: 0.125000
2019-03-16 20:53:36,177 2019-03-16 20:53:36: step 710/50000, loss = 0.325942 (1.082 sec/batch), lr: 0.125000
2019-03-16 20:53:37,350 2019-03-16 20:53:37: step 711/50000, loss = 0.277992 (1.164 sec/batch), lr: 0.125000
2019-03-16 20:53:38,650 2019-03-16 20:53:38: step 712/50000, loss = 0.338433 (1.291 sec/batch), lr: 0.125000
2019-03-16 20:53:40,098 2019-03-16 20:53:40: step 713/50000, loss = 0.302570 (1.441 sec/batch), lr: 0.125000
2019-03-16 20:53:41,542 2019-03-16 20:53:41: step 714/50000, loss = 0.314033 (1.436 sec/batch), lr: 0.125000
2019-03-16 20:53:43,090 2019-03-16 20:53:43: step 715/50000, loss = 0.350922 (1.541 sec/batch), lr: 0.125000
2019-03-16 20:53:44,964 2019-03-16 20:53:44: step 716/50000, loss = 0.288600 (1.865 sec/batch), lr: 0.125000
2019-03-16 20:53:47,001 2019-03-16 20:53:47: step 717/50000, loss = 0.338689 (2.025 sec/batch), lr: 0.125000
2019-03-16 20:53:49,129 2019-03-16 20:53:49: step 718/50000, loss = 0.282691 (2.115 sec/batch), lr: 0.125000
2019-03-16 20:53:51,385 2019-03-16 20:53:51: step 719/50000, loss = 0.272236 (2.244 sec/batch), lr: 0.125000
2019-03-16 20:53:53,603 2019-03-16 20:53:53: step 720/50000, loss = 0.236992 (2.207 sec/batch), lr: 0.125000
2019-03-16 20:53:56,142 2019-03-16 20:53:56: step 721/50000, loss = 0.218053 (2.526 sec/batch), lr: 0.125000
2019-03-16 20:53:58,862 2019-03-16 20:53:58: step 722/50000, loss = 0.214882 (2.707 sec/batch), lr: 0.125000
2019-03-16 20:54:01,525 2019-03-16 20:54:01: step 723/50000, loss = 0.224370 (2.649 sec/batch), lr: 0.125000
2019-03-16 20:54:04,562 2019-03-16 20:54:04: step 724/50000, loss = 0.236126 (3.019 sec/batch), lr: 0.125000
2019-03-16 20:54:07,525 2019-03-16 20:54:07: step 725/50000, loss = 0.220137 (2.946 sec/batch), lr: 0.125000
2019-03-16 20:54:10,920 2019-03-16 20:54:10: step 726/50000, loss = 0.230869 (3.377 sec/batch), lr: 0.125000
2019-03-16 20:54:14,420 2019-03-16 20:54:14: step 727/50000, loss = 0.213782 (3.482 sec/batch), lr: 0.125000
2019-03-16 20:54:18,132 2019-03-16 20:54:18: step 728/50000, loss = 0.234283 (3.693 sec/batch), lr: 0.125000
2019-03-16 20:54:22,107 2019-03-16 20:54:22: step 729/50000, loss = 0.235110 (3.954 sec/batch), lr: 0.125000
2019-03-16 20:54:26,198 2019-03-16 20:54:26: step 730/50000, loss = 0.243796 (4.070 sec/batch), lr: 0.125000
2019-03-16 20:54:30,439 2019-03-16 20:54:30: step 731/50000, loss = 0.235173 (4.218 sec/batch), lr: 0.125000
2019-03-16 20:54:35,025 2019-03-16 20:54:35: step 732/50000, loss = 0.245143 (4.561 sec/batch), lr: 0.125000
2019-03-16 20:54:39,997 2019-03-16 20:54:39: step 733/50000, loss = 0.234471 (4.963 sec/batch), lr: 0.125000
2019-03-16 20:54:45,166 2019-03-16 20:54:45: step 734/50000, loss = 0.231941 (5.141 sec/batch), lr: 0.125000
2019-03-16 20:54:50,734 2019-03-16 20:54:50: step 735/50000, loss = 0.227153 (5.536 sec/batch), lr: 0.125000
2019-03-16 20:54:56,402 2019-03-16 20:54:56: step 736/50000, loss = 0.252507 (5.658 sec/batch), lr: 0.125000
2019-03-16 20:55:02,385 2019-03-16 20:55:02: step 737/50000, loss = 0.226691 (5.975 sec/batch), lr: 0.125000
2019-03-16 20:55:09,133 2019-03-16 20:55:09: step 738/50000, loss = 0.252091 (6.711 sec/batch), lr: 0.125000
2019-03-16 20:55:16,306 2019-03-16 20:55:16: step 739/50000, loss = 0.228293 (7.134 sec/batch), lr: 0.125000
2019-03-16 20:55:24,047 2019-03-16 20:55:24: step 740/50000, loss = 0.259126 (7.731 sec/batch), lr: 0.125000
2019-03-16 20:55:32,266 2019-03-16 20:55:32: step 741/50000, loss = 0.235771 (8.172 sec/batch), lr: 0.125000
2019-03-16 20:55:41,425 2019-03-16 20:55:41: step 742/50000, loss = 0.259939 (9.105 sec/batch), lr: 0.125000
2019-03-16 20:55:51,601 2019-03-16 20:55:51: step 743/50000, loss = 0.236245 (10.116 sec/batch), lr: 0.125000
2019-03-16 20:56:02,631 2019-03-16 20:56:02: step 744/50000, loss = 0.257703 (10.969 sec/batch), lr: 0.125000
2019-03-16 20:56:14,636 2019-03-16 20:56:14: step 745/50000, loss = 0.233453 (11.941 sec/batch), lr: 0.125000
2019-03-16 20:56:28,677 2019-03-16 20:56:28: step 746/50000, loss = 0.280990 (13.962 sec/batch), lr: 0.125000
2019-03-16 20:56:45,688 2019-03-16 20:56:45: step 747/50000, loss = 0.243769 (16.907 sec/batch), lr: 0.125000
2019-03-16 20:57:05,683 2019-03-16 20:57:05: step 748/50000, loss = 0.275136 (19.874 sec/batch), lr: 0.125000
2019-03-16 20:57:33,540 2019-03-16 20:57:33: step 749/50000, loss = 0.238235 (27.701 sec/batch), lr: 0.125000
2019-03-16 20:58:07,393 2019-03-16 20:58:07: step 750/50000, loss = 0.220624 (33.674 sec/batch), lr: 0.125000
2019-03-16 20:58:07,544 2019-03-16 20:58:07: step 751/50000, loss = 0.907656 (0.146 sec/batch), lr: 0.125000
2019-03-16 20:58:07,766 2019-03-16 20:58:07: step 752/50000, loss = 0.166195 (0.219 sec/batch), lr: 0.125000
2019-03-16 20:58:08,062 2019-03-16 20:58:08: step 753/50000, loss = 0.620310 (0.293 sec/batch), lr: 0.125000
2019-03-16 20:58:08,492 2019-03-16 20:58:08: step 754/50000, loss = 0.189577 (0.425 sec/batch), lr: 0.125000
2019-03-16 20:58:09,017 2019-03-16 20:58:09: step 755/50000, loss = 0.320356 (0.520 sec/batch), lr: 0.125000
2019-03-16 20:58:09,646 2019-03-16 20:58:09: step 756/50000, loss = 0.418471 (0.624 sec/batch), lr: 0.125000
2019-03-16 20:58:10,425 2019-03-16 20:58:10: step 757/50000, loss = 0.198081 (0.775 sec/batch), lr: 0.125000
2019-03-16 20:58:11,233 2019-03-16 20:58:11: step 758/50000, loss = 0.246690 (0.802 sec/batch), lr: 0.125000
2019-03-16 20:58:12,144 2019-03-16 20:58:12: step 759/50000, loss = 0.224745 (0.903 sec/batch), lr: 0.125000
2019-03-16 20:58:13,057 2019-03-16 20:58:13: step 760/50000, loss = 0.209475 (0.909 sec/batch), lr: 0.125000
2019-03-16 20:58:14,074 2019-03-16 20:58:14: step 761/50000, loss = 0.198422 (1.011 sec/batch), lr: 0.125000
2019-03-16 20:58:15,239 2019-03-16 20:58:15: step 762/50000, loss = 0.203658 (1.156 sec/batch), lr: 0.125000
2019-03-16 20:58:16,575 2019-03-16 20:58:16: step 763/50000, loss = 0.194358 (1.328 sec/batch), lr: 0.125000
2019-03-16 20:58:18,175 2019-03-16 20:58:18: step 764/50000, loss = 0.187250 (1.590 sec/batch), lr: 0.125000
2019-03-16 20:58:19,851 2019-03-16 20:58:19: step 765/50000, loss = 0.193661 (1.666 sec/batch), lr: 0.125000
2019-03-16 20:58:21,557 2019-03-16 20:58:21: step 766/50000, loss = 0.211959 (1.702 sec/batch), lr: 0.125000
2019-03-16 20:58:23,415 2019-03-16 20:58:23: step 767/50000, loss = 0.191830 (1.848 sec/batch), lr: 0.125000
2019-03-16 20:58:25,490 2019-03-16 20:58:25: step 768/50000, loss = 0.213182 (2.064 sec/batch), lr: 0.125000
2019-03-16 20:58:27,612 2019-03-16 20:58:27: step 769/50000, loss = 0.193048 (2.114 sec/batch), lr: 0.125000
2019-03-16 20:58:29,815 2019-03-16 20:58:29: step 770/50000, loss = 0.210800 (2.194 sec/batch), lr: 0.125000
2019-03-16 20:58:32,192 2019-03-16 20:58:32: step 771/50000, loss = 0.204686 (2.365 sec/batch), lr: 0.125000
2019-03-16 20:58:34,952 2019-03-16 20:58:34: step 772/50000, loss = 0.202532 (2.746 sec/batch), lr: 0.125000
2019-03-16 20:58:37,766 2019-03-16 20:58:37: step 773/50000, loss = 0.205639 (2.799 sec/batch), lr: 0.125000
2019-03-16 20:58:40,859 2019-03-16 20:58:40: step 774/50000, loss = 0.213410 (3.077 sec/batch), lr: 0.125000
2019-03-16 20:58:43,846 2019-03-16 20:58:43: step 775/50000, loss = 0.204200 (2.972 sec/batch), lr: 0.125000
2019-03-16 21:00:58,300 2019-03-16 21:00:58: step 1/50000, loss = 0.344588 (49.153 sec/batch), lr: 1.000000
2019-03-16 21:01:21,443 2019-03-16 21:01:21: step 2/50000, loss = 0.452280 (23.130 sec/batch), lr: 1.000000
2019-03-16 21:01:39,266 2019-03-16 21:01:39: step 3/50000, loss = 0.468313 (17.811 sec/batch), lr: 1.000000
2019-03-16 21:01:54,729 2019-03-16 21:01:54: step 4/50000, loss = 0.470339 (15.374 sec/batch), lr: 1.000000
2019-03-16 21:02:07,256 2019-03-16 21:02:07: step 5/50000, loss = 0.477272 (12.455 sec/batch), lr: 1.000000
2019-03-16 21:02:18,577 2019-03-16 21:02:18: step 6/50000, loss = 0.471270 (11.258 sec/batch), lr: 1.000000
2019-03-16 21:02:29,139 2019-03-16 21:02:29: step 7/50000, loss = 0.475387 (10.538 sec/batch), lr: 1.000000
2019-03-16 21:02:38,725 2019-03-16 21:02:38: step 8/50000, loss = 0.475531 (9.530 sec/batch), lr: 1.000000
2019-03-16 21:02:47,595 2019-03-16 21:02:47: step 9/50000, loss = 0.460888 (8.819 sec/batch), lr: 1.000000
2019-03-16 21:02:55,852 2019-03-16 21:02:55: step 10/50000, loss = 0.467227 (8.216 sec/batch), lr: 1.000000
2019-03-16 21:03:02,948 2019-03-16 21:03:02: step 11/50000, loss = 0.468147 (7.056 sec/batch), lr: 1.000000
2019-03-16 21:03:09,805 2019-03-16 21:03:09: step 12/50000, loss = 0.460318 (6.820 sec/batch), lr: 1.000000
2019-03-16 21:03:16,169 2019-03-16 21:03:16: step 13/50000, loss = 0.449785 (6.332 sec/batch), lr: 1.000000
2019-03-16 21:03:22,027 2019-03-16 21:03:22: step 14/50000, loss = 0.420556 (5.828 sec/batch), lr: 1.000000
2019-03-16 21:03:27,678 2019-03-16 21:03:27: step 15/50000, loss = 0.209454 (5.619 sec/batch), lr: 1.000000
2019-03-16 21:03:32,956 2019-03-16 21:03:32: step 16/50000, loss = 0.408472 (5.269 sec/batch), lr: 1.000000
2019-03-16 21:03:37,896 2019-03-16 21:03:37: step 17/50000, loss = 0.251090 (4.930 sec/batch), lr: 1.000000
2019-03-16 21:03:42,776 2019-03-16 21:03:42: step 18/50000, loss = 0.418405 (4.854 sec/batch), lr: 1.000000
2019-03-16 21:03:47,339 2019-03-16 21:03:47: step 19/50000, loss = 0.225388 (4.538 sec/batch), lr: 1.000000
2019-03-16 21:03:51,630 2019-03-16 21:03:51: step 20/50000, loss = 0.376027 (4.269 sec/batch), lr: 1.000000
2019-03-16 21:03:55,744 2019-03-16 21:03:55: step 21/50000, loss = 0.209697 (4.092 sec/batch), lr: 1.000000
2019-03-16 21:03:59,624 2019-03-16 21:03:59: step 22/50000, loss = 0.383500 (3.859 sec/batch), lr: 1.000000
2019-03-16 21:04:03,269 2019-03-16 21:04:03: step 23/50000, loss = 0.201209 (3.624 sec/batch), lr: 1.000000
2019-03-16 21:04:06,659 2019-03-16 21:04:06: step 24/50000, loss = 0.317051 (3.371 sec/batch), lr: 1.000000
2019-03-16 21:04:09,908 2019-03-16 21:04:09: step 25/50000, loss = 0.195797 (3.231 sec/batch), lr: 1.000000
2019-03-16 21:04:12,833 2019-03-16 21:04:12: step 26/50000, loss = 0.363682 (2.910 sec/batch), lr: 1.000000
2019-03-16 21:04:15,803 2019-03-16 21:04:15: step 27/50000, loss = 0.198261 (2.955 sec/batch), lr: 1.000000
2019-03-16 21:04:18,642 2019-03-16 21:04:18: step 28/50000, loss = 0.426730 (2.823 sec/batch), lr: 1.000000
2019-03-16 21:04:21,232 2019-03-16 21:04:21: step 29/50000, loss = 0.387278 (2.576 sec/batch), lr: 1.000000
2019-03-16 21:04:23,742 2019-03-16 21:04:23: step 30/50000, loss = 0.340344 (2.497 sec/batch), lr: 1.000000
2019-03-16 21:04:25,975 2019-03-16 21:04:25: step 31/50000, loss = 0.261006 (2.226 sec/batch), lr: 1.000000
2019-03-16 21:04:28,015 2019-03-16 21:04:28: step 32/50000, loss = 0.295406 (2.029 sec/batch), lr: 1.000000
2019-03-16 21:04:30,077 2019-03-16 21:04:30: step 33/50000, loss = 0.377895 (2.050 sec/batch), lr: 1.000000
2019-03-16 21:04:31,970 2019-03-16 21:04:31: step 34/50000, loss = 0.280365 (1.881 sec/batch), lr: 1.000000
2019-03-16 21:04:33,734 2019-03-16 21:04:33: step 35/50000, loss = 0.360417 (1.751 sec/batch), lr: 1.000000
2019-03-16 21:04:35,367 2019-03-16 21:04:35: step 36/50000, loss = 0.259809 (1.623 sec/batch), lr: 1.000000
2019-03-16 21:04:36,811 2019-03-16 21:04:36: step 37/50000, loss = 0.360806 (1.435 sec/batch), lr: 1.000000
2019-03-16 21:04:38,198 2019-03-16 21:04:38: step 38/50000, loss = 0.235809 (1.381 sec/batch), lr: 1.000000
2019-03-16 21:04:39,436 2019-03-16 21:04:39: step 39/50000, loss = 0.326833 (1.229 sec/batch), lr: 1.000000
2019-03-16 21:04:40,537 2019-03-16 21:04:40: step 40/50000, loss = 0.237919 (1.093 sec/batch), lr: 1.000000
2019-03-16 21:04:41,503 2019-03-16 21:04:41: step 41/50000, loss = 0.345234 (0.959 sec/batch), lr: 1.000000
2019-03-16 21:04:42,441 2019-03-16 21:04:42: step 42/50000, loss = 0.240500 (0.931 sec/batch), lr: 1.000000
2019-03-16 21:04:43,256 2019-03-16 21:04:43: step 43/50000, loss = 0.328986 (0.807 sec/batch), lr: 1.000000
2019-03-16 21:04:43,923 2019-03-16 21:04:43: step 44/50000, loss = 0.257743 (0.660 sec/batch), lr: 1.000000
2019-03-16 21:04:44,469 2019-03-16 21:04:44: step 45/50000, loss = 0.321794 (0.540 sec/batch), lr: 1.000000
2019-03-16 21:04:44,976 2019-03-16 21:04:44: step 46/50000, loss = 0.258289 (0.502 sec/batch), lr: 1.000000
2019-03-16 21:04:45,384 2019-03-16 21:04:45: step 47/50000, loss = 0.282544 (0.402 sec/batch), lr: 1.000000
2019-03-16 21:04:45,708 2019-03-16 21:04:45: step 48/50000, loss = 0.278708 (0.320 sec/batch), lr: 1.000000
2019-03-16 21:04:45,904 2019-03-16 21:04:45: step 49/50000, loss = 0.351066 (0.191 sec/batch), lr: 1.000000
2019-03-16 21:04:46,030 2019-03-16 21:04:46: step 50/50000, loss = 0.530983 (0.124 sec/batch), lr: 1.000000
2019-03-16 21:04:46,214 2019-03-16 21:04:46: step 51/50000, loss = 0.789055 (0.177 sec/batch), lr: 1.000000
2019-03-16 21:04:46,467 2019-03-16 21:04:46: step 52/50000, loss = 0.546026 (0.249 sec/batch), lr: 1.000000
2019-03-16 21:04:46,806 2019-03-16 21:04:46: step 53/50000, loss = 0.514020 (0.333 sec/batch), lr: 1.000000
2019-03-16 21:04:47,228 2019-03-16 21:04:47: step 54/50000, loss = 0.488586 (0.417 sec/batch), lr: 1.000000
2019-03-16 21:04:47,749 2019-03-16 21:04:47: step 55/50000, loss = 0.486197 (0.514 sec/batch), lr: 1.000000
2019-03-16 21:04:48,378 2019-03-16 21:04:48: step 56/50000, loss = 0.469379 (0.623 sec/batch), lr: 1.000000
2019-03-16 21:04:49,162 2019-03-16 21:04:49: step 57/50000, loss = 0.480068 (0.776 sec/batch), lr: 1.000000
2019-03-16 21:04:49,973 2019-03-16 21:04:49: step 58/50000, loss = 0.510063 (0.803 sec/batch), lr: 1.000000
2019-03-16 21:04:50,923 2019-03-16 21:04:50: step 59/50000, loss = 0.505295 (0.942 sec/batch), lr: 1.000000
2019-03-16 21:04:51,906 2019-03-16 21:04:51: step 60/50000, loss = 0.465305 (0.978 sec/batch), lr: 1.000000
2019-03-16 21:04:52,877 2019-03-16 21:04:52: step 61/50000, loss = 0.505705 (0.965 sec/batch), lr: 1.000000
2019-03-16 21:04:54,018 2019-03-16 21:04:54: step 62/50000, loss = 0.492161 (1.137 sec/batch), lr: 1.000000
2019-03-16 21:04:55,451 2019-03-16 21:04:55: step 63/50000, loss = 0.484772 (1.423 sec/batch), lr: 1.000000
2019-03-16 21:04:57,032 2019-03-16 21:04:57: step 64/50000, loss = 0.471212 (1.572 sec/batch), lr: 1.000000
2019-03-16 21:04:58,711 2019-03-16 21:04:58: step 65/50000, loss = 0.503000 (1.665 sec/batch), lr: 1.000000
2019-03-16 21:05:00,507 2019-03-16 21:05:00: step 66/50000, loss = 0.502460 (1.785 sec/batch), lr: 1.000000
2019-03-16 21:05:02,503 2019-03-16 21:05:02: step 67/50000, loss = 0.472296 (1.983 sec/batch), lr: 1.000000
2019-03-16 21:05:04,596 2019-03-16 21:05:04: step 68/50000, loss = 0.501744 (2.080 sec/batch), lr: 1.000000
2019-03-16 21:05:06,879 2019-03-16 21:05:06: step 69/50000, loss = 0.476337 (2.269 sec/batch), lr: 1.000000
2019-03-16 21:05:09,600 2019-03-16 21:05:09: step 70/50000, loss = 0.501134 (2.707 sec/batch), lr: 1.000000
2019-03-16 21:05:12,706 2019-03-16 21:05:12: step 71/50000, loss = 0.495295 (3.083 sec/batch), lr: 1.000000
2019-03-16 21:05:15,927 2019-03-16 21:05:15: step 72/50000, loss = 0.482156 (3.200 sec/batch), lr: 1.000000
2019-03-16 21:05:18,837 2019-03-16 21:05:18: step 73/50000, loss = 0.500341 (2.894 sec/batch), lr: 1.000000
2019-03-16 21:05:22,005 2019-03-16 21:05:22: step 74/50000, loss = 0.496387 (3.151 sec/batch), lr: 1.000000
2019-03-16 21:05:25,127 2019-03-16 21:05:25: step 75/50000, loss = 0.499924 (3.105 sec/batch), lr: 1.000000
2019-03-16 21:05:28,582 2019-03-16 21:05:28: step 76/50000, loss = 0.497341 (3.436 sec/batch), lr: 1.000000
2019-03-16 21:05:32,231 2019-03-16 21:05:32: step 77/50000, loss = 0.484758 (3.629 sec/batch), lr: 1.000000
2019-03-16 21:05:35,983 2019-03-16 21:05:35: step 78/50000, loss = 0.499325 (3.731 sec/batch), lr: 1.000000
2019-03-16 21:05:40,043 2019-03-16 21:05:40: step 79/50000, loss = 0.499180 (4.037 sec/batch), lr: 1.000000
2019-03-16 21:05:44,281 2019-03-16 21:05:44: step 80/50000, loss = 0.489625 (4.215 sec/batch), lr: 1.000000
2019-03-16 21:05:48,671 2019-03-16 21:05:48: step 81/50000, loss = 0.498865 (4.366 sec/batch), lr: 1.000000
2019-03-16 21:05:53,423 2019-03-16 21:05:53: step 82/50000, loss = 0.497696 (4.725 sec/batch), lr: 1.000000
2019-03-16 21:05:58,402 2019-03-16 21:05:58: step 83/50000, loss = 0.493757 (4.952 sec/batch), lr: 1.000000
2019-03-16 21:06:03,701 2019-03-16 21:06:03: step 84/50000, loss = 0.485513 (5.271 sec/batch), lr: 1.000000
2019-03-16 21:06:09,347 2019-03-16 21:06:09: step 85/50000, loss = 0.482285 (5.615 sec/batch), lr: 1.000000
2019-03-16 21:06:15,103 2019-03-16 21:06:15: step 86/50000, loss = 0.498158 (5.723 sec/batch), lr: 1.000000
2019-03-16 21:06:21,162 2019-03-16 21:06:21: step 87/50000, loss = 0.494561 (6.025 sec/batch), lr: 1.000000
2019-03-16 21:06:28,028 2019-03-16 21:06:28: step 88/50000, loss = 0.481813 (6.828 sec/batch), lr: 1.000000
2019-03-16 21:06:35,282 2019-03-16 21:06:35: step 89/50000, loss = 0.484554 (7.213 sec/batch), lr: 1.000000
2019-03-16 21:06:43,111 2019-03-16 21:06:43: step 90/50000, loss = 0.489366 (7.787 sec/batch), lr: 1.000000
2019-03-16 21:06:51,411 2019-03-16 21:06:51: step 91/50000, loss = 0.493929 (8.252 sec/batch), lr: 1.000000
2019-03-16 21:07:00,731 2019-03-16 21:07:00: step 92/50000, loss = 0.490567 (9.266 sec/batch), lr: 1.000000
2019-03-16 21:07:10,899 2019-03-16 21:07:10: step 93/50000, loss = 0.487585 (10.110 sec/batch), lr: 1.000000
2019-03-16 21:07:22,040 2019-03-16 21:07:22: step 94/50000, loss = 0.484278 (11.079 sec/batch), lr: 1.000000
2019-03-16 21:07:34,281 2019-03-16 21:07:34: step 95/50000, loss = 0.483586 (12.168 sec/batch), lr: 1.000000
2019-03-16 21:07:48,639 2019-03-16 21:07:48: step 96/50000, loss = 0.471766 (14.344 sec/batch), lr: 1.000000
2019-03-16 21:08:05,685 2019-03-16 21:08:05: step 97/50000, loss = 0.477312 (16.950 sec/batch), lr: 1.000000
2019-03-16 21:08:26,235 2019-03-16 21:08:26: step 98/50000, loss = 0.465934 (20.430 sec/batch), lr: 1.000000
2019-03-16 21:08:54,561 2019-03-16 21:08:54: step 99/50000, loss = 0.447538 (28.155 sec/batch), lr: 1.000000
2019-03-16 21:09:28,784 2019-03-16 21:09:28: step 100/50000, loss = 0.377893 (34.041 sec/batch), lr: 1.000000
2019-03-16 21:09:56,827 step 100: Full loss = 0.266068, Edge acc. = 0.3370
2019-03-16 21:09:56,888 step 100: Dev acc. = 0.332879
2019-03-16 21:10:46,889 2019-03-16 21:10:46: step 101/50000, loss = 0.353820 (49.760 sec/batch), lr: 1.000000
2019-03-16 21:11:10,487 2019-03-16 21:11:10: step 102/50000, loss = 0.457840 (23.458 sec/batch), lr: 1.000000
2019-03-16 21:11:28,725 2019-03-16 21:11:28: step 103/50000, loss = 0.474910 (18.223 sec/batch), lr: 1.000000
2019-03-16 21:11:44,586 2019-03-16 21:11:44: step 104/50000, loss = 0.477514 (15.765 sec/batch), lr: 1.000000
2019-03-16 21:11:57,461 2019-03-16 21:11:57: step 105/50000, loss = 0.485794 (12.797 sec/batch), lr: 1.000000
2019-03-16 21:12:09,104 2019-03-16 21:12:09: step 106/50000, loss = 0.480659 (11.572 sec/batch), lr: 1.000000
2019-03-16 21:12:19,604 2019-03-16 21:12:19: step 107/50000, loss = 0.485442 (10.486 sec/batch), lr: 1.000000
2019-03-16 21:12:29,125 2019-03-16 21:12:29: step 108/50000, loss = 0.487602 (9.465 sec/batch), lr: 1.000000
2019-03-16 21:12:37,969 2019-03-16 21:12:37: step 109/50000, loss = 0.474544 (8.832 sec/batch), lr: 1.000000
2019-03-16 21:12:46,170 2019-03-16 21:12:46: step 110/50000, loss = 0.483053 (8.156 sec/batch), lr: 1.000000
2019-03-16 21:12:53,626 2019-03-16 21:12:53: step 111/50000, loss = 0.487764 (7.413 sec/batch), lr: 1.000000
2019-03-16 21:13:00,510 2019-03-16 21:13:00: step 112/50000, loss = 0.485106 (6.874 sec/batch), lr: 1.000000
2019-03-16 21:13:06,954 2019-03-16 21:13:06: step 113/50000, loss = 0.482444 (6.409 sec/batch), lr: 1.000000
2019-03-16 21:13:12,913 2019-03-16 21:13:12: step 114/50000, loss = 0.478519 (5.950 sec/batch), lr: 1.000000
2019-03-16 21:13:18,646 2019-03-16 21:13:18: step 115/50000, loss = 0.482266 (5.700 sec/batch), lr: 1.000000
2019-03-16 21:13:24,006 2019-03-16 21:13:24: step 116/50000, loss = 0.484059 (5.332 sec/batch), lr: 1.000000
2019-03-16 21:13:29,038 2019-03-16 21:13:29: step 117/50000, loss = 0.484944 (5.024 sec/batch), lr: 1.000000
2019-03-16 21:13:33,852 2019-03-16 21:13:33: step 118/50000, loss = 0.469713 (4.787 sec/batch), lr: 1.000000
2019-03-16 21:13:38,464 2019-03-16 21:13:38: step 119/50000, loss = 0.468576 (4.604 sec/batch), lr: 1.000000
2019-03-16 21:13:42,792 2019-03-16 21:13:42: step 120/50000, loss = 0.474597 (4.304 sec/batch), lr: 1.000000
2019-03-16 21:13:47,063 2019-03-16 21:13:47: step 121/50000, loss = 0.448939 (4.248 sec/batch), lr: 1.000000
2019-03-16 21:13:51,005 2019-03-16 21:13:51: step 122/50000, loss = 0.442807 (3.933 sec/batch), lr: 1.000000
2019-03-16 21:13:54,602 2019-03-16 21:13:54: step 123/50000, loss = 0.409709 (3.576 sec/batch), lr: 1.000000
2019-03-16 21:13:57,919 2019-03-16 21:13:57: step 124/50000, loss = 0.275776 (3.299 sec/batch), lr: 1.000000
2019-03-16 21:14:01,535 2019-03-16 21:14:01: step 125/50000, loss = 0.398420 (3.598 sec/batch), lr: 1.000000
2019-03-16 21:14:04,673 2019-03-16 21:14:04: step 126/50000, loss = 0.411034 (3.121 sec/batch), lr: 1.000000
2019-03-16 21:14:07,787 2019-03-16 21:14:07: step 127/50000, loss = 0.197582 (3.097 sec/batch), lr: 1.000000
2019-03-16 21:14:10,634 2019-03-16 21:14:10: step 128/50000, loss = 0.315871 (2.838 sec/batch), lr: 1.000000
2019-03-16 21:14:13,288 2019-03-16 21:14:13: step 129/50000, loss = 0.558333 (2.646 sec/batch), lr: 1.000000
2019-03-16 21:14:15,834 2019-03-16 21:14:15: step 130/50000, loss = 0.457237 (2.532 sec/batch), lr: 1.000000
2019-03-16 21:14:18,198 2019-03-16 21:14:18: step 131/50000, loss = 0.299309 (2.351 sec/batch), lr: 1.000000
2019-03-16 21:14:20,330 2019-03-16 21:14:20: step 132/50000, loss = 0.200045 (2.119 sec/batch), lr: 1.000000
2019-03-16 21:14:22,443 2019-03-16 21:14:22: step 133/50000, loss = 0.251699 (2.099 sec/batch), lr: 1.000000
2019-03-16 21:14:24,354 2019-03-16 21:14:24: step 134/50000, loss = 0.360282 (1.903 sec/batch), lr: 1.000000
2019-03-16 21:14:26,186 2019-03-16 21:14:26: step 135/50000, loss = 0.233330 (1.822 sec/batch), lr: 1.000000
2019-03-16 21:14:27,831 2019-03-16 21:14:27: step 136/50000, loss = 0.349454 (1.638 sec/batch), lr: 1.000000
2019-03-16 21:14:29,291 2019-03-16 21:14:29: step 137/50000, loss = 0.247129 (1.454 sec/batch), lr: 1.000000
2019-03-16 21:14:30,687 2019-03-16 21:14:30: step 138/50000, loss = 0.348771 (1.389 sec/batch), lr: 1.000000
2019-03-16 21:14:31,922 2019-03-16 21:14:31: step 139/50000, loss = 0.202544 (1.226 sec/batch), lr: 1.000000
2019-03-16 21:14:33,066 2019-03-16 21:14:33: step 140/50000, loss = 0.353716 (1.134 sec/batch), lr: 1.000000
2019-03-16 21:14:34,047 2019-03-16 21:14:34: step 141/50000, loss = 0.242617 (0.973 sec/batch), lr: 1.000000
2019-03-16 21:14:34,987 2019-03-16 21:14:34: step 142/50000, loss = 0.367893 (0.932 sec/batch), lr: 1.000000
2019-03-16 21:14:35,810 2019-03-16 21:14:35: step 143/50000, loss = 0.236213 (0.815 sec/batch), lr: 1.000000
2019-03-16 21:14:36,488 2019-03-16 21:14:36: step 144/50000, loss = 0.408055 (0.670 sec/batch), lr: 1.000000
2019-03-16 21:14:37,042 2019-03-16 21:14:37: step 145/50000, loss = 0.224360 (0.548 sec/batch), lr: 1.000000
2019-03-16 21:14:37,556 2019-03-16 21:14:37: step 146/50000, loss = 0.389246 (0.508 sec/batch), lr: 1.000000
2019-03-16 21:14:37,948 2019-03-16 21:14:37: step 147/50000, loss = 0.181204 (0.386 sec/batch), lr: 1.000000
2019-03-16 21:14:38,252 2019-03-16 21:14:38: step 148/50000, loss = 0.391002 (0.299 sec/batch), lr: 1.000000
2019-03-16 21:14:38,454 2019-03-16 21:14:38: step 149/50000, loss = 0.087554 (0.198 sec/batch), lr: 1.000000
2019-03-16 21:14:38,583 2019-03-16 21:14:38: step 150/50000, loss = 0.035090 (0.127 sec/batch), lr: 1.000000
2019-03-16 21:15:28,399 2019-03-16 21:15:28: step 151/50000, loss = 0.196081 (49.566 sec/batch), lr: 1.000000
2019-03-16 21:15:52,048 2019-03-16 21:15:52: step 152/50000, loss = 0.253897 (23.632 sec/batch), lr: 1.000000
2019-03-16 21:16:10,432 2019-03-16 21:16:10: step 153/50000, loss = 0.244283 (18.278 sec/batch), lr: 1.000000
2019-03-16 21:16:26,132 2019-03-16 21:16:26: step 154/50000, loss = 0.343448 (15.686 sec/batch), lr: 1.000000
2019-03-16 21:16:39,083 2019-03-16 21:16:39: step 155/50000, loss = 0.264754 (12.939 sec/batch), lr: 1.000000
2019-03-16 21:16:50,783 2019-03-16 21:16:50: step 156/50000, loss = 0.336099 (11.687 sec/batch), lr: 1.000000
2019-03-16 21:17:01,452 2019-03-16 21:17:01: step 157/50000, loss = 0.249941 (10.606 sec/batch), lr: 1.000000
2019-03-16 21:17:11,136 2019-03-16 21:17:11: step 158/50000, loss = 0.338899 (9.631 sec/batch), lr: 1.000000
2019-03-16 21:17:20,158 2019-03-16 21:17:20: step 159/50000, loss = 0.240491 (8.971 sec/batch), lr: 1.000000
2019-03-16 21:17:28,362 2019-03-16 21:17:28: step 160/50000, loss = 0.338135 (8.158 sec/batch), lr: 1.000000
2019-03-16 21:17:35,773 2019-03-16 21:17:35: step 161/50000, loss = 0.241904 (7.370 sec/batch), lr: 1.000000
2019-03-16 21:17:42,658 2019-03-16 21:17:42: step 162/50000, loss = 0.335468 (6.839 sec/batch), lr: 1.000000
2019-03-16 21:17:49,094 2019-03-16 21:17:49: step 163/50000, loss = 0.232467 (6.427 sec/batch), lr: 1.000000
2019-03-16 21:17:55,146 2019-03-16 21:17:55: step 164/50000, loss = 0.334554 (6.022 sec/batch), lr: 1.000000
2019-03-16 21:18:00,749 2019-03-16 21:18:00: step 165/50000, loss = 0.231648 (5.572 sec/batch), lr: 1.000000
2019-03-16 21:18:06,118 2019-03-16 21:18:06: step 166/50000, loss = 0.335792 (5.339 sec/batch), lr: 1.000000
2019-03-16 21:18:11,260 2019-03-16 21:18:11: step 167/50000, loss = 0.228148 (5.133 sec/batch), lr: 1.000000
2019-03-16 21:18:16,338 2019-03-16 21:18:16: step 168/50000, loss = 0.328660 (5.051 sec/batch), lr: 1.000000
2019-03-16 21:18:20,845 2019-03-16 21:18:20: step 169/50000, loss = 0.230238 (4.483 sec/batch), lr: 1.000000
2019-03-16 21:18:25,125 2019-03-16 21:18:25: step 170/50000, loss = 0.339888 (4.256 sec/batch), lr: 1.000000
2019-03-16 21:18:29,249 2019-03-16 21:18:29: step 171/50000, loss = 0.226910 (4.100 sec/batch), lr: 1.000000
2019-03-16 21:18:33,259 2019-03-16 21:18:33: step 172/50000, loss = 0.319958 (3.980 sec/batch), lr: 1.000000
2019-03-16 21:18:36,974 2019-03-16 21:18:36: step 173/50000, loss = 0.236919 (3.696 sec/batch), lr: 1.000000
2019-03-16 21:18:40,400 2019-03-16 21:18:40: step 174/50000, loss = 0.342846 (3.408 sec/batch), lr: 1.000000
2019-03-16 21:18:43,796 2019-03-16 21:18:43: step 175/50000, loss = 0.216808 (3.378 sec/batch), lr: 1.000000
2019-03-16 21:18:46,938 2019-03-16 21:18:46: step 176/50000, loss = 0.333003 (3.125 sec/batch), lr: 1.000000
2019-03-16 21:18:49,957 2019-03-16 21:18:49: step 177/50000, loss = 0.215615 (3.003 sec/batch), lr: 1.000000
2019-03-16 21:18:52,781 2019-03-16 21:18:52: step 178/50000, loss = 0.311178 (2.810 sec/batch), lr: 1.000000
2019-03-16 21:18:55,396 2019-03-16 21:18:55: step 179/50000, loss = 0.245706 (2.606 sec/batch), lr: 1.000000
2019-03-16 21:18:57,889 2019-03-16 21:18:57: step 180/50000, loss = 0.325515 (2.480 sec/batch), lr: 1.000000
2019-03-16 21:19:00,227 2019-03-16 21:19:00: step 181/50000, loss = 0.212495 (2.326 sec/batch), lr: 1.000000
2019-03-16 21:19:02,294 2019-03-16 21:19:02: step 182/50000, loss = 0.316791 (2.060 sec/batch), lr: 1.000000
2019-03-16 21:19:04,250 2019-03-16 21:19:04: step 183/50000, loss = 0.243421 (1.944 sec/batch), lr: 1.000000
2019-03-16 21:19:06,024 2019-03-16 21:19:06: step 184/50000, loss = 0.337642 (1.765 sec/batch), lr: 1.000000
2019-03-16 21:19:07,853 2019-03-16 21:19:07: step 185/50000, loss = 0.232107 (1.818 sec/batch), lr: 1.000000
2019-03-16 21:19:09,483 2019-03-16 21:19:09: step 186/50000, loss = 0.341491 (1.624 sec/batch), lr: 1.000000
2019-03-16 21:19:10,861 2019-03-16 21:19:10: step 187/50000, loss = 0.256656 (1.373 sec/batch), lr: 1.000000
2019-03-16 21:19:12,247 2019-03-16 21:19:12: step 188/50000, loss = 0.372806 (1.378 sec/batch), lr: 1.000000
2019-03-16 21:19:13,342 2019-03-16 21:19:13: step 189/50000, loss = 0.211258 (1.089 sec/batch), lr: 1.000000
2019-03-16 21:19:14,452 2019-03-16 21:19:14: step 190/50000, loss = 0.391506 (1.102 sec/batch), lr: 1.000000
2019-03-16 21:19:15,411 2019-03-16 21:19:15: step 191/50000, loss = 0.274080 (0.952 sec/batch), lr: 1.000000
2019-03-16 21:19:16,257 2019-03-16 21:19:16: step 192/50000, loss = 0.444282 (0.837 sec/batch), lr: 1.000000
2019-03-16 21:19:17,058 2019-03-16 21:19:17: step 193/50000, loss = 0.201688 (0.794 sec/batch), lr: 1.000000
2019-03-16 21:19:17,718 2019-03-16 21:19:17: step 194/50000, loss = 0.287805 (0.653 sec/batch), lr: 1.000000
2019-03-16 21:19:18,273 2019-03-16 21:19:18: step 195/50000, loss = 0.333221 (0.548 sec/batch), lr: 1.000000
2019-03-16 21:19:18,783 2019-03-16 21:19:18: step 196/50000, loss = 0.393580 (0.504 sec/batch), lr: 1.000000
2019-03-16 21:19:19,192 2019-03-16 21:19:19: step 197/50000, loss = 0.182732 (0.404 sec/batch), lr: 1.000000
2019-03-16 21:19:19,483 2019-03-16 21:19:19: step 198/50000, loss = 0.289059 (0.285 sec/batch), lr: 1.000000
2019-03-16 21:19:19,656 2019-03-16 21:19:19: step 199/50000, loss = 0.380952 (0.170 sec/batch), lr: 1.000000
2019-03-16 21:19:19,785 2019-03-16 21:19:19: step 200/50000, loss = 0.762322 (0.127 sec/batch), lr: 1.000000
2019-03-16 21:19:47,789 step 200: Full loss = 0.217422, Edge acc. = 0.2807
2019-03-16 21:19:47,847 step 200: Dev acc. = 0.312708
2019-03-16 21:19:47,990 2019-03-16 21:19:47: step 201/50000, loss = 0.185691 (0.138 sec/batch), lr: 0.500000
2019-03-16 21:19:48,207 2019-03-16 21:19:48: step 202/50000, loss = 0.152824 (0.214 sec/batch), lr: 0.500000
2019-03-16 21:19:48,483 2019-03-16 21:19:48: step 203/50000, loss = 0.183909 (0.272 sec/batch), lr: 0.500000
2019-03-16 21:19:48,900 2019-03-16 21:19:48: step 204/50000, loss = 0.190777 (0.413 sec/batch), lr: 0.500000
2019-03-16 21:19:49,434 2019-03-16 21:19:49: step 205/50000, loss = 0.179963 (0.527 sec/batch), lr: 0.500000
2019-03-16 21:19:50,073 2019-03-16 21:19:50: step 206/50000, loss = 0.179205 (0.632 sec/batch), lr: 0.500000
2019-03-16 21:19:50,864 2019-03-16 21:19:50: step 207/50000, loss = 0.181772 (0.785 sec/batch), lr: 0.500000
2019-03-16 21:19:51,675 2019-03-16 21:19:51: step 208/50000, loss = 0.203371 (0.803 sec/batch), lr: 0.500000
2019-03-16 21:19:52,605 2019-03-16 21:19:52: step 209/50000, loss = 0.213333 (0.922 sec/batch), lr: 0.500000
2019-03-16 21:19:53,693 2019-03-16 21:19:53: step 210/50000, loss = 0.184647 (1.079 sec/batch), lr: 0.500000
2019-03-16 21:19:54,833 2019-03-16 21:19:54: step 211/50000, loss = 0.183433 (1.132 sec/batch), lr: 0.500000
2019-03-16 21:19:56,140 2019-03-16 21:19:56: step 212/50000, loss = 0.197015 (1.297 sec/batch), lr: 0.500000
2019-03-16 21:19:57,560 2019-03-16 21:19:57: step 213/50000, loss = 0.194136 (1.410 sec/batch), lr: 0.500000
2019-03-16 21:19:59,117 2019-03-16 21:19:59: step 214/50000, loss = 0.182635 (1.548 sec/batch), lr: 0.500000
2019-03-16 21:20:00,843 2019-03-16 21:20:00: step 215/50000, loss = 0.209928 (1.715 sec/batch), lr: 0.500000
2019-03-16 21:20:02,619 2019-03-16 21:20:02: step 216/50000, loss = 0.186864 (1.763 sec/batch), lr: 0.500000
2019-03-16 21:20:04,535 2019-03-16 21:20:04: step 217/50000, loss = 0.188765 (1.904 sec/batch), lr: 0.500000
2019-03-16 21:20:06,530 2019-03-16 21:20:06: step 218/50000, loss = 0.198288 (1.988 sec/batch), lr: 0.500000
2019-03-16 21:20:08,823 2019-03-16 21:20:08: step 219/50000, loss = 0.199129 (2.279 sec/batch), lr: 0.500000
2019-03-16 21:20:11,184 2019-03-16 21:20:11: step 220/50000, loss = 0.191453 (2.347 sec/batch), lr: 0.500000
2019-03-16 21:20:13,787 2019-03-16 21:20:13: step 221/50000, loss = 0.209583 (2.589 sec/batch), lr: 0.500000
2019-03-16 21:20:16,543 2019-03-16 21:20:16: step 222/50000, loss = 0.180448 (2.740 sec/batch), lr: 0.500000
2019-03-16 21:20:19,390 2019-03-16 21:20:19: step 223/50000, loss = 0.213502 (2.831 sec/batch), lr: 0.500000
2019-03-16 21:20:22,489 2019-03-16 21:20:22: step 224/50000, loss = 0.188963 (3.083 sec/batch), lr: 0.500000
2019-03-16 21:20:25,433 2019-03-16 21:20:25: step 225/50000, loss = 0.213032 (2.927 sec/batch), lr: 0.500000
2019-03-16 21:20:28,617 2019-03-16 21:20:28: step 226/50000, loss = 0.190053 (3.167 sec/batch), lr: 0.500000
2019-03-16 21:20:32,249 2019-03-16 21:20:32: step 227/50000, loss = 0.208695 (3.611 sec/batch), lr: 0.500000
2019-03-16 21:20:35,941 2019-03-16 21:20:35: step 228/50000, loss = 0.194040 (3.673 sec/batch), lr: 0.500000
2019-03-16 21:20:39,797 2019-03-16 21:20:39: step 229/50000, loss = 0.224523 (3.847 sec/batch), lr: 0.500000
2019-03-16 21:20:44,023 2019-03-16 21:20:44: step 230/50000, loss = 0.195881 (4.217 sec/batch), lr: 0.500000
2019-03-16 21:20:48,235 2019-03-16 21:20:48: step 231/50000, loss = 0.223635 (4.202 sec/batch), lr: 0.500000
2019-03-16 21:20:52,940 2019-03-16 21:20:52: step 232/50000, loss = 0.199714 (4.678 sec/batch), lr: 0.500000
2019-03-16 21:20:57,937 2019-03-16 21:20:57: step 233/50000, loss = 0.220386 (4.987 sec/batch), lr: 0.500000
2019-03-16 21:21:03,019 2019-03-16 21:21:03: step 234/50000, loss = 0.193154 (5.054 sec/batch), lr: 0.500000
2019-03-16 21:21:08,594 2019-03-16 21:21:08: step 235/50000, loss = 0.216161 (5.566 sec/batch), lr: 0.500000
2019-03-16 21:21:14,390 2019-03-16 21:21:14: step 236/50000, loss = 0.204134 (5.787 sec/batch), lr: 0.500000
2019-03-16 21:21:20,525 2019-03-16 21:21:20: step 237/50000, loss = 0.216067 (6.099 sec/batch), lr: 0.500000
2019-03-16 21:21:27,392 2019-03-16 21:21:27: step 238/50000, loss = 0.195892 (6.857 sec/batch), lr: 0.500000
2019-03-16 21:21:34,672 2019-03-16 21:21:34: step 239/50000, loss = 0.222824 (7.241 sec/batch), lr: 0.500000
2019-03-16 21:21:42,470 2019-03-16 21:21:42: step 240/50000, loss = 0.198367 (7.755 sec/batch), lr: 0.500000
2019-03-16 21:21:50,820 2019-03-16 21:21:50: step 241/50000, loss = 0.228257 (8.303 sec/batch), lr: 0.500000
2019-03-16 21:22:00,259 2019-03-16 21:22:00: step 242/50000, loss = 0.201988 (9.385 sec/batch), lr: 0.500000
2019-03-16 21:22:10,369 2019-03-16 21:22:10: step 243/50000, loss = 0.233860 (10.052 sec/batch), lr: 0.500000
2019-03-16 21:22:21,539 2019-03-16 21:22:21: step 244/50000, loss = 0.198100 (11.108 sec/batch), lr: 0.500000
2019-03-16 21:22:33,668 2019-03-16 21:22:33: step 245/50000, loss = 0.219798 (12.060 sec/batch), lr: 0.500000
2019-03-16 21:22:47,950 2019-03-16 21:22:47: step 246/50000, loss = 0.216453 (14.201 sec/batch), lr: 0.500000
2019-03-16 21:23:05,027 2019-03-16 21:23:05: step 247/50000, loss = 0.234654 (16.981 sec/batch), lr: 0.500000
2019-03-16 21:23:24,960 2019-03-16 21:23:24: step 248/50000, loss = 0.206151 (19.822 sec/batch), lr: 0.500000
2019-03-16 21:23:52,842 2019-03-16 21:23:52: step 249/50000, loss = 0.235363 (27.728 sec/batch), lr: 0.500000
2019-03-16 21:24:26,745 2019-03-16 21:24:26: step 250/50000, loss = 0.167638 (33.709 sec/batch), lr: 0.500000
2019-03-16 21:24:26,907 2019-03-16 21:24:26: step 251/50000, loss = 0.700391 (0.157 sec/batch), lr: 0.500000
2019-03-16 21:24:27,164 2019-03-16 21:24:27: step 252/50000, loss = 0.135738 (0.253 sec/batch), lr: 0.500000
2019-03-16 21:24:27,508 2019-03-16 21:24:27: step 253/50000, loss = 0.208392 (0.340 sec/batch), lr: 0.500000
2019-03-16 21:24:27,938 2019-03-16 21:24:27: step 254/50000, loss = 0.180291 (0.425 sec/batch), lr: 0.500000
2019-03-16 21:24:28,476 2019-03-16 21:24:28: step 255/50000, loss = 0.212264 (0.532 sec/batch), lr: 0.500000
2019-03-16 21:24:29,128 2019-03-16 21:24:29: step 256/50000, loss = 0.178701 (0.646 sec/batch), lr: 0.500000
2019-03-16 21:24:29,916 2019-03-16 21:24:29: step 257/50000, loss = 0.213715 (0.779 sec/batch), lr: 0.500000
2019-03-16 21:24:30,742 2019-03-16 21:24:30: step 258/50000, loss = 0.210364 (0.819 sec/batch), lr: 0.500000
2019-03-16 21:24:31,719 2019-03-16 21:24:31: step 259/50000, loss = 0.224935 (0.968 sec/batch), lr: 0.500000
2019-03-16 21:24:32,809 2019-03-16 21:24:32: step 260/50000, loss = 0.182580 (1.081 sec/batch), lr: 0.500000
2019-03-16 21:24:33,961 2019-03-16 21:24:33: step 261/50000, loss = 0.204153 (1.142 sec/batch), lr: 0.500000
2019-03-16 21:24:35,251 2019-03-16 21:24:35: step 262/50000, loss = 0.186202 (1.283 sec/batch), lr: 0.500000
2019-03-16 21:24:36,680 2019-03-16 21:24:36: step 263/50000, loss = 0.203538 (1.422 sec/batch), lr: 0.500000
2019-03-16 21:24:38,316 2019-03-16 21:24:38: step 264/50000, loss = 0.171875 (1.624 sec/batch), lr: 0.500000
2019-03-16 21:24:40,004 2019-03-16 21:24:40: step 265/50000, loss = 0.206486 (1.681 sec/batch), lr: 0.500000
2019-03-16 21:24:41,882 2019-03-16 21:24:41: step 266/50000, loss = 0.180133 (1.871 sec/batch), lr: 0.500000
2019-03-16 21:24:43,938 2019-03-16 21:24:43: step 267/50000, loss = 0.198476 (2.044 sec/batch), lr: 0.500000
2019-03-16 21:24:46,036 2019-03-16 21:24:46: step 268/50000, loss = 0.178096 (2.086 sec/batch), lr: 0.500000
2019-03-16 21:24:48,343 2019-03-16 21:24:48: step 269/50000, loss = 0.200856 (2.293 sec/batch), lr: 0.500000
2019-03-16 21:24:50,662 2019-03-16 21:24:50: step 270/50000, loss = 0.175080 (2.306 sec/batch), lr: 0.500000
2019-03-16 21:24:53,256 2019-03-16 21:24:53: step 271/50000, loss = 0.207142 (2.579 sec/batch), lr: 0.500000
2019-03-16 21:24:55,934 2019-03-16 21:24:55: step 272/50000, loss = 0.167757 (2.662 sec/batch), lr: 0.500000
2019-03-16 21:24:58,721 2019-03-16 21:24:58: step 273/50000, loss = 0.209601 (2.772 sec/batch), lr: 0.500000
2019-03-16 21:25:01,842 2019-03-16 21:25:01: step 274/50000, loss = 0.175736 (3.104 sec/batch), lr: 0.500000
2019-03-16 21:25:04,965 2019-03-16 21:25:04: step 275/50000, loss = 0.207662 (3.106 sec/batch), lr: 0.500000
2019-03-16 21:25:08,345 2019-03-16 21:25:08: step 276/50000, loss = 0.179771 (3.361 sec/batch), lr: 0.500000
2019-03-16 21:25:11,962 2019-03-16 21:25:11: step 277/50000, loss = 0.202767 (3.599 sec/batch), lr: 0.500000
2019-03-16 21:25:15,650 2019-03-16 21:25:15: step 278/50000, loss = 0.182904 (3.668 sec/batch), lr: 0.500000
2019-03-16 21:25:19,674 2019-03-16 21:25:19: step 279/50000, loss = 0.219162 (4.016 sec/batch), lr: 0.500000
2019-03-16 21:25:23,851 2019-03-16 21:25:23: step 280/50000, loss = 0.183218 (4.153 sec/batch), lr: 0.500000
2019-03-16 21:25:28,079 2019-03-16 21:25:28: step 281/50000, loss = 0.215543 (4.204 sec/batch), lr: 0.500000
2019-03-16 21:25:32,545 2019-03-16 21:25:32: step 282/50000, loss = 0.187416 (4.456 sec/batch), lr: 0.500000
2019-03-16 21:25:37,352 2019-03-16 21:25:37: step 283/50000, loss = 0.211240 (4.780 sec/batch), lr: 0.500000
2019-03-16 21:25:42,597 2019-03-16 21:25:42: step 284/50000, loss = 0.179594 (5.214 sec/batch), lr: 0.500000
2019-03-16 21:25:48,150 2019-03-16 21:25:48: step 285/50000, loss = 0.211876 (5.543 sec/batch), lr: 0.500000
2019-03-16 21:25:53,924 2019-03-16 21:25:53: step 286/50000, loss = 0.190466 (5.764 sec/batch), lr: 0.500000
2019-03-16 21:26:00,063 2019-03-16 21:26:00: step 287/50000, loss = 0.210541 (6.116 sec/batch), lr: 0.500000
2019-03-16 21:26:06,713 2019-03-16 21:26:06: step 288/50000, loss = 0.185952 (6.615 sec/batch), lr: 0.500000
2019-03-16 21:26:13,991 2019-03-16 21:26:13: step 289/50000, loss = 0.216883 (7.268 sec/batch), lr: 0.500000
2019-03-16 21:26:21,717 2019-03-16 21:26:21: step 290/50000, loss = 0.186974 (7.715 sec/batch), lr: 0.500000
2019-03-16 21:26:30,028 2019-03-16 21:26:30: step 291/50000, loss = 0.222198 (8.264 sec/batch), lr: 0.500000
2019-03-16 21:26:39,109 2019-03-16 21:26:39: step 292/50000, loss = 0.192301 (9.027 sec/batch), lr: 0.500000
2019-03-16 21:26:49,318 2019-03-16 21:26:49: step 293/50000, loss = 0.227887 (10.150 sec/batch), lr: 0.500000
2019-03-16 21:27:00,486 2019-03-16 21:27:00: step 294/50000, loss = 0.189648 (11.100 sec/batch), lr: 0.500000
2019-03-16 21:27:12,763 2019-03-16 21:27:12: step 295/50000, loss = 0.225820 (12.207 sec/batch), lr: 0.500000
2019-03-16 21:27:27,038 2019-03-16 21:27:27: step 296/50000, loss = 0.200650 (14.195 sec/batch), lr: 0.500000
2019-03-16 21:27:44,194 2019-03-16 21:27:44: step 297/50000, loss = 0.237535 (17.059 sec/batch), lr: 0.500000
2019-03-16 21:28:04,067 2019-03-16 21:28:04: step 298/50000, loss = 0.195941 (19.760 sec/batch), lr: 0.500000
2019-03-16 21:28:32,187 2019-03-16 21:28:32: step 299/50000, loss = 0.222888 (27.965 sec/batch), lr: 0.500000
2019-03-16 21:29:06,051 2019-03-16 21:29:06: step 300/50000, loss = 0.162870 (33.691 sec/batch), lr: 0.500000
2019-03-16 21:29:33,790 step 300: Full loss = 0.127461, Edge acc. = 0.3649
2019-03-16 21:29:33,850 step 300: Dev acc. = 0.385079
2019-03-16 21:30:23,114 2019-03-16 21:30:23: step 301/50000, loss = 0.180125 (49.026 sec/batch), lr: 0.500000
2019-03-16 21:30:46,665 2019-03-16 21:30:46: step 302/50000, loss = 0.202294 (23.535 sec/batch), lr: 0.500000
2019-03-16 21:31:04,867 2019-03-16 21:31:04: step 303/50000, loss = 0.216280 (18.187 sec/batch), lr: 0.500000
2019-03-16 21:31:20,541 2019-03-16 21:31:20: step 304/50000, loss = 0.220142 (15.660 sec/batch), lr: 0.500000
2019-03-16 21:31:33,241 2019-03-16 21:31:33: step 305/50000, loss = 0.210764 (12.687 sec/batch), lr: 0.500000
2019-03-16 21:31:44,854 2019-03-16 21:31:44: step 306/50000, loss = 0.224270 (11.601 sec/batch), lr: 0.500000
2019-03-16 21:31:55,517 2019-03-16 21:31:55: step 307/50000, loss = 0.213287 (10.599 sec/batch), lr: 0.500000
2019-03-16 21:32:05,195 2019-03-16 21:32:05: step 308/50000, loss = 0.217917 (9.623 sec/batch), lr: 0.500000
2019-03-16 21:32:14,196 2019-03-16 21:32:14: step 309/50000, loss = 0.196294 (8.951 sec/batch), lr: 0.500000
2019-03-16 21:32:22,421 2019-03-16 21:32:22: step 310/50000, loss = 0.198426 (8.178 sec/batch), lr: 0.500000
2019-03-16 21:32:29,780 2019-03-16 21:32:29: step 311/50000, loss = 0.202470 (7.350 sec/batch), lr: 0.500000
2019-03-16 21:32:36,511 2019-03-16 21:32:36: step 312/50000, loss = 0.213134 (6.692 sec/batch), lr: 0.500000
2019-03-16 21:32:42,945 2019-03-16 21:32:42: step 313/50000, loss = 0.203144 (6.424 sec/batch), lr: 0.500000
2019-03-16 21:32:49,004 2019-03-16 21:32:49: step 314/50000, loss = 0.196347 (6.026 sec/batch), lr: 0.500000
2019-03-16 21:32:54,717 2019-03-16 21:32:54: step 315/50000, loss = 0.202455 (5.682 sec/batch), lr: 0.500000
2019-03-16 21:33:00,118 2019-03-16 21:33:00: step 316/50000, loss = 0.203072 (5.371 sec/batch), lr: 0.500000
2019-03-16 21:33:05,120 2019-03-16 21:33:05: step 317/50000, loss = 0.201287 (4.975 sec/batch), lr: 0.500000
2019-03-16 21:33:10,059 2019-03-16 21:33:10: step 318/50000, loss = 0.181775 (4.912 sec/batch), lr: 0.500000
2019-03-16 21:33:14,662 2019-03-16 21:33:14: step 319/50000, loss = 0.191336 (4.577 sec/batch), lr: 0.500000
2019-03-16 21:33:19,067 2019-03-16 21:33:19: step 320/50000, loss = 0.194808 (4.381 sec/batch), lr: 0.500000
2019-03-16 21:33:23,364 2019-03-16 21:33:23: step 321/50000, loss = 0.199481 (4.276 sec/batch), lr: 0.500000
2019-03-16 21:33:27,305 2019-03-16 21:33:27: step 322/50000, loss = 0.192171 (3.920 sec/batch), lr: 0.500000
2019-03-16 21:33:30,824 2019-03-16 21:33:30: step 323/50000, loss = 0.198021 (3.499 sec/batch), lr: 0.500000
2019-03-16 21:33:34,214 2019-03-16 21:33:34: step 324/50000, loss = 0.185865 (3.372 sec/batch), lr: 0.500000
2019-03-16 21:33:37,413 2019-03-16 21:33:37: step 325/50000, loss = 0.196168 (3.181 sec/batch), lr: 0.500000
2019-03-16 21:33:40,540 2019-03-16 21:33:40: step 326/50000, loss = 0.188472 (3.110 sec/batch), lr: 0.500000
2019-03-16 21:33:43,598 2019-03-16 21:33:43: step 327/50000, loss = 0.200168 (3.042 sec/batch), lr: 0.500000
2019-03-16 21:33:46,262 2019-03-16 21:33:46: step 328/50000, loss = 0.188454 (2.649 sec/batch), lr: 0.500000
2019-03-16 21:33:48,700 2019-03-16 21:33:48: step 329/50000, loss = 0.203051 (2.424 sec/batch), lr: 0.500000
2019-03-16 21:33:51,202 2019-03-16 21:33:51: step 330/50000, loss = 0.175566 (2.489 sec/batch), lr: 0.500000
2019-03-16 21:33:53,404 2019-03-16 21:33:53: step 331/50000, loss = 0.201514 (2.189 sec/batch), lr: 0.500000
2019-03-16 21:33:55,349 2019-03-16 21:33:55: step 332/50000, loss = 0.197703 (1.934 sec/batch), lr: 0.500000
2019-03-16 21:33:57,328 2019-03-16 21:33:57: step 333/50000, loss = 0.206397 (1.967 sec/batch), lr: 0.500000
2019-03-16 21:33:59,094 2019-03-16 21:33:59: step 334/50000, loss = 0.184638 (1.755 sec/batch), lr: 0.500000
2019-03-16 21:34:00,821 2019-03-16 21:34:00: step 335/50000, loss = 0.198386 (1.717 sec/batch), lr: 0.500000
2019-03-16 21:34:02,446 2019-03-16 21:34:02: step 336/50000, loss = 0.181988 (1.615 sec/batch), lr: 0.500000
2019-03-16 21:34:03,974 2019-03-16 21:34:03: step 337/50000, loss = 0.200405 (1.519 sec/batch), lr: 0.500000
2019-03-16 21:34:05,401 2019-03-16 21:34:05: step 338/50000, loss = 0.180543 (1.417 sec/batch), lr: 0.500000
2019-03-16 21:34:06,658 2019-03-16 21:34:06: step 339/50000, loss = 0.189201 (1.247 sec/batch), lr: 0.500000
2019-03-16 21:34:07,788 2019-03-16 21:34:07: step 340/50000, loss = 0.195568 (1.120 sec/batch), lr: 0.500000
2019-03-16 21:34:08,747 2019-03-16 21:34:08: step 341/50000, loss = 0.219311 (0.952 sec/batch), lr: 0.500000
2019-03-16 21:34:09,694 2019-03-16 21:34:09: step 342/50000, loss = 0.200863 (0.939 sec/batch), lr: 0.500000
2019-03-16 21:34:10,524 2019-03-16 21:34:10: step 343/50000, loss = 0.204697 (0.824 sec/batch), lr: 0.500000
2019-03-16 21:34:11,202 2019-03-16 21:34:11: step 344/50000, loss = 0.211060 (0.670 sec/batch), lr: 0.500000
2019-03-16 21:34:11,750 2019-03-16 21:34:11: step 345/50000, loss = 0.210266 (0.542 sec/batch), lr: 0.500000
2019-03-16 21:34:12,260 2019-03-16 21:34:12: step 346/50000, loss = 0.175421 (0.504 sec/batch), lr: 0.500000
2019-03-16 21:34:12,674 2019-03-16 21:34:12: step 347/50000, loss = 0.194357 (0.408 sec/batch), lr: 0.500000
2019-03-16 21:34:12,999 2019-03-16 21:34:12: step 348/50000, loss = 0.146455 (0.320 sec/batch), lr: 0.500000
2019-03-16 21:34:13,199 2019-03-16 21:34:13: step 349/50000, loss = 0.170307 (0.196 sec/batch), lr: 0.500000
2019-03-16 21:34:13,325 2019-03-16 21:34:13: step 350/50000, loss = 0.323624 (0.124 sec/batch), lr: 0.500000
2019-03-16 21:35:03,198 2019-03-16 21:35:03: step 351/50000, loss = 0.329147 (49.616 sec/batch), lr: 0.500000
2019-03-16 21:35:27,055 2019-03-16 21:35:27: step 352/50000, loss = 0.385486 (23.726 sec/batch), lr: 0.500000
2019-03-16 21:35:45,456 2019-03-16 21:35:45: step 353/50000, loss = 0.266190 (18.387 sec/batch), lr: 0.500000
2019-03-16 21:36:01,338 2019-03-16 21:36:01: step 354/50000, loss = 0.361990 (15.794 sec/batch), lr: 0.500000
2019-03-16 21:36:14,105 2019-03-16 21:36:14: step 355/50000, loss = 0.309726 (12.754 sec/batch), lr: 0.500000
2019-03-16 21:36:25,859 2019-03-16 21:36:25: step 356/50000, loss = 0.325627 (11.742 sec/batch), lr: 0.500000
2019-03-16 21:36:36,612 2019-03-16 21:36:36: step 357/50000, loss = 0.317960 (10.689 sec/batch), lr: 0.500000
2019-03-16 21:36:46,471 2019-03-16 21:36:46: step 358/50000, loss = 0.340729 (9.803 sec/batch), lr: 0.500000
2019-03-16 21:36:55,379 2019-03-16 21:36:55: step 359/50000, loss = 0.307205 (8.860 sec/batch), lr: 0.500000
2019-03-16 21:37:03,651 2019-03-16 21:37:03: step 360/50000, loss = 0.332519 (8.226 sec/batch), lr: 0.500000
2019-03-16 21:37:11,123 2019-03-16 21:37:11: step 361/50000, loss = 0.313725 (7.431 sec/batch), lr: 0.500000
2019-03-16 21:37:18,080 2019-03-16 21:37:18: step 362/50000, loss = 0.282787 (6.919 sec/batch), lr: 0.500000
2019-03-16 21:37:24,597 2019-03-16 21:37:24: step 363/50000, loss = 0.253445 (6.482 sec/batch), lr: 0.500000
2019-03-16 21:37:30,701 2019-03-16 21:37:30: step 364/50000, loss = 0.238746 (6.095 sec/batch), lr: 0.500000
2019-03-16 21:37:36,533 2019-03-16 21:37:36: step 365/50000, loss = 0.239317 (5.800 sec/batch), lr: 0.500000
2019-03-16 21:37:41,941 2019-03-16 21:37:41: step 366/50000, loss = 0.247081 (5.381 sec/batch), lr: 0.500000
2019-03-16 21:37:47,018 2019-03-16 21:37:47: step 367/50000, loss = 0.236708 (5.069 sec/batch), lr: 0.500000
2019-03-16 21:37:51,933 2019-03-16 21:37:51: step 368/50000, loss = 0.229382 (4.886 sec/batch), lr: 0.500000
2019-03-16 21:37:56,608 2019-03-16 21:37:56: step 369/50000, loss = 0.231707 (4.649 sec/batch), lr: 0.500000
2019-03-16 21:38:00,994 2019-03-16 21:38:00: step 370/50000, loss = 0.225703 (4.362 sec/batch), lr: 0.500000
2019-03-16 21:38:05,244 2019-03-16 21:38:05: step 371/50000, loss = 0.232362 (4.225 sec/batch), lr: 0.500000
2019-03-16 21:38:09,269 2019-03-16 21:38:09: step 372/50000, loss = 0.227953 (4.016 sec/batch), lr: 0.500000
2019-03-16 21:38:12,979 2019-03-16 21:38:12: step 373/50000, loss = 0.240435 (3.690 sec/batch), lr: 0.500000
2019-03-16 21:38:16,402 2019-03-16 21:38:16: step 374/50000, loss = 0.216763 (3.404 sec/batch), lr: 0.500000
2019-03-16 21:38:19,776 2019-03-16 21:38:19: step 375/50000, loss = 0.239838 (3.356 sec/batch), lr: 0.500000
2019-03-16 21:38:22,928 2019-03-16 21:38:22: step 376/50000, loss = 0.216876 (3.144 sec/batch), lr: 0.500000
2019-03-16 21:38:26,009 2019-03-16 21:38:26: step 377/50000, loss = 0.242565 (3.064 sec/batch), lr: 0.500000
2019-03-16 21:38:28,848 2019-03-16 21:38:28: step 378/50000, loss = 0.227888 (2.824 sec/batch), lr: 0.500000
2019-03-16 21:38:31,433 2019-03-16 21:38:31: step 379/50000, loss = 0.247335 (2.578 sec/batch), lr: 0.500000
2019-03-16 21:38:33,968 2019-03-16 21:38:33: step 380/50000, loss = 0.217153 (2.520 sec/batch), lr: 0.500000
2019-03-16 21:38:36,328 2019-03-16 21:38:36: step 381/50000, loss = 0.256393 (2.348 sec/batch), lr: 0.500000
2019-03-16 21:38:38,465 2019-03-16 21:38:38: step 382/50000, loss = 0.231853 (2.129 sec/batch), lr: 0.500000
2019-03-16 21:38:40,548 2019-03-16 21:38:40: step 383/50000, loss = 0.269987 (2.069 sec/batch), lr: 0.500000
2019-03-16 21:38:42,495 2019-03-16 21:38:42: step 384/50000, loss = 0.233675 (1.935 sec/batch), lr: 0.500000
2019-03-16 21:38:44,398 2019-03-16 21:38:44: step 385/50000, loss = 0.265483 (1.890 sec/batch), lr: 0.500000
2019-03-16 21:38:46,088 2019-03-16 21:38:46: step 386/50000, loss = 0.248830 (1.679 sec/batch), lr: 0.500000
2019-03-16 21:38:47,623 2019-03-16 21:38:47: step 387/50000, loss = 0.296688 (1.525 sec/batch), lr: 0.500000
2019-03-16 21:38:49,071 2019-03-16 21:38:49: step 388/50000, loss = 0.255751 (1.437 sec/batch), lr: 0.500000
2019-03-16 21:38:50,364 2019-03-16 21:38:50: step 389/50000, loss = 0.279833 (1.283 sec/batch), lr: 0.500000
2019-03-16 21:38:51,464 2019-03-16 21:38:51: step 390/50000, loss = 0.299073 (1.093 sec/batch), lr: 0.500000
2019-03-16 21:38:52,440 2019-03-16 21:38:52: step 391/50000, loss = 0.410842 (0.968 sec/batch), lr: 0.500000
2019-03-16 21:38:53,351 2019-03-16 21:38:53: step 392/50000, loss = 0.294850 (0.902 sec/batch), lr: 0.500000
2019-03-16 21:38:54,081 2019-03-16 21:38:54: step 393/50000, loss = 0.408096 (0.722 sec/batch), lr: 0.500000
2019-03-16 21:38:54,744 2019-03-16 21:38:54: step 394/50000, loss = 0.395899 (0.656 sec/batch), lr: 0.500000
2019-03-16 21:38:55,266 2019-03-16 21:38:55: step 395/50000, loss = 0.529927 (0.516 sec/batch), lr: 0.500000
2019-03-16 21:38:55,768 2019-03-16 21:38:55: step 396/50000, loss = 0.154829 (0.496 sec/batch), lr: 0.500000
2019-03-16 21:38:56,185 2019-03-16 21:38:56: step 397/50000, loss = 0.171925 (0.411 sec/batch), lr: 0.500000
2019-03-16 21:38:56,513 2019-03-16 21:38:56: step 398/50000, loss = 0.176932 (0.323 sec/batch), lr: 0.500000
2019-03-16 21:38:56,717 2019-03-16 21:38:56: step 399/50000, loss = 0.165673 (0.200 sec/batch), lr: 0.500000
2019-03-16 21:38:56,846 2019-03-16 21:38:56: step 400/50000, loss = 0.698726 (0.127 sec/batch), lr: 0.500000
2019-03-16 21:39:24,829 step 400: Full loss = 0.286620, Edge acc. = 0.1119
2019-03-16 21:39:24,888 step 400: Dev acc. = 0.097243
2019-03-16 21:39:25,032 2019-03-16 21:39:25: step 401/50000, loss = 0.404929 (0.139 sec/batch), lr: 0.250000
2019-03-16 21:39:25,255 2019-03-16 21:39:25: step 402/50000, loss = 0.366561 (0.219 sec/batch), lr: 0.250000
2019-03-16 21:39:25,552 2019-03-16 21:39:25: step 403/50000, loss = 0.276170 (0.293 sec/batch), lr: 0.250000
2019-03-16 21:39:25,973 2019-03-16 21:39:25: step 404/50000, loss = 0.166572 (0.416 sec/batch), lr: 0.250000
2019-03-16 21:39:26,511 2019-03-16 21:39:26: step 405/50000, loss = 0.163558 (0.531 sec/batch), lr: 0.250000
2019-03-16 21:39:27,162 2019-03-16 21:39:27: step 406/50000, loss = 0.165204 (0.645 sec/batch), lr: 0.250000
2019-03-16 21:39:27,952 2019-03-16 21:39:27: step 407/50000, loss = 0.163761 (0.784 sec/batch), lr: 0.250000
2019-03-16 21:39:28,799 2019-03-16 21:39:28: step 408/50000, loss = 0.176519 (0.839 sec/batch), lr: 0.250000
2019-03-16 21:39:29,763 2019-03-16 21:39:29: step 409/50000, loss = 0.186557 (0.954 sec/batch), lr: 0.250000
2019-03-16 21:39:30,867 2019-03-16 21:39:30: step 410/50000, loss = 0.168873 (1.094 sec/batch), lr: 0.250000
2019-03-16 21:39:32,030 2019-03-16 21:39:32: step 411/50000, loss = 0.176210 (1.153 sec/batch), lr: 0.250000
2019-03-16 21:39:33,349 2019-03-16 21:39:33: step 412/50000, loss = 0.167564 (1.309 sec/batch), lr: 0.250000
2019-03-16 21:39:34,809 2019-03-16 21:39:34: step 413/50000, loss = 0.173864 (1.453 sec/batch), lr: 0.250000
2019-03-16 21:39:36,444 2019-03-16 21:39:36: step 414/50000, loss = 0.164253 (1.625 sec/batch), lr: 0.250000
2019-03-16 21:39:38,148 2019-03-16 21:39:38: step 415/50000, loss = 0.184438 (1.693 sec/batch), lr: 0.250000
2019-03-16 21:39:40,051 2019-03-16 21:39:40: step 416/50000, loss = 0.174165 (1.895 sec/batch), lr: 0.250000
2019-03-16 21:39:42,073 2019-03-16 21:39:42: step 417/50000, loss = 0.181906 (2.015 sec/batch), lr: 0.250000
2019-03-16 21:39:44,070 2019-03-16 21:39:44: step 418/50000, loss = 0.176348 (1.984 sec/batch), lr: 0.250000
2019-03-16 21:39:46,230 2019-03-16 21:39:46: step 419/50000, loss = 0.182275 (2.147 sec/batch), lr: 0.250000
2019-03-16 21:39:48,559 2019-03-16 21:39:48: step 420/50000, loss = 0.174131 (2.315 sec/batch), lr: 0.250000
2019-03-16 21:39:50,999 2019-03-16 21:39:50: step 421/50000, loss = 0.191863 (2.427 sec/batch), lr: 0.250000
2019-03-16 21:39:53,733 2019-03-16 21:39:53: step 422/50000, loss = 0.166559 (2.718 sec/batch), lr: 0.250000
2019-03-16 21:39:56,471 2019-03-16 21:39:56: step 423/50000, loss = 0.196264 (2.723 sec/batch), lr: 0.250000
2019-03-16 21:39:59,597 2019-03-16 21:39:59: step 424/50000, loss = 0.171499 (3.110 sec/batch), lr: 0.250000
2019-03-16 21:40:02,737 2019-03-16 21:40:02: step 425/50000, loss = 0.194862 (3.123 sec/batch), lr: 0.250000
2019-03-16 21:40:06,202 2019-03-16 21:40:06: step 426/50000, loss = 0.175163 (3.446 sec/batch), lr: 0.250000
2019-03-16 21:40:09,832 2019-03-16 21:40:09: step 427/50000, loss = 0.190385 (3.621 sec/batch), lr: 0.250000
2019-03-16 21:40:13,579 2019-03-16 21:40:13: step 428/50000, loss = 0.178978 (3.727 sec/batch), lr: 0.250000
2019-03-16 21:40:17,646 2019-03-16 21:40:17: step 429/50000, loss = 0.208688 (4.045 sec/batch), lr: 0.250000
2019-03-16 21:40:21,950 2019-03-16 21:40:21: step 430/50000, loss = 0.182554 (4.282 sec/batch), lr: 0.250000
2019-03-16 21:40:26,154 2019-03-16 21:40:26: step 431/50000, loss = 0.204294 (4.180 sec/batch), lr: 0.250000
2019-03-16 21:40:30,779 2019-03-16 21:40:30: step 432/50000, loss = 0.184052 (4.600 sec/batch), lr: 0.250000
2019-03-16 21:40:35,729 2019-03-16 21:40:35: step 433/50000, loss = 0.199889 (4.924 sec/batch), lr: 0.250000
2019-03-16 21:40:40,992 2019-03-16 21:40:40: step 434/50000, loss = 0.178984 (5.237 sec/batch), lr: 0.250000
2019-03-16 21:40:46,636 2019-03-16 21:40:46: step 435/50000, loss = 0.203378 (5.613 sec/batch), lr: 0.250000
2019-03-16 21:40:52,364 2019-03-16 21:40:52: step 436/50000, loss = 0.188914 (5.696 sec/batch), lr: 0.250000
2019-03-16 21:40:58,553 2019-03-16 21:40:58: step 437/50000, loss = 0.203537 (6.155 sec/batch), lr: 0.250000
2019-03-16 21:41:05,399 2019-03-16 21:41:05: step 438/50000, loss = 0.185651 (6.807 sec/batch), lr: 0.250000
2019-03-16 21:41:12,577 2019-03-16 21:41:12: step 439/50000, loss = 0.208892 (7.139 sec/batch), lr: 0.250000
2019-03-16 21:41:20,413 2019-03-16 21:41:20: step 440/50000, loss = 0.188120 (7.794 sec/batch), lr: 0.250000
2019-03-16 21:41:28,763 2019-03-16 21:41:28: step 441/50000, loss = 0.213361 (8.303 sec/batch), lr: 0.250000
2019-03-16 21:41:38,125 2019-03-16 21:41:38: step 442/50000, loss = 0.193951 (9.351 sec/batch), lr: 0.250000
2019-03-16 21:41:48,485 2019-03-16 21:41:48: step 443/50000, loss = 0.218679 (10.302 sec/batch), lr: 0.250000
2019-03-16 21:41:59,732 2019-03-16 21:41:59: step 444/50000, loss = 0.192305 (11.184 sec/batch), lr: 0.250000
2019-03-16 21:42:12,080 2019-03-16 21:42:12: step 445/50000, loss = 0.217785 (12.275 sec/batch), lr: 0.250000
2019-03-16 21:42:26,499 2019-03-16 21:42:26: step 446/50000, loss = 0.202669 (14.338 sec/batch), lr: 0.250000
2019-03-16 21:42:43,551 2019-03-16 21:42:43: step 447/50000, loss = 0.216116 (16.955 sec/batch), lr: 0.250000
2019-03-16 21:43:03,660 2019-03-16 21:43:03: step 448/50000, loss = 0.213731 (19.995 sec/batch), lr: 0.250000
2019-03-16 21:43:31,921 2019-03-16 21:43:31: step 449/50000, loss = 0.223062 (28.098 sec/batch), lr: 0.250000
2019-03-16 21:44:06,174 2019-03-16 21:44:06: step 450/50000, loss = 0.165791 (34.068 sec/batch), lr: 0.250000
2019-03-16 21:44:55,604 2019-03-16 21:44:55: step 451/50000, loss = 0.179287 (49.191 sec/batch), lr: 0.250000
2019-03-16 21:45:19,350 2019-03-16 21:45:19: step 452/50000, loss = 0.197348 (23.612 sec/batch), lr: 0.250000
2019-03-16 21:45:37,728 2019-03-16 21:45:37: step 453/50000, loss = 0.215138 (18.363 sec/batch), lr: 0.250000
2019-03-16 21:45:53,615 2019-03-16 21:45:53: step 454/50000, loss = 0.220617 (15.874 sec/batch), lr: 0.250000
2019-03-16 21:46:06,579 2019-03-16 21:46:06: step 455/50000, loss = 0.209613 (12.950 sec/batch), lr: 0.250000
2019-03-16 21:46:18,300 2019-03-16 21:46:18: step 456/50000, loss = 0.216755 (11.653 sec/batch), lr: 0.250000
2019-03-16 21:46:29,185 2019-03-16 21:46:29: step 457/50000, loss = 0.206690 (10.873 sec/batch), lr: 0.250000
2019-03-16 21:46:39,050 2019-03-16 21:46:39: step 458/50000, loss = 0.218091 (9.808 sec/batch), lr: 0.250000
2019-03-16 21:46:48,221 2019-03-16 21:46:48: step 459/50000, loss = 0.191728 (9.114 sec/batch), lr: 0.250000
2019-03-16 21:46:56,469 2019-03-16 21:46:56: step 460/50000, loss = 0.198463 (8.204 sec/batch), lr: 0.250000
2019-03-16 21:47:03,946 2019-03-16 21:47:03: step 461/50000, loss = 0.194507 (7.435 sec/batch), lr: 0.250000
2019-03-16 21:47:10,925 2019-03-16 21:47:10: step 462/50000, loss = 0.215517 (6.940 sec/batch), lr: 0.250000
2019-03-16 21:47:17,520 2019-03-16 21:47:17: step 463/50000, loss = 0.194369 (6.558 sec/batch), lr: 0.250000
2019-03-16 21:47:23,674 2019-03-16 21:47:23: step 464/50000, loss = 0.198502 (6.145 sec/batch), lr: 0.250000
2019-03-16 21:47:29,417 2019-03-16 21:47:29: step 465/50000, loss = 0.192506 (5.703 sec/batch), lr: 0.250000
2019-03-16 21:47:34,725 2019-03-16 21:47:34: step 466/50000, loss = 0.202838 (5.278 sec/batch), lr: 0.250000
2019-03-16 21:47:39,696 2019-03-16 21:47:39: step 467/50000, loss = 0.187981 (4.943 sec/batch), lr: 0.250000
2019-03-16 21:47:44,691 2019-03-16 21:47:44: step 468/50000, loss = 0.182198 (4.967 sec/batch), lr: 0.250000
2019-03-16 21:47:49,307 2019-03-16 21:47:49: step 469/50000, loss = 0.184476 (4.593 sec/batch), lr: 0.250000
2019-03-16 21:47:53,574 2019-03-16 21:47:53: step 470/50000, loss = 0.200429 (4.243 sec/batch), lr: 0.250000
2019-03-16 21:47:57,741 2019-03-16 21:47:57: step 471/50000, loss = 0.191135 (4.147 sec/batch), lr: 0.250000
2019-03-16 21:48:01,677 2019-03-16 21:48:01: step 472/50000, loss = 0.189585 (3.918 sec/batch), lr: 0.250000
2019-03-16 21:48:05,452 2019-03-16 21:48:05: step 473/50000, loss = 0.185699 (3.755 sec/batch), lr: 0.250000
2019-03-16 21:48:08,931 2019-03-16 21:48:08: step 474/50000, loss = 0.184360 (3.460 sec/batch), lr: 0.250000
2019-03-16 21:48:12,053 2019-03-16 21:48:12: step 475/50000, loss = 0.180673 (3.103 sec/batch), lr: 0.250000
2019-03-16 21:48:15,142 2019-03-16 21:48:15: step 476/50000, loss = 0.185045 (3.073 sec/batch), lr: 0.250000
2019-03-16 21:48:18,266 2019-03-16 21:48:18: step 477/50000, loss = 0.184416 (3.108 sec/batch), lr: 0.250000
2019-03-16 21:48:21,132 2019-03-16 21:48:21: step 478/50000, loss = 0.187163 (2.850 sec/batch), lr: 0.250000
2019-03-16 21:48:23,749 2019-03-16 21:48:23: step 479/50000, loss = 0.184786 (2.599 sec/batch), lr: 0.250000
2019-03-16 21:48:26,273 2019-03-16 21:48:26: step 480/50000, loss = 0.171362 (2.511 sec/batch), lr: 0.250000
2019-03-16 21:48:28,605 2019-03-16 21:48:28: step 481/50000, loss = 0.182573 (2.320 sec/batch), lr: 0.250000
2019-03-16 21:48:30,526 2019-03-16 21:48:30: step 482/50000, loss = 0.184468 (1.907 sec/batch), lr: 0.250000
2019-03-16 21:48:32,348 2019-03-16 21:48:32: step 483/50000, loss = 0.186697 (1.811 sec/batch), lr: 0.250000
2019-03-16 21:48:34,142 2019-03-16 21:48:34: step 484/50000, loss = 0.182003 (1.782 sec/batch), lr: 0.250000
2019-03-16 21:48:36,033 2019-03-16 21:48:36: step 485/50000, loss = 0.180355 (1.879 sec/batch), lr: 0.250000
2019-03-16 21:48:37,745 2019-03-16 21:48:37: step 486/50000, loss = 0.168888 (1.702 sec/batch), lr: 0.250000
2019-03-16 21:48:39,258 2019-03-16 21:48:39: step 487/50000, loss = 0.176374 (1.502 sec/batch), lr: 0.250000
2019-03-16 21:48:40,678 2019-03-16 21:48:40: step 488/50000, loss = 0.164740 (1.410 sec/batch), lr: 0.250000
2019-03-16 21:48:41,979 2019-03-16 21:48:41: step 489/50000, loss = 0.160877 (1.293 sec/batch), lr: 0.250000
2019-03-16 21:48:43,121 2019-03-16 21:48:43: step 490/50000, loss = 0.166516 (1.133 sec/batch), lr: 0.250000
2019-03-16 21:48:44,124 2019-03-16 21:48:44: step 491/50000, loss = 0.185098 (0.995 sec/batch), lr: 0.250000
2019-03-16 21:48:45,074 2019-03-16 21:48:45: step 492/50000, loss = 0.173602 (0.941 sec/batch), lr: 0.250000
2019-03-16 21:48:45,890 2019-03-16 21:48:45: step 493/50000, loss = 0.170333 (0.809 sec/batch), lr: 0.250000
2019-03-16 21:48:46,568 2019-03-16 21:48:46: step 494/50000, loss = 0.166785 (0.670 sec/batch), lr: 0.250000
2019-03-16 21:48:47,134 2019-03-16 21:48:47: step 495/50000, loss = 0.174914 (0.560 sec/batch), lr: 0.250000
2019-03-16 21:48:47,648 2019-03-16 21:48:47: step 496/50000, loss = 0.146486 (0.508 sec/batch), lr: 0.250000
2019-03-16 21:48:48,063 2019-03-16 21:48:48: step 497/50000, loss = 0.154837 (0.409 sec/batch), lr: 0.250000
2019-03-16 21:48:48,389 2019-03-16 21:48:48: step 498/50000, loss = 0.140893 (0.321 sec/batch), lr: 0.250000
2019-03-16 21:48:48,590 2019-03-16 21:48:48: step 499/50000, loss = 0.100430 (0.196 sec/batch), lr: 0.250000
2019-03-16 21:48:48,703 2019-03-16 21:48:48: step 500/50000, loss = 0.253692 (0.111 sec/batch), lr: 0.250000
2019-03-16 21:49:16,649 step 500: Full loss = 0.210866, Edge acc. = 0.3490
2019-03-16 21:49:16,708 step 500: Dev acc. = 0.374198
2019-03-16 21:49:16,852 2019-03-16 21:49:16: step 501/50000, loss = 0.208707 (0.140 sec/batch), lr: 0.250000
2019-03-16 21:49:17,085 2019-03-16 21:49:17: step 502/50000, loss = 0.118866 (0.229 sec/batch), lr: 0.250000
2019-03-16 21:49:17,409 2019-03-16 21:49:17: step 503/50000, loss = 0.202327 (0.319 sec/batch), lr: 0.250000
2019-03-16 21:49:17,849 2019-03-16 21:49:17: step 504/50000, loss = 0.174114 (0.434 sec/batch), lr: 0.250000
2019-03-16 21:49:18,392 2019-03-16 21:49:18: step 505/50000, loss = 0.162024 (0.537 sec/batch), lr: 0.250000
2019-03-16 21:49:19,038 2019-03-16 21:49:19: step 506/50000, loss = 0.176630 (0.639 sec/batch), lr: 0.250000
2019-03-16 21:49:19,831 2019-03-16 21:49:19: step 507/50000, loss = 0.181037 (0.785 sec/batch), lr: 0.250000
2019-03-16 21:49:20,659 2019-03-16 21:49:20: step 508/50000, loss = 0.206973 (0.820 sec/batch), lr: 0.250000
2019-03-16 21:49:21,644 2019-03-16 21:49:21: step 509/50000, loss = 0.198320 (0.976 sec/batch), lr: 0.250000
2019-03-16 21:49:22,755 2019-03-16 21:49:22: step 510/50000, loss = 0.203262 (1.102 sec/batch), lr: 0.250000
2019-03-16 21:49:23,916 2019-03-16 21:49:23: step 511/50000, loss = 0.190317 (1.151 sec/batch), lr: 0.250000
2019-03-16 21:49:25,214 2019-03-16 21:49:25: step 512/50000, loss = 0.217234 (1.289 sec/batch), lr: 0.250000
2019-03-16 21:49:26,683 2019-03-16 21:49:26: step 513/50000, loss = 0.199882 (1.461 sec/batch), lr: 0.250000
2019-03-16 21:49:28,319 2019-03-16 21:49:28: step 514/50000, loss = 0.215339 (1.625 sec/batch), lr: 0.250000
2019-03-16 21:49:30,006 2019-03-16 21:49:30: step 515/50000, loss = 0.175514 (1.676 sec/batch), lr: 0.250000
2019-03-16 21:49:31,814 2019-03-16 21:49:31: step 516/50000, loss = 0.211112 (1.798 sec/batch), lr: 0.250000
2019-03-16 21:49:33,875 2019-03-16 21:49:33: step 517/50000, loss = 0.185583 (2.049 sec/batch), lr: 0.250000
2019-03-16 21:49:35,998 2019-03-16 21:49:35: step 518/50000, loss = 0.210119 (2.116 sec/batch), lr: 0.250000
2019-03-16 21:49:38,151 2019-03-16 21:49:38: step 519/50000, loss = 0.172186 (2.138 sec/batch), lr: 0.250000
2019-03-16 21:49:40,305 2019-03-16 21:49:40: step 520/50000, loss = 0.200366 (2.141 sec/batch), lr: 0.250000
2019-03-16 21:49:42,839 2019-03-16 21:49:42: step 521/50000, loss = 0.184315 (2.519 sec/batch), lr: 0.250000
2019-03-16 21:49:45,559 2019-03-16 21:49:45: step 522/50000, loss = 0.191137 (2.705 sec/batch), lr: 0.250000
2019-03-16 21:49:48,394 2019-03-16 21:49:48: step 523/50000, loss = 0.180344 (2.821 sec/batch), lr: 0.250000
2019-03-16 21:49:51,307 2019-03-16 21:49:51: step 524/50000, loss = 0.193607 (2.900 sec/batch), lr: 0.250000
2019-03-16 21:49:54,382 2019-03-16 21:49:54: step 525/50000, loss = 0.188696 (3.059 sec/batch), lr: 0.250000
2019-03-16 21:49:57,791 2019-03-16 21:49:57: step 526/50000, loss = 0.196841 (3.391 sec/batch), lr: 0.250000
2019-03-16 21:50:01,495 2019-03-16 21:50:01: step 527/50000, loss = 0.176097 (3.684 sec/batch), lr: 0.250000
2019-03-16 21:50:05,233 2019-03-16 21:50:05: step 528/50000, loss = 0.196821 (3.718 sec/batch), lr: 0.250000
2019-03-16 21:50:09,203 2019-03-16 21:50:09: step 529/50000, loss = 0.196531 (3.962 sec/batch), lr: 0.250000
2019-03-16 21:50:13,366 2019-03-16 21:50:13: step 530/50000, loss = 0.202095 (4.142 sec/batch), lr: 0.250000
2019-03-16 21:50:17,747 2019-03-16 21:50:17: step 531/50000, loss = 0.190528 (4.356 sec/batch), lr: 0.250000
2019-03-16 21:50:22,455 2019-03-16 21:50:22: step 532/50000, loss = 0.205675 (4.684 sec/batch), lr: 0.250000
2019-03-16 21:50:27,276 2019-03-16 21:50:27: step 533/50000, loss = 0.189687 (4.812 sec/batch), lr: 0.250000
2019-03-16 21:50:32,628 2019-03-16 21:50:32: step 534/50000, loss = 0.203841 (5.321 sec/batch), lr: 0.250000
2019-03-16 21:50:38,440 2019-03-16 21:50:38: step 535/50000, loss = 0.186608 (5.781 sec/batch), lr: 0.250000
2019-03-16 21:50:44,256 2019-03-16 21:50:44: step 536/50000, loss = 0.208836 (5.783 sec/batch), lr: 0.250000
2019-03-16 21:50:50,439 2019-03-16 21:50:50: step 537/50000, loss = 0.187754 (6.174 sec/batch), lr: 0.250000
2019-03-16 21:50:57,153 2019-03-16 21:50:57: step 538/50000, loss = 0.201986 (6.678 sec/batch), lr: 0.250000
2019-03-16 21:51:04,448 2019-03-16 21:51:04: step 539/50000, loss = 0.189528 (7.258 sec/batch), lr: 0.250000
2019-03-16 21:51:12,148 2019-03-16 21:51:12: step 540/50000, loss = 0.211422 (7.659 sec/batch), lr: 0.250000
2019-03-16 21:51:20,518 2019-03-16 21:51:20: step 541/50000, loss = 0.193569 (8.324 sec/batch), lr: 0.250000
2019-03-16 21:51:29,819 2019-03-16 21:51:29: step 542/50000, loss = 0.214636 (9.290 sec/batch), lr: 0.250000
2019-03-16 21:51:40,071 2019-03-16 21:51:40: step 543/50000, loss = 0.197726 (10.192 sec/batch), lr: 0.250000
2019-03-16 21:51:51,319 2019-03-16 21:51:51: step 544/50000, loss = 0.217866 (11.186 sec/batch), lr: 0.250000
2019-03-16 21:52:03,752 2019-03-16 21:52:03: step 545/50000, loss = 0.194596 (12.366 sec/batch), lr: 0.250000
2019-03-16 21:52:18,175 2019-03-16 21:52:18: step 546/50000, loss = 0.224358 (14.343 sec/batch), lr: 0.250000
2019-03-16 21:52:35,339 2019-03-16 21:52:35: step 547/50000, loss = 0.199258 (17.061 sec/batch), lr: 0.250000
2019-03-16 21:52:55,670 2019-03-16 21:52:55: step 548/50000, loss = 0.223363 (20.209 sec/batch), lr: 0.250000
2019-03-16 21:53:23,816 2019-03-16 21:53:23: step 549/50000, loss = 0.195592 (27.984 sec/batch), lr: 0.250000
2019-03-16 21:53:57,983 2019-03-16 21:53:57: step 550/50000, loss = 0.233436 (34.155 sec/batch), lr: 0.250000
2019-03-16 21:54:47,755 2019-03-16 21:54:47: step 551/50000, loss = 0.168865 (49.545 sec/batch), lr: 0.250000
2019-03-16 21:55:11,554 2019-03-16 21:55:11: step 552/50000, loss = 0.294494 (23.782 sec/batch), lr: 0.250000
2019-03-16 21:55:30,295 2019-03-16 21:55:30: step 553/50000, loss = 0.208697 (18.637 sec/batch), lr: 0.250000
2019-03-16 21:55:46,149 2019-03-16 21:55:46: step 554/50000, loss = 0.328616 (15.758 sec/batch), lr: 0.250000
2019-03-16 21:55:59,001 2019-03-16 21:55:59: step 555/50000, loss = 0.210904 (12.839 sec/batch), lr: 0.250000
2019-03-16 21:56:10,608 2019-03-16 21:56:10: step 556/50000, loss = 0.314700 (11.543 sec/batch), lr: 0.250000
2019-03-16 21:56:21,138 2019-03-16 21:56:21: step 557/50000, loss = 0.218412 (10.473 sec/batch), lr: 0.250000
2019-03-16 21:56:30,703 2019-03-16 21:56:30: step 558/50000, loss = 0.305594 (9.512 sec/batch), lr: 0.250000
2019-03-16 21:56:39,510 2019-03-16 21:56:39: step 559/50000, loss = 0.367595 (8.758 sec/batch), lr: 0.250000
2019-03-16 21:56:47,418 2019-03-16 21:56:47: step 560/50000, loss = 0.236514 (7.864 sec/batch), lr: 0.250000
2019-03-16 21:56:54,835 2019-03-16 21:56:54: step 561/50000, loss = 0.223392 (7.375 sec/batch), lr: 0.250000
2019-03-16 21:57:01,739 2019-03-16 21:57:01: step 562/50000, loss = 0.268647 (6.866 sec/batch), lr: 0.250000
2019-03-16 21:57:08,216 2019-03-16 21:57:08: step 563/50000, loss = 0.222050 (6.441 sec/batch), lr: 0.250000
2019-03-16 21:57:14,205 2019-03-16 21:57:14: step 564/50000, loss = 0.249206 (5.957 sec/batch), lr: 0.250000
2019-03-16 21:57:19,935 2019-03-16 21:57:19: step 565/50000, loss = 0.216896 (5.701 sec/batch), lr: 0.250000
2019-03-16 21:57:25,307 2019-03-16 21:57:25: step 566/50000, loss = 0.254046 (5.342 sec/batch), lr: 0.250000
2019-03-16 21:57:30,353 2019-03-16 21:57:30: step 567/50000, loss = 0.217317 (5.008 sec/batch), lr: 0.250000
2019-03-16 21:57:35,245 2019-03-16 21:57:35: step 568/50000, loss = 0.214036 (4.866 sec/batch), lr: 0.250000
2019-03-16 21:57:39,845 2019-03-16 21:57:39: step 569/50000, loss = 0.201387 (4.576 sec/batch), lr: 0.250000
2019-03-16 21:57:44,047 2019-03-16 21:57:44: step 570/50000, loss = 0.249419 (4.177 sec/batch), lr: 0.250000
2019-03-16 21:57:48,231 2019-03-16 21:57:48: step 571/50000, loss = 0.214413 (4.176 sec/batch), lr: 0.250000
2019-03-16 21:57:52,238 2019-03-16 21:57:52: step 572/50000, loss = 0.217446 (3.998 sec/batch), lr: 0.250000
2019-03-16 21:57:55,940 2019-03-16 21:57:55: step 573/50000, loss = 0.216959 (3.681 sec/batch), lr: 0.250000
2019-03-16 21:57:59,298 2019-03-16 21:57:59: step 574/50000, loss = 0.220809 (3.340 sec/batch), lr: 0.250000
2019-03-16 21:58:02,436 2019-03-16 21:58:02: step 575/50000, loss = 0.214220 (3.122 sec/batch), lr: 0.250000
2019-03-16 21:58:05,545 2019-03-16 21:58:05: step 576/50000, loss = 0.214044 (3.093 sec/batch), lr: 0.250000
2019-03-16 21:58:08,425 2019-03-16 21:58:08: step 577/50000, loss = 0.222542 (2.864 sec/batch), lr: 0.250000
2019-03-16 21:58:11,292 2019-03-16 21:58:11: step 578/50000, loss = 0.212538 (2.849 sec/batch), lr: 0.250000
2019-03-16 21:58:13,760 2019-03-16 21:58:13: step 579/50000, loss = 0.226797 (2.454 sec/batch), lr: 0.250000
2019-03-16 21:58:16,228 2019-03-16 21:58:16: step 580/50000, loss = 0.199040 (2.454 sec/batch), lr: 0.250000
2019-03-16 21:58:18,514 2019-03-16 21:58:18: step 581/50000, loss = 0.224344 (2.273 sec/batch), lr: 0.250000
2019-03-16 21:58:20,670 2019-03-16 21:58:20: step 582/50000, loss = 0.210667 (2.142 sec/batch), lr: 0.250000
2019-03-16 21:58:22,763 2019-03-16 21:58:22: step 583/50000, loss = 0.237864 (2.086 sec/batch), lr: 0.250000
2019-03-16 21:58:24,660 2019-03-16 21:58:24: step 584/50000, loss = 0.209686 (1.890 sec/batch), lr: 0.250000
2019-03-16 21:58:26,452 2019-03-16 21:58:26: step 585/50000, loss = 0.237336 (1.781 sec/batch), lr: 0.250000
2019-03-16 21:58:27,908 2019-03-16 21:58:27: step 586/50000, loss = 0.206857 (1.449 sec/batch), lr: 0.250000
2019-03-16 21:58:29,254 2019-03-16 21:58:29: step 587/50000, loss = 0.235357 (1.338 sec/batch), lr: 0.250000
2019-03-16 21:58:30,658 2019-03-16 21:58:30: step 588/50000, loss = 0.209219 (1.398 sec/batch), lr: 0.250000
2019-03-16 21:58:31,888 2019-03-16 21:58:31: step 589/50000, loss = 0.222666 (1.223 sec/batch), lr: 0.250000
2019-03-16 21:58:33,011 2019-03-16 21:58:33: step 590/50000, loss = 0.216131 (1.114 sec/batch), lr: 0.250000
2019-03-16 21:58:33,989 2019-03-16 21:58:33: step 591/50000, loss = 0.270595 (0.970 sec/batch), lr: 0.250000
2019-03-16 21:58:34,930 2019-03-16 21:58:34: step 592/50000, loss = 0.224311 (0.933 sec/batch), lr: 0.250000
2019-03-16 21:58:35,757 2019-03-16 21:58:35: step 593/50000, loss = 0.230514 (0.820 sec/batch), lr: 0.250000
2019-03-16 21:58:36,426 2019-03-16 21:58:36: step 594/50000, loss = 0.234712 (0.662 sec/batch), lr: 0.250000
2019-03-16 21:58:36,979 2019-03-16 21:58:36: step 595/50000, loss = 0.274287 (0.548 sec/batch), lr: 0.250000
2019-03-16 21:58:37,501 2019-03-16 21:58:37: step 596/50000, loss = 0.277664 (0.515 sec/batch), lr: 0.250000
2019-03-16 21:58:37,912 2019-03-16 21:58:37: step 597/50000, loss = 0.214385 (0.406 sec/batch), lr: 0.250000
2019-03-16 21:58:38,196 2019-03-16 21:58:38: step 598/50000, loss = 0.209249 (0.278 sec/batch), lr: 0.250000
2019-03-16 21:58:38,381 2019-03-16 21:58:38: step 599/50000, loss = 0.215393 (0.181 sec/batch), lr: 0.250000
2019-03-16 21:58:38,464 2019-03-16 21:58:38: step 600/50000, loss = 0.645378 (0.081 sec/batch), lr: 0.250000
2019-03-16 21:59:06,294 step 600: Full loss = 0.310180, Edge acc. = 0.0764
2019-03-16 21:59:06,354 step 600: Dev acc. = 0.074044
2019-03-16 21:59:06,488 2019-03-16 21:59:06: step 601/50000, loss = 0.454537 (0.129 sec/batch), lr: 0.125000
2019-03-16 21:59:06,692 2019-03-16 21:59:06: step 602/50000, loss = 0.369670 (0.201 sec/batch), lr: 0.125000
2019-03-16 21:59:06,995 2019-03-16 21:59:06: step 603/50000, loss = 0.228010 (0.298 sec/batch), lr: 0.125000
2019-03-16 21:59:07,344 2019-03-16 21:59:07: step 604/50000, loss = 0.146163 (0.345 sec/batch), lr: 0.125000
2019-03-16 21:59:07,781 2019-03-16 21:59:07: step 605/50000, loss = 0.149761 (0.433 sec/batch), lr: 0.125000
2019-03-16 21:59:08,337 2019-03-16 21:59:08: step 606/50000, loss = 0.151493 (0.550 sec/batch), lr: 0.125000
2019-03-16 21:59:09,091 2019-03-16 21:59:09: step 607/50000, loss = 0.159060 (0.749 sec/batch), lr: 0.125000
2019-03-16 21:59:09,859 2019-03-16 21:59:09: step 608/50000, loss = 0.176592 (0.762 sec/batch), lr: 0.125000
2019-03-16 21:59:10,686 2019-03-16 21:59:10: step 609/50000, loss = 0.180450 (0.821 sec/batch), lr: 0.125000
2019-03-16 21:59:11,660 2019-03-16 21:59:11: step 610/50000, loss = 0.162961 (0.965 sec/batch), lr: 0.125000
2019-03-16 21:59:12,689 2019-03-16 21:59:12: step 611/50000, loss = 0.165458 (1.020 sec/batch), lr: 0.125000
2019-03-16 21:59:13,851 2019-03-16 21:59:13: step 612/50000, loss = 0.168334 (1.153 sec/batch), lr: 0.125000
2019-03-16 21:59:15,143 2019-03-16 21:59:15: step 613/50000, loss = 0.164220 (1.284 sec/batch), lr: 0.125000
2019-03-16 21:59:16,612 2019-03-16 21:59:16: step 614/50000, loss = 0.164694 (1.461 sec/batch), lr: 0.125000
2019-03-16 21:59:18,200 2019-03-16 21:59:18: step 615/50000, loss = 0.172965 (1.581 sec/batch), lr: 0.125000
2019-03-16 21:59:20,126 2019-03-16 21:59:20: step 616/50000, loss = 0.173539 (1.918 sec/batch), lr: 0.125000
2019-03-16 21:59:22,152 2019-03-16 21:59:22: step 617/50000, loss = 0.171353 (2.013 sec/batch), lr: 0.125000
2019-03-16 21:59:24,236 2019-03-16 21:59:24: step 618/50000, loss = 0.172484 (2.071 sec/batch), lr: 0.125000
2019-03-16 21:59:26,522 2019-03-16 21:59:26: step 619/50000, loss = 0.172256 (2.273 sec/batch), lr: 0.125000
2019-03-16 21:59:28,850 2019-03-16 21:59:28: step 620/50000, loss = 0.178187 (2.314 sec/batch), lr: 0.125000
2019-03-16 21:59:31,424 2019-03-16 21:59:31: step 621/50000, loss = 0.182953 (2.560 sec/batch), lr: 0.125000
2019-03-16 21:59:34,190 2019-03-16 21:59:34: step 622/50000, loss = 0.162677 (2.752 sec/batch), lr: 0.125000
2019-03-16 21:59:36,938 2019-03-16 21:59:36: step 623/50000, loss = 0.184456 (2.733 sec/batch), lr: 0.125000
2019-03-16 21:59:40,050 2019-03-16 21:59:40: step 624/50000, loss = 0.167535 (3.095 sec/batch), lr: 0.125000
2019-03-16 21:59:43,086 2019-03-16 21:59:43: step 625/50000, loss = 0.186009 (3.019 sec/batch), lr: 0.125000
2019-03-16 21:59:46,441 2019-03-16 21:59:46: step 626/50000, loss = 0.170269 (3.330 sec/batch), lr: 0.125000
2019-03-16 21:59:50,094 2019-03-16 21:59:50: step 627/50000, loss = 0.178082 (3.644 sec/batch), lr: 0.125000
2019-03-16 21:59:53,649 2019-03-16 21:59:53: step 628/50000, loss = 0.170866 (3.535 sec/batch), lr: 0.125000
2019-03-16 21:59:57,517 2019-03-16 21:59:57: step 629/50000, loss = 0.193912 (3.846 sec/batch), lr: 0.125000
2019-03-16 22:00:01,858 2019-03-16 22:00:01: step 630/50000, loss = 0.176143 (4.320 sec/batch), lr: 0.125000
2019-03-16 22:00:06,201 2019-03-16 22:00:06: step 631/50000, loss = 0.192946 (4.319 sec/batch), lr: 0.125000
2019-03-16 22:00:10,873 2019-03-16 22:00:10: step 632/50000, loss = 0.179896 (4.645 sec/batch), lr: 0.125000
2019-03-16 22:00:15,877 2019-03-16 22:00:15: step 633/50000, loss = 0.187465 (4.979 sec/batch), lr: 0.125000
2019-03-16 22:00:21,237 2019-03-16 22:00:21: step 634/50000, loss = 0.175542 (5.330 sec/batch), lr: 0.125000
2019-03-16 22:00:26,965 2019-03-16 22:00:26: step 635/50000, loss = 0.191141 (5.697 sec/batch), lr: 0.125000
2019-03-16 22:00:32,768 2019-03-16 22:00:32: step 636/50000, loss = 0.186986 (5.770 sec/batch), lr: 0.125000
2019-03-16 22:00:38,901 2019-03-16 22:00:38: step 637/50000, loss = 0.189596 (6.098 sec/batch), lr: 0.125000
2019-03-16 22:00:45,759 2019-03-16 22:00:45: step 638/50000, loss = 0.179628 (6.821 sec/batch), lr: 0.125000
2019-03-16 22:00:53,064 2019-03-16 22:00:53: step 639/50000, loss = 0.193601 (7.265 sec/batch), lr: 0.125000
2019-03-16 22:01:00,963 2019-03-16 22:01:00: step 640/50000, loss = 0.183838 (7.854 sec/batch), lr: 0.125000
2019-03-16 22:01:09,503 2019-03-16 22:01:09: step 641/50000, loss = 0.198641 (8.494 sec/batch), lr: 0.125000
2019-03-16 22:01:18,743 2019-03-16 22:01:18: step 642/50000, loss = 0.188841 (9.187 sec/batch), lr: 0.125000
2019-03-16 22:01:28,972 2019-03-16 22:01:28: step 643/50000, loss = 0.203819 (10.175 sec/batch), lr: 0.125000
2019-03-16 22:01:40,302 2019-03-16 22:01:40: step 644/50000, loss = 0.190015 (11.264 sec/batch), lr: 0.125000
2019-03-16 22:01:52,589 2019-03-16 22:01:52: step 645/50000, loss = 0.204620 (12.215 sec/batch), lr: 0.125000
2019-03-16 22:02:06,878 2019-03-16 22:02:06: step 646/50000, loss = 0.197138 (14.209 sec/batch), lr: 0.125000
2019-03-16 22:02:23,997 2019-03-16 22:02:23: step 647/50000, loss = 0.215376 (17.021 sec/batch), lr: 0.125000
2019-03-16 22:02:44,233 2019-03-16 22:02:44: step 648/50000, loss = 0.195156 (20.125 sec/batch), lr: 0.125000
2019-03-16 22:03:12,311 2019-03-16 22:03:12: step 649/50000, loss = 0.207062 (27.914 sec/batch), lr: 0.125000
2019-03-16 22:03:46,493 2019-03-16 22:03:46: step 650/50000, loss = 0.171062 (34.168 sec/batch), lr: 0.125000
2019-03-16 22:04:36,082 2019-03-16 22:04:36: step 651/50000, loss = 0.167094 (49.346 sec/batch), lr: 0.125000
2019-03-16 22:04:59,751 2019-03-16 22:04:59: step 652/50000, loss = 0.205838 (23.655 sec/batch), lr: 0.125000
2019-03-16 22:05:17,837 2019-03-16 22:05:17: step 653/50000, loss = 0.201585 (18.072 sec/batch), lr: 0.125000
2019-03-16 22:05:33,494 2019-03-16 22:05:33: step 654/50000, loss = 0.232082 (15.571 sec/batch), lr: 0.125000
2019-03-16 22:05:46,499 2019-03-16 22:05:46: step 655/50000, loss = 0.198330 (12.932 sec/batch), lr: 0.125000
2019-03-16 22:05:58,267 2019-03-16 22:05:58: step 656/50000, loss = 0.222287 (11.705 sec/batch), lr: 0.125000
2019-03-16 22:06:08,888 2019-03-16 22:06:08: step 657/50000, loss = 0.197779 (10.611 sec/batch), lr: 0.125000
2019-03-16 22:06:18,560 2019-03-16 22:06:18: step 658/50000, loss = 0.231280 (9.664 sec/batch), lr: 0.125000
2019-03-16 22:06:27,600 2019-03-16 22:06:27: step 659/50000, loss = 0.184155 (8.989 sec/batch), lr: 0.125000
2019-03-16 22:06:35,692 2019-03-16 22:06:35: step 660/50000, loss = 0.204686 (8.046 sec/batch), lr: 0.125000
2019-03-16 22:06:43,136 2019-03-16 22:06:43: step 661/50000, loss = 0.185459 (7.435 sec/batch), lr: 0.125000
2019-03-16 22:06:49,934 2019-03-16 22:06:49: step 662/50000, loss = 0.223227 (6.763 sec/batch), lr: 0.125000
2019-03-16 22:06:56,467 2019-03-16 22:06:56: step 663/50000, loss = 0.186253 (6.522 sec/batch), lr: 0.125000
2019-03-16 22:07:02,539 2019-03-16 22:07:02: step 664/50000, loss = 0.215063 (6.041 sec/batch), lr: 0.125000
2019-03-16 22:07:08,313 2019-03-16 22:07:08: step 665/50000, loss = 0.183965 (5.742 sec/batch), lr: 0.125000
2019-03-16 22:07:13,733 2019-03-16 22:07:13: step 666/50000, loss = 0.214314 (5.392 sec/batch), lr: 0.125000
2019-03-16 22:07:18,752 2019-03-16 22:07:18: step 667/50000, loss = 0.182751 (4.991 sec/batch), lr: 0.125000
2019-03-16 22:07:23,641 2019-03-16 22:07:23: step 668/50000, loss = 0.192661 (4.865 sec/batch), lr: 0.125000
2019-03-16 22:07:28,231 2019-03-16 22:07:28: step 669/50000, loss = 0.176640 (4.565 sec/batch), lr: 0.125000
2019-03-16 22:07:32,468 2019-03-16 22:07:32: step 670/50000, loss = 0.214252 (4.227 sec/batch), lr: 0.125000
2019-03-16 22:07:36,574 2019-03-16 22:07:36: step 671/50000, loss = 0.184100 (4.085 sec/batch), lr: 0.125000
2019-03-16 22:07:40,559 2019-03-16 22:07:40: step 672/50000, loss = 0.196443 (3.964 sec/batch), lr: 0.125000
2019-03-16 22:07:44,059 2019-03-16 22:07:44: step 673/50000, loss = 0.180801 (3.492 sec/batch), lr: 0.125000
2019-03-16 22:07:47,471 2019-03-16 22:07:47: step 674/50000, loss = 0.192884 (3.395 sec/batch), lr: 0.125000
2019-03-16 22:07:50,670 2019-03-16 22:07:50: step 675/50000, loss = 0.175873 (3.191 sec/batch), lr: 0.125000
2019-03-16 22:07:53,655 2019-03-16 22:07:53: step 676/50000, loss = 0.189970 (2.969 sec/batch), lr: 0.125000
2019-03-16 22:07:56,672 2019-03-16 22:07:56: step 677/50000, loss = 0.184001 (3.009 sec/batch), lr: 0.125000
2019-03-16 22:07:59,386 2019-03-16 22:07:59: step 678/50000, loss = 0.189512 (2.710 sec/batch), lr: 0.125000
2019-03-16 22:08:01,912 2019-03-16 22:08:01: step 679/50000, loss = 0.183885 (2.515 sec/batch), lr: 0.125000
2019-03-16 22:08:04,103 2019-03-16 22:08:04: step 680/50000, loss = 0.171682 (2.181 sec/batch), lr: 0.125000
2019-03-16 22:08:06,323 2019-03-16 22:08:06: step 681/50000, loss = 0.178296 (2.209 sec/batch), lr: 0.125000
2019-03-16 22:08:08,459 2019-03-16 22:08:08: step 682/50000, loss = 0.183162 (2.125 sec/batch), lr: 0.125000
2019-03-16 22:08:10,415 2019-03-16 22:08:10: step 683/50000, loss = 0.182699 (1.947 sec/batch), lr: 0.125000
2019-03-16 22:08:12,308 2019-03-16 22:08:12: step 684/50000, loss = 0.181639 (1.886 sec/batch), lr: 0.125000
2019-03-16 22:08:14,183 2019-03-16 22:08:14: step 685/50000, loss = 0.179297 (1.866 sec/batch), lr: 0.125000
2019-03-16 22:08:15,693 2019-03-16 22:08:15: step 686/50000, loss = 0.170554 (1.503 sec/batch), lr: 0.125000
2019-03-16 22:08:17,036 2019-03-16 22:08:17: step 687/50000, loss = 0.172618 (1.336 sec/batch), lr: 0.125000
2019-03-16 22:08:18,335 2019-03-16 22:08:18: step 688/50000, loss = 0.161704 (1.290 sec/batch), lr: 0.125000
2019-03-16 22:08:19,572 2019-03-16 22:08:19: step 689/50000, loss = 0.157570 (1.230 sec/batch), lr: 0.125000
2019-03-16 22:08:20,716 2019-03-16 22:08:20: step 690/50000, loss = 0.164690 (1.138 sec/batch), lr: 0.125000
2019-03-16 22:08:21,704 2019-03-16 22:08:21: step 691/50000, loss = 0.179702 (0.979 sec/batch), lr: 0.125000
2019-03-16 22:08:22,657 2019-03-16 22:08:22: step 692/50000, loss = 0.171829 (0.945 sec/batch), lr: 0.125000
2019-03-16 22:08:23,486 2019-03-16 22:08:23: step 693/50000, loss = 0.163764 (0.821 sec/batch), lr: 0.125000
2019-03-16 22:08:24,160 2019-03-16 22:08:24: step 694/50000, loss = 0.160494 (0.667 sec/batch), lr: 0.125000
2019-03-16 22:08:24,716 2019-03-16 22:08:24: step 695/50000, loss = 0.168815 (0.550 sec/batch), lr: 0.125000
2019-03-16 22:08:25,219 2019-03-16 22:08:25: step 696/50000, loss = 0.141768 (0.497 sec/batch), lr: 0.125000
2019-03-16 22:08:25,588 2019-03-16 22:08:25: step 697/50000, loss = 0.145986 (0.364 sec/batch), lr: 0.125000
2019-03-16 22:08:25,895 2019-03-16 22:08:25: step 698/50000, loss = 0.134218 (0.301 sec/batch), lr: 0.125000
2019-03-16 22:08:26,096 2019-03-16 22:08:26: step 699/50000, loss = 0.086282 (0.198 sec/batch), lr: 0.125000
2019-03-16 22:08:26,189 2019-03-16 22:08:26: step 700/50000, loss = 0.258991 (0.090 sec/batch), lr: 0.125000
2019-03-16 22:08:54,111 step 700: Full loss = 0.225145, Edge acc. = 0.3541
2019-03-16 22:08:54,172 step 700: Dev acc. = 0.384857
2019-03-16 22:08:54,312 2019-03-16 22:08:54: step 701/50000, loss = 0.240345 (0.136 sec/batch), lr: 0.125000
2019-03-16 22:08:54,537 2019-03-16 22:08:54: step 702/50000, loss = 0.115405 (0.221 sec/batch), lr: 0.125000
2019-03-16 22:08:54,825 2019-03-16 22:08:54: step 703/50000, loss = 0.185251 (0.284 sec/batch), lr: 0.125000
2019-03-16 22:08:55,169 2019-03-16 22:08:55: step 704/50000, loss = 0.161499 (0.338 sec/batch), lr: 0.125000
2019-03-16 22:08:55,579 2019-03-16 22:08:55: step 705/50000, loss = 0.157258 (0.407 sec/batch), lr: 0.125000
2019-03-16 22:08:56,131 2019-03-16 22:08:56: step 706/50000, loss = 0.157035 (0.547 sec/batch), lr: 0.125000
2019-03-16 22:08:56,812 2019-03-16 22:08:56: step 707/50000, loss = 0.191429 (0.675 sec/batch), lr: 0.125000
2019-03-16 22:08:57,568 2019-03-16 22:08:57: step 708/50000, loss = 0.200507 (0.750 sec/batch), lr: 0.125000
2019-03-16 22:08:58,534 2019-03-16 22:08:58: step 709/50000, loss = 0.235815 (0.958 sec/batch), lr: 0.125000
2019-03-16 22:08:59,584 2019-03-16 22:08:59: step 710/50000, loss = 0.195421 (1.044 sec/batch), lr: 0.125000
2019-03-16 22:09:00,561 2019-03-16 22:09:00: step 711/50000, loss = 0.249704 (0.972 sec/batch), lr: 0.125000
2019-03-16 22:09:01,719 2019-03-16 22:09:01: step 712/50000, loss = 0.204164 (1.154 sec/batch), lr: 0.125000
2019-03-16 22:09:03,053 2019-03-16 22:09:03: step 713/50000, loss = 0.280183 (1.325 sec/batch), lr: 0.125000
2019-03-16 22:09:04,532 2019-03-16 22:09:04: step 714/50000, loss = 0.194419 (1.469 sec/batch), lr: 0.125000
2019-03-16 22:09:06,253 2019-03-16 22:09:06: step 715/50000, loss = 0.259083 (1.710 sec/batch), lr: 0.125000
2019-03-16 22:09:08,208 2019-03-16 22:09:08: step 716/50000, loss = 0.217417 (1.948 sec/batch), lr: 0.125000
2019-03-16 22:09:09,972 2019-03-16 22:09:09: step 717/50000, loss = 0.275197 (1.754 sec/batch), lr: 0.125000
2019-03-16 22:09:12,074 2019-03-16 22:09:12: step 718/50000, loss = 0.206388 (2.092 sec/batch), lr: 0.125000
2019-03-16 22:09:14,026 2019-03-16 22:09:14: step 719/50000, loss = 0.282461 (1.939 sec/batch), lr: 0.125000
2019-03-16 22:09:16,259 2019-03-16 22:09:16: step 720/50000, loss = 0.207201 (2.223 sec/batch), lr: 0.125000
2019-03-16 22:09:18,680 2019-03-16 22:09:18: step 721/50000, loss = 0.277305 (2.409 sec/batch), lr: 0.125000
2019-03-16 22:09:21,337 2019-03-16 22:09:21: step 722/50000, loss = 0.194917 (2.643 sec/batch), lr: 0.125000
2019-03-16 22:09:24,180 2019-03-16 22:09:24: step 723/50000, loss = 0.194608 (2.829 sec/batch), lr: 0.125000
2019-03-16 22:09:27,241 2019-03-16 22:09:27: step 724/50000, loss = 0.173898 (3.044 sec/batch), lr: 0.125000
2019-03-16 22:09:30,427 2019-03-16 22:09:30: step 725/50000, loss = 0.193914 (3.169 sec/batch), lr: 0.125000
2019-03-16 22:09:33,874 2019-03-16 22:09:33: step 726/50000, loss = 0.174514 (3.428 sec/batch), lr: 0.125000
2019-03-16 22:09:37,463 2019-03-16 22:09:37: step 727/50000, loss = 0.184227 (3.580 sec/batch), lr: 0.125000
2019-03-16 22:09:41,143 2019-03-16 22:09:41: step 728/50000, loss = 0.175867 (3.660 sec/batch), lr: 0.125000
2019-03-16 22:09:45,085 2019-03-16 22:09:45: step 729/50000, loss = 0.199712 (3.933 sec/batch), lr: 0.125000
2019-03-16 22:09:49,387 2019-03-16 22:09:49: step 730/50000, loss = 0.180405 (4.280 sec/batch), lr: 0.125000
2019-03-16 22:09:53,554 2019-03-16 22:09:53: step 731/50000, loss = 0.198512 (4.146 sec/batch), lr: 0.125000
2019-03-16 22:09:58,160 2019-03-16 22:09:58: step 732/50000, loss = 0.184761 (4.580 sec/batch), lr: 0.125000
2019-03-16 22:10:03,127 2019-03-16 22:10:03: step 733/50000, loss = 0.193313 (4.957 sec/batch), lr: 0.125000
2019-03-16 22:10:08,385 2019-03-16 22:10:08: step 734/50000, loss = 0.179905 (5.230 sec/batch), lr: 0.125000
2019-03-16 22:10:13,963 2019-03-16 22:10:13: step 735/50000, loss = 0.194645 (5.569 sec/batch), lr: 0.125000
2019-03-16 22:10:19,736 2019-03-16 22:10:19: step 736/50000, loss = 0.192347 (5.746 sec/batch), lr: 0.125000
2019-03-16 22:10:25,775 2019-03-16 22:10:25: step 737/50000, loss = 0.192339 (6.009 sec/batch), lr: 0.125000
2019-03-16 22:10:32,536 2019-03-16 22:10:32: step 738/50000, loss = 0.184888 (6.728 sec/batch), lr: 0.125000
2019-03-16 22:10:39,470 2019-03-16 22:10:39: step 739/50000, loss = 0.195928 (6.898 sec/batch), lr: 0.125000
2019-03-16 22:10:47,120 2019-03-16 22:10:47: step 740/50000, loss = 0.184801 (7.639 sec/batch), lr: 0.125000
2019-03-16 22:10:55,407 2019-03-16 22:10:55: step 741/50000, loss = 0.202415 (8.238 sec/batch), lr: 0.125000
2019-03-16 22:11:04,718 2019-03-16 22:11:04: step 742/50000, loss = 0.190203 (9.260 sec/batch), lr: 0.125000
2019-03-16 22:11:14,814 2019-03-16 22:11:14: step 743/50000, loss = 0.206526 (10.039 sec/batch), lr: 0.125000
2019-03-16 22:11:26,167 2019-03-16 22:11:26: step 744/50000, loss = 0.192618 (11.287 sec/batch), lr: 0.125000
2019-03-16 22:11:38,563 2019-03-16 22:11:38: step 745/50000, loss = 0.208093 (12.323 sec/batch), lr: 0.125000
2019-03-16 22:11:53,097 2019-03-16 22:11:53: step 746/50000, loss = 0.197598 (14.450 sec/batch), lr: 0.125000
2019-03-16 22:12:10,031 2019-03-16 22:12:10: step 747/50000, loss = 0.217757 (16.838 sec/batch), lr: 0.125000
2019-03-16 22:12:30,247 2019-03-16 22:12:30: step 748/50000, loss = 0.195525 (20.096 sec/batch), lr: 0.125000
2019-03-16 22:12:58,303 2019-03-16 22:12:58: step 749/50000, loss = 0.216975 (27.904 sec/batch), lr: 0.125000
2019-03-16 22:13:32,458 2019-03-16 22:13:32: step 750/50000, loss = 0.164261 (33.987 sec/batch), lr: 0.125000
2019-03-16 22:13:32,611 2019-03-16 22:13:32: step 751/50000, loss = 0.571389 (0.147 sec/batch), lr: 0.125000
2019-03-16 22:13:32,871 2019-03-16 22:13:32: step 752/50000, loss = 0.141230 (0.255 sec/batch), lr: 0.125000
2019-03-16 22:13:33,215 2019-03-16 22:13:33: step 753/50000, loss = 0.158481 (0.340 sec/batch), lr: 0.125000
2019-03-16 22:13:33,649 2019-03-16 22:13:33: step 754/50000, loss = 0.147558 (0.429 sec/batch), lr: 0.125000
2019-03-16 22:13:34,185 2019-03-16 22:13:34: step 755/50000, loss = 0.160487 (0.531 sec/batch), lr: 0.125000
2019-03-16 22:13:34,830 2019-03-16 22:13:34: step 756/50000, loss = 0.160990 (0.638 sec/batch), lr: 0.125000
2019-03-16 22:13:35,624 2019-03-16 22:13:35: step 757/50000, loss = 0.173667 (0.788 sec/batch), lr: 0.125000
2019-03-16 22:13:36,449 2019-03-16 22:13:36: step 758/50000, loss = 0.196090 (0.820 sec/batch), lr: 0.125000
2019-03-16 22:13:37,437 2019-03-16 22:13:37: step 759/50000, loss = 0.211439 (0.980 sec/batch), lr: 0.125000
2019-03-16 22:13:38,548 2019-03-16 22:13:38: step 760/50000, loss = 0.195477 (1.104 sec/batch), lr: 0.125000
2019-03-16 22:13:39,617 2019-03-16 22:13:39: step 761/50000, loss = 0.184289 (1.061 sec/batch), lr: 0.125000
2019-03-16 22:13:40,648 2019-03-16 22:13:40: step 762/50000, loss = 0.227442 (1.026 sec/batch), lr: 0.125000
2019-03-16 22:13:41,994 2019-03-16 22:13:41: step 763/50000, loss = 0.182533 (1.338 sec/batch), lr: 0.125000
2019-03-16 22:13:43,510 2019-03-16 22:13:43: step 764/50000, loss = 0.234620 (1.506 sec/batch), lr: 0.125000
2019-03-16 22:13:45,198 2019-03-16 22:13:45: step 765/50000, loss = 0.198880 (1.677 sec/batch), lr: 0.125000
2019-03-16 22:13:47,152 2019-03-16 22:13:47: step 766/50000, loss = 0.287791 (1.947 sec/batch), lr: 0.125000
2019-03-16 22:13:49,233 2019-03-16 22:13:49: step 767/50000, loss = 0.195617 (2.069 sec/batch), lr: 0.125000
2019-03-16 22:13:51,330 2019-03-16 22:13:51: step 768/50000, loss = 0.267756 (2.090 sec/batch), lr: 0.125000
2019-03-16 22:13:53,645 2019-03-16 22:13:53: step 769/50000, loss = 0.194440 (2.303 sec/batch), lr: 0.125000
2019-03-16 22:13:55,859 2019-03-16 22:13:55: step 770/50000, loss = 0.315316 (2.202 sec/batch), lr: 0.125000
2019-03-16 22:13:58,379 2019-03-16 22:13:58: step 771/50000, loss = 0.208053 (2.506 sec/batch), lr: 0.125000
2019-03-16 22:14:01,210 2019-03-16 22:14:01: step 772/50000, loss = 0.269381 (2.817 sec/batch), lr: 0.125000
2019-03-16 22:14:04,074 2019-03-16 22:14:04: step 773/50000, loss = 0.206589 (2.849 sec/batch), lr: 0.125000
2019-03-16 22:14:07,101 2019-03-16 22:14:07: step 774/50000, loss = 0.283659 (3.010 sec/batch), lr: 0.125000
2019-03-16 22:14:10,252 2019-03-16 22:14:10: step 775/50000, loss = 0.203688 (3.134 sec/batch), lr: 0.125000
2019-03-16 22:14:13,644 2019-03-16 22:14:13: step 776/50000, loss = 0.283687 (3.376 sec/batch), lr: 0.125000
2019-03-16 22:14:17,148 2019-03-16 22:14:17: step 777/50000, loss = 0.200688 (3.486 sec/batch), lr: 0.125000
2019-03-16 22:14:20,859 2019-03-16 22:14:20: step 778/50000, loss = 0.260613 (3.692 sec/batch), lr: 0.125000
2019-03-16 22:14:24,696 2019-03-16 22:14:24: step 779/50000, loss = 0.211644 (3.817 sec/batch), lr: 0.125000
2019-03-16 22:14:28,807 2019-03-16 22:14:28: step 780/50000, loss = 0.274652 (4.103 sec/batch), lr: 0.125000
2019-03-16 22:14:32,975 2019-03-16 22:14:32: step 781/50000, loss = 0.216612 (4.145 sec/batch), lr: 0.125000
2019-03-16 22:14:37,653 2019-03-16 22:14:37: step 782/50000, loss = 0.272090 (4.669 sec/batch), lr: 0.125000
2019-03-16 22:14:42,569 2019-03-16 22:14:42: step 783/50000, loss = 0.204681 (4.888 sec/batch), lr: 0.125000
2019-03-16 22:14:47,920 2019-03-16 22:14:47: step 784/50000, loss = 0.284150 (5.322 sec/batch), lr: 0.125000
2019-03-16 22:14:53,545 2019-03-16 22:14:53: step 785/50000, loss = 0.211332 (5.615 sec/batch), lr: 0.125000
2019-03-16 22:14:59,337 2019-03-16 22:14:59: step 786/50000, loss = 0.291626 (5.760 sec/batch), lr: 0.125000
2019-03-16 22:15:05,456 2019-03-16 22:15:05: step 787/50000, loss = 0.205894 (6.109 sec/batch), lr: 0.125000
2019-03-16 22:15:12,269 2019-03-16 22:15:12: step 788/50000, loss = 0.288669 (6.780 sec/batch), lr: 0.125000
2019-03-16 22:15:19,473 2019-03-16 22:15:19: step 789/50000, loss = 0.207722 (7.196 sec/batch), lr: 0.125000
2019-03-16 22:15:27,148 2019-03-16 22:15:27: step 790/50000, loss = 0.271095 (7.636 sec/batch), lr: 0.125000
2019-03-16 22:15:35,367 2019-03-16 22:15:35: step 791/50000, loss = 0.215466 (8.177 sec/batch), lr: 0.125000
2019-03-16 22:15:44,497 2019-03-16 22:15:44: step 792/50000, loss = 0.289323 (9.079 sec/batch), lr: 0.125000
2019-03-16 22:15:54,689 2019-03-16 22:15:54: step 793/50000, loss = 0.217776 (10.180 sec/batch), lr: 0.125000
2019-03-16 22:16:05,831 2019-03-16 22:16:05: step 794/50000, loss = 0.299559 (11.080 sec/batch), lr: 0.125000
2019-03-16 22:16:18,052 2019-03-16 22:16:18: step 795/50000, loss = 0.218382 (12.208 sec/batch), lr: 0.125000
2019-03-16 22:16:32,308 2019-03-16 22:16:32: step 796/50000, loss = 0.283682 (14.175 sec/batch), lr: 0.125000
2019-03-16 22:16:49,342 2019-03-16 22:16:49: step 797/50000, loss = 0.223785 (16.931 sec/batch), lr: 0.125000
2019-03-16 22:17:09,422 2019-03-16 22:17:09: step 798/50000, loss = 0.279044 (19.968 sec/batch), lr: 0.125000
2019-03-16 22:17:37,349 2019-03-16 22:17:37: step 799/50000, loss = 0.224031 (27.913 sec/batch), lr: 0.125000
2019-03-16 22:18:11,354 2019-03-16 22:18:11: step 800/50000, loss = 0.219328 (33.822 sec/batch), lr: 0.125000
2019-03-16 22:18:39,099 step 800: Full loss = 0.125725, Edge acc. = 0.3585
2019-03-16 22:18:39,159 step 800: Dev acc. = 0.376500
2019-03-16 22:18:39,302 2019-03-16 22:18:39: step 801/50000, loss = 0.297295 (0.138 sec/batch), lr: 0.062500
2019-03-16 22:18:39,520 2019-03-16 22:18:39: step 802/50000, loss = 0.121902 (0.214 sec/batch), lr: 0.062500
2019-03-16 22:18:39,821 2019-03-16 22:18:39: step 803/50000, loss = 0.154904 (0.297 sec/batch), lr: 0.062500
2019-03-16 22:18:40,243 2019-03-16 22:18:40: step 804/50000, loss = 0.143004 (0.418 sec/batch), lr: 0.062500
2019-03-16 22:18:40,782 2019-03-16 22:18:40: step 805/50000, loss = 0.145419 (0.532 sec/batch), lr: 0.062500
2019-03-16 22:18:41,425 2019-03-16 22:18:41: step 806/50000, loss = 0.139224 (0.636 sec/batch), lr: 0.062500
2019-03-16 22:18:42,204 2019-03-16 22:18:42: step 807/50000, loss = 0.144459 (0.773 sec/batch), lr: 0.062500
2019-03-16 22:18:43,011 2019-03-16 22:18:43: step 808/50000, loss = 0.162514 (0.803 sec/batch), lr: 0.062500
2019-03-16 22:18:43,967 2019-03-16 22:18:43: step 809/50000, loss = 0.165942 (0.948 sec/batch), lr: 0.062500
2019-03-16 22:18:44,955 2019-03-16 22:18:44: step 810/50000, loss = 0.153694 (0.981 sec/batch), lr: 0.062500
2019-03-16 22:18:46,086 2019-03-16 22:18:46: step 811/50000, loss = 0.158204 (1.123 sec/batch), lr: 0.062500
2019-03-16 22:18:47,358 2019-03-16 22:18:47: step 812/50000, loss = 0.157278 (1.265 sec/batch), lr: 0.062500
2019-03-16 22:18:48,783 2019-03-16 22:18:48: step 813/50000, loss = 0.156169 (1.419 sec/batch), lr: 0.062500
2019-03-16 22:18:50,226 2019-03-16 22:18:50: step 814/50000, loss = 0.157036 (1.435 sec/batch), lr: 0.062500
2019-03-16 22:18:51,722 2019-03-16 22:18:51: step 815/50000, loss = 0.163369 (1.488 sec/batch), lr: 0.062500
2019-03-16 22:18:53,589 2019-03-16 22:18:53: step 816/50000, loss = 0.168848 (1.861 sec/batch), lr: 0.062500
2019-03-16 22:18:55,626 2019-03-16 22:18:55: step 817/50000, loss = 0.162840 (2.021 sec/batch), lr: 0.062500
2019-03-16 22:18:57,778 2019-03-16 22:18:57: step 818/50000, loss = 0.172295 (2.144 sec/batch), lr: 0.062500
2019-03-16 22:18:59,872 2019-03-16 22:18:59: step 819/50000, loss = 0.165594 (2.089 sec/batch), lr: 0.062500
2019-03-16 22:19:02,175 2019-03-16 22:19:02: step 820/50000, loss = 0.173889 (2.291 sec/batch), lr: 0.062500
2019-03-16 22:19:04,697 2019-03-16 22:19:04: step 821/50000, loss = 0.174562 (2.509 sec/batch), lr: 0.062500
2019-03-16 22:19:07,449 2019-03-16 22:19:07: step 822/50000, loss = 0.164572 (2.740 sec/batch), lr: 0.062500
2019-03-16 22:19:10,115 2019-03-16 22:19:10: step 823/50000, loss = 0.175917 (2.652 sec/batch), lr: 0.062500
2019-03-16 22:19:13,098 2019-03-16 22:19:13: step 824/50000, loss = 0.165229 (2.969 sec/batch), lr: 0.062500
2019-03-16 22:19:15,983 2019-03-16 22:19:15: step 825/50000, loss = 0.177898 (2.870 sec/batch), lr: 0.062500
2019-03-16 22:19:19,276 2019-03-16 22:19:19: step 826/50000, loss = 0.172458 (3.275 sec/batch), lr: 0.062500
2019-03-16 22:19:22,900 2019-03-16 22:19:22: step 827/50000, loss = 0.168524 (3.615 sec/batch), lr: 0.062500
2019-03-16 22:19:26,498 2019-03-16 22:19:26: step 828/50000, loss = 0.169578 (3.578 sec/batch), lr: 0.062500
2019-03-16 22:19:30,376 2019-03-16 22:19:30: step 829/50000, loss = 0.184307 (3.869 sec/batch), lr: 0.062500
2019-03-16 22:19:34,590 2019-03-16 22:19:34: step 830/50000, loss = 0.175018 (4.205 sec/batch), lr: 0.062500
2019-03-16 22:19:38,638 2019-03-16 22:19:38: step 831/50000, loss = 0.186237 (4.026 sec/batch), lr: 0.062500
2019-03-16 22:19:43,093 2019-03-16 22:19:43: step 832/50000, loss = 0.180011 (4.447 sec/batch), lr: 0.062500
2019-03-16 22:19:48,021 2019-03-16 22:19:48: step 833/50000, loss = 0.181286 (4.919 sec/batch), lr: 0.062500
2019-03-16 22:19:53,350 2019-03-16 22:19:53: step 834/50000, loss = 0.174807 (5.299 sec/batch), lr: 0.062500
2019-03-16 22:19:58,957 2019-03-16 22:19:58: step 835/50000, loss = 0.185467 (5.576 sec/batch), lr: 0.062500
2019-03-16 22:20:04,559 2019-03-16 22:20:04: step 836/50000, loss = 0.189874 (5.570 sec/batch), lr: 0.062500
2019-03-16 22:20:10,734 2019-03-16 22:20:10: step 837/50000, loss = 0.182451 (6.140 sec/batch), lr: 0.062500
2019-03-16 22:20:17,588 2019-03-16 22:20:17: step 838/50000, loss = 0.179284 (6.804 sec/batch), lr: 0.062500
2019-03-16 22:20:24,740 2019-03-16 22:20:24: step 839/50000, loss = 0.185253 (7.142 sec/batch), lr: 0.062500
2019-03-16 22:20:32,326 2019-03-16 22:20:32: step 840/50000, loss = 0.182572 (7.547 sec/batch), lr: 0.062500
2019-03-16 22:20:40,393 2019-03-16 22:20:40: step 841/50000, loss = 0.193134 (8.022 sec/batch), lr: 0.062500
2019-03-16 22:20:49,660 2019-03-16 22:20:49: step 842/50000, loss = 0.185758 (9.214 sec/batch), lr: 0.062500
2019-03-16 22:20:59,885 2019-03-16 22:20:59: step 843/50000, loss = 0.197250 (10.166 sec/batch), lr: 0.062500
2019-03-16 22:21:11,024 2019-03-16 22:21:11: step 844/50000, loss = 0.191643 (11.126 sec/batch), lr: 0.062500
2019-03-16 22:21:23,347 2019-03-16 22:21:23: step 845/50000, loss = 0.198764 (12.250 sec/batch), lr: 0.062500
2019-03-16 22:21:37,768 2019-03-16 22:21:37: step 846/50000, loss = 0.197135 (14.341 sec/batch), lr: 0.062500
2019-03-16 22:21:54,851 2019-03-16 22:21:54: step 847/50000, loss = 0.208134 (16.983 sec/batch), lr: 0.062500
2019-03-16 22:22:15,086 2019-03-16 22:22:15: step 848/50000, loss = 0.194936 (20.114 sec/batch), lr: 0.062500
2019-03-16 22:22:43,105 2019-03-16 22:22:43: step 849/50000, loss = 0.236387 (27.864 sec/batch), lr: 0.062500
2019-03-16 22:23:17,191 2019-03-16 22:23:17: step 850/50000, loss = 0.169721 (33.903 sec/batch), lr: 0.062500
2019-03-16 22:24:07,054 2019-03-16 22:24:07: step 851/50000, loss = 0.186909 (49.619 sec/batch), lr: 0.062500
2019-03-16 22:24:30,555 2019-03-16 22:24:30: step 852/50000, loss = 0.194535 (23.488 sec/batch), lr: 0.062500
2019-03-16 22:24:49,050 2019-03-16 22:24:49: step 853/50000, loss = 0.203390 (18.480 sec/batch), lr: 0.062500
2019-03-16 22:25:04,816 2019-03-16 22:25:04: step 854/50000, loss = 0.204334 (15.751 sec/batch), lr: 0.062500
2019-03-16 22:25:17,866 2019-03-16 22:25:17: step 855/50000, loss = 0.197195 (13.037 sec/batch), lr: 0.062500
2019-03-16 22:25:29,500 2019-03-16 22:25:29: step 856/50000, loss = 0.193759 (11.622 sec/batch), lr: 0.062500
2019-03-16 22:25:40,269 2019-03-16 22:25:40: step 857/50000, loss = 0.194640 (10.705 sec/batch), lr: 0.062500
2019-03-16 22:25:50,006 2019-03-16 22:25:50: step 858/50000, loss = 0.198303 (9.725 sec/batch), lr: 0.062500
2019-03-16 22:25:59,087 2019-03-16 22:25:59: step 859/50000, loss = 0.180330 (9.071 sec/batch), lr: 0.062500
2019-03-16 22:26:07,475 2019-03-16 22:26:07: step 860/50000, loss = 0.184330 (8.377 sec/batch), lr: 0.062500
2019-03-16 22:26:14,811 2019-03-16 22:26:14: step 861/50000, loss = 0.181637 (7.328 sec/batch), lr: 0.062500
2019-03-16 22:26:21,618 2019-03-16 22:26:21: step 862/50000, loss = 0.190750 (6.799 sec/batch), lr: 0.062500
2019-03-16 22:26:28,098 2019-03-16 22:26:28: step 863/50000, loss = 0.177612 (6.470 sec/batch), lr: 0.062500
2019-03-16 22:26:34,111 2019-03-16 22:26:34: step 864/50000, loss = 0.185406 (5.981 sec/batch), lr: 0.062500
2019-03-16 22:26:39,807 2019-03-16 22:26:39: step 865/50000, loss = 0.175514 (5.663 sec/batch), lr: 0.062500
2019-03-16 22:26:45,307 2019-03-16 22:26:45: step 866/50000, loss = 0.195146 (5.492 sec/batch), lr: 0.062500
2019-03-16 22:26:50,194 2019-03-16 22:26:50: step 867/50000, loss = 0.173870 (4.860 sec/batch), lr: 0.062500
2019-03-16 22:26:55,142 2019-03-16 22:26:55: step 868/50000, loss = 0.171826 (4.922 sec/batch), lr: 0.062500
2019-03-16 22:26:59,730 2019-03-16 22:26:59: step 869/50000, loss = 0.169908 (4.565 sec/batch), lr: 0.062500
2019-03-16 22:27:04,091 2019-03-16 22:27:04: step 870/50000, loss = 0.183625 (4.340 sec/batch), lr: 0.062500
2019-03-16 22:27:08,320 2019-03-16 22:27:08: step 871/50000, loss = 0.174857 (4.208 sec/batch), lr: 0.062500
2019-03-16 22:27:12,036 2019-03-16 22:27:12: step 872/50000, loss = 0.171810 (3.698 sec/batch), lr: 0.062500
2019-03-16 22:27:15,679 2019-03-16 22:27:15: step 873/50000, loss = 0.164683 (3.622 sec/batch), lr: 0.062500
2019-03-16 22:27:19,009 2019-03-16 22:27:19: step 874/50000, loss = 0.168768 (3.312 sec/batch), lr: 0.062500
2019-03-16 22:27:22,305 2019-03-16 22:27:22: step 875/50000, loss = 0.159601 (3.278 sec/batch), lr: 0.062500
2019-03-16 22:27:25,406 2019-03-16 22:27:25: step 876/50000, loss = 0.173763 (3.086 sec/batch), lr: 0.062500
2019-03-16 22:27:28,356 2019-03-16 22:27:28: step 877/50000, loss = 0.164698 (2.937 sec/batch), lr: 0.062500
2019-03-16 22:27:31,107 2019-03-16 22:27:31: step 878/50000, loss = 0.170854 (2.740 sec/batch), lr: 0.062500
2019-03-16 22:27:33,590 2019-03-16 22:27:33: step 879/50000, loss = 0.167841 (2.472 sec/batch), lr: 0.062500
2019-03-16 22:27:36,113 2019-03-16 22:27:36: step 880/50000, loss = 0.155321 (2.510 sec/batch), lr: 0.062500
2019-03-16 22:27:38,484 2019-03-16 22:27:38: step 881/50000, loss = 0.160026 (2.358 sec/batch), lr: 0.062500
2019-03-16 22:27:40,638 2019-03-16 22:27:40: step 882/50000, loss = 0.165250 (2.141 sec/batch), lr: 0.062500
2019-03-16 22:27:42,767 2019-03-16 22:27:42: step 883/50000, loss = 0.165299 (2.116 sec/batch), lr: 0.062500
2019-03-16 22:27:44,725 2019-03-16 22:27:44: step 884/50000, loss = 0.167396 (1.945 sec/batch), lr: 0.062500
2019-03-16 22:27:46,595 2019-03-16 22:27:46: step 885/50000, loss = 0.159268 (1.858 sec/batch), lr: 0.062500
2019-03-16 22:27:48,228 2019-03-16 22:27:48: step 886/50000, loss = 0.159471 (1.627 sec/batch), lr: 0.062500
2019-03-16 22:27:49,703 2019-03-16 22:27:49: step 887/50000, loss = 0.158035 (1.466 sec/batch), lr: 0.062500
2019-03-16 22:27:50,973 2019-03-16 22:27:50: step 888/50000, loss = 0.151087 (1.261 sec/batch), lr: 0.062500
2019-03-16 22:27:52,076 2019-03-16 22:27:52: step 889/50000, loss = 0.147524 (1.096 sec/batch), lr: 0.062500
2019-03-16 22:27:53,159 2019-03-16 22:27:53: step 890/50000, loss = 0.150371 (1.075 sec/batch), lr: 0.062500
2019-03-16 22:27:54,001 2019-03-16 22:27:54: step 891/50000, loss = 0.165627 (0.835 sec/batch), lr: 0.062500
2019-03-16 22:27:54,805 2019-03-16 22:27:54: step 892/50000, loss = 0.156520 (0.799 sec/batch), lr: 0.062500
2019-03-16 22:27:55,522 2019-03-16 22:27:55: step 893/50000, loss = 0.159933 (0.711 sec/batch), lr: 0.062500
2019-03-16 22:27:56,184 2019-03-16 22:27:56: step 894/50000, loss = 0.152094 (0.656 sec/batch), lr: 0.062500
2019-03-16 22:27:56,737 2019-03-16 22:27:56: step 895/50000, loss = 0.148369 (0.546 sec/batch), lr: 0.062500
2019-03-16 22:27:57,251 2019-03-16 22:27:57: step 896/50000, loss = 0.128350 (0.508 sec/batch), lr: 0.062500
2019-03-16 22:27:57,662 2019-03-16 22:27:57: step 897/50000, loss = 0.137117 (0.405 sec/batch), lr: 0.062500
2019-03-16 22:27:57,984 2019-03-16 22:27:57: step 898/50000, loss = 0.128422 (0.318 sec/batch), lr: 0.062500
2019-03-16 22:27:58,166 2019-03-16 22:27:58: step 899/50000, loss = 0.075061 (0.177 sec/batch), lr: 0.062500
2019-03-16 22:27:58,257 2019-03-16 22:27:58: step 900/50000, loss = 0.115639 (0.089 sec/batch), lr: 0.062500
2019-03-16 22:28:26,103 step 900: Full loss = 0.153114, Edge acc. = 0.3752
2019-03-16 22:28:26,163 step 900: Dev acc. = 0.409436
2019-03-16 22:28:26,306 2019-03-16 22:28:26: step 901/50000, loss = 0.074230 (0.138 sec/batch), lr: 0.062500
2019-03-16 22:28:26,525 2019-03-16 22:28:26: step 902/50000, loss = 0.098315 (0.216 sec/batch), lr: 0.062500
2019-03-16 22:28:26,820 2019-03-16 22:28:26: step 903/50000, loss = 0.150281 (0.291 sec/batch), lr: 0.062500
2019-03-16 22:28:27,198 2019-03-16 22:28:27: step 904/50000, loss = 0.136708 (0.373 sec/batch), lr: 0.062500
2019-03-16 22:28:27,680 2019-03-16 22:28:27: step 905/50000, loss = 0.138809 (0.477 sec/batch), lr: 0.062500
2019-03-16 22:28:28,265 2019-03-16 22:28:28: step 906/50000, loss = 0.135974 (0.579 sec/batch), lr: 0.062500
2019-03-16 22:28:28,961 2019-03-16 22:28:28: step 907/50000, loss = 0.140432 (0.691 sec/batch), lr: 0.062500
2019-03-16 22:28:29,693 2019-03-16 22:28:29: step 908/50000, loss = 0.158871 (0.725 sec/batch), lr: 0.062500
2019-03-16 22:28:30,575 2019-03-16 22:28:30: step 909/50000, loss = 0.162582 (0.874 sec/batch), lr: 0.062500
2019-03-16 22:28:31,530 2019-03-16 22:28:31: step 910/50000, loss = 0.151432 (0.947 sec/batch), lr: 0.062500
2019-03-16 22:28:32,538 2019-03-16 22:28:32: step 911/50000, loss = 0.155507 (1.001 sec/batch), lr: 0.062500
2019-03-16 22:28:33,700 2019-03-16 22:28:33: step 912/50000, loss = 0.163489 (1.153 sec/batch), lr: 0.062500
2019-03-16 22:28:35,107 2019-03-16 22:28:35: step 913/50000, loss = 0.153341 (1.401 sec/batch), lr: 0.062500
2019-03-16 22:28:36,679 2019-03-16 22:28:36: step 914/50000, loss = 0.155121 (1.561 sec/batch), lr: 0.062500
2019-03-16 22:28:38,411 2019-03-16 22:28:38: step 915/50000, loss = 0.161264 (1.721 sec/batch), lr: 0.062500
2019-03-16 22:28:40,313 2019-03-16 22:28:40: step 916/50000, loss = 0.161968 (1.894 sec/batch), lr: 0.062500
2019-03-16 22:28:42,340 2019-03-16 22:28:42: step 917/50000, loss = 0.159708 (2.014 sec/batch), lr: 0.062500
2019-03-16 22:28:44,505 2019-03-16 22:28:44: step 918/50000, loss = 0.169852 (2.152 sec/batch), lr: 0.062500
2019-03-16 22:28:46,820 2019-03-16 22:28:46: step 919/50000, loss = 0.161386 (2.301 sec/batch), lr: 0.062500
2019-03-16 22:28:49,211 2019-03-16 22:28:49: step 920/50000, loss = 0.164955 (2.377 sec/batch), lr: 0.062500
2019-03-16 22:28:51,832 2019-03-16 22:28:51: step 921/50000, loss = 0.171959 (2.605 sec/batch), lr: 0.062500
2019-03-16 22:28:54,597 2019-03-16 22:28:54: step 922/50000, loss = 0.162944 (2.750 sec/batch), lr: 0.062500
2019-03-16 22:28:57,477 2019-03-16 22:28:57: step 923/50000, loss = 0.172368 (2.865 sec/batch), lr: 0.062500
2019-03-16 22:29:00,366 2019-03-16 22:29:00: step 924/50000, loss = 0.167406 (2.871 sec/batch), lr: 0.062500
2019-03-16 22:29:03,345 2019-03-16 22:29:03: step 925/50000, loss = 0.174737 (2.962 sec/batch), lr: 0.062500
2019-03-16 22:29:06,638 2019-03-16 22:29:06: step 926/50000, loss = 0.170563 (3.274 sec/batch), lr: 0.062500
2019-03-16 22:29:10,079 2019-03-16 22:29:10: step 927/50000, loss = 0.165047 (3.432 sec/batch), lr: 0.062500
2019-03-16 22:29:13,684 2019-03-16 22:29:13: step 928/50000, loss = 0.169453 (3.585 sec/batch), lr: 0.062500
2019-03-16 22:29:17,715 2019-03-16 22:29:17: step 929/50000, loss = 0.182005 (4.021 sec/batch), lr: 0.062500
2019-03-16 22:29:21,885 2019-03-16 22:29:21: step 930/50000, loss = 0.171051 (4.148 sec/batch), lr: 0.062500
2019-03-16 22:29:26,110 2019-03-16 22:29:26: step 931/50000, loss = 0.183640 (4.200 sec/batch), lr: 0.062500
2019-03-16 22:29:30,672 2019-03-16 22:29:30: step 932/50000, loss = 0.174023 (4.538 sec/batch), lr: 0.062500
2019-03-16 22:29:35,568 2019-03-16 22:29:35: step 933/50000, loss = 0.179093 (4.887 sec/batch), lr: 0.062500
2019-03-16 22:29:40,757 2019-03-16 22:29:40: step 934/50000, loss = 0.170885 (5.182 sec/batch), lr: 0.062500
2019-03-16 22:29:46,342 2019-03-16 22:29:46: step 935/50000, loss = 0.183053 (5.554 sec/batch), lr: 0.062500
2019-03-16 22:29:51,978 2019-03-16 22:29:51: step 936/50000, loss = 0.183847 (5.628 sec/batch), lr: 0.062500
2019-03-16 22:29:58,114 2019-03-16 22:29:58: step 937/50000, loss = 0.180481 (6.102 sec/batch), lr: 0.062500
2019-03-16 22:30:04,948 2019-03-16 22:30:04: step 938/50000, loss = 0.174254 (6.796 sec/batch), lr: 0.062500
2019-03-16 22:30:12,229 2019-03-16 22:30:12: step 939/50000, loss = 0.182777 (7.240 sec/batch), lr: 0.062500
2019-03-16 22:30:20,095 2019-03-16 22:30:20: step 940/50000, loss = 0.179647 (7.820 sec/batch), lr: 0.062500
2019-03-16 22:30:28,415 2019-03-16 22:30:28: step 941/50000, loss = 0.184541 (8.274 sec/batch), lr: 0.062500
2019-03-16 22:30:37,586 2019-03-16 22:30:37: step 942/50000, loss = 0.211703 (9.104 sec/batch), lr: 0.062500
2019-03-16 22:30:47,818 2019-03-16 22:30:47: step 943/50000, loss = 0.191126 (10.161 sec/batch), lr: 0.062500
2019-03-16 22:30:58,986 2019-03-16 22:30:58: step 944/50000, loss = 0.213396 (11.100 sec/batch), lr: 0.062500
2019-03-16 22:31:11,308 2019-03-16 22:31:11: step 945/50000, loss = 0.194838 (12.249 sec/batch), lr: 0.062500
2019-03-16 22:31:25,644 2019-03-16 22:31:25: step 946/50000, loss = 0.208933 (14.256 sec/batch), lr: 0.062500
2019-03-16 22:31:42,848 2019-03-16 22:31:42: step 947/50000, loss = 0.205909 (17.105 sec/batch), lr: 0.062500
2019-03-16 22:32:03,172 2019-03-16 22:32:03: step 948/50000, loss = 0.204896 (20.204 sec/batch), lr: 0.062500
2019-03-16 22:32:31,473 2019-03-16 22:32:31: step 949/50000, loss = 0.208588 (27.760 sec/batch), lr: 0.062500
2019-03-16 22:33:05,415 2019-03-16 22:33:05: step 950/50000, loss = 0.171402 (33.762 sec/batch), lr: 0.062500
2019-03-16 22:33:05,588 2019-03-16 22:33:05: step 951/50000, loss = 0.299779 (0.167 sec/batch), lr: 0.062500
2019-03-16 22:33:05,849 2019-03-16 22:33:05: step 952/50000, loss = 0.157826 (0.257 sec/batch), lr: 0.062500
2019-03-16 22:33:06,198 2019-03-16 22:33:06: step 953/50000, loss = 0.158788 (0.344 sec/batch), lr: 0.062500
2019-03-16 22:33:06,629 2019-03-16 22:33:06: step 954/50000, loss = 0.137654 (0.425 sec/batch), lr: 0.062500
2019-03-16 22:33:07,165 2019-03-16 22:33:07: step 955/50000, loss = 0.138961 (0.530 sec/batch), lr: 0.062500
2019-03-16 22:33:07,811 2019-03-16 22:33:07: step 956/50000, loss = 0.136416 (0.640 sec/batch), lr: 0.062500
2019-03-16 22:33:08,610 2019-03-16 22:33:08: step 957/50000, loss = 0.140396 (0.793 sec/batch), lr: 0.062500
2019-03-16 22:33:09,433 2019-03-16 22:33:09: step 958/50000, loss = 0.158704 (0.815 sec/batch), lr: 0.062500
2019-03-16 22:33:10,414 2019-03-16 22:33:10: step 959/50000, loss = 0.161469 (0.975 sec/batch), lr: 0.062500
2019-03-16 22:33:11,517 2019-03-16 22:33:11: step 960/50000, loss = 0.149895 (1.096 sec/batch), lr: 0.062500
2019-03-16 22:33:12,670 2019-03-16 22:33:12: step 961/50000, loss = 0.155376 (1.143 sec/batch), lr: 0.062500
2019-03-16 22:33:13,990 2019-03-16 22:33:13: step 962/50000, loss = 0.152469 (1.312 sec/batch), lr: 0.062500
2019-03-16 22:33:15,428 2019-03-16 22:33:15: step 963/50000, loss = 0.151572 (1.433 sec/batch), lr: 0.062500
2019-03-16 22:33:17,061 2019-03-16 22:33:17: step 964/50000, loss = 0.148763 (1.622 sec/batch), lr: 0.062500
2019-03-16 22:33:18,786 2019-03-16 22:33:18: step 965/50000, loss = 0.160155 (1.713 sec/batch), lr: 0.062500
2019-03-16 22:33:20,713 2019-03-16 22:33:20: step 966/50000, loss = 0.160035 (1.920 sec/batch), lr: 0.062500
2019-03-16 22:33:22,743 2019-03-16 22:33:22: step 967/50000, loss = 0.158764 (2.018 sec/batch), lr: 0.062500
2019-03-16 22:33:24,906 2019-03-16 22:33:24: step 968/50000, loss = 0.168247 (2.156 sec/batch), lr: 0.062500
2019-03-16 22:33:27,165 2019-03-16 22:33:27: step 969/50000, loss = 0.159857 (2.245 sec/batch), lr: 0.062500
2019-03-16 22:33:29,548 2019-03-16 22:33:29: step 970/50000, loss = 0.165173 (2.366 sec/batch), lr: 0.062500
2019-03-16 22:33:32,111 2019-03-16 22:33:32: step 971/50000, loss = 0.171250 (2.549 sec/batch), lr: 0.062500
2019-03-16 22:33:34,687 2019-03-16 22:33:34: step 972/50000, loss = 0.160365 (2.560 sec/batch), lr: 0.062500
2019-03-16 22:33:37,415 2019-03-16 22:33:37: step 973/50000, loss = 0.172079 (2.712 sec/batch), lr: 0.062500
2019-03-16 22:33:40,362 2019-03-16 22:33:40: step 974/50000, loss = 0.161249 (2.930 sec/batch), lr: 0.062500
2019-03-16 22:33:43,434 2019-03-16 22:33:43: step 975/50000, loss = 0.174678 (3.056 sec/batch), lr: 0.062500
2019-03-16 22:33:46,730 2019-03-16 22:33:46: step 976/50000, loss = 0.167907 (3.280 sec/batch), lr: 0.062500
2019-03-16 22:33:50,201 2019-03-16 22:33:50: step 977/50000, loss = 0.164655 (3.452 sec/batch), lr: 0.062500
2019-03-16 22:33:53,834 2019-03-16 22:33:53: step 978/50000, loss = 0.166181 (3.613 sec/batch), lr: 0.062500
2019-03-16 22:33:57,804 2019-03-16 22:33:57: step 979/50000, loss = 0.181590 (3.961 sec/batch), lr: 0.062500
2019-03-16 22:34:01,898 2019-03-16 22:34:01: step 980/50000, loss = 0.170120 (4.085 sec/batch), lr: 0.062500
2019-03-16 22:34:05,997 2019-03-16 22:34:05: step 981/50000, loss = 0.182990 (4.091 sec/batch), lr: 0.062500
2019-03-16 22:34:10,596 2019-03-16 22:34:10: step 982/50000, loss = 0.173118 (4.591 sec/batch), lr: 0.062500
2019-03-16 22:34:15,539 2019-03-16 22:34:15: step 983/50000, loss = 0.178644 (4.924 sec/batch), lr: 0.062500
2019-03-16 22:34:20,808 2019-03-16 22:34:20: step 984/50000, loss = 0.168960 (5.240 sec/batch), lr: 0.062500
2019-03-16 22:34:26,397 2019-03-16 22:34:26: step 985/50000, loss = 0.182474 (5.578 sec/batch), lr: 0.062500
2019-03-16 22:34:32,092 2019-03-16 22:34:32: step 986/50000, loss = 0.179665 (5.664 sec/batch), lr: 0.062500
2019-03-16 22:34:37,998 2019-03-16 22:34:37: step 987/50000, loss = 0.180114 (5.897 sec/batch), lr: 0.062500
2019-03-16 22:34:44,642 2019-03-16 22:34:44: step 988/50000, loss = 0.172823 (6.636 sec/batch), lr: 0.062500
2019-03-16 22:34:51,710 2019-03-16 22:34:51: step 989/50000, loss = 0.182266 (7.035 sec/batch), lr: 0.062500
2019-03-16 22:34:59,548 2019-03-16 22:34:59: step 990/50000, loss = 0.178780 (7.829 sec/batch), lr: 0.062500
2019-03-16 22:35:07,704 2019-03-16 22:35:07: step 991/50000, loss = 0.186386 (8.105 sec/batch), lr: 0.062500
2019-03-16 22:35:16,774 2019-03-16 22:35:16: step 992/50000, loss = 0.190370 (9.018 sec/batch), lr: 0.062500
2019-03-16 22:35:26,864 2019-03-16 22:35:26: step 993/50000, loss = 0.190314 (10.030 sec/batch), lr: 0.062500
2019-03-16 22:35:37,956 2019-03-16 22:35:37: step 994/50000, loss = 0.194872 (11.032 sec/batch), lr: 0.062500
2019-03-16 22:35:50,035 2019-03-16 22:35:50: step 995/50000, loss = 0.186887 (12.007 sec/batch), lr: 0.062500
2019-03-16 22:36:04,274 2019-03-16 22:36:04: step 996/50000, loss = 0.201525 (14.157 sec/batch), lr: 0.062500
2019-03-16 22:36:21,130 2019-03-16 22:36:21: step 997/50000, loss = 0.198253 (16.759 sec/batch), lr: 0.062500
2019-03-16 22:36:41,125 2019-03-16 22:36:41: step 998/50000, loss = 0.202985 (19.879 sec/batch), lr: 0.062500
2019-03-16 22:37:09,121 2019-03-16 22:37:09: step 999/50000, loss = 0.196183 (27.817 sec/batch), lr: 0.062500
2019-03-16 22:37:42,652 2019-03-16 22:37:42: step 1000/50000, loss = 0.200536 (33.519 sec/batch), lr: 0.062500
2019-03-16 22:38:09,683 step 1000: Full loss = 0.132971, Edge acc. = 0.3884
2019-03-16 22:38:09,747 step 1000: Dev acc. = 0.385047
2019-03-16 22:38:09,895 2019-03-16 22:38:09: step 1001/50000, loss = 0.256761 (0.143 sec/batch), lr: 0.031250
2019-03-16 22:38:10,131 2019-03-16 22:38:10: step 1002/50000, loss = 0.188807 (0.233 sec/batch), lr: 0.031250
2019-03-16 22:38:10,471 2019-03-16 22:38:10: step 1003/50000, loss = 0.210828 (0.335 sec/batch), lr: 0.031250
2019-03-16 22:38:10,895 2019-03-16 22:38:10: step 1004/50000, loss = 0.180853 (0.419 sec/batch), lr: 0.031250
2019-03-16 22:38:11,423 2019-03-16 22:38:11: step 1005/50000, loss = 0.161038 (0.522 sec/batch), lr: 0.031250
2019-03-16 22:38:12,047 2019-03-16 22:38:12: step 1006/50000, loss = 0.147307 (0.619 sec/batch), lr: 0.031250
2019-03-16 22:38:12,813 2019-03-16 22:38:12: step 1007/50000, loss = 0.145223 (0.761 sec/batch), lr: 0.031250
2019-03-16 22:38:13,560 2019-03-16 22:38:13: step 1008/50000, loss = 0.162001 (0.739 sec/batch), lr: 0.031250
2019-03-16 22:38:14,408 2019-03-16 22:38:14: step 1009/50000, loss = 0.160303 (0.843 sec/batch), lr: 0.031250
2019-03-16 22:38:15,350 2019-03-16 22:38:15: step 1010/50000, loss = 0.151331 (0.934 sec/batch), lr: 0.031250
2019-03-16 22:38:16,354 2019-03-16 22:38:16: step 1011/50000, loss = 0.153498 (0.999 sec/batch), lr: 0.031250
2019-03-16 22:38:17,521 2019-03-16 22:38:17: step 1012/50000, loss = 0.152316 (1.160 sec/batch), lr: 0.031250
2019-03-16 22:38:18,827 2019-03-16 22:38:18: step 1013/50000, loss = 0.147253 (1.300 sec/batch), lr: 0.031250
2019-03-16 22:38:20,317 2019-03-16 22:38:20: step 1014/50000, loss = 0.146975 (1.480 sec/batch), lr: 0.031250
2019-03-16 22:38:21,961 2019-03-16 22:38:21: step 1015/50000, loss = 0.157509 (1.638 sec/batch), lr: 0.031250
2019-03-16 22:38:23,728 2019-03-16 22:38:23: step 1016/50000, loss = 0.158052 (1.761 sec/batch), lr: 0.031250
2019-03-16 22:38:25,623 2019-03-16 22:38:25: step 1017/50000, loss = 0.154037 (1.882 sec/batch), lr: 0.031250
2019-03-16 22:38:27,747 2019-03-16 22:38:27: step 1018/50000, loss = 0.165305 (2.111 sec/batch), lr: 0.031250
2019-03-16 22:38:29,865 2019-03-16 22:38:29: step 1019/50000, loss = 0.155182 (2.106 sec/batch), lr: 0.031250
2019-03-16 22:38:32,199 2019-03-16 22:38:32: step 1020/50000, loss = 0.160467 (2.320 sec/batch), lr: 0.031250
2019-03-16 22:38:34,723 2019-03-16 22:38:34: step 1021/50000, loss = 0.165871 (2.510 sec/batch), lr: 0.031250
2019-03-16 22:38:37,414 2019-03-16 22:38:37: step 1022/50000, loss = 0.155250 (2.677 sec/batch), lr: 0.031250
2019-03-16 22:38:40,067 2019-03-16 22:38:40: step 1023/50000, loss = 0.166596 (2.645 sec/batch), lr: 0.031250
2019-03-16 22:38:43,096 2019-03-16 22:38:43: step 1024/50000, loss = 0.157482 (3.014 sec/batch), lr: 0.031250
2019-03-16 22:38:46,087 2019-03-16 22:38:46: step 1025/50000, loss = 0.171201 (2.976 sec/batch), lr: 0.031250
2019-03-16 22:38:49,312 2019-03-16 22:38:49: step 1026/50000, loss = 0.161566 (3.204 sec/batch), lr: 0.031250
2019-03-16 22:38:52,923 2019-03-16 22:38:52: step 1027/50000, loss = 0.161387 (3.603 sec/batch), lr: 0.031250
2019-03-16 22:38:56,507 2019-03-16 22:38:56: step 1028/50000, loss = 0.162401 (3.576 sec/batch), lr: 0.031250
2019-03-16 22:39:00,530 2019-03-16 22:39:00: step 1029/50000, loss = 0.178678 (4.013 sec/batch), lr: 0.031250
2019-03-16 22:39:04,767 2019-03-16 22:39:04: step 1030/50000, loss = 0.168691 (4.213 sec/batch), lr: 0.031250
2019-03-16 22:39:09,031 2019-03-16 22:39:09: step 1031/50000, loss = 0.179390 (4.241 sec/batch), lr: 0.031250
2019-03-16 22:39:13,669 2019-03-16 22:39:13: step 1032/50000, loss = 0.175871 (4.629 sec/batch), lr: 0.031250
2019-03-16 22:39:18,502 2019-03-16 22:39:18: step 1033/50000, loss = 0.175326 (4.807 sec/batch), lr: 0.031250
2019-03-16 22:39:23,523 2019-03-16 22:39:23: step 1034/50000, loss = 0.172337 (4.995 sec/batch), lr: 0.031250
2019-03-16 22:39:28,969 2019-03-16 22:39:28: step 1035/50000, loss = 0.178456 (5.417 sec/batch), lr: 0.031250
2019-03-16 22:39:34,672 2019-03-16 22:39:34: step 1036/50000, loss = 0.182861 (5.671 sec/batch), lr: 0.031250
2019-03-16 22:39:40,629 2019-03-16 22:39:40: step 1037/50000, loss = 0.173945 (5.921 sec/batch), lr: 0.031250
2019-03-16 22:39:47,393 2019-03-16 22:39:47: step 1038/50000, loss = 0.181473 (6.754 sec/batch), lr: 0.031250
2019-03-16 22:39:54,457 2019-03-16 22:39:54: step 1039/50000, loss = 0.180082 (7.055 sec/batch), lr: 0.031250
2019-03-16 22:40:02,158 2019-03-16 22:40:02: step 1040/50000, loss = 0.185855 (7.660 sec/batch), lr: 0.031250
2019-03-16 22:40:10,334 2019-03-16 22:40:10: step 1041/50000, loss = 0.185114 (8.132 sec/batch), lr: 0.031250
2019-03-16 22:40:19,446 2019-03-16 22:40:19: step 1042/50000, loss = 0.191267 (9.101 sec/batch), lr: 0.031250
2019-03-16 22:40:29,400 2019-03-16 22:40:29: step 1043/50000, loss = 0.190412 (9.893 sec/batch), lr: 0.031250
2019-03-16 22:40:40,434 2019-03-16 22:40:40: step 1044/50000, loss = 0.192565 (10.963 sec/batch), lr: 0.031250
2019-03-16 22:40:53,181 2019-03-16 22:40:53: step 1045/50000, loss = 0.192832 (12.675 sec/batch), lr: 0.031250
2019-03-16 22:41:07,349 2019-03-16 22:41:07: step 1046/50000, loss = 0.197770 (14.088 sec/batch), lr: 0.031250
2019-03-16 22:41:24,161 2019-03-16 22:41:24: step 1047/50000, loss = 0.203028 (16.800 sec/batch), lr: 0.031250
2019-03-16 22:41:44,459 2019-03-16 22:41:44: step 1048/50000, loss = 0.195535 (20.179 sec/batch), lr: 0.031250
2019-03-16 22:42:12,067 2019-03-16 22:42:12: step 1049/50000, loss = 0.205605 (27.458 sec/batch), lr: 0.031250
2019-03-16 22:42:45,502 2019-03-16 22:42:45: step 1050/50000, loss = 0.172232 (33.266 sec/batch), lr: 0.031250
2019-03-16 22:43:34,799 2019-03-16 22:43:34: step 1051/50000, loss = 0.174297 (49.275 sec/batch), lr: 0.031250
2019-03-16 22:43:57,914 2019-03-16 22:43:57: step 1052/50000, loss = 0.197095 (22.986 sec/batch), lr: 0.031250
2019-03-16 22:44:16,007 2019-03-16 22:44:16: step 1053/50000, loss = 0.227757 (18.081 sec/batch), lr: 0.031250
2019-03-16 22:44:31,476 2019-03-16 22:44:31: step 1054/50000, loss = 0.203161 (15.373 sec/batch), lr: 0.031250
2019-03-16 22:44:44,154 2019-03-16 22:44:44: step 1055/50000, loss = 0.193234 (12.665 sec/batch), lr: 0.031250
2019-03-16 22:44:55,660 2019-03-16 22:44:55: step 1056/50000, loss = 0.191356 (11.494 sec/batch), lr: 0.031250
2019-03-16 22:45:06,229 2019-03-16 22:45:06: step 1057/50000, loss = 0.190661 (10.504 sec/batch), lr: 0.031250
2019-03-16 22:45:15,844 2019-03-16 22:45:15: step 1058/50000, loss = 0.196271 (9.604 sec/batch), lr: 0.031250
2019-03-16 22:45:24,633 2019-03-16 22:45:24: step 1059/50000, loss = 0.176783 (8.741 sec/batch), lr: 0.031250
2019-03-16 22:45:32,789 2019-03-16 22:45:32: step 1060/50000, loss = 0.183207 (8.109 sec/batch), lr: 0.031250
2019-03-16 22:45:40,112 2019-03-16 22:45:40: step 1061/50000, loss = 0.181138 (7.313 sec/batch), lr: 0.031250
2019-03-16 22:45:46,995 2019-03-16 22:45:46: step 1062/50000, loss = 0.175647 (6.845 sec/batch), lr: 0.031250
2019-03-16 22:45:53,403 2019-03-16 22:45:53: step 1063/50000, loss = 0.173662 (6.373 sec/batch), lr: 0.031250
2019-03-16 22:45:59,266 2019-03-16 22:45:59: step 1064/50000, loss = 0.175183 (5.855 sec/batch), lr: 0.031250
2019-03-16 22:46:04,976 2019-03-16 22:46:04: step 1065/50000, loss = 0.171043 (5.678 sec/batch), lr: 0.031250
2019-03-16 22:46:10,261 2019-03-16 22:46:10: step 1066/50000, loss = 0.181259 (5.258 sec/batch), lr: 0.031250
2019-03-16 22:46:15,222 2019-03-16 22:46:15: step 1067/50000, loss = 0.169720 (4.934 sec/batch), lr: 0.031250
2019-03-16 22:46:19,869 2019-03-16 22:46:19: step 1068/50000, loss = 0.167640 (4.626 sec/batch), lr: 0.031250
2019-03-16 22:46:24,304 2019-03-16 22:46:24: step 1069/50000, loss = 0.169642 (4.429 sec/batch), lr: 0.031250
2019-03-16 22:46:28,450 2019-03-16 22:46:28: step 1070/50000, loss = 0.174371 (4.124 sec/batch), lr: 0.031250
2019-03-16 22:46:32,594 2019-03-16 22:46:32: step 1071/50000, loss = 0.171034 (4.124 sec/batch), lr: 0.031250
2019-03-16 22:46:36,366 2019-03-16 22:46:36: step 1072/50000, loss = 0.161854 (3.765 sec/batch), lr: 0.031250
2019-03-16 22:46:39,934 2019-03-16 22:46:39: step 1073/50000, loss = 0.160974 (3.559 sec/batch), lr: 0.031250
2019-03-16 22:46:43,262 2019-03-16 22:46:43: step 1074/50000, loss = 0.156817 (3.311 sec/batch), lr: 0.031250
2019-03-16 22:46:46,315 2019-03-16 22:46:46: step 1075/50000, loss = 0.155088 (3.034 sec/batch), lr: 0.031250
2019-03-16 22:46:49,426 2019-03-16 22:46:49: step 1076/50000, loss = 0.162750 (3.094 sec/batch), lr: 0.031250
2019-03-16 22:46:52,425 2019-03-16 22:46:52: step 1077/50000, loss = 0.159427 (2.983 sec/batch), lr: 0.031250
2019-03-16 22:46:55,112 2019-03-16 22:46:55: step 1078/50000, loss = 0.160394 (2.672 sec/batch), lr: 0.031250
2019-03-16 22:46:57,734 2019-03-16 22:46:57: step 1079/50000, loss = 0.163898 (2.608 sec/batch), lr: 0.031250
2019-03-16 22:47:00,257 2019-03-16 22:47:00: step 1080/50000, loss = 0.149772 (2.515 sec/batch), lr: 0.031250
2019-03-16 22:47:02,600 2019-03-16 22:47:02: step 1081/50000, loss = 0.153142 (2.329 sec/batch), lr: 0.031250
2019-03-16 22:47:04,693 2019-03-16 22:47:04: step 1082/50000, loss = 0.156993 (2.086 sec/batch), lr: 0.031250
2019-03-16 22:47:06,657 2019-03-16 22:47:06: step 1083/50000, loss = 0.160390 (1.954 sec/batch), lr: 0.031250
2019-03-16 22:47:08,212 2019-03-16 22:47:08: step 1084/50000, loss = 0.158660 (1.546 sec/batch), lr: 0.031250
2019-03-16 22:47:10,018 2019-03-16 22:47:10: step 1085/50000, loss = 0.156007 (1.794 sec/batch), lr: 0.031250
2019-03-16 22:47:11,677 2019-03-16 22:47:11: step 1086/50000, loss = 0.150832 (1.652 sec/batch), lr: 0.031250
2019-03-16 22:47:13,143 2019-03-16 22:47:13: step 1087/50000, loss = 0.156167 (1.460 sec/batch), lr: 0.031250
2019-03-16 22:47:14,554 2019-03-16 22:47:14: step 1088/50000, loss = 0.146881 (1.401 sec/batch), lr: 0.031250
2019-03-16 22:47:15,790 2019-03-16 22:47:15: step 1089/50000, loss = 0.147956 (1.227 sec/batch), lr: 0.031250
2019-03-16 22:47:16,884 2019-03-16 22:47:16: step 1090/50000, loss = 0.149835 (1.085 sec/batch), lr: 0.031250
2019-03-16 22:47:17,848 2019-03-16 22:47:17: step 1091/50000, loss = 0.165829 (0.957 sec/batch), lr: 0.031250
2019-03-16 22:47:18,785 2019-03-16 22:47:18: step 1092/50000, loss = 0.156452 (0.928 sec/batch), lr: 0.031250
2019-03-16 22:47:19,588 2019-03-16 22:47:19: step 1093/50000, loss = 0.165733 (0.796 sec/batch), lr: 0.031250
2019-03-16 22:47:20,212 2019-03-16 22:47:20: step 1094/50000, loss = 0.150751 (0.620 sec/batch), lr: 0.031250
2019-03-16 22:47:20,675 2019-03-16 22:47:20: step 1095/50000, loss = 0.149876 (0.459 sec/batch), lr: 0.031250
2019-03-16 22:47:21,121 2019-03-16 22:47:21: step 1096/50000, loss = 0.125239 (0.440 sec/batch), lr: 0.031250
2019-03-16 22:47:21,514 2019-03-16 22:47:21: step 1097/50000, loss = 0.136313 (0.389 sec/batch), lr: 0.031250
2019-03-16 22:47:21,827 2019-03-16 22:47:21: step 1098/50000, loss = 0.128510 (0.307 sec/batch), lr: 0.031250
2019-03-16 22:47:22,018 2019-03-16 22:47:22: step 1099/50000, loss = 0.074087 (0.188 sec/batch), lr: 0.031250
2019-03-16 22:47:22,126 2019-03-16 22:47:22: step 1100/50000, loss = 0.102192 (0.106 sec/batch), lr: 0.031250
2019-03-16 22:47:49,409 step 1100: Full loss = 0.139535, Edge acc. = 0.3775
2019-03-16 22:47:49,474 step 1100: Dev acc. = 0.412825
2019-03-16 22:47:49,621 2019-03-16 22:47:49: step 1101/50000, loss = 0.053352 (0.142 sec/batch), lr: 0.031250
2019-03-16 22:47:49,827 2019-03-16 22:47:49: step 1102/50000, loss = 0.106069 (0.203 sec/batch), lr: 0.031250
2019-03-16 22:47:50,119 2019-03-16 22:47:50: step 1103/50000, loss = 0.150400 (0.288 sec/batch), lr: 0.031250
2019-03-16 22:47:50,545 2019-03-16 22:47:50: step 1104/50000, loss = 0.136466 (0.420 sec/batch), lr: 0.031250
2019-03-16 22:47:51,051 2019-03-16 22:47:51: step 1105/50000, loss = 0.138195 (0.500 sec/batch), lr: 0.031250
2019-03-16 22:47:51,667 2019-03-16 22:47:51: step 1106/50000, loss = 0.134067 (0.611 sec/batch), lr: 0.031250
2019-03-16 22:47:52,452 2019-03-16 22:47:52: step 1107/50000, loss = 0.139374 (0.778 sec/batch), lr: 0.031250
2019-03-16 22:47:53,271 2019-03-16 22:47:53: step 1108/50000, loss = 0.158662 (0.811 sec/batch), lr: 0.031250
2019-03-16 22:47:54,225 2019-03-16 22:47:54: step 1109/50000, loss = 0.159823 (0.946 sec/batch), lr: 0.031250
2019-03-16 22:47:55,279 2019-03-16 22:47:55: step 1110/50000, loss = 0.149416 (1.046 sec/batch), lr: 0.031250
2019-03-16 22:47:56,387 2019-03-16 22:47:56: step 1111/50000, loss = 0.151638 (1.100 sec/batch), lr: 0.031250
2019-03-16 22:47:57,643 2019-03-16 22:47:57: step 1112/50000, loss = 0.150961 (1.250 sec/batch), lr: 0.031250
2019-03-16 22:47:58,944 2019-03-16 22:47:58: step 1113/50000, loss = 0.145211 (1.294 sec/batch), lr: 0.031250
2019-03-16 22:48:00,375 2019-03-16 22:48:00: step 1114/50000, loss = 0.145477 (1.425 sec/batch), lr: 0.031250
2019-03-16 22:48:01,890 2019-03-16 22:48:01: step 1115/50000, loss = 0.155442 (1.508 sec/batch), lr: 0.031250
2019-03-16 22:48:03,603 2019-03-16 22:48:03: step 1116/50000, loss = 0.155830 (1.706 sec/batch), lr: 0.031250
2019-03-16 22:48:05,473 2019-03-16 22:48:05: step 1117/50000, loss = 0.151811 (1.863 sec/batch), lr: 0.031250
2019-03-16 22:48:07,579 2019-03-16 22:48:07: step 1118/50000, loss = 0.161737 (2.094 sec/batch), lr: 0.031250
2019-03-16 22:48:09,616 2019-03-16 22:48:09: step 1119/50000, loss = 0.152292 (2.027 sec/batch), lr: 0.031250
2019-03-16 22:48:11,640 2019-03-16 22:48:11: step 1120/50000, loss = 0.157227 (2.015 sec/batch), lr: 0.031250
2019-03-16 22:48:14,027 2019-03-16 22:48:14: step 1121/50000, loss = 0.163412 (2.377 sec/batch), lr: 0.031250
2019-03-16 22:48:16,594 2019-03-16 22:48:16: step 1122/50000, loss = 0.151253 (2.558 sec/batch), lr: 0.031250
2019-03-16 22:48:19,289 2019-03-16 22:48:19: step 1123/50000, loss = 0.164234 (2.683 sec/batch), lr: 0.031250
2019-03-16 22:48:22,301 2019-03-16 22:48:22: step 1124/50000, loss = 0.153855 (2.995 sec/batch), lr: 0.031250
2019-03-16 22:48:25,431 2019-03-16 22:48:25: step 1125/50000, loss = 0.168775 (3.114 sec/batch), lr: 0.031250
2019-03-16 22:48:28,782 2019-03-16 22:48:28: step 1126/50000, loss = 0.158038 (3.335 sec/batch), lr: 0.031250
2019-03-16 22:48:32,212 2019-03-16 22:48:32: step 1127/50000, loss = 0.158021 (3.424 sec/batch), lr: 0.031250
2019-03-16 22:48:35,770 2019-03-16 22:48:35: step 1128/50000, loss = 0.159518 (3.539 sec/batch), lr: 0.031250
2019-03-16 22:48:39,816 2019-03-16 22:48:39: step 1129/50000, loss = 0.175364 (4.038 sec/batch), lr: 0.031250
2019-03-16 22:48:44,032 2019-03-16 22:48:44: step 1130/50000, loss = 0.166403 (4.208 sec/batch), lr: 0.031250
2019-03-16 22:48:48,314 2019-03-16 22:48:48: step 1131/50000, loss = 0.176301 (4.258 sec/batch), lr: 0.031250
2019-03-16 22:48:52,902 2019-03-16 22:48:52: step 1132/50000, loss = 0.169551 (4.579 sec/batch), lr: 0.031250
2019-03-16 22:48:57,711 2019-03-16 22:48:57: step 1133/50000, loss = 0.172575 (4.786 sec/batch), lr: 0.031250
2019-03-16 22:49:02,920 2019-03-16 22:49:02: step 1134/50000, loss = 0.168860 (5.181 sec/batch), lr: 0.031250
2019-03-16 22:49:08,523 2019-03-16 22:49:08: step 1135/50000, loss = 0.175856 (5.574 sec/batch), lr: 0.031250
2019-03-16 22:49:14,200 2019-03-16 22:49:14: step 1136/50000, loss = 0.179474 (5.645 sec/batch), lr: 0.031250
2019-03-16 22:49:20,126 2019-03-16 22:49:20: step 1137/50000, loss = 0.171595 (5.890 sec/batch), lr: 0.031250
2019-03-16 22:49:26,736 2019-03-16 22:49:26: step 1138/50000, loss = 0.177227 (6.572 sec/batch), lr: 0.031250
2019-03-16 22:49:33,928 2019-03-16 22:49:33: step 1139/50000, loss = 0.177417 (7.155 sec/batch), lr: 0.031250
2019-03-16 22:49:41,426 2019-03-16 22:49:41: step 1140/50000, loss = 0.183039 (7.490 sec/batch), lr: 0.031250
2019-03-16 22:49:49,812 2019-03-16 22:49:49: step 1141/50000, loss = 0.183039 (8.341 sec/batch), lr: 0.031250
2019-03-16 22:49:58,963 2019-03-16 22:49:58: step 1142/50000, loss = 0.188324 (9.100 sec/batch), lr: 0.031250
2019-03-16 22:50:08,909 2019-03-16 22:50:08: step 1143/50000, loss = 0.188867 (9.894 sec/batch), lr: 0.031250
2019-03-16 22:50:19,792 2019-03-16 22:50:19: step 1144/50000, loss = 0.187390 (10.819 sec/batch), lr: 0.031250
2019-03-16 22:50:31,868 2019-03-16 22:50:31: step 1145/50000, loss = 0.191480 (12.008 sec/batch), lr: 0.031250
2019-03-16 22:50:45,886 2019-03-16 22:50:45: step 1146/50000, loss = 0.194940 (13.940 sec/batch), lr: 0.031250
2019-03-16 22:51:02,623 2019-03-16 22:51:02: step 1147/50000, loss = 0.203153 (16.645 sec/batch), lr: 0.031250
2019-03-16 22:51:22,369 2019-03-16 22:51:22: step 1148/50000, loss = 0.194052 (19.636 sec/batch), lr: 0.031250
2019-03-16 22:51:49,943 2019-03-16 22:51:49: step 1149/50000, loss = 0.206982 (27.426 sec/batch), lr: 0.031250
2019-03-16 22:52:23,430 2019-03-16 22:52:23: step 1150/50000, loss = 0.171498 (33.317 sec/batch), lr: 0.031250
2019-03-16 22:52:23,588 2019-03-16 22:52:23: step 1151/50000, loss = 0.174609 (0.153 sec/batch), lr: 0.031250
2019-03-16 22:52:23,835 2019-03-16 22:52:23: step 1152/50000, loss = 0.143680 (0.244 sec/batch), lr: 0.031250
2019-03-16 22:52:24,176 2019-03-16 22:52:24: step 1153/50000, loss = 0.186179 (0.336 sec/batch), lr: 0.031250
2019-03-16 22:52:24,605 2019-03-16 22:52:24: step 1154/50000, loss = 0.165504 (0.424 sec/batch), lr: 0.031250
2019-03-16 22:52:25,136 2019-03-16 22:52:25: step 1155/50000, loss = 0.151949 (0.525 sec/batch), lr: 0.031250
2019-03-16 22:52:25,778 2019-03-16 22:52:25: step 1156/50000, loss = 0.141711 (0.634 sec/batch), lr: 0.031250
2019-03-16 22:52:26,563 2019-03-16 22:52:26: step 1157/50000, loss = 0.141213 (0.779 sec/batch), lr: 0.031250
2019-03-16 22:52:27,373 2019-03-16 22:52:27: step 1158/50000, loss = 0.158490 (0.803 sec/batch), lr: 0.031250
2019-03-16 22:52:28,198 2019-03-16 22:52:28: step 1159/50000, loss = 0.157519 (0.820 sec/batch), lr: 0.031250
2019-03-16 22:52:29,121 2019-03-16 22:52:29: step 1160/50000, loss = 0.147887 (0.917 sec/batch), lr: 0.031250
2019-03-16 22:52:30,133 2019-03-16 22:52:30: step 1161/50000, loss = 0.150974 (1.006 sec/batch), lr: 0.031250
2019-03-16 22:52:31,317 2019-03-16 22:52:31: step 1162/50000, loss = 0.149773 (1.177 sec/batch), lr: 0.031250
2019-03-16 22:52:32,791 2019-03-16 22:52:32: step 1163/50000, loss = 0.144719 (1.467 sec/batch), lr: 0.031250
2019-03-16 22:52:34,312 2019-03-16 22:52:34: step 1164/50000, loss = 0.145357 (1.514 sec/batch), lr: 0.031250
2019-03-16 22:52:35,829 2019-03-16 22:52:35: step 1165/50000, loss = 0.154669 (1.510 sec/batch), lr: 0.031250
2019-03-16 22:52:37,689 2019-03-16 22:52:37: step 1166/50000, loss = 0.155782 (1.854 sec/batch), lr: 0.031250
2019-03-16 22:52:39,651 2019-03-16 22:52:39: step 1167/50000, loss = 0.151368 (1.950 sec/batch), lr: 0.031250
2019-03-16 22:52:41,727 2019-03-16 22:52:41: step 1168/50000, loss = 0.162455 (2.069 sec/batch), lr: 0.031250
2019-03-16 22:52:43,960 2019-03-16 22:52:43: step 1169/50000, loss = 0.152126 (2.222 sec/batch), lr: 0.031250
2019-03-16 22:52:45,988 2019-03-16 22:52:45: step 1170/50000, loss = 0.156815 (2.023 sec/batch), lr: 0.031250
2019-03-16 22:52:48,429 2019-03-16 22:52:48: step 1171/50000, loss = 0.164458 (2.427 sec/batch), lr: 0.031250
2019-03-16 22:52:51,049 2019-03-16 22:52:51: step 1172/50000, loss = 0.151152 (2.605 sec/batch), lr: 0.031250
2019-03-16 22:52:53,831 2019-03-16 22:52:53: step 1173/50000, loss = 0.164429 (2.768 sec/batch), lr: 0.031250
2019-03-16 22:52:56,904 2019-03-16 22:52:56: step 1174/50000, loss = 0.154287 (3.056 sec/batch), lr: 0.031250
2019-03-16 22:52:59,940 2019-03-16 22:52:59: step 1175/50000, loss = 0.169114 (3.018 sec/batch), lr: 0.031250
2019-03-16 22:53:03,325 2019-03-16 22:53:03: step 1176/50000, loss = 0.158411 (3.367 sec/batch), lr: 0.031250
2019-03-16 22:53:06,784 2019-03-16 22:53:06: step 1177/50000, loss = 0.158816 (3.450 sec/batch), lr: 0.031250
2019-03-16 22:53:10,395 2019-03-16 22:53:10: step 1178/50000, loss = 0.159729 (3.602 sec/batch), lr: 0.031250
2019-03-16 22:53:14,324 2019-03-16 22:53:14: step 1179/50000, loss = 0.174477 (3.921 sec/batch), lr: 0.031250
2019-03-16 22:53:18,458 2019-03-16 22:53:18: step 1180/50000, loss = 0.167283 (4.126 sec/batch), lr: 0.031250
2019-03-16 22:53:22,765 2019-03-16 22:53:22: step 1181/50000, loss = 0.176391 (4.284 sec/batch), lr: 0.031250
2019-03-16 22:53:27,247 2019-03-16 22:53:27: step 1182/50000, loss = 0.169652 (4.458 sec/batch), lr: 0.031250
2019-03-16 22:53:32,202 2019-03-16 22:53:32: step 1183/50000, loss = 0.172635 (4.927 sec/batch), lr: 0.031250
2019-03-16 22:53:37,437 2019-03-16 22:53:37: step 1184/50000, loss = 0.166613 (5.206 sec/batch), lr: 0.031250
2019-03-16 22:53:42,840 2019-03-16 22:53:42: step 1185/50000, loss = 0.178096 (5.393 sec/batch), lr: 0.031250
2019-03-16 22:53:48,613 2019-03-16 22:53:48: step 1186/50000, loss = 0.176374 (5.743 sec/batch), lr: 0.031250
2019-03-16 22:53:54,609 2019-03-16 22:53:54: step 1187/50000, loss = 0.175408 (5.987 sec/batch), lr: 0.031250
2019-03-16 22:54:01,265 2019-03-16 22:54:01: step 1188/50000, loss = 0.170640 (6.610 sec/batch), lr: 0.031250
2019-03-16 22:54:08,176 2019-03-16 22:54:08: step 1189/50000, loss = 0.177799 (6.902 sec/batch), lr: 0.031250
2019-03-16 22:54:15,951 2019-03-16 22:54:15: step 1190/50000, loss = 0.177174 (7.733 sec/batch), lr: 0.031250
2019-03-16 22:54:24,185 2019-03-16 22:54:24: step 1191/50000, loss = 0.199114 (8.187 sec/batch), lr: 0.031250
2019-03-16 22:54:33,313 2019-03-16 22:54:33: step 1192/50000, loss = 0.182163 (9.074 sec/batch), lr: 0.031250
2019-03-16 22:54:43,340 2019-03-16 22:54:43: step 1193/50000, loss = 0.196065 (9.969 sec/batch), lr: 0.031250
2019-03-16 22:54:54,393 2019-03-16 22:54:54: step 1194/50000, loss = 0.187832 (10.986 sec/batch), lr: 0.031250
2019-03-16 22:55:06,531 2019-03-16 22:55:06: step 1195/50000, loss = 0.194758 (12.070 sec/batch), lr: 0.031250
2019-03-16 22:55:20,654 2019-03-16 22:55:20: step 1196/50000, loss = 0.196445 (14.040 sec/batch), lr: 0.031250
2019-03-16 22:55:37,294 2019-03-16 22:55:37: step 1197/50000, loss = 0.204762 (16.543 sec/batch), lr: 0.031250
2019-03-16 22:55:57,495 2019-03-16 22:55:57: step 1198/50000, loss = 0.199092 (20.087 sec/batch), lr: 0.031250
2019-03-16 22:56:25,030 2019-03-16 22:56:25: step 1199/50000, loss = 0.201338 (27.388 sec/batch), lr: 0.031250
2019-03-16 22:56:58,748 2019-03-16 22:56:58: step 1200/50000, loss = 0.179176 (33.549 sec/batch), lr: 0.031250
2019-03-16 22:57:26,035 step 1200: Full loss = 0.122170, Edge acc. = 0.3888
2019-03-16 22:57:26,100 step 1200: Dev acc. = 0.378807
2019-03-16 22:58:14,861 2019-03-16 22:58:14: step 1201/50000, loss = 0.161187 (48.522 sec/batch), lr: 0.015625
2019-03-16 22:58:38,252 2019-03-16 22:58:38: step 1202/50000, loss = 0.198878 (23.374 sec/batch), lr: 0.015625
2019-03-16 22:58:56,435 2019-03-16 22:58:56: step 1203/50000, loss = 0.197992 (18.080 sec/batch), lr: 0.015625
2019-03-16 22:59:12,040 2019-03-16 22:59:12: step 1204/50000, loss = 0.198262 (15.515 sec/batch), lr: 0.015625
2019-03-16 22:59:24,797 2019-03-16 22:59:24: step 1205/50000, loss = 0.192956 (12.685 sec/batch), lr: 0.015625
2019-03-16 22:59:36,236 2019-03-16 22:59:36: step 1206/50000, loss = 0.181923 (11.372 sec/batch), lr: 0.015625
2019-03-16 22:59:46,763 2019-03-16 22:59:46: step 1207/50000, loss = 0.189241 (10.468 sec/batch), lr: 0.015625
2019-03-16 22:59:56,323 2019-03-16 22:59:56: step 1208/50000, loss = 0.183212 (9.504 sec/batch), lr: 0.015625
2019-03-16 23:00:05,283 2019-03-16 23:00:05: step 1209/50000, loss = 0.174566 (8.910 sec/batch), lr: 0.015625
2019-03-16 23:00:13,339 2019-03-16 23:00:13: step 1210/50000, loss = 0.179194 (8.014 sec/batch), lr: 0.015625
2019-03-16 23:00:20,354 2019-03-16 23:00:20: step 1211/50000, loss = 0.178541 (7.008 sec/batch), lr: 0.015625
2019-03-16 23:00:26,909 2019-03-16 23:00:26: step 1212/50000, loss = 0.173869 (6.519 sec/batch), lr: 0.015625
2019-03-16 23:00:33,368 2019-03-16 23:00:33: step 1213/50000, loss = 0.171455 (6.450 sec/batch), lr: 0.015625
2019-03-16 23:00:39,140 2019-03-16 23:00:39: step 1214/50000, loss = 0.171229 (5.763 sec/batch), lr: 0.015625
2019-03-16 23:00:44,795 2019-03-16 23:00:44: step 1215/50000, loss = 0.168839 (5.624 sec/batch), lr: 0.015625
2019-03-16 23:00:50,145 2019-03-16 23:00:50: step 1216/50000, loss = 0.178541 (5.320 sec/batch), lr: 0.015625
2019-03-16 23:00:55,120 2019-03-16 23:00:55: step 1217/50000, loss = 0.167499 (4.966 sec/batch), lr: 0.015625
2019-03-16 23:00:59,969 2019-03-16 23:00:59: step 1218/50000, loss = 0.166045 (4.822 sec/batch), lr: 0.015625
2019-03-16 23:01:04,327 2019-03-16 23:01:04: step 1219/50000, loss = 0.163638 (4.349 sec/batch), lr: 0.015625
2019-03-16 23:01:08,480 2019-03-16 23:01:08: step 1220/50000, loss = 0.171513 (4.133 sec/batch), lr: 0.015625
2019-03-16 23:01:12,505 2019-03-16 23:01:12: step 1221/50000, loss = 0.168775 (4.005 sec/batch), lr: 0.015625
2019-03-16 23:01:16,267 2019-03-16 23:01:16: step 1222/50000, loss = 0.159457 (3.753 sec/batch), lr: 0.015625
2019-03-16 23:01:19,859 2019-03-16 23:01:19: step 1223/50000, loss = 0.158657 (3.575 sec/batch), lr: 0.015625
2019-03-16 23:01:23,000 2019-03-16 23:01:23: step 1224/50000, loss = 0.153468 (3.124 sec/batch), lr: 0.015625
2019-03-16 23:01:26,258 2019-03-16 23:01:26: step 1225/50000, loss = 0.152885 (3.240 sec/batch), lr: 0.015625
2019-03-16 23:01:29,327 2019-03-16 23:01:29: step 1226/50000, loss = 0.160377 (3.052 sec/batch), lr: 0.015625
2019-03-16 23:01:32,127 2019-03-16 23:01:32: step 1227/50000, loss = 0.156268 (2.783 sec/batch), lr: 0.015625
2019-03-16 23:01:34,743 2019-03-16 23:01:34: step 1228/50000, loss = 0.157849 (2.601 sec/batch), lr: 0.015625
2019-03-16 23:01:37,166 2019-03-16 23:01:37: step 1229/50000, loss = 0.162734 (2.408 sec/batch), lr: 0.015625
2019-03-16 23:01:39,423 2019-03-16 23:01:39: step 1230/50000, loss = 0.147450 (2.244 sec/batch), lr: 0.015625
2019-03-16 23:01:41,454 2019-03-16 23:01:41: step 1231/50000, loss = 0.150301 (2.021 sec/batch), lr: 0.015625
2019-03-16 23:01:43,262 2019-03-16 23:01:43: step 1232/50000, loss = 0.155804 (1.798 sec/batch), lr: 0.015625
2019-03-16 23:01:45,156 2019-03-16 23:01:45: step 1233/50000, loss = 0.158555 (1.881 sec/batch), lr: 0.015625
2019-03-16 23:01:47,002 2019-03-16 23:01:47: step 1234/50000, loss = 0.155818 (1.834 sec/batch), lr: 0.015625
2019-03-16 23:01:48,875 2019-03-16 23:01:48: step 1235/50000, loss = 0.154839 (1.861 sec/batch), lr: 0.015625
2019-03-16 23:01:50,405 2019-03-16 23:01:50: step 1236/50000, loss = 0.149666 (1.522 sec/batch), lr: 0.015625
2019-03-16 23:01:51,832 2019-03-16 23:01:51: step 1237/50000, loss = 0.155134 (1.420 sec/batch), lr: 0.015625
2019-03-16 23:01:53,228 2019-03-16 23:01:53: step 1238/50000, loss = 0.145734 (1.386 sec/batch), lr: 0.015625
2019-03-16 23:01:54,484 2019-03-16 23:01:54: step 1239/50000, loss = 0.147877 (1.249 sec/batch), lr: 0.015625
2019-03-16 23:01:55,577 2019-03-16 23:01:55: step 1240/50000, loss = 0.150149 (1.087 sec/batch), lr: 0.015625
2019-03-16 23:01:56,395 2019-03-16 23:01:56: step 1241/50000, loss = 0.165892 (0.813 sec/batch), lr: 0.015625
2019-03-16 23:01:57,316 2019-03-16 23:01:57: step 1242/50000, loss = 0.157184 (0.914 sec/batch), lr: 0.015625
2019-03-16 23:01:58,121 2019-03-16 23:01:58: step 1243/50000, loss = 0.169949 (0.797 sec/batch), lr: 0.015625
2019-03-16 23:01:58,721 2019-03-16 23:01:58: step 1244/50000, loss = 0.153059 (0.594 sec/batch), lr: 0.015625
2019-03-16 23:01:59,192 2019-03-16 23:01:59: step 1245/50000, loss = 0.153173 (0.465 sec/batch), lr: 0.015625
2019-03-16 23:01:59,587 2019-03-16 23:01:59: step 1246/50000, loss = 0.124457 (0.391 sec/batch), lr: 0.015625
2019-03-16 23:01:59,884 2019-03-16 23:01:59: step 1247/50000, loss = 0.135789 (0.294 sec/batch), lr: 0.015625
2019-03-16 23:02:00,184 2019-03-16 23:02:00: step 1248/50000, loss = 0.128038 (0.296 sec/batch), lr: 0.015625
2019-03-16 23:02:00,382 2019-03-16 23:02:00: step 1249/50000, loss = 0.073207 (0.195 sec/batch), lr: 0.015625
2019-03-16 23:02:00,482 2019-03-16 23:02:00: step 1250/50000, loss = 0.083254 (0.098 sec/batch), lr: 0.015625
2019-03-16 23:02:00,636 2019-03-16 23:02:00: step 1251/50000, loss = 0.053575 (0.148 sec/batch), lr: 0.015625
2019-03-16 23:02:00,893 2019-03-16 23:02:00: step 1252/50000, loss = 0.102194 (0.252 sec/batch), lr: 0.015625
2019-03-16 23:02:01,232 2019-03-16 23:02:01: step 1253/50000, loss = 0.149200 (0.334 sec/batch), lr: 0.015625
2019-03-16 23:02:01,650 2019-03-16 23:02:01: step 1254/50000, loss = 0.136105 (0.412 sec/batch), lr: 0.015625
2019-03-16 23:02:02,176 2019-03-16 23:02:02: step 1255/50000, loss = 0.138580 (0.520 sec/batch), lr: 0.015625
2019-03-16 23:02:02,780 2019-03-16 23:02:02: step 1256/50000, loss = 0.134702 (0.597 sec/batch), lr: 0.015625
2019-03-16 23:02:03,561 2019-03-16 23:02:03: step 1257/50000, loss = 0.139927 (0.773 sec/batch), lr: 0.015625
2019-03-16 23:02:04,344 2019-03-16 23:02:04: step 1258/50000, loss = 0.160452 (0.775 sec/batch), lr: 0.015625
2019-03-16 23:02:05,261 2019-03-16 23:02:05: step 1259/50000, loss = 0.160064 (0.909 sec/batch), lr: 0.015625
2019-03-16 23:02:06,334 2019-03-16 23:02:06: step 1260/50000, loss = 0.150669 (1.065 sec/batch), lr: 0.015625
2019-03-16 23:02:07,470 2019-03-16 23:02:07: step 1261/50000, loss = 0.152655 (1.127 sec/batch), lr: 0.015625
2019-03-16 23:02:08,782 2019-03-16 23:02:08: step 1262/50000, loss = 0.153273 (1.302 sec/batch), lr: 0.015625
2019-03-16 23:02:10,204 2019-03-16 23:02:10: step 1263/50000, loss = 0.148972 (1.413 sec/batch), lr: 0.015625
2019-03-16 23:02:11,607 2019-03-16 23:02:11: step 1264/50000, loss = 0.148912 (1.394 sec/batch), lr: 0.015625
2019-03-16 23:02:12,990 2019-03-16 23:02:12: step 1265/50000, loss = 0.156847 (1.372 sec/batch), lr: 0.015625
2019-03-16 23:02:14,748 2019-03-16 23:02:14: step 1266/50000, loss = 0.156960 (1.745 sec/batch), lr: 0.015625
2019-03-16 23:02:16,608 2019-03-16 23:02:16: step 1267/50000, loss = 0.152118 (1.848 sec/batch), lr: 0.015625
2019-03-16 23:02:18,710 2019-03-16 23:02:18: step 1268/50000, loss = 0.160711 (2.090 sec/batch), lr: 0.015625
2019-03-16 23:02:20,991 2019-03-16 23:02:20: step 1269/50000, loss = 0.151687 (2.269 sec/batch), lr: 0.015625
2019-03-16 23:02:23,215 2019-03-16 23:02:23: step 1270/50000, loss = 0.153763 (2.208 sec/batch), lr: 0.015625
2019-03-16 23:02:25,484 2019-03-16 23:02:25: step 1271/50000, loss = 0.161839 (2.255 sec/batch), lr: 0.015625
2019-03-16 23:02:28,183 2019-03-16 23:02:28: step 1272/50000, loss = 0.147792 (2.684 sec/batch), lr: 0.015625
2019-03-16 23:02:30,834 2019-03-16 23:02:30: step 1273/50000, loss = 0.159722 (2.636 sec/batch), lr: 0.015625
2019-03-16 23:02:33,828 2019-03-16 23:02:33: step 1274/50000, loss = 0.150454 (2.977 sec/batch), lr: 0.015625
2019-03-16 23:02:36,703 2019-03-16 23:02:36: step 1275/50000, loss = 0.164577 (2.862 sec/batch), lr: 0.015625
2019-03-16 23:02:39,783 2019-03-16 23:02:39: step 1276/50000, loss = 0.154754 (3.064 sec/batch), lr: 0.015625
2019-03-16 23:02:43,348 2019-03-16 23:02:43: step 1277/50000, loss = 0.154224 (3.545 sec/batch), lr: 0.015625
2019-03-16 23:02:47,042 2019-03-16 23:02:47: step 1278/50000, loss = 0.157229 (3.674 sec/batch), lr: 0.015625
2019-03-16 23:02:50,997 2019-03-16 23:02:50: step 1279/50000, loss = 0.172824 (3.933 sec/batch), lr: 0.015625
2019-03-16 23:02:55,056 2019-03-16 23:02:55: step 1280/50000, loss = 0.165056 (4.039 sec/batch), lr: 0.015625
2019-03-16 23:02:59,079 2019-03-16 23:02:59: step 1281/50000, loss = 0.173156 (3.994 sec/batch), lr: 0.015625
2019-03-16 23:03:03,627 2019-03-16 23:03:03: step 1282/50000, loss = 0.169024 (4.523 sec/batch), lr: 0.015625
2019-03-16 23:03:08,375 2019-03-16 23:03:08: step 1283/50000, loss = 0.168922 (4.720 sec/batch), lr: 0.015625
2019-03-16 23:03:13,455 2019-03-16 23:03:13: step 1284/50000, loss = 0.163226 (5.051 sec/batch), lr: 0.015625
2019-03-16 23:03:18,837 2019-03-16 23:03:18: step 1285/50000, loss = 0.174196 (5.355 sec/batch), lr: 0.015625
2019-03-16 23:03:24,292 2019-03-16 23:03:24: step 1286/50000, loss = 0.173609 (5.425 sec/batch), lr: 0.015625
2019-03-16 23:03:30,289 2019-03-16 23:03:30: step 1287/50000, loss = 0.170515 (5.962 sec/batch), lr: 0.015625
2019-03-16 23:03:36,866 2019-03-16 23:03:36: step 1288/50000, loss = 0.169366 (6.542 sec/batch), lr: 0.015625
2019-03-16 23:03:43,910 2019-03-16 23:03:43: step 1289/50000, loss = 0.175077 (7.009 sec/batch), lr: 0.015625
2019-03-16 23:03:51,362 2019-03-16 23:03:51: step 1290/50000, loss = 0.175577 (7.412 sec/batch), lr: 0.015625
2019-03-16 23:03:59,434 2019-03-16 23:03:59: step 1291/50000, loss = 0.184045 (8.025 sec/batch), lr: 0.015625
2019-03-16 23:04:08,554 2019-03-16 23:04:08: step 1292/50000, loss = 0.180955 (9.071 sec/batch), lr: 0.015625
2019-03-16 23:04:18,633 2019-03-16 23:04:18: step 1293/50000, loss = 0.186675 (10.020 sec/batch), lr: 0.015625
2019-03-16 23:04:29,492 2019-03-16 23:04:29: step 1294/50000, loss = 0.185766 (10.847 sec/batch), lr: 0.015625
2019-03-16 23:04:41,392 2019-03-16 23:04:41: step 1295/50000, loss = 0.191577 (11.829 sec/batch), lr: 0.015625
2019-03-16 23:04:55,403 2019-03-16 23:04:55: step 1296/50000, loss = 0.194726 (13.931 sec/batch), lr: 0.015625
2019-03-16 23:05:12,200 2019-03-16 23:05:12: step 1297/50000, loss = 0.199707 (16.694 sec/batch), lr: 0.015625
2019-03-16 23:05:32,182 2019-03-16 23:05:32: step 1298/50000, loss = 0.196718 (19.871 sec/batch), lr: 0.015625
2019-03-16 23:05:59,638 2019-03-16 23:05:59: step 1299/50000, loss = 0.201589 (27.442 sec/batch), lr: 0.015625
2019-03-16 23:06:33,172 2019-03-16 23:06:33: step 1300/50000, loss = 0.171452 (33.355 sec/batch), lr: 0.015625
2019-03-16 23:07:00,457 step 1300: Full loss = 0.128300, Edge acc. = 0.3459
2019-03-16 23:07:00,458 step 1300: Dev acc. = 0.318371
2019-03-16 23:07:00,600 2019-03-16 23:07:00: step 1301/50000, loss = 0.129358 (0.138 sec/batch), lr: 0.015625
2019-03-16 23:07:00,817 2019-03-16 23:07:00: step 1302/50000, loss = 0.131006 (0.213 sec/batch), lr: 0.015625
2019-03-16 23:07:01,112 2019-03-16 23:07:01: step 1303/50000, loss = 0.192690 (0.291 sec/batch), lr: 0.015625
2019-03-16 23:07:01,525 2019-03-16 23:07:01: step 1304/50000, loss = 0.187584 (0.408 sec/batch), lr: 0.015625
2019-03-16 23:07:02,061 2019-03-16 23:07:02: step 1305/50000, loss = 0.177457 (0.530 sec/batch), lr: 0.015625
2019-03-16 23:07:02,686 2019-03-16 23:07:02: step 1306/50000, loss = 0.169098 (0.619 sec/batch), lr: 0.015625
2019-03-16 23:07:03,441 2019-03-16 23:07:03: step 1307/50000, loss = 0.166671 (0.748 sec/batch), lr: 0.015625
2019-03-16 23:07:04,161 2019-03-16 23:07:04: step 1308/50000, loss = 0.184280 (0.714 sec/batch), lr: 0.015625
2019-03-16 23:07:05,023 2019-03-16 23:07:05: step 1309/50000, loss = 0.163667 (0.855 sec/batch), lr: 0.015625
2019-03-16 23:07:05,950 2019-03-16 23:07:05: step 1310/50000, loss = 0.152783 (0.921 sec/batch), lr: 0.015625
2019-03-16 23:07:06,948 2019-03-16 23:07:06: step 1311/50000, loss = 0.152542 (0.989 sec/batch), lr: 0.015625
2019-03-16 23:07:08,092 2019-03-16 23:07:08: step 1312/50000, loss = 0.149185 (1.135 sec/batch), lr: 0.015625
2019-03-16 23:07:09,401 2019-03-16 23:07:09: step 1313/50000, loss = 0.143364 (1.301 sec/batch), lr: 0.015625
2019-03-16 23:07:10,978 2019-03-16 23:07:10: step 1314/50000, loss = 0.143630 (1.569 sec/batch), lr: 0.015625
2019-03-16 23:07:12,500 2019-03-16 23:07:12: step 1315/50000, loss = 0.153532 (1.513 sec/batch), lr: 0.015625
2019-03-16 23:07:14,330 2019-03-16 23:07:14: step 1316/50000, loss = 0.153338 (1.823 sec/batch), lr: 0.015625
2019-03-16 23:07:16,178 2019-03-16 23:07:16: step 1317/50000, loss = 0.149381 (1.839 sec/batch), lr: 0.015625
2019-03-16 23:07:18,184 2019-03-16 23:07:18: step 1318/50000, loss = 0.157655 (1.994 sec/batch), lr: 0.015625
2019-03-16 23:07:20,290 2019-03-16 23:07:20: step 1319/50000, loss = 0.150327 (2.093 sec/batch), lr: 0.015625
2019-03-16 23:07:22,507 2019-03-16 23:07:22: step 1320/50000, loss = 0.153895 (2.204 sec/batch), lr: 0.015625
2019-03-16 23:07:24,984 2019-03-16 23:07:24: step 1321/50000, loss = 0.161905 (2.462 sec/batch), lr: 0.015625
2019-03-16 23:07:27,680 2019-03-16 23:07:27: step 1322/50000, loss = 0.149001 (2.680 sec/batch), lr: 0.015625
2019-03-16 23:07:30,449 2019-03-16 23:07:30: step 1323/50000, loss = 0.160908 (2.759 sec/batch), lr: 0.015625
2019-03-16 23:07:33,343 2019-03-16 23:07:33: step 1324/50000, loss = 0.152518 (2.879 sec/batch), lr: 0.015625
2019-03-16 23:07:36,326 2019-03-16 23:07:36: step 1325/50000, loss = 0.167522 (2.968 sec/batch), lr: 0.015625
2019-03-16 23:07:39,614 2019-03-16 23:07:39: step 1326/50000, loss = 0.157100 (3.272 sec/batch), lr: 0.015625
2019-03-16 23:07:43,160 2019-03-16 23:07:43: step 1327/50000, loss = 0.155858 (3.528 sec/batch), lr: 0.015625
2019-03-16 23:07:46,576 2019-03-16 23:07:46: step 1328/50000, loss = 0.159671 (3.397 sec/batch), lr: 0.015625
2019-03-16 23:07:50,370 2019-03-16 23:07:50: step 1329/50000, loss = 0.173362 (3.773 sec/batch), lr: 0.015625
2019-03-16 23:07:54,551 2019-03-16 23:07:54: step 1330/50000, loss = 0.165811 (4.173 sec/batch), lr: 0.015625
2019-03-16 23:07:58,840 2019-03-16 23:07:58: step 1331/50000, loss = 0.175941 (4.259 sec/batch), lr: 0.015625
2019-03-16 23:08:03,373 2019-03-16 23:08:03: step 1332/50000, loss = 0.170165 (4.525 sec/batch), lr: 0.015625
2019-03-16 23:08:08,114 2019-03-16 23:08:08: step 1333/50000, loss = 0.172167 (4.734 sec/batch), lr: 0.015625
2019-03-16 23:08:13,136 2019-03-16 23:08:13: step 1334/50000, loss = 0.167442 (4.993 sec/batch), lr: 0.015625
2019-03-16 23:08:18,459 2019-03-16 23:08:18: step 1335/50000, loss = 0.178107 (5.314 sec/batch), lr: 0.015625
2019-03-16 23:08:24,050 2019-03-16 23:08:24: step 1336/50000, loss = 0.176779 (5.560 sec/batch), lr: 0.015625
2019-03-16 23:08:30,067 2019-03-16 23:08:30: step 1337/50000, loss = 0.173459 (5.983 sec/batch), lr: 0.015625
2019-03-16 23:08:36,694 2019-03-16 23:08:36: step 1338/50000, loss = 0.172002 (6.591 sec/batch), lr: 0.015625
2019-03-16 23:08:43,753 2019-03-16 23:08:43: step 1339/50000, loss = 0.177910 (7.048 sec/batch), lr: 0.015625
2019-03-16 23:08:51,256 2019-03-16 23:08:51: step 1340/50000, loss = 0.183221 (7.496 sec/batch), lr: 0.015625
2019-03-16 23:08:59,352 2019-03-16 23:08:59: step 1341/50000, loss = 0.185590 (8.047 sec/batch), lr: 0.015625
2019-03-16 23:09:08,178 2019-03-16 23:09:08: step 1342/50000, loss = 0.182664 (8.779 sec/batch), lr: 0.015625
2019-03-16 23:09:18,078 2019-03-16 23:09:18: step 1343/50000, loss = 0.190945 (9.843 sec/batch), lr: 0.015625
2019-03-16 23:09:29,141 2019-03-16 23:09:29: step 1344/50000, loss = 0.188299 (11.003 sec/batch), lr: 0.015625
2019-03-16 23:09:41,173 2019-03-16 23:09:41: step 1345/50000, loss = 0.192314 (11.959 sec/batch), lr: 0.015625
2019-03-16 23:09:55,334 2019-03-16 23:09:55: step 1346/50000, loss = 0.197513 (14.075 sec/batch), lr: 0.015625
2019-03-16 23:10:12,128 2019-03-16 23:10:12: step 1347/50000, loss = 0.204082 (16.700 sec/batch), lr: 0.015625
2019-03-16 23:10:31,862 2019-03-16 23:10:31: step 1348/50000, loss = 0.200955 (19.626 sec/batch), lr: 0.015625
2019-03-16 23:10:59,454 2019-03-16 23:10:59: step 1349/50000, loss = 0.205346 (27.442 sec/batch), lr: 0.015625
2019-03-16 23:11:32,987 2019-03-16 23:11:32: step 1350/50000, loss = 0.174355 (33.364 sec/batch), lr: 0.015625
2019-03-16 23:12:21,360 2019-03-16 23:12:21: step 1351/50000, loss = 0.170184 (48.125 sec/batch), lr: 0.015625
2019-03-16 23:12:44,417 2019-03-16 23:12:44: step 1352/50000, loss = 0.200479 (22.930 sec/batch), lr: 0.015625
2019-03-16 23:13:02,190 2019-03-16 23:13:02: step 1353/50000, loss = 0.198521 (17.761 sec/batch), lr: 0.015625
2019-03-16 23:13:17,536 2019-03-16 23:13:17: step 1354/50000, loss = 0.205256 (15.335 sec/batch), lr: 0.015625
2019-03-16 23:13:30,002 2019-03-16 23:13:30: step 1355/50000, loss = 0.191542 (12.456 sec/batch), lr: 0.015625
2019-03-16 23:13:41,367 2019-03-16 23:13:41: step 1356/50000, loss = 0.182026 (11.298 sec/batch), lr: 0.015625
2019-03-16 23:13:51,955 2019-03-16 23:13:51: step 1357/50000, loss = 0.196625 (10.530 sec/batch), lr: 0.015625
2019-03-16 23:14:01,738 2019-03-16 23:14:01: step 1358/50000, loss = 0.181899 (9.774 sec/batch), lr: 0.015625
2019-03-16 23:14:10,671 2019-03-16 23:14:10: step 1359/50000, loss = 0.173842 (8.922 sec/batch), lr: 0.015625
2019-03-16 23:14:18,746 2019-03-16 23:14:18: step 1360/50000, loss = 0.178623 (8.029 sec/batch), lr: 0.015625
2019-03-16 23:14:26,046 2019-03-16 23:14:26: step 1361/50000, loss = 0.174813 (7.259 sec/batch), lr: 0.015625
2019-03-16 23:14:32,957 2019-03-16 23:14:32: step 1362/50000, loss = 0.172521 (6.875 sec/batch), lr: 0.015625
2019-03-16 23:14:39,345 2019-03-16 23:14:39: step 1363/50000, loss = 0.170436 (6.380 sec/batch), lr: 0.015625
2019-03-16 23:14:45,375 2019-03-16 23:14:45: step 1364/50000, loss = 0.169716 (6.000 sec/batch), lr: 0.015625
2019-03-16 23:14:50,795 2019-03-16 23:14:50: step 1365/50000, loss = 0.167438 (5.391 sec/batch), lr: 0.015625
2019-03-16 23:14:56,110 2019-03-16 23:14:56: step 1366/50000, loss = 0.178698 (5.287 sec/batch), lr: 0.015625
2019-03-16 23:15:01,093 2019-03-16 23:15:01: step 1367/50000, loss = 0.167186 (4.957 sec/batch), lr: 0.015625
2019-03-16 23:15:05,860 2019-03-16 23:15:05: step 1368/50000, loss = 0.164399 (4.743 sec/batch), lr: 0.015625
2019-03-16 23:15:10,305 2019-03-16 23:15:10: step 1369/50000, loss = 0.162906 (4.416 sec/batch), lr: 0.015625
2019-03-16 23:15:14,588 2019-03-16 23:15:14: step 1370/50000, loss = 0.170628 (4.262 sec/batch), lr: 0.015625
2019-03-16 23:15:18,770 2019-03-16 23:15:18: step 1371/50000, loss = 0.167377 (4.160 sec/batch), lr: 0.015625
2019-03-16 23:15:22,756 2019-03-16 23:15:22: step 1372/50000, loss = 0.157966 (3.957 sec/batch), lr: 0.015625
2019-03-16 23:15:26,500 2019-03-16 23:15:26: step 1373/50000, loss = 0.157457 (3.724 sec/batch), lr: 0.015625
2019-03-16 23:15:29,925 2019-03-16 23:15:29: step 1374/50000, loss = 0.152474 (3.408 sec/batch), lr: 0.015625
2019-03-16 23:15:33,268 2019-03-16 23:15:33: step 1375/50000, loss = 0.151687 (3.325 sec/batch), lr: 0.015625
2019-03-16 23:15:36,166 2019-03-16 23:15:36: step 1376/50000, loss = 0.159213 (2.883 sec/batch), lr: 0.015625
2019-03-16 23:15:39,272 2019-03-16 23:15:39: step 1377/50000, loss = 0.155289 (3.091 sec/batch), lr: 0.015625
2019-03-16 23:15:42,044 2019-03-16 23:15:42: step 1378/50000, loss = 0.156198 (2.758 sec/batch), lr: 0.015625
2019-03-16 23:15:44,654 2019-03-16 23:15:44: step 1379/50000, loss = 0.161321 (2.597 sec/batch), lr: 0.015625
2019-03-16 23:15:47,053 2019-03-16 23:15:47: step 1380/50000, loss = 0.146252 (2.388 sec/batch), lr: 0.015625
2019-03-16 23:15:49,259 2019-03-16 23:15:49: step 1381/50000, loss = 0.149266 (2.195 sec/batch), lr: 0.015625
2019-03-16 23:15:51,358 2019-03-16 23:15:51: step 1382/50000, loss = 0.154678 (2.092 sec/batch), lr: 0.015625
2019-03-16 23:15:53,481 2019-03-16 23:15:53: step 1383/50000, loss = 0.157542 (2.109 sec/batch), lr: 0.015625
2019-03-16 23:15:55,393 2019-03-16 23:15:55: step 1384/50000, loss = 0.154260 (1.901 sec/batch), lr: 0.015625
2019-03-16 23:15:57,246 2019-03-16 23:15:57: step 1385/50000, loss = 0.153514 (1.841 sec/batch), lr: 0.015625
2019-03-16 23:15:58,865 2019-03-16 23:15:58: step 1386/50000, loss = 0.148448 (1.612 sec/batch), lr: 0.015625
2019-03-16 23:16:00,163 2019-03-16 23:16:00: step 1387/50000, loss = 0.153316 (1.291 sec/batch), lr: 0.015625
2019-03-16 23:16:01,429 2019-03-16 23:16:01: step 1388/50000, loss = 0.144233 (1.261 sec/batch), lr: 0.015625
2019-03-16 23:16:02,660 2019-03-16 23:16:02: step 1389/50000, loss = 0.146503 (1.223 sec/batch), lr: 0.015625
2019-03-16 23:16:03,600 2019-03-16 23:16:03: step 1390/50000, loss = 0.148401 (0.934 sec/batch), lr: 0.015625
2019-03-16 23:16:04,460 2019-03-16 23:16:04: step 1391/50000, loss = 0.164178 (0.853 sec/batch), lr: 0.015625
2019-03-16 23:16:05,369 2019-03-16 23:16:05: step 1392/50000, loss = 0.154856 (0.901 sec/batch), lr: 0.015625
2019-03-16 23:16:06,066 2019-03-16 23:16:06: step 1393/50000, loss = 0.166911 (0.692 sec/batch), lr: 0.015625
2019-03-16 23:16:06,623 2019-03-16 23:16:06: step 1394/50000, loss = 0.150301 (0.553 sec/batch), lr: 0.015625
2019-03-16 23:16:07,104 2019-03-16 23:16:07: step 1395/50000, loss = 0.148959 (0.475 sec/batch), lr: 0.015625
2019-03-16 23:16:07,530 2019-03-16 23:16:07: step 1396/50000, loss = 0.122269 (0.422 sec/batch), lr: 0.015625
2019-03-16 23:16:07,869 2019-03-16 23:16:07: step 1397/50000, loss = 0.134305 (0.335 sec/batch), lr: 0.015625
2019-03-16 23:16:08,175 2019-03-16 23:16:08: step 1398/50000, loss = 0.127116 (0.302 sec/batch), lr: 0.015625
2019-03-16 23:16:08,340 2019-03-16 23:16:08: step 1399/50000, loss = 0.072954 (0.160 sec/batch), lr: 0.015625
2019-03-16 23:16:08,446 2019-03-16 23:16:08: step 1400/50000, loss = 0.074659 (0.105 sec/batch), lr: 0.015625
2019-03-16 23:16:35,976 step 1400: Full loss = 0.135403, Edge acc. = 0.3854
2019-03-16 23:16:36,036 step 1400: Dev acc. = 0.427825
2019-03-16 23:17:25,108 2019-03-16 23:17:25: step 1401/50000, loss = 0.237038 (48.849 sec/batch), lr: 0.007812
2019-03-16 23:17:48,920 2019-03-16 23:17:48: step 1402/50000, loss = 0.288325 (23.798 sec/batch), lr: 0.007812
2019-03-16 23:18:07,319 2019-03-16 23:18:07: step 1403/50000, loss = 0.286363 (18.384 sec/batch), lr: 0.007812
2019-03-16 23:18:23,096 2019-03-16 23:18:23: step 1404/50000, loss = 0.282488 (15.689 sec/batch), lr: 0.007812
2019-03-16 23:18:36,127 2019-03-16 23:18:36: step 1405/50000, loss = 0.272995 (12.954 sec/batch), lr: 0.007812
2019-03-16 23:18:47,891 2019-03-16 23:18:47: step 1406/50000, loss = 0.256929 (11.695 sec/batch), lr: 0.007812
2019-03-16 23:18:58,659 2019-03-16 23:18:58: step 1407/50000, loss = 0.260138 (10.709 sec/batch), lr: 0.007812
2019-03-16 23:19:08,545 2019-03-16 23:19:08: step 1408/50000, loss = 0.246604 (9.832 sec/batch), lr: 0.007812
2019-03-16 23:19:17,600 2019-03-16 23:19:17: step 1409/50000, loss = 0.229231 (9.003 sec/batch), lr: 0.007812
2019-03-16 23:19:25,819 2019-03-16 23:19:25: step 1410/50000, loss = 0.234934 (8.173 sec/batch), lr: 0.007812
2019-03-16 23:19:33,121 2019-03-16 23:19:33: step 1411/50000, loss = 0.219861 (7.293 sec/batch), lr: 0.007812
2019-03-16 23:19:40,105 2019-03-16 23:19:40: step 1412/50000, loss = 0.211714 (6.944 sec/batch), lr: 0.007812
2019-03-16 23:19:46,710 2019-03-16 23:19:46: step 1413/50000, loss = 0.207022 (6.595 sec/batch), lr: 0.007812
2019-03-16 23:19:52,808 2019-03-16 23:19:52: step 1414/50000, loss = 0.200057 (6.089 sec/batch), lr: 0.007812
2019-03-16 23:19:58,514 2019-03-16 23:19:58: step 1415/50000, loss = 0.195367 (5.678 sec/batch), lr: 0.007812
2019-03-16 23:20:03,809 2019-03-16 23:20:03: step 1416/50000, loss = 0.196569 (5.262 sec/batch), lr: 0.007812
2019-03-16 23:20:08,720 2019-03-16 23:20:08: step 1417/50000, loss = 0.181854 (4.885 sec/batch), lr: 0.007812
2019-03-16 23:20:13,652 2019-03-16 23:20:13: step 1418/50000, loss = 0.179929 (4.909 sec/batch), lr: 0.007812
2019-03-16 23:20:18,260 2019-03-16 23:20:18: step 1419/50000, loss = 0.171897 (4.583 sec/batch), lr: 0.007812
2019-03-16 23:20:22,614 2019-03-16 23:20:22: step 1420/50000, loss = 0.175545 (4.330 sec/batch), lr: 0.007812
2019-03-16 23:20:26,887 2019-03-16 23:20:26: step 1421/50000, loss = 0.170167 (4.249 sec/batch), lr: 0.007812
2019-03-16 23:20:30,895 2019-03-16 23:20:30: step 1422/50000, loss = 0.157985 (3.985 sec/batch), lr: 0.007812
2019-03-16 23:20:34,608 2019-03-16 23:20:34: step 1423/50000, loss = 0.157452 (3.693 sec/batch), lr: 0.007812
2019-03-16 23:20:38,006 2019-03-16 23:20:38: step 1424/50000, loss = 0.151697 (3.391 sec/batch), lr: 0.007812
2019-03-16 23:20:41,327 2019-03-16 23:20:41: step 1425/50000, loss = 0.150853 (3.304 sec/batch), lr: 0.007812
2019-03-16 23:20:44,350 2019-03-16 23:20:44: step 1426/50000, loss = 0.158681 (3.000 sec/batch), lr: 0.007812
2019-03-16 23:20:47,426 2019-03-16 23:20:47: step 1427/50000, loss = 0.154611 (3.060 sec/batch), lr: 0.007812
2019-03-16 23:20:50,275 2019-03-16 23:20:50: step 1428/50000, loss = 0.155178 (2.840 sec/batch), lr: 0.007812
2019-03-16 23:20:52,839 2019-03-16 23:20:52: step 1429/50000, loss = 0.160716 (2.557 sec/batch), lr: 0.007812
2019-03-16 23:20:55,202 2019-03-16 23:20:55: step 1430/50000, loss = 0.146506 (2.351 sec/batch), lr: 0.007812
2019-03-16 23:20:57,270 2019-03-16 23:20:57: step 1431/50000, loss = 0.148785 (2.057 sec/batch), lr: 0.007812
2019-03-16 23:20:59,280 2019-03-16 23:20:59: step 1432/50000, loss = 0.153881 (2.000 sec/batch), lr: 0.007812
2019-03-16 23:21:01,266 2019-03-16 23:21:01: step 1433/50000, loss = 0.157118 (1.978 sec/batch), lr: 0.007812
2019-03-16 23:21:03,016 2019-03-16 23:21:03: step 1434/50000, loss = 0.154681 (1.742 sec/batch), lr: 0.007812
2019-03-16 23:21:04,624 2019-03-16 23:21:04: step 1435/50000, loss = 0.154092 (1.600 sec/batch), lr: 0.007812
2019-03-16 23:21:06,195 2019-03-16 23:21:06: step 1436/50000, loss = 0.149613 (1.564 sec/batch), lr: 0.007812
2019-03-16 23:21:07,719 2019-03-16 23:21:07: step 1437/50000, loss = 0.153782 (1.513 sec/batch), lr: 0.007812
2019-03-16 23:21:09,151 2019-03-16 23:21:09: step 1438/50000, loss = 0.145610 (1.425 sec/batch), lr: 0.007812
2019-03-16 23:21:10,337 2019-03-16 23:21:10: step 1439/50000, loss = 0.149819 (1.180 sec/batch), lr: 0.007812
2019-03-16 23:21:11,296 2019-03-16 23:21:11: step 1440/50000, loss = 0.152121 (0.954 sec/batch), lr: 0.007812
2019-03-16 23:21:12,149 2019-03-16 23:21:12: step 1441/50000, loss = 0.167072 (0.847 sec/batch), lr: 0.007812
2019-03-16 23:21:12,944 2019-03-16 23:21:12: step 1442/50000, loss = 0.158871 (0.791 sec/batch), lr: 0.007812
2019-03-16 23:21:13,640 2019-03-16 23:21:13: step 1443/50000, loss = 0.175059 (0.691 sec/batch), lr: 0.007812
2019-03-16 23:21:14,208 2019-03-16 23:21:14: step 1444/50000, loss = 0.156184 (0.564 sec/batch), lr: 0.007812
2019-03-16 23:21:14,673 2019-03-16 23:21:14: step 1445/50000, loss = 0.156715 (0.461 sec/batch), lr: 0.007812
2019-03-16 23:21:15,103 2019-03-16 23:21:15: step 1446/50000, loss = 0.125885 (0.426 sec/batch), lr: 0.007812
2019-03-16 23:21:15,445 2019-03-16 23:21:15: step 1447/50000, loss = 0.136648 (0.338 sec/batch), lr: 0.007812
2019-03-16 23:21:15,721 2019-03-16 23:21:15: step 1448/50000, loss = 0.127520 (0.272 sec/batch), lr: 0.007812
2019-03-16 23:21:15,868 2019-03-16 23:21:15: step 1449/50000, loss = 0.070375 (0.145 sec/batch), lr: 0.007812
2019-03-16 23:21:15,958 2019-03-16 23:21:15: step 1450/50000, loss = 0.079955 (0.089 sec/batch), lr: 0.007812
2019-03-16 23:21:16,101 2019-03-16 23:21:16: step 1451/50000, loss = 0.053636 (0.139 sec/batch), lr: 0.007812
2019-03-16 23:21:16,323 2019-03-16 23:21:16: step 1452/50000, loss = 0.099025 (0.218 sec/batch), lr: 0.007812
2019-03-16 23:21:16,617 2019-03-16 23:21:16: step 1453/50000, loss = 0.148178 (0.291 sec/batch), lr: 0.007812
2019-03-16 23:21:16,962 2019-03-16 23:21:16: step 1454/50000, loss = 0.136103 (0.341 sec/batch), lr: 0.007812
2019-03-16 23:21:17,404 2019-03-16 23:21:17: step 1455/50000, loss = 0.138538 (0.438 sec/batch), lr: 0.007812
2019-03-16 23:21:17,947 2019-03-16 23:21:17: step 1456/50000, loss = 0.134956 (0.538 sec/batch), lr: 0.007812
2019-03-16 23:21:18,637 2019-03-16 23:21:18: step 1457/50000, loss = 0.139317 (0.685 sec/batch), lr: 0.007812
2019-03-16 23:21:19,331 2019-03-16 23:21:19: step 1458/50000, loss = 0.161119 (0.690 sec/batch), lr: 0.007812
2019-03-16 23:21:20,177 2019-03-16 23:21:20: step 1459/50000, loss = 0.157905 (0.840 sec/batch), lr: 0.007812
2019-03-16 23:21:21,050 2019-03-16 23:21:21: step 1460/50000, loss = 0.149132 (0.867 sec/batch), lr: 0.007812
2019-03-16 23:21:22,013 2019-03-16 23:21:22: step 1461/50000, loss = 0.151216 (0.957 sec/batch), lr: 0.007812
2019-03-16 23:21:23,061 2019-03-16 23:21:23: step 1462/50000, loss = 0.151564 (1.042 sec/batch), lr: 0.007812
2019-03-16 23:21:24,287 2019-03-16 23:21:24: step 1463/50000, loss = 0.147368 (1.219 sec/batch), lr: 0.007812
2019-03-16 23:21:25,672 2019-03-16 23:21:25: step 1464/50000, loss = 0.148248 (1.377 sec/batch), lr: 0.007812
2019-03-16 23:21:27,135 2019-03-16 23:21:27: step 1465/50000, loss = 0.156959 (1.452 sec/batch), lr: 0.007812
2019-03-16 23:21:29,040 2019-03-16 23:21:29: step 1466/50000, loss = 0.157985 (1.892 sec/batch), lr: 0.007812
2019-03-16 23:21:31,058 2019-03-16 23:21:31: step 1467/50000, loss = 0.153889 (2.007 sec/batch), lr: 0.007812
2019-03-16 23:21:33,214 2019-03-16 23:21:33: step 1468/50000, loss = 0.163859 (2.143 sec/batch), lr: 0.007812
2019-03-16 23:21:35,485 2019-03-16 23:21:35: step 1469/50000, loss = 0.155869 (2.260 sec/batch), lr: 0.007812
2019-03-16 23:21:37,829 2019-03-16 23:21:37: step 1470/50000, loss = 0.158867 (2.332 sec/batch), lr: 0.007812
2019-03-16 23:21:40,462 2019-03-16 23:21:40: step 1471/50000, loss = 0.166280 (2.620 sec/batch), lr: 0.007812
2019-03-16 23:21:43,249 2019-03-16 23:21:43: step 1472/50000, loss = 0.154505 (2.772 sec/batch), lr: 0.007812
2019-03-16 23:21:46,109 2019-03-16 23:21:46: step 1473/50000, loss = 0.166996 (2.840 sec/batch), lr: 0.007812
2019-03-16 23:21:49,278 2019-03-16 23:21:49: step 1474/50000, loss = 0.157196 (3.152 sec/batch), lr: 0.007812
2019-03-16 23:21:52,448 2019-03-16 23:21:52: step 1475/50000, loss = 0.169574 (3.152 sec/batch), lr: 0.007812
2019-03-16 23:21:55,891 2019-03-16 23:21:55: step 1476/50000, loss = 0.161228 (3.425 sec/batch), lr: 0.007812
2019-03-16 23:21:59,541 2019-03-16 23:21:59: step 1477/50000, loss = 0.160145 (3.630 sec/batch), lr: 0.007812
2019-03-16 23:22:03,280 2019-03-16 23:22:03: step 1478/50000, loss = 0.162668 (3.720 sec/batch), lr: 0.007812
2019-03-16 23:22:07,342 2019-03-16 23:22:07: step 1479/50000, loss = 0.176617 (4.038 sec/batch), lr: 0.007812
2019-03-16 23:22:11,487 2019-03-16 23:22:11: step 1480/50000, loss = 0.168250 (4.122 sec/batch), lr: 0.007812
2019-03-16 23:22:15,888 2019-03-16 23:22:15: step 1481/50000, loss = 0.175785 (4.376 sec/batch), lr: 0.007812
2019-03-16 23:22:20,616 2019-03-16 23:22:20: step 1482/50000, loss = 0.171670 (4.701 sec/batch), lr: 0.007812
2019-03-16 23:22:25,663 2019-03-16 23:22:25: step 1483/50000, loss = 0.171110 (5.021 sec/batch), lr: 0.007812
2019-03-16 23:22:30,961 2019-03-16 23:22:30: step 1484/50000, loss = 0.166458 (5.272 sec/batch), lr: 0.007812
2019-03-16 23:22:36,622 2019-03-16 23:22:36: step 1485/50000, loss = 0.176062 (5.630 sec/batch), lr: 0.007812
2019-03-16 23:22:42,386 2019-03-16 23:22:42: step 1486/50000, loss = 0.175575 (5.732 sec/batch), lr: 0.007812
2019-03-16 23:22:48,425 2019-03-16 23:22:48: step 1487/50000, loss = 0.171676 (6.005 sec/batch), lr: 0.007812
2019-03-16 23:22:55,251 2019-03-16 23:22:55: step 1488/50000, loss = 0.169515 (6.816 sec/batch), lr: 0.007812
2019-03-16 23:23:02,581 2019-03-16 23:23:02: step 1489/50000, loss = 0.174336 (7.288 sec/batch), lr: 0.007812
2019-03-16 23:23:10,402 2019-03-16 23:23:10: step 1490/50000, loss = 0.174629 (7.778 sec/batch), lr: 0.007812
2019-03-16 23:23:18,574 2019-03-16 23:23:18: step 1491/50000, loss = 0.180360 (8.119 sec/batch), lr: 0.007812
2019-03-16 23:23:27,691 2019-03-16 23:23:27: step 1492/50000, loss = 0.179842 (9.068 sec/batch), lr: 0.007812
2019-03-16 23:23:37,819 2019-03-16 23:23:37: step 1493/50000, loss = 0.186078 (10.076 sec/batch), lr: 0.007812
2019-03-16 23:23:48,809 2019-03-16 23:23:48: step 1494/50000, loss = 0.185363 (10.928 sec/batch), lr: 0.007812
2019-03-16 23:24:00,965 2019-03-16 23:24:00: step 1495/50000, loss = 0.187214 (12.087 sec/batch), lr: 0.007812
2019-03-16 23:24:15,304 2019-03-16 23:24:15: step 1496/50000, loss = 0.195785 (14.258 sec/batch), lr: 0.007812
2019-03-16 23:24:32,573 2019-03-16 23:24:32: step 1497/50000, loss = 0.200019 (17.169 sec/batch), lr: 0.007812
2019-03-16 23:24:52,754 2019-03-16 23:24:52: step 1498/50000, loss = 0.196022 (20.060 sec/batch), lr: 0.007812
2019-03-16 23:25:20,812 2019-03-16 23:25:20: step 1499/50000, loss = 0.202575 (27.903 sec/batch), lr: 0.007812
2019-03-16 23:25:55,037 2019-03-16 23:25:55: step 1500/50000, loss = 0.173514 (34.057 sec/batch), lr: 0.007812
2019-03-16 23:26:22,874 step 1500: Full loss = 0.119904, Edge acc. = 0.3622
2019-03-16 23:26:22,875 step 1500: Dev acc. = 0.367107
2019-03-16 23:26:23,021 2019-03-16 23:26:23: step 1501/50000, loss = 0.095443 (0.142 sec/batch), lr: 0.007812
2019-03-16 23:26:23,241 2019-03-16 23:26:23: step 1502/50000, loss = 0.116569 (0.216 sec/batch), lr: 0.007812
2019-03-16 23:26:23,543 2019-03-16 23:26:23: step 1503/50000, loss = 0.181873 (0.298 sec/batch), lr: 0.007812
2019-03-16 23:26:23,962 2019-03-16 23:26:23: step 1504/50000, loss = 0.184017 (0.414 sec/batch), lr: 0.007812
2019-03-16 23:26:24,506 2019-03-16 23:26:24: step 1505/50000, loss = 0.181823 (0.537 sec/batch), lr: 0.007812
2019-03-16 23:26:25,108 2019-03-16 23:26:25: step 1506/50000, loss = 0.181078 (0.597 sec/batch), lr: 0.007812
2019-03-16 23:26:25,904 2019-03-16 23:26:25: step 1507/50000, loss = 0.185844 (0.790 sec/batch), lr: 0.007812
2019-03-16 23:26:26,737 2019-03-16 23:26:26: step 1508/50000, loss = 0.210983 (0.826 sec/batch), lr: 0.007812
2019-03-16 23:26:27,713 2019-03-16 23:26:27: step 1509/50000, loss = 0.184766 (0.968 sec/batch), lr: 0.007812
2019-03-16 23:26:28,902 2019-03-16 23:26:28: step 1510/50000, loss = 0.170911 (1.183 sec/batch), lr: 0.007812
2019-03-16 23:26:30,169 2019-03-16 23:26:30: step 1511/50000, loss = 0.172703 (1.257 sec/batch), lr: 0.007812
2019-03-16 23:26:31,604 2019-03-16 23:26:31: step 1512/50000, loss = 0.159866 (1.426 sec/batch), lr: 0.007812
2019-03-16 23:26:33,010 2019-03-16 23:26:33: step 1513/50000, loss = 0.151303 (1.399 sec/batch), lr: 0.007812
2019-03-16 23:26:34,473 2019-03-16 23:26:34: step 1514/50000, loss = 0.147202 (1.453 sec/batch), lr: 0.007812
2019-03-16 23:26:36,007 2019-03-16 23:26:36: step 1515/50000, loss = 0.155610 (1.522 sec/batch), lr: 0.007812
2019-03-16 23:26:37,801 2019-03-16 23:26:37: step 1516/50000, loss = 0.152141 (1.783 sec/batch), lr: 0.007812
2019-03-16 23:26:39,780 2019-03-16 23:26:39: step 1517/50000, loss = 0.147896 (1.969 sec/batch), lr: 0.007812
2019-03-16 23:26:41,639 2019-03-16 23:26:41: step 1518/50000, loss = 0.156094 (1.854 sec/batch), lr: 0.007812
2019-03-16 23:26:43,892 2019-03-16 23:26:43: step 1519/50000, loss = 0.148918 (2.242 sec/batch), lr: 0.007812
2019-03-16 23:26:46,240 2019-03-16 23:26:46: step 1520/50000, loss = 0.151609 (2.335 sec/batch), lr: 0.007812
2019-03-16 23:26:48,864 2019-03-16 23:26:48: step 1521/50000, loss = 0.160357 (2.609 sec/batch), lr: 0.007812
2019-03-16 23:26:51,676 2019-03-16 23:26:51: step 1522/50000, loss = 0.147074 (2.801 sec/batch), lr: 0.007812
2019-03-16 23:26:54,454 2019-03-16 23:26:54: step 1523/50000, loss = 0.158994 (2.770 sec/batch), lr: 0.007812
2019-03-16 23:26:57,533 2019-03-16 23:26:57: step 1524/50000, loss = 0.150210 (3.062 sec/batch), lr: 0.007812
2019-03-16 23:27:00,482 2019-03-16 23:27:00: step 1525/50000, loss = 0.164438 (2.933 sec/batch), lr: 0.007812
2019-03-16 23:27:03,718 2019-03-16 23:27:03: step 1526/50000, loss = 0.155440 (3.217 sec/batch), lr: 0.007812
2019-03-16 23:27:07,356 2019-03-16 23:27:07: step 1527/50000, loss = 0.154290 (3.618 sec/batch), lr: 0.007812
2019-03-16 23:27:11,121 2019-03-16 23:27:11: step 1528/50000, loss = 0.157370 (3.744 sec/batch), lr: 0.007812
2019-03-16 23:27:14,983 2019-03-16 23:27:14: step 1529/50000, loss = 0.172362 (3.853 sec/batch), lr: 0.007812
2019-03-16 23:27:19,273 2019-03-16 23:27:19: step 1530/50000, loss = 0.164381 (4.267 sec/batch), lr: 0.007812
2019-03-16 23:27:23,657 2019-03-16 23:27:23: step 1531/50000, loss = 0.173463 (4.375 sec/batch), lr: 0.007812
2019-03-16 23:27:28,308 2019-03-16 23:27:28: step 1532/50000, loss = 0.168276 (4.642 sec/batch), lr: 0.007812
2019-03-16 23:27:33,302 2019-03-16 23:27:33: step 1533/50000, loss = 0.169245 (4.985 sec/batch), lr: 0.007812
2019-03-16 23:27:38,475 2019-03-16 23:27:38: step 1534/50000, loss = 0.165553 (5.163 sec/batch), lr: 0.007812
2019-03-16 23:27:44,010 2019-03-16 23:27:44: step 1535/50000, loss = 0.175396 (5.527 sec/batch), lr: 0.007812
2019-03-16 23:27:49,787 2019-03-16 23:27:49: step 1536/50000, loss = 0.174899 (5.767 sec/batch), lr: 0.007812
2019-03-16 23:27:55,819 2019-03-16 23:27:55: step 1537/50000, loss = 0.171381 (6.025 sec/batch), lr: 0.007812
2019-03-16 23:28:02,671 2019-03-16 23:28:02: step 1538/50000, loss = 0.170440 (6.814 sec/batch), lr: 0.007812
2019-03-16 23:28:10,017 2019-03-16 23:28:10: step 1539/50000, loss = 0.176437 (7.305 sec/batch), lr: 0.007812
2019-03-16 23:28:17,683 2019-03-16 23:28:17: step 1540/50000, loss = 0.176598 (7.624 sec/batch), lr: 0.007812
2019-03-16 23:28:26,064 2019-03-16 23:28:26: step 1541/50000, loss = 0.187341 (8.327 sec/batch), lr: 0.007812
2019-03-16 23:28:35,312 2019-03-16 23:28:35: step 1542/50000, loss = 0.182873 (9.195 sec/batch), lr: 0.007812
2019-03-16 23:28:45,566 2019-03-16 23:28:45: step 1543/50000, loss = 0.189566 (10.195 sec/batch), lr: 0.007812
2019-03-16 23:28:56,901 2019-03-16 23:28:56: step 1544/50000, loss = 0.188685 (11.266 sec/batch), lr: 0.007812
2019-03-16 23:29:09,201 2019-03-16 23:29:09: step 1545/50000, loss = 0.193337 (12.227 sec/batch), lr: 0.007812
2019-03-16 23:29:23,385 2019-03-16 23:29:23: step 1546/50000, loss = 0.197907 (14.101 sec/batch), lr: 0.007812
2019-03-16 23:29:40,653 2019-03-16 23:29:40: step 1547/50000, loss = 0.207224 (17.173 sec/batch), lr: 0.007812
2019-03-16 23:30:00,908 2019-03-16 23:30:00: step 1548/50000, loss = 0.201811 (20.145 sec/batch), lr: 0.007812
2019-03-16 23:30:29,111 2019-03-16 23:30:29: step 1549/50000, loss = 0.207530 (28.047 sec/batch), lr: 0.007812
2019-03-16 23:31:03,307 2019-03-16 23:31:03: step 1550/50000, loss = 0.177644 (34.013 sec/batch), lr: 0.007812
2019-03-16 23:31:03,481 2019-03-16 23:31:03: step 1551/50000, loss = 0.076093 (0.168 sec/batch), lr: 0.007812
2019-03-16 23:31:03,742 2019-03-16 23:31:03: step 1552/50000, loss = 0.106459 (0.257 sec/batch), lr: 0.007812
2019-03-16 23:31:04,083 2019-03-16 23:31:04: step 1553/50000, loss = 0.163702 (0.336 sec/batch), lr: 0.007812
2019-03-16 23:31:04,517 2019-03-16 23:31:04: step 1554/50000, loss = 0.163410 (0.428 sec/batch), lr: 0.007812
2019-03-16 23:31:05,065 2019-03-16 23:31:05: step 1555/50000, loss = 0.162475 (0.543 sec/batch), lr: 0.007812
2019-03-16 23:31:05,709 2019-03-16 23:31:05: step 1556/50000, loss = 0.162031 (0.638 sec/batch), lr: 0.007812
2019-03-16 23:31:06,503 2019-03-16 23:31:06: step 1557/50000, loss = 0.166478 (0.787 sec/batch), lr: 0.007812
2019-03-16 23:31:07,334 2019-03-16 23:31:07: step 1558/50000, loss = 0.190122 (0.824 sec/batch), lr: 0.007812
2019-03-16 23:31:08,319 2019-03-16 23:31:08: step 1559/50000, loss = 0.169953 (0.978 sec/batch), lr: 0.007812
2019-03-16 23:31:09,411 2019-03-16 23:31:09: step 1560/50000, loss = 0.159276 (1.083 sec/batch), lr: 0.007812
2019-03-16 23:31:10,551 2019-03-16 23:31:10: step 1561/50000, loss = 0.160503 (1.131 sec/batch), lr: 0.007812
2019-03-16 23:31:11,726 2019-03-16 23:31:11: step 1562/50000, loss = 0.152260 (1.168 sec/batch), lr: 0.007812
2019-03-16 23:31:13,070 2019-03-16 23:31:13: step 1563/50000, loss = 0.144368 (1.338 sec/batch), lr: 0.007812
2019-03-16 23:31:14,721 2019-03-16 23:31:14: step 1564/50000, loss = 0.143523 (1.640 sec/batch), lr: 0.007812
2019-03-16 23:31:16,440 2019-03-16 23:31:16: step 1565/50000, loss = 0.153118 (1.707 sec/batch), lr: 0.007812
2019-03-16 23:31:18,363 2019-03-16 23:31:18: step 1566/50000, loss = 0.151695 (1.915 sec/batch), lr: 0.007812
2019-03-16 23:31:20,412 2019-03-16 23:31:20: step 1567/50000, loss = 0.147992 (2.042 sec/batch), lr: 0.007812
2019-03-16 23:31:22,583 2019-03-16 23:31:22: step 1568/50000, loss = 0.156286 (2.157 sec/batch), lr: 0.007812
2019-03-16 23:31:24,833 2019-03-16 23:31:24: step 1569/50000, loss = 0.149199 (2.238 sec/batch), lr: 0.007812
2019-03-16 23:31:27,124 2019-03-16 23:31:27: step 1570/50000, loss = 0.151869 (2.279 sec/batch), lr: 0.007812
2019-03-16 23:31:29,488 2019-03-16 23:31:29: step 1571/50000, loss = 0.160594 (2.350 sec/batch), lr: 0.007812
2019-03-16 23:31:32,152 2019-03-16 23:31:32: step 1572/50000, loss = 0.147362 (2.647 sec/batch), lr: 0.007812
2019-03-16 23:31:34,863 2019-03-16 23:31:34: step 1573/50000, loss = 0.159191 (2.695 sec/batch), lr: 0.007812
2019-03-16 23:31:38,012 2019-03-16 23:31:38: step 1574/50000, loss = 0.150677 (3.131 sec/batch), lr: 0.007812
2019-03-16 23:31:41,211 2019-03-16 23:31:41: step 1575/50000, loss = 0.164798 (3.182 sec/batch), lr: 0.007812
2019-03-16 23:31:44,637 2019-03-16 23:31:44: step 1576/50000, loss = 0.155858 (3.406 sec/batch), lr: 0.007812
2019-03-16 23:31:48,263 2019-03-16 23:31:48: step 1577/50000, loss = 0.154482 (3.607 sec/batch), lr: 0.007812
2019-03-16 23:31:51,940 2019-03-16 23:31:51: step 1578/50000, loss = 0.157741 (3.658 sec/batch), lr: 0.007812
2019-03-16 23:31:56,014 2019-03-16 23:31:56: step 1579/50000, loss = 0.172339 (4.065 sec/batch), lr: 0.007812
2019-03-16 23:32:00,317 2019-03-16 23:32:00: step 1580/50000, loss = 0.164812 (4.279 sec/batch), lr: 0.007812
2019-03-16 23:32:04,741 2019-03-16 23:32:04: step 1581/50000, loss = 0.173880 (4.400 sec/batch), lr: 0.007812
2019-03-16 23:32:09,432 2019-03-16 23:32:09: step 1582/50000, loss = 0.168803 (4.661 sec/batch), lr: 0.007812
2019-03-16 23:32:14,476 2019-03-16 23:32:14: step 1583/50000, loss = 0.169735 (5.015 sec/batch), lr: 0.007812
2019-03-16 23:32:19,948 2019-03-16 23:32:19: step 1584/50000, loss = 0.166305 (5.442 sec/batch), lr: 0.007812
2019-03-16 23:32:25,526 2019-03-16 23:32:25: step 1585/50000, loss = 0.175973 (5.570 sec/batch), lr: 0.007812
2019-03-16 23:32:31,348 2019-03-16 23:32:31: step 1586/50000, loss = 0.175505 (5.789 sec/batch), lr: 0.007812
2019-03-16 23:32:37,479 2019-03-16 23:32:37: step 1587/50000, loss = 0.172996 (6.097 sec/batch), lr: 0.007812
2019-03-16 23:32:44,286 2019-03-16 23:32:44: step 1588/50000, loss = 0.172344 (6.773 sec/batch), lr: 0.007812
2019-03-16 23:32:51,542 2019-03-16 23:32:51: step 1589/50000, loss = 0.176884 (7.246 sec/batch), lr: 0.007812
2019-03-16 23:32:59,384 2019-03-16 23:32:59: step 1590/50000, loss = 0.177248 (7.832 sec/batch), lr: 0.007812
2019-03-16 23:33:07,782 2019-03-16 23:33:07: step 1591/50000, loss = 0.187744 (8.341 sec/batch), lr: 0.007812
2019-03-16 23:33:17,055 2019-03-16 23:33:17: step 1592/50000, loss = 0.183156 (9.219 sec/batch), lr: 0.007812
2019-03-16 23:33:27,304 2019-03-16 23:33:27: step 1593/50000, loss = 0.188802 (10.190 sec/batch), lr: 0.007812
2019-03-16 23:33:38,553 2019-03-16 23:33:38: step 1594/50000, loss = 0.188998 (11.183 sec/batch), lr: 0.007812
2019-03-16 23:33:50,842 2019-03-16 23:33:50: step 1595/50000, loss = 0.193217 (12.217 sec/batch), lr: 0.007812
2019-03-16 23:34:05,286 2019-03-16 23:34:05: step 1596/50000, loss = 0.198321 (14.359 sec/batch), lr: 0.007812
2019-03-16 23:34:22,767 2019-03-16 23:34:22: step 1597/50000, loss = 0.205508 (17.385 sec/batch), lr: 0.007812
2019-03-16 23:34:43,054 2019-03-16 23:34:43: step 1598/50000, loss = 0.199848 (20.175 sec/batch), lr: 0.007812
2019-03-16 23:35:11,523 2019-03-16 23:35:11: step 1599/50000, loss = 0.207168 (28.306 sec/batch), lr: 0.007812
2019-03-16 23:35:45,882 2019-03-16 23:35:45: step 1600/50000, loss = 0.176591 (34.177 sec/batch), lr: 0.007812
2019-03-16 23:36:14,382 step 1600: Full loss = 0.116719, Edge acc. = 0.3615
2019-03-16 23:36:14,383 step 1600: Dev acc. = 0.354176
2019-03-16 23:39:01,435 2019-03-16 23:39:01: step 1601/50000, loss = 0.168486 (166.706 sec/batch), lr: 0.003906
2019-03-16 23:39:26,705 2019-03-16 23:39:26: step 1602/50000, loss = 0.203588 (25.240 sec/batch), lr: 0.003906
2019-03-16 23:39:45,739 2019-03-16 23:39:45: step 1603/50000, loss = 0.207561 (19.019 sec/batch), lr: 0.003906
2019-03-16 23:40:02,105 2019-03-16 23:40:02: step 1604/50000, loss = 0.206774 (16.351 sec/batch), lr: 0.003906
2019-03-16 23:40:19,886 2019-03-16 23:40:19: step 1605/50000, loss = 0.200948 (17.766 sec/batch), lr: 0.003906
2019-03-16 23:40:31,484 2019-03-16 23:40:31: step 1606/50000, loss = 0.190343 (11.529 sec/batch), lr: 0.003906
2019-03-16 23:40:42,105 2019-03-16 23:40:42: step 1607/50000, loss = 0.200760 (10.559 sec/batch), lr: 0.003906
2019-03-16 23:40:51,686 2019-03-16 23:40:51: step 1608/50000, loss = 0.188075 (9.525 sec/batch), lr: 0.003906
2019-03-16 23:41:00,657 2019-03-16 23:41:00: step 1609/50000, loss = 0.181620 (8.924 sec/batch), lr: 0.003906
2019-03-16 23:41:08,703 2019-03-16 23:41:08: step 1610/50000, loss = 0.181284 (8.038 sec/batch), lr: 0.003906
2019-03-16 23:41:16,016 2019-03-16 23:41:16: step 1611/50000, loss = 0.178355 (7.269 sec/batch), lr: 0.003906
2019-03-16 23:41:22,872 2019-03-16 23:41:22: step 1612/50000, loss = 0.174862 (6.817 sec/batch), lr: 0.003906
2019-03-16 23:41:29,292 2019-03-16 23:41:29: step 1613/50000, loss = 0.171496 (6.410 sec/batch), lr: 0.003906
2019-03-16 23:41:35,310 2019-03-16 23:41:35: step 1614/50000, loss = 0.169975 (6.008 sec/batch), lr: 0.003906
2019-03-16 23:41:40,995 2019-03-16 23:41:40: step 1615/50000, loss = 0.167176 (5.654 sec/batch), lr: 0.003906
2019-03-16 23:41:46,202 2019-03-16 23:41:46: step 1616/50000, loss = 0.178611 (5.179 sec/batch), lr: 0.003906
2019-03-16 23:41:51,263 2019-03-16 23:41:51: step 1617/50000, loss = 0.167166 (5.025 sec/batch), lr: 0.003906
2019-03-16 23:41:56,104 2019-03-16 23:41:56: step 1618/50000, loss = 0.163870 (4.816 sec/batch), lr: 0.003906
2019-03-16 23:42:00,724 2019-03-16 23:42:00: step 1619/50000, loss = 0.162323 (4.594 sec/batch), lr: 0.003906
2019-03-16 23:42:05,102 2019-03-16 23:42:05: step 1620/50000, loss = 0.171380 (4.354 sec/batch), lr: 0.003906
2019-03-16 23:42:09,358 2019-03-16 23:42:09: step 1621/50000, loss = 0.167631 (4.232 sec/batch), lr: 0.003906
2019-03-16 23:42:13,348 2019-03-16 23:42:13: step 1622/50000, loss = 0.159136 (3.968 sec/batch), lr: 0.003906
2019-03-16 23:42:17,065 2019-03-16 23:42:17: step 1623/50000, loss = 0.157564 (3.707 sec/batch), lr: 0.003906
2019-03-16 23:42:20,539 2019-03-16 23:42:20: step 1624/50000, loss = 0.153641 (3.455 sec/batch), lr: 0.003906
2019-03-16 23:42:23,948 2019-03-16 23:42:23: step 1625/50000, loss = 0.152983 (3.391 sec/batch), lr: 0.003906
2019-03-16 23:42:27,131 2019-03-16 23:42:27: step 1626/50000, loss = 0.160785 (3.165 sec/batch), lr: 0.003906
2019-03-16 23:42:30,206 2019-03-16 23:42:30: step 1627/50000, loss = 0.155344 (3.057 sec/batch), lr: 0.003906
2019-03-16 23:42:33,076 2019-03-16 23:42:33: step 1628/50000, loss = 0.155849 (2.855 sec/batch), lr: 0.003906
2019-03-16 23:42:35,630 2019-03-16 23:42:35: step 1629/50000, loss = 0.162435 (2.540 sec/batch), lr: 0.003906
2019-03-16 23:42:38,127 2019-03-16 23:42:38: step 1630/50000, loss = 0.148132 (2.479 sec/batch), lr: 0.003906
2019-03-16 23:42:40,405 2019-03-16 23:42:40: step 1631/50000, loss = 0.151096 (2.272 sec/batch), lr: 0.003906
2019-03-16 23:42:42,560 2019-03-16 23:42:42: step 1632/50000, loss = 0.155882 (2.141 sec/batch), lr: 0.003906
2019-03-16 23:42:44,679 2019-03-16 23:42:44: step 1633/50000, loss = 0.159393 (2.111 sec/batch), lr: 0.003906
2019-03-16 23:42:46,600 2019-03-16 23:42:46: step 1634/50000, loss = 0.157344 (1.913 sec/batch), lr: 0.003906
2019-03-16 23:42:48,503 2019-03-16 23:42:48: step 1635/50000, loss = 0.157252 (1.895 sec/batch), lr: 0.003906
2019-03-16 23:42:50,167 2019-03-16 23:42:50: step 1636/50000, loss = 0.152883 (1.653 sec/batch), lr: 0.003906
2019-03-16 23:42:51,679 2019-03-16 23:42:51: step 1637/50000, loss = 0.155726 (1.501 sec/batch), lr: 0.003906
2019-03-16 23:42:53,119 2019-03-16 23:42:53: step 1638/50000, loss = 0.147902 (1.431 sec/batch), lr: 0.003906
2019-03-16 23:42:54,363 2019-03-16 23:42:54: step 1639/50000, loss = 0.154012 (1.235 sec/batch), lr: 0.003906
2019-03-16 23:42:55,471 2019-03-16 23:42:55: step 1640/50000, loss = 0.156541 (1.100 sec/batch), lr: 0.003906
2019-03-16 23:42:56,441 2019-03-16 23:42:56: step 1641/50000, loss = 0.169906 (0.962 sec/batch), lr: 0.003906
2019-03-16 23:42:57,390 2019-03-16 23:42:57: step 1642/50000, loss = 0.161580 (0.940 sec/batch), lr: 0.003906
2019-03-16 23:42:58,198 2019-03-16 23:42:58: step 1643/50000, loss = 0.179812 (0.800 sec/batch), lr: 0.003906
2019-03-16 23:42:58,873 2019-03-16 23:42:58: step 1644/50000, loss = 0.159248 (0.668 sec/batch), lr: 0.003906
2019-03-16 23:42:59,430 2019-03-16 23:42:59: step 1645/50000, loss = 0.157921 (0.551 sec/batch), lr: 0.003906
2019-03-16 23:42:59,946 2019-03-16 23:42:59: step 1646/50000, loss = 0.127417 (0.510 sec/batch), lr: 0.003906
2019-03-16 23:43:00,363 2019-03-16 23:43:00: step 1647/50000, loss = 0.136394 (0.410 sec/batch), lr: 0.003906
2019-03-16 23:43:00,690 2019-03-16 23:43:00: step 1648/50000, loss = 0.127167 (0.322 sec/batch), lr: 0.003906
2019-03-16 23:43:00,895 2019-03-16 23:43:00: step 1649/50000, loss = 0.068374 (0.201 sec/batch), lr: 0.003906
2019-03-16 23:43:01,007 2019-03-16 23:43:01: step 1650/50000, loss = 0.073962 (0.110 sec/batch), lr: 0.003906
2019-03-16 23:43:01,156 2019-03-16 23:43:01: step 1651/50000, loss = 0.051312 (0.144 sec/batch), lr: 0.003906
2019-03-16 23:43:01,370 2019-03-16 23:43:01: step 1652/50000, loss = 0.098473 (0.211 sec/batch), lr: 0.003906
2019-03-16 23:43:01,712 2019-03-16 23:43:01: step 1653/50000, loss = 0.147812 (0.337 sec/batch), lr: 0.003906
2019-03-16 23:43:02,138 2019-03-16 23:43:02: step 1654/50000, loss = 0.137287 (0.421 sec/batch), lr: 0.003906
2019-03-16 23:43:02,679 2019-03-16 23:43:02: step 1655/50000, loss = 0.140755 (0.535 sec/batch), lr: 0.003906
2019-03-16 23:43:03,329 2019-03-16 23:43:03: step 1656/50000, loss = 0.137992 (0.643 sec/batch), lr: 0.003906
2019-03-16 23:43:04,126 2019-03-16 23:43:04: step 1657/50000, loss = 0.142773 (0.789 sec/batch), lr: 0.003906
2019-03-16 23:43:04,951 2019-03-16 23:43:04: step 1658/50000, loss = 0.165238 (0.817 sec/batch), lr: 0.003906
2019-03-16 23:43:05,965 2019-03-16 23:43:05: step 1659/50000, loss = 0.157091 (1.003 sec/batch), lr: 0.003906
2019-03-16 23:43:07,056 2019-03-16 23:43:07: step 1660/50000, loss = 0.149364 (1.082 sec/batch), lr: 0.003906
2019-03-16 23:43:08,227 2019-03-16 23:43:08: step 1661/50000, loss = 0.150523 (1.161 sec/batch), lr: 0.003906
2019-03-16 23:43:09,556 2019-03-16 23:43:09: step 1662/50000, loss = 0.149151 (1.320 sec/batch), lr: 0.003906
2019-03-16 23:43:11,030 2019-03-16 23:43:11: step 1663/50000, loss = 0.143297 (1.463 sec/batch), lr: 0.003906
2019-03-16 23:43:12,486 2019-03-16 23:43:12: step 1664/50000, loss = 0.144543 (1.449 sec/batch), lr: 0.003906
2019-03-16 23:43:14,032 2019-03-16 23:43:14: step 1665/50000, loss = 0.153718 (1.536 sec/batch), lr: 0.003906
2019-03-16 23:43:15,819 2019-03-16 23:43:15: step 1666/50000, loss = 0.153963 (1.778 sec/batch), lr: 0.003906
2019-03-16 23:43:17,746 2019-03-16 23:43:17: step 1667/50000, loss = 0.150203 (1.919 sec/batch), lr: 0.003906
2019-03-16 23:43:19,792 2019-03-16 23:43:19: step 1668/50000, loss = 0.159749 (2.035 sec/batch), lr: 0.003906
2019-03-16 23:43:21,931 2019-03-16 23:43:21: step 1669/50000, loss = 0.152635 (2.129 sec/batch), lr: 0.003906
2019-03-16 23:43:24,246 2019-03-16 23:43:24: step 1670/50000, loss = 0.155490 (2.295 sec/batch), lr: 0.003906
2019-03-16 23:43:26,725 2019-03-16 23:43:26: step 1671/50000, loss = 0.164145 (2.465 sec/batch), lr: 0.003906
2019-03-16 23:43:29,542 2019-03-16 23:43:29: step 1672/50000, loss = 0.152441 (2.801 sec/batch), lr: 0.003906
2019-03-16 23:43:32,412 2019-03-16 23:43:32: step 1673/50000, loss = 0.165180 (2.856 sec/batch), lr: 0.003906
2019-03-16 23:43:35,428 2019-03-16 23:43:35: step 1674/50000, loss = 0.156622 (3.002 sec/batch), lr: 0.003906
2019-03-16 23:43:38,382 2019-03-16 23:43:38: step 1675/50000, loss = 0.169513 (2.940 sec/batch), lr: 0.003906
2019-03-16 23:43:41,789 2019-03-16 23:43:41: step 1676/50000, loss = 0.162033 (3.388 sec/batch), lr: 0.003906
2019-03-16 23:43:45,390 2019-03-16 23:43:45: step 1677/50000, loss = 0.161096 (3.581 sec/batch), lr: 0.003906
2019-03-16 23:43:48,881 2019-03-16 23:43:48: step 1678/50000, loss = 0.164704 (3.473 sec/batch), lr: 0.003906
2019-03-16 23:43:52,803 2019-03-16 23:43:52: step 1679/50000, loss = 0.178435 (3.903 sec/batch), lr: 0.003906
2019-03-16 23:43:57,091 2019-03-16 23:43:57: step 1680/50000, loss = 0.171468 (4.266 sec/batch), lr: 0.003906
2019-03-16 23:44:01,383 2019-03-16 23:44:01: step 1681/50000, loss = 0.179926 (4.271 sec/batch), lr: 0.003906
2019-03-16 23:44:06,899 2019-03-16 23:44:06: step 1682/50000, loss = 0.176474 (5.486 sec/batch), lr: 0.003906
2019-03-16 23:44:13,720 2019-03-16 23:44:13: step 1683/50000, loss = 0.176949 (6.787 sec/batch), lr: 0.003906
2019-03-16 23:44:19,566 2019-03-16 23:44:19: step 1684/50000, loss = 0.173463 (5.801 sec/batch), lr: 0.003906
2019-03-16 23:44:25,569 2019-03-16 23:44:25: step 1685/50000, loss = 0.182678 (5.970 sec/batch), lr: 0.003906
2019-03-16 23:44:31,532 2019-03-16 23:44:31: step 1686/50000, loss = 0.184084 (5.929 sec/batch), lr: 0.003906
2019-03-16 23:44:37,730 2019-03-16 23:44:37: step 1687/50000, loss = 0.180032 (6.162 sec/batch), lr: 0.003906
2019-03-16 23:44:44,688 2019-03-16 23:44:44: step 1688/50000, loss = 0.177166 (6.920 sec/batch), lr: 0.003906
2019-03-16 23:44:52,220 2019-03-16 23:44:52: step 1689/50000, loss = 0.181862 (7.489 sec/batch), lr: 0.003906
2019-03-16 23:45:00,303 2019-03-16 23:45:00: step 1690/50000, loss = 0.185392 (8.036 sec/batch), lr: 0.003906
2019-03-16 23:45:08,861 2019-03-16 23:45:08: step 1691/50000, loss = 0.191249 (8.508 sec/batch), lr: 0.003906
2019-03-16 23:45:18,424 2019-03-16 23:45:18: step 1692/50000, loss = 0.191016 (9.507 sec/batch), lr: 0.003906
2019-03-16 23:45:28,937 2019-03-16 23:45:28: step 1693/50000, loss = 0.195995 (10.452 sec/batch), lr: 0.003906
2019-03-16 23:45:40,621 2019-03-16 23:45:40: step 1694/50000, loss = 0.196986 (11.614 sec/batch), lr: 0.003906
2019-03-16 23:45:53,370 2019-03-16 23:45:53: step 1695/50000, loss = 0.199418 (12.672 sec/batch), lr: 0.003906
2019-03-16 23:46:08,275 2019-03-16 23:46:08: step 1696/50000, loss = 0.204547 (14.815 sec/batch), lr: 0.003906
2019-03-16 23:46:26,224 2019-03-16 23:46:26: step 1697/50000, loss = 0.211108 (17.844 sec/batch), lr: 0.003906
2019-03-16 23:46:49,904 2019-03-16 23:46:49: step 1698/50000, loss = 0.207261 (23.545 sec/batch), lr: 0.003906
2019-03-16 23:48:16,099 2019-03-16 23:48:16: step 1699/50000, loss = 0.213615 (86.025 sec/batch), lr: 0.003906
2019-03-16 23:50:55,608 2019-03-16 23:50:55: step 1700/50000, loss = 0.185302 (159.497 sec/batch), lr: 0.003906
